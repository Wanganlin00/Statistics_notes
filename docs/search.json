[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "医学与生物统计学",
    "section": "",
    "text": "推荐阅读\n\nR语言教程 Ⅶ 统计模型 ——李东风\n统计学习 ISLR\nR语言实战医学统计\nhttps://www.tidymodels.org/\n医学研究中的生存数据建模（4e）\nApplied Propensity Score Analysis with R\nModern Statistics for Modern Biology",
    "crumbs": [
      "推荐阅读"
    ]
  },
  {
    "objectID": "descriptive_statistics.html",
    "href": "descriptive_statistics.html",
    "title": "描述性统计学",
    "section": "",
    "text": "基本概念",
    "crumbs": [
      "描述性统计学"
    ]
  },
  {
    "objectID": "descriptive_statistics.html#基本概念",
    "href": "descriptive_statistics.html#基本概念",
    "title": "描述性统计学",
    "section": "",
    "text": "同质 (Homogeneity)：指数据样本的同质性，即样本中各个个体之间的相似性或一致性。\n变异 (Variation)：指数据样本中各个个体之间的差异性或变化程度。\n总体 (Population)：研究对象的全部个体的集合。描述总体特征的统计学指标称为参数 (Parameter)。\n样本 (Sample)：从总体中抽取的一部分个体。由样本计算出的特征指标称为统计量 (Statistic)。\n变量 (Variable)：随机变量的简称，是研究对象的属性或特征，可以在不同个体之间或同一个体在不同时间上取不同值。\n数据 (Data)：变量的观测值",
    "crumbs": [
      "描述性统计学"
    ]
  },
  {
    "objectID": "descriptive_statistics.html#数据类型及其分布",
    "href": "descriptive_statistics.html#数据类型及其分布",
    "title": "描述性统计学",
    "section": "数据类型及其分布",
    "text": "数据类型及其分布\n定量数据（quantitative data）\n连续型\n\n\n正态分布：t 检验，方差分析，相关性检验\n\n\\[\nf(x)= \\frac{1}{\\sqrt{2πσ^2}} e^{\\frac {−(x−μ) ^2 }{2σ^2 }}\n\\]\n其中，\\(\\mu\\)是均值， \\(\\sigma\\)是标准差\n\nCodelibrary(ggplot2)\nlibrary(tibble)\n# 标准正态分布\nnormal_data &lt;- tibble(x = seq(-5, 5, length.out = 500),\n                      y = dnorm(x, mean = 0, sd = 1))\n\n\nggplot(normal_data, aes(x = x, y = y)) +\n    geom_line() +\n    ggtitle(\"Normal Distribution\")\n\n\n\n\n\n\n\n\n对数正态分布：非参数检验\n指数分布：广义线性模型，对数秩（log-rank ）检验\n\n\\[\nf(x)=λe^{−λx}，x\\ge 0\n\\]\n其中，默认(rate)：\\(\\lambda = 1\\)。\n\nCode# 指数分布\nexponential_data &lt;- tibble(x = seq(0, 3, length.out = 100),\n                           y = dexp(x, rate = 1))\n\n\nggplot(exponential_data, aes(x = x, y = y)) +\n    geom_line() +\n    ggtitle(\"Exponential Distribution\")\n\n\n\n\n\n\n\n\n均匀分布\n离散型\n\n二项分布\n\n\\[\n    P(x)=\\binom{n}{x}p^x(1-p)^{n-x}\n\\]\n\nCode# 二项分布\nbinomial_data &lt;- tibble(x = 0:100, y = dbinom(x, size = 100, prob = 0.5))\n\nggplot(binomial_data, aes(x = x, y = y, color = y)) +\n    geom_bar(stat = \"identity\") +\n    ggtitle(\"Binomial Distribution\")\n\n\n\n\n\n\n\n\n\n负二项分布：DESeq2 差异分析\n\n\\[\n    P(x)=\\frac{\\Gamma(x+n)}{\\Gamma(n)\\ x!}p^n(1-p)^x\n\\]\n其中，均值 \\(\\mu = \\frac{n(1-p)}{p}\\)，方差 \\(\\frac{(1-p)}{p^2}\\)。\n\nCode# 负二项分布\nnegative_binomial_data &lt;- tibble(x = 0:20, y =  dnbinom(x, size = 1, prob = 0.5))\n\nggplot(negative_binomial_data, aes(x = x, y = y)) +\n    geom_bar(stat = \"identity\") +\n    ggtitle(\"Negative Binomial Distribution\")\n\n\n\n\n\n\n\n\n泊松分布\n\n\\[\nP(x)=\\frac{\\lambda^x e^{-\\lambda}}{x!}，E(X)=Var(X)=λ\n\\]\n\nCode# 泊松分布\npoisson_data &lt;- tibble(x = 0:20,\n                       y = dpois(x, lambda = 5))\n\nggplot(poisson_data, aes(x = x, y = y)) +\n    geom_bar(stat = \"identity\") +\n    ggtitle(\"Poisson Distribution\")\n\n\n\n\n\n\n\n\n\n超几何分布：Hypergeometric Distribution，不放回抽样 ， Fisher’s Exact Test\n\n\\[\nP(x)=\\frac{\\binom {m}{x}\\binom{n}{k-x}}{\\binom{m+n}{k}}；x=0，...，k；p=m/(m+n) ；N=m+n\n\\]\n其中，\\(p = \\frac{m}{m+n}\\)，\\(N = m+n\\)，均值 \\(E[X] = \\mu = kp\\)，方差 \\(Var(X) = kp(1-p) \\frac{(m+n-1)}{(m+n-k)}\\)。\n\nCode# 超几何分布\nhypergeometric_data &lt;- tibble(x = -10:10, y = dhyper(x, m = 10,n = 7,k = 8))\n\nggplot(hypergeometric_data, aes(x = x, y = y)) +\n    geom_bar(stat = \"identity\") +\n    ggtitle(\"Hypergeometric Distribution\")\n\n\n\n\n\n\n\n定性数据（qualitative data）\n名义型（nominal）\n有序型（ordered）",
    "crumbs": [
      "描述性统计学"
    ]
  },
  {
    "objectID": "descriptive_statistics.html#数据可视化",
    "href": "descriptive_statistics.html#数据可视化",
    "title": "描述性统计学",
    "section": "数据可视化",
    "text": "数据可视化",
    "crumbs": [
      "描述性统计学"
    ]
  },
  {
    "objectID": "quantitative_data.html",
    "href": "quantitative_data.html",
    "title": "\n1  定量数据的统计描述\n",
    "section": "",
    "text": "1.1 频数分布\nCodelibrary(ggplot2)\nlibrary(tibble)\nggplot(data = mtcars, aes(x = mpg)) +\n    geom_histogram(color = \"black\", bins = 10)\n\n\n\n\n\n\nCode\nggplot(data = mtcars, aes(x = mpg)) +\n    geom_histogram(color = \"black\", binwidth = diff(range(mtcars$mpg)) / 9)",
    "crumbs": [
      "描述性统计学",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>定量数据的统计描述</span>"
    ]
  },
  {
    "objectID": "quantitative_data.html#频数分布",
    "href": "quantitative_data.html#频数分布",
    "title": "\n1  定量数据的统计描述\n",
    "section": "",
    "text": "极差(Range) : \\(R=X_{max}-X_{min}\\)\n组数 (Number of Bins) \\(k\\) : 通常选择 \\(8\\) 到 \\(15\\) 之间的值。\n组距 (Bin Width) : \\(interval=\\frac{R}{k}\\)\n频数 (Frequency) : \\(Frequency = count\\)\n频率 (Relative Frequency)： \\(Relative\\ Frequency = \\frac{count}{n} \\times 100\\%\\)",
    "crumbs": [
      "描述性统计学",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>定量数据的统计描述</span>"
    ]
  },
  {
    "objectID": "quantitative_data.html#集中趋势central-tendency",
    "href": "quantitative_data.html#集中趋势central-tendency",
    "title": "\n1  定量数据的统计描述\n",
    "section": "\n1.2 集中趋势（central tendency）",
    "text": "1.2 集中趋势（central tendency）\n\nCode#算术均数\nmean(mtcars$mpg)     \n#&gt; [1] 20.09062\n\n# 截尾均数\nx &lt;- c(1,2:9,11)\nmean(x)\n#&gt; [1] 5.6\n\nmean(x,trim = 0.1)\n#&gt; [1] 5.5\n#中位数\nmedian(mtcars$mpg)   \n#&gt; [1] 19.2\n\n#众数 mode \nrstatix::get_mode(mtcars$mpg)\n#&gt; [1] 10.4 15.2 19.2 21.0 21.4 22.8 30.4\n\n\n注意：函数rstatix::get_mode() 可能返回多个众数，如果存在多个众数，请检查其处理方式。",
    "crumbs": [
      "描述性统计学",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>定量数据的统计描述</span>"
    ]
  },
  {
    "objectID": "quantitative_data.html#离散趋势dispersion-tendency",
    "href": "quantitative_data.html#离散趋势dispersion-tendency",
    "title": "\n1  定量数据的统计描述\n",
    "section": "\n1.3 离散趋势（dispersion tendency）",
    "text": "1.3 离散趋势（dispersion tendency）\n\nCode# 值域\nrange(mtcars$mpg)  \n#&gt; [1] 10.4 33.9\n# 极差 or 全距\ndiff(range(mtcars$mpg) )  \n#&gt; [1] 23.5\n\n# 分位数\nquantile(mtcars$mpg,probs = c(0,0.1,0.25,0.5,0.75,1))    \n#&gt;     0%    10%    25%    50%    75%   100% \n#&gt; 10.400 14.340 15.425 19.200 22.800 33.900\n# 四分位数间距\nIQR(mtcars$mpg)     \n#&gt; [1] 7.375\n\n# 方差 variance\nvar(mtcars$mpg)       \n#&gt; [1] 36.3241\n\n# 标准差 standard deviation\nsd(mtcars$mpg)       \n#&gt; [1] 6.026948\n\n\n# 变异系数 Coefficient of Variation\nCV &lt;- function(x, na.rm = TRUE) {  \n    if (na.rm) x &lt;- x[!is.na(x)]\n    CV = sd(x) / mean(x) * 100\n    sprintf(\"%.6f%%\", CV)\n}\nCV(mtcars$mpg)\n#&gt; [1] \"29.998808%\"\n\n\n# 绝对中位差 median absolute deviation\nmad(mtcars$mpg,constant = 1.4826)\n#&gt; [1] 5.41149\nmedian(abs(mtcars$mpg-median(mtcars$mpg)))\n#&gt; [1] 3.65\nmedian(abs(mtcars$mpg-median(mtcars$mpg)))*1.4826\n#&gt; [1] 5.41149\n\n\n说明：mad() 计算时乘以比例因子 constant = 1.4826 以实现渐进正态一致性。",
    "crumbs": [
      "描述性统计学",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>定量数据的统计描述</span>"
    ]
  },
  {
    "objectID": "quantitative_data.html#分布形态",
    "href": "quantitative_data.html#分布形态",
    "title": "\n1  定量数据的统计描述\n",
    "section": "\n1.4 分布形态",
    "text": "1.4 分布形态\n\n1.4.1 偏度系数\n\n1.4.1.1 总体偏度（Population Skewness）\n表示随机变量概率分布的不对称性。\nhttps://www.macroption.com/skewness-formula/\n三阶中心矩。二阶中心矩即方差。\n\\[\nPopulation\\ Skewness (X) =  \\frac{E(X_i-E(X))^3}{Var(X)^{\\frac{3}{2}}} =E  [(\\frac{X_i-\\mu}{\\sigma})^3]= \\frac{1}{n} \\sum_{i=1}^{n}  (\\frac{X_i-\\mu}{\\sigma} )^3\n\\]\n偏度的取值范围： \\((-\\infty,+\\infty)\\)\n\nSkew＞0，正偏态分布，右偏 = 尾部向右延伸。Mode &lt; Median &lt; Mean；\nSkew=0，数据相对均匀的分布在均值两侧；\nSkew＜0，负偏态分布，左偏 = 尾部向左延伸；Mode &gt; Median &gt; Mean。\n\n\nCodex &lt;- c(1,2,3,5)\ns &lt;- psych::describeBy(x=x,group = NULL)\ns$skew\n#&gt; [1] 0.2823139\n\nskewness &lt;- function(x,na.rm=TRUE){\n    if(na.rm) x &lt;- x[!is.na(x)]\n    n=length(x)\n    μ=mean(x)\n    SD=sd(x)\n    sknewness = mean(((x-μ)/SD)^3)\n    return(sknewness=sknewness)\n}\nskewness(x)\n#&gt; [1] 0.2823139\n\ne1071::skewness(x)\n#&gt; [1] 0.2823139\n\n\n\n1.4.1.2 样本偏度（Sample Skewness）\n\\[\nSample\\ Skewness(X) =  \\frac{n}{(n-1)(n-2)} \\sum_{i=1}^{n}  \\left [\\frac{X_i-\\bar X}{S} \\right ]^3\n\\]\n\n\n\n\n\n1.4.2 峰度系数\n\n1.4.2.1 总体峰度（Population Kurtosis）\n表示随机变量概率分布的尖峭程度。四阶中心矩与方差平方的比值。\nhttps://www.macroption.com/kurtosis-formula/\n超额峰度 excess kurtosis ：四阶中心矩与方差平方的比值减3。\nhttps://www.macroption.com/excess-kurtosis/\n\\[\nPopulation\\ Kurtosis(X) =  \\frac{E(X_i-E(X))^4}{Var(X)^{2}}-3= E  [(\\frac{X_i-\\mu}{\\sigma})^4] - 3= \\frac{1}{n} \\sum_{i=1}^{n}  (\\frac{X_i-\\mu}{\\sigma} )^4-3\n\\]\n超额峰度的取值范围：\\([-2,+\\infty)\\)\n\n超额峰度＜0，数据分布与正态分布相比较为扁平；\n超额峰度=0，正态分布；\n超额峰度＞0，数据分布与正态分布相比较为高尖。\n\n\nCodes$kurtosis\n#&gt; [1] -1.961786\n\nkurtosis&lt;-function(x,na.rm=TRUE){\n    if(na.rm) x&lt;-x[!is.na(x)]\n    n=length(x)\n    μ=mean(x)\n    SD=sd(x)\n    kurtosis= mean(((x-μ)/SD)^4)-3\n    return(kurtosis=kurtosis)\n}\nkurtosis(x)\n#&gt; [1] -1.961786\ne1071::kurtosis(x)\n#&gt; [1] -1.961786\n\n\n\n1.4.2.2 样本峰度（Sample Kurtosis）\n\\[\nSample \\ Kurtosis(X) =   \\frac{n(n+1)}{(n-1)(n-2)(n-3)} \\sum_{i=1}^{n} \\left [\\frac{X_i-\\bar X}{S} \\right]^4-\\frac{3(n-1)^2}{(n-2)(n-3)}\n\\]",
    "crumbs": [
      "描述性统计学",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>定量数据的统计描述</span>"
    ]
  },
  {
    "objectID": "quantitative_data.html#标准化变换",
    "href": "quantitative_data.html#标准化变换",
    "title": "\n1  定量数据的统计描述\n",
    "section": "\n1.5 标准化变换",
    "text": "1.5 标准化变换\n\nCodescale(mtcars$mpg,center = T,scale = T) %&gt;%  tibble(normalization = .) %&gt;% \n    DT::datatable()",
    "crumbs": [
      "描述性统计学",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>定量数据的统计描述</span>"
    ]
  },
  {
    "objectID": "quantitative_data.html#统计摘要",
    "href": "quantitative_data.html#统计摘要",
    "title": "\n1  定量数据的统计描述\n",
    "section": "\n1.6 统计摘要",
    "text": "1.6 统计摘要\n\nCodesummary(mtcars$mpg)\n#&gt;    Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n#&gt;   10.40   15.43   19.20   20.09   22.80   33.90\nrstatix::get_summary_stats(mtcars,mpg,type = \"full\")\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nvariable\nn\nmin\nmax\nmedian\nq1\nq3\niqr\nmad\nmean\nsd\nse\nci\n\n\nmpg\n32\n10.4\n33.9\n19.2\n15.425\n22.8\n7.375\n5.411\n20.091\n6.027\n1.065\n2.173\n\n\n\n\nCode\n\npsych::describeBy(mtcars$mpg,group =NULL)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nvars\nn\nmean\nsd\nmedian\ntrimmed\nmad\nmin\nmax\nrange\nskew\nkurtosis\nse\n\n\nX1\n1\n32\n20.09062\n6.026948\n19.2\n19.69615\n5.41149\n10.4\n33.9\n23.5\n0.610655\n-0.372766\n1.065424",
    "crumbs": [
      "描述性统计学",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>定量数据的统计描述</span>"
    ]
  },
  {
    "objectID": "qualitative_data.html",
    "href": "qualitative_data.html",
    "title": "\n2  定性数据的统计描述\n",
    "section": "",
    "text": "2.0.1 率\n率（rate）表示在一定空间或时间范围内某现象的发生数与可能发生的总数之比，说明某现象出现的频率。\n标准化率（standardized rate）",
    "crumbs": [
      "描述性统计学",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>定性数据的统计描述</span>"
    ]
  },
  {
    "objectID": "qualitative_data.html#构成比",
    "href": "qualitative_data.html#构成比",
    "title": "\n2  定性数据的统计描述\n",
    "section": "\n2.1 构成比",
    "text": "2.1 构成比\n构成比（proportion）",
    "crumbs": [
      "描述性统计学",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>定性数据的统计描述</span>"
    ]
  },
  {
    "objectID": "qualitative_data.html#相对比",
    "href": "qualitative_data.html#相对比",
    "title": "\n2  定性数据的统计描述\n",
    "section": "\n2.2 相对比",
    "text": "2.2 相对比\n相对比（relative ratio）是A和B两个有关联指标值之比。\nUsing R for Biomedical Statistics\n\n\n相对危险度 （Relative Risk，RR），是指暴露组人群的发病率与非暴露组人群的发病率之比。RR 用于反映暴露因素与结局事件的关联程度， 其 取值范围为 0 到无穷大。数值为 1 时，表明暴露因素与结局事件无关联；小于 1 时，表 明暴露因素导致结局事件的发生率降低；大于 1 时，表明暴露因素导致结局事件的发生率增加。相对风险适用于前瞻性队列研究。\n\nCodex &lt;- matrix(c(156,9421,1531,14797),nrow=2,byrow=TRUE,\n             dimnames = list(c(\"Exposed\",\"Unexposed\"),c(\"Disease\",\"Control\")))\n\nx\n#&gt;           Disease Control\n#&gt; Exposed       156    9421\n#&gt; Unexposed    1531   14797\n# RR\n156/(156+9421)*(1531+14797)/1531\n#&gt; [1] 0.1737212\nsource(\"function/calcRelativeRisk.R\")\ncalcRelativeRisk(x,alpha=0.05)\n#&gt; [1] \"category = Exposed , relative risk =  0.173721236521721\"\n#&gt; [1] \"category = Exposed ,  95 % confidence interval = [ 0.147624440337197 , 0.204431379720742 ]\"\n\n# OR\n156/9421/(1531/14797)\n#&gt; [1] 0.1600391\nsource(\"function/calcOddsRatio.R\")\ncalcOddsRatio(x,alpha = 0.05)\n#&gt; [1] \"category = Exposed , odds ratio =  0.160039091621751\"\n#&gt; [1] \"category = Exposed ,  95 % confidence interval = [ 0.135460641900536 , 0.189077140693912 ]\"\n\n\n\n\n优势比（Odds Ratio，OR），是指暴露组中病例与非病例人数的比值除以非暴露组中病例与非病例人数的比值。　　OR 的取值范围也为 0 到无穷大。如果 OR 值大于 1 ，说明该暴露因素更 容易导致结果事件发生，或者说该因素是一个危险因素；小于 1 ，则说明该暴露因素更不 容易导致结果事件发生，或者说该因素是一个保护因素。比值比适用于队列研究和病例对照研究。\n\nCodey &lt;- matrix(c(30,24,76,241,82,509),nrow=3,byrow=TRUE,\n            dimnames = list(c(\"Exposure1\",\"Exposure2\",\"Unexposed\"),\n                            c(\"Disease\",\"Control\")))\ny\n#&gt;           Disease Control\n#&gt; Exposure1      30      24\n#&gt; Exposure2      76     241\n#&gt; Unexposed      82     509\ncalcOddsRatio(y, referencerow=3)\n#&gt; [1] \"category = Exposure1 , odds ratio =  7.75914634146342\"\n#&gt; [1] \"category = Exposure1 ,  95 % confidence interval = [ 4.32163714854064 , 13.9309131884372 ]\"\n#&gt; [1] \"category = Exposure2 , odds ratio =  1.95749418075094\"\n#&gt; [1] \"category = Exposure2 ,  95 % confidence interval = [ 1.38263094540732 , 2.77137111707344 ]\"\ncalcRelativeRisk(y, referencerow=3)\n#&gt; [1] \"category = Exposure1 , relative risk =  4.00406504065041\"\n#&gt; [1] \"category = Exposure1 ,  95 % confidence interval = [ 2.93130744422409 , 5.46941498113737 ]\"\n#&gt; [1] \"category = Exposure2 , relative risk =  1.72793721628068\"\n#&gt; [1] \"category = Exposure2 ,  95 % confidence interval = [ 1.30507489771431 , 2.2878127750653 ]\"",
    "crumbs": [
      "描述性统计学",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>定性数据的统计描述</span>"
    ]
  },
  {
    "objectID": "qualitative_data.html#列联表",
    "href": "qualitative_data.html#列联表",
    "title": "\n2  定性数据的统计描述\n",
    "section": "\n2.3 列联表",
    "text": "2.3 列联表\n\nCodeeg &lt;- matrix(c(156,9421,1531,14797),nrow=2,byrow=TRUE)\ncolnames(eg) &lt;- c(\"Disease\",\"Control\")\nrownames(eg) &lt;- c(\"Exposed\",\"Unexposed\")\nprint(eg)\n#&gt;           Disease Control\n#&gt; Exposed       156    9421\n#&gt; Unexposed    1531   14797\nprop.table(eg)          #各单元格比例\n#&gt;               Disease   Control\n#&gt; Exposed   0.006022003 0.3636750\n#&gt; Unexposed 0.059100560 0.5712025\nprop.table(eg,margin = 1)        #行比例 \n#&gt;              Disease   Control\n#&gt; Exposed   0.01628903 0.9837110\n#&gt; Unexposed 0.09376531 0.9062347",
    "crumbs": [
      "描述性统计学",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>定性数据的统计描述</span>"
    ]
  },
  {
    "objectID": "qualitative_data.html#边际列联表",
    "href": "qualitative_data.html#边际列联表",
    "title": "\n2  定性数据的统计描述\n",
    "section": "\n2.4 边际列联表",
    "text": "2.4 边际列联表\n\nCode# 边际\nmargin.table(x=eg,margin = 2)      #列和\n#&gt; Disease Control \n#&gt;    1687   24218\naddmargins(eg)          #添加行和、列和\n#&gt;           Disease Control   Sum\n#&gt; Exposed       156    9421  9577\n#&gt; Unexposed    1531   14797 16328\n#&gt; Sum          1687   24218 25905\naddmargins(eg,1)        #添加列和\n#&gt;           Disease Control\n#&gt; Exposed       156    9421\n#&gt; Unexposed    1531   14797\n#&gt; Sum          1687   24218\naddmargins(eg,2)        #添加行和\n#&gt;           Disease Control   Sum\n#&gt; Exposed       156    9421  9577\n#&gt; Unexposed    1531   14797 16328\naddmargins(prop.table(eg,1))\n#&gt;              Disease   Control Sum\n#&gt; Exposed   0.01628903 0.9837110   1\n#&gt; Unexposed 0.09376531 0.9062347   1\n#&gt; Sum       0.11005434 1.8899457   2\n\nftable(eg)   # \"平铺式\"列联表\n#&gt;            Disease Control\n#&gt;                           \n#&gt; Exposed        156    9421\n#&gt; Unexposed     1531   14797",
    "crumbs": [
      "描述性统计学",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>定性数据的统计描述</span>"
    ]
  },
  {
    "objectID": "qualitative_data.html#混淆矩阵",
    "href": "qualitative_data.html#混淆矩阵",
    "title": "\n2  定性数据的统计描述\n",
    "section": "\n2.5 混淆矩阵",
    "text": "2.5 混淆矩阵",
    "crumbs": [
      "描述性统计学",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>定性数据的统计描述</span>"
    ]
  },
  {
    "objectID": "probability_theory.html",
    "href": "probability_theory.html",
    "title": "\n3  概率论基础\n",
    "section": "",
    "text": "3.1 古典概率\n样本点（sample point）是每一次随机试验的结果，用 \\(\\omega\\) 表示。\nCode# 假设随机试验是抛掷硬币\nw1 &lt;- \"正面\"\nw2 &lt;- \"反面\"\n样本空间（sample space）是所有样本点的集合，用\\(\\Omega=\\{\\omega_{i};i=0,1,2,... \\}\\)表示。\nCodespace&lt;- c(w1=w1,w2=w2)\nspace\n#&gt;     w1     w2 \n#&gt; \"正面\" \"反面\"\n随机事件（random event）是样本空间中满足一定条件的子集（\\(\\Omega\\)的子集），用大写字母 \\(A,B,C,...\\)表示。\n一个样本点的集合称为简单事件（simple event），用 \\(\\Omega=\\{\\omega\\}\\) 表示。\n若干个简单事件的集合称为混合事件（composite event）。\n全集 \\(\\Omega\\) 称为必然事件（deterministic event）。\n空集（null set） \\(\\emptyset\\) 称为不可能事件（impossible event）。",
    "crumbs": [
      "概率论与数理统计",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>概率论基础</span>"
    ]
  },
  {
    "objectID": "probability_theory.html#古典概率",
    "href": "probability_theory.html#古典概率",
    "title": "\n3  概率论基础\n",
    "section": "",
    "text": "3.1.1 事件的运算\n\n\n包含关系（containment） ：Venn diagram\n\n\\(A\\subseteq B\\)\n\\(A\\supseteq B\\)\n\n\n并集（\\(A\\cup B\\)）\n交集（\\(A\\cap B\\)，\\(AB\\) ）\n补集（\\(\\bar A\\)）\n互斥事件 \\(A\\cap B=\\emptyset\\)\n对立（互补）事件 \\(A\\cap B=\\emptyset\\) 且 \\(A\\cup B=\\Omega\\)\n\n3.1.2 排列组合\n组合（combination）：\\(C_n^k =\\binom{n}{k} =\\frac {n!}{k!(n-k)!}\\)\n\nCodechoose(5,3)\n#&gt; [1] 10\n\n\n排列（permutation）：\\(P_n^k =k!\\binom{n}{k} =\\frac {n!}{(n-k)!}\\)\n\n3.1.3 概率的运算法则\n加法定理\n\\[\nP(A\\cup B)=P(A)+P(B)-P(A\\cap B)\n\\]\n条件概率 conditional probability\n\\[\nP(B|A)=\\frac{P(AB)}{P(A)}\n\\]\n推出乘法定理 \\(P(A B)=P(A)\\times P(B|A)\\)\n独立性（积的概率等于各自概率的积）\n\\[\nP(B|A)=P(B) \\ 或者\\  P(A)=0\\\\\nP(AB)=P(A) \\times P(B)\n\\]\n\n3.1.4 全概率公式\n（给定Ai发生，B的加权平均条件概率）\n\\[P(B)=\\sum_{i=1}^{n}P(A_i)P(B|A_i)\\]\n\n3.1.5 贝叶斯公式\n条件概率定义与全概率公式的推论\n逆概率公式（后验概率）\n\\[P(A_k |B)=\\frac{P(A_k)P(B|A_k)}{\\sum_{i=1}^{n}P(A_i)P(B|A_i)}\\]",
    "crumbs": [
      "概率论与数理统计",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>概率论基础</span>"
    ]
  },
  {
    "objectID": "probability_theory.html#离散型随机变量",
    "href": "probability_theory.html#离散型随机变量",
    "title": "\n3  概率论基础\n",
    "section": "\n3.2 离散型随机变量",
    "text": "3.2 离散型随机变量\n离散型随机变量的全部可能取值只有有限多个或可列无穷多个。\n离散型随机变量的概率分布列：\n\\[P(X=x_k)=p_k \\ ,\\ \\  (k=1,2,…)\\]\n累计分布函数：\n\\[F(x) =P(X≤x)= \\sum_{x_k≤x}p_k\\]\n随机变量的数学期望或均值：\n\\[E(X)=\\sum_{k}x_k p_k\\ ,\\ \\ (k=1,2,...)\\]\n方差：\n\\[Var(X)=\\sum_{k}(x_k-\\mu)^2 p_k\\]\n\n3.2.1 二项分布\n二项试验\n\\[\nX\\sim B(n,\\pi)\n\\]\n概率质量函数（pmf）：\n\\[P(X=k)=p_k=C_n^k\\pi^k(1-\\pi)^{n-k} \\ ，\\ \\ (k=0,1,...,n)\\]\n其中n表示独立试验的次数，\\(\\pi\\) 表示成功概率。\n累计概率：至多k0次成功的概率\n\\[F(X)=P(X≤k_0)=\\sum_{k=0}^{k_0} p_k\\]\n至少k0次成功的概率\n\\[P(X≥k_0)=\\sum_{k=k_0}^{n} p_k\\]\n期望：\\(E(X)=n\\pi\\)\n方差：\\(Var(X)=n\\pi(1-\\pi)\\)\n\nCodebinom &lt;- function(n,p){\n    ggplot() +\n        geom_line(data.frame(x = 0:n, \n                      y = dbinom(0:n, size = n, prob = p)), \n           mapping=aes(x = x, y = y),\n           color=\"red\")+\n        geom_line(data.frame(x = 0:n, \n                      y = pbinom(0:n, size = n, prob = p)), \n           mapping=aes(x = x, y = y),\n           color=\"blue\")\n}\n\nbinom(30,0.5)\n\n\n\n\n\n\n\n\n3.2.2 超几何分布\n概率分布律：\n\\[P(X=k)=p_k=\\frac {\\binom{r}{k}\\binom{N-r}{n-k}}{\\binom{N}{n}} \\ ，\\ \\ (k=0,1,...,r)\\]\nr为N中表示合格的元素个数，N-r表示不合格的元素个数，超几何分布考虑在n次无放回的试验中，k个合格n-k个不合格的概率。\n期望：\\(E(X)=\\frac{nr}{N}\\)\n\n3.2.3 多项式分布\n概率：\\(P(X_1=n_1,...,X_i=n_i,...,X_k=n_k)=\\frac {n!}{n_1!...n_i!...n_k!}\\pi_1^{n_1}...\\pi_i^{n_i}...\\pi_k^{n_k}\\)\n\\[\nX \\sim M(n,\\pi_1,\\pi_2,...,\\pi_k)\n\\]\n其中\\(n=n_1+n_2+...+n_k\\) 表示独立试验的次数，\\(\\pi_k\\) 表示\\(k\\) 个互斥结果的成功概率。\n期望(\\(A_i 与 -A_i\\))：\\(\\mu_{A_i}=n\\pi_{A_i}\\)\n方差(\\(A_i 与 -A_i\\))：\\(\\sigma_{A_i}^2=n\\pi_{A_i}(1-\\pi_{A_i})\\)\n\n3.2.4 泊松分布\n特定时间段或某空间段内事件发生的次数\n\\[\nX\\sim P(\\lambda)\n\\] 概率分布列：\n\\[P(X=k)=p_k=\\frac {\\lambda ^k}{k!}e^{-\\lambda} \\ ,\\ \\ (\\lambda &gt; 0;k=0,1,…)\\]\n其中\\(\\lambda\\) 表示单位时间/空间罕见事件发生的期望值。\n期望：\\(\\mu=\\lambda\\)\n方差：\\(Var(X)=\\lambda\\)\n\n3.2.4.1 二项分布近似泊松分布\n当\\(n(n≥100)\\)足够大，\\(\\pi(\\pi ≤0.01)\\) 足够小，二项分布的均值 \\(n\\pi\\) 与方差\\(n\\pi(1-\\pi)\\approx n\\pi\\) 近似相等，此时的二项分布近似\\(\\lambda=n\\pi\\) 的泊松分布。\n\\[\nP(X=k)=C_n^k \\pi^k(1-\\pi)^{n-k} \\approx \\frac{\\lambda ^k}{k!}e^{-\\lambda}\n\\]",
    "crumbs": [
      "概率论与数理统计",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>概率论基础</span>"
    ]
  },
  {
    "objectID": "probability_theory.html#连续型随机变量",
    "href": "probability_theory.html#连续型随机变量",
    "title": "\n3  概率论基础\n",
    "section": "\n3.3 连续型随机变量",
    "text": "3.3 连续型随机变量\n对于随机变量X，如果存在一个定义在（-∞，+∞）上的非负函数f(x)，使得对于任意实数x，总有：累计分布函数（cdf）：\n\\[F(x)=P(X≤x)=\\int_{-\\infty}^{x}f(t)dt\\]\n概率：\\(P(a≤X≤b)=\\int_{a}^{b}f(x)dx\\)\n概率密度函数（pdf）：\\(f(x)\\)\n期望：\\(E(X)\\equiv\\mu =\\int_{-\\infty}^{+\\infty}xf(x)dx\\)\n方差：\\(Var(X)\\equiv \\int_{-\\infty}^{+\\infty}(x-\\mu)^2f(x)dx\\)\n\n3.3.1 正态分布\n概率密度函数（pdf）：\\(f(x)=\\frac {1}{\\sigma\\sqrt{2\\pi}}e^{-\\frac{(x-\\mu)^2}{2\\sigma^2}}（-\\infty ＜x ＜+\\infty）\\)\n累计分布函数（cdf）:\\(F(x)=P(X≤x)=\\int_{-\\infty}^{x}f(t)dt=\\frac{1}{\\sqrt{2\\pi}\\sigma}\\int_{-\\infty}^{x}e^{-\\frac{(t-\\mu)^2}{2\\sigma^2}}dt\\ (-\\infty＜x＜+\\infty)\\)\n\\[\nX \\sim N(\\mu,\\sigma^2)\n\\]\n\n3.3.2 标准正态分布\n\\[\nZ=\\frac {X-\\mu}{\\sigma} \\sim \\ N(0,1)\n\\]\npdf：\\(\\varphi (z)=\\frac{1}{\\sqrt{2\\pi}}e^{-\\frac{z^2}{2}} (-\\infty＜z＜+\\infty)\\)\ncdf：\\(\\Phi(z)=P(Z≤z)=\\int_{-\\infty}^{z}\\varphi (\\nu )d\\nu =\\frac{1}{\\sqrt{2\\pi}}\\int_{-\\infty}^{z}e^{-\\frac{\\nu^2}{2}}dt\\ (-\\infty＜z＜+\\infty)\\)\n\nCode# 标准正态分布\nnorm &lt;- function(mu=0,sigma=1,...){\n  ggplot() + xlim(c(mu-4*sigma,mu+4*sigma)) +\n    geom_function(fun = dnorm, args = list(mean = mu, sd = sigma), color=\"red\")+\n        scale_y_continuous(limits = c(0,1))+\n    geom_function(fun = pnorm,color=\"blue\")\n}\nnorm()        # Area Under the Curve (AUC) = 1\n\n\n\n\n\n\n\n\n3.3.3 正态性的检验\n\n3.3.3.1 直方图/茎叶图\n直方图：钟形分布（bell-shaped distribution）\n\nCodemtcars$mpg\n#&gt;  [1] 21.0 21.0 22.8 21.4 18.7 18.1 14.3 24.4 22.8 19.2 17.8 16.4 17.3 15.2 10.4\n#&gt; [16] 10.4 14.7 32.4 30.4 33.9 21.5 15.5 15.2 13.3 19.2 27.3 26.0 30.4 15.8 19.7\n#&gt; [31] 15.0 21.4\nh&lt;-hist(mtcars$mpg,breaks = 12)\nx&lt;-seq(min(mtcars$mpg),max(mtcars$mpg),by=0.001)\ny&lt;-dnorm(x,mean=mean(mtcars$mpg),sd=sd(mtcars$mpg)) #密度曲线  f(x)=(F(i)/n)/ΔXi\ny&lt;-y*diff(h$mids[1:2])*length(mtcars$mpg)  # f(x)*ΔXi*n  正态分布\nlines(x,y,col=\"blue\")\n\n\n\n\n\n\n\n茎叶图（Stem-and-Leaf Plot）\n\nCodestem(mtcars$mpg,scale = 1)\n#&gt; \n#&gt;   The decimal point is at the |\n#&gt; \n#&gt;   10 | 44\n#&gt;   12 | 3\n#&gt;   14 | 3702258\n#&gt;   16 | 438\n#&gt;   18 | 17227\n#&gt;   20 | 00445\n#&gt;   22 | 88\n#&gt;   24 | 4\n#&gt;   26 | 03\n#&gt;   28 | \n#&gt;   30 | 44\n#&gt;   32 | 49\nlength(mtcars$mpg)\n#&gt; [1] 32\n\n\n\n3.3.3.2 P-P图/Q-Q图\nP-P图是累计相对频率的观测值（x轴）与理论值（y轴）的散点图；\nQ-Q图是分位数的观测值（x轴）与理论值（y轴）的散点图。\n\nCodelibrary(ggpubr)\nggqqplot(mtcars$mpg)  #  直线 \n\n\n\n\n\n\n\n\n3.3.3.3 矩量法（Moment Method）\n偏度=0 且 超值峰度=0\n\\[\nH_0:总体偏度系数\\gamma_1=0 或者总体峰度系数\\gamma_2=0\n\\]\n\\[\nz_i=\\frac{g_i-0}{\\sigma_{g_i}}  \\ \\ \\ \\ 临界值z_{1-\\alpha/2}\n\\]\n\n3.3.3.4 Shapiro-Wilk检验（小样本）\n\nCodeshapiro.test(mtcars$mpg)  \n#&gt; \n#&gt;  Shapiro-Wilk normality test\n#&gt; \n#&gt; data:  mtcars$mpg\n#&gt; W = 0.94756, p-value = 0.1229\n\n\n\n3.3.3.5 Kolmogorov-Smirnov检验（Lilliefors correction 大样本）\n\nCodeks.test(rnorm(1000),\"pnorm\")\n#&gt; \n#&gt;  Asymptotic one-sample Kolmogorov-Smirnov test\n#&gt; \n#&gt; data:  rnorm(1000)\n#&gt; D = 0.016935, p-value = 0.9366\n#&gt; alternative hypothesis: two-sided\n\n\n\nCodex &lt;- rnorm(50) \ny &lt;- runif(50) \nks.test(x, y)  # perform ks test\n#&gt; \n#&gt;  Exact two-sample Kolmogorov-Smirnov test\n#&gt; \n#&gt; data:  x and y\n#&gt; D = 0.42, p-value = 0.000246\n#&gt; alternative hypothesis: two-sided\n\nx &lt;- rnorm(50)\ny &lt;- rnorm(50)\nks.test(x, y) \n#&gt; \n#&gt;  Exact two-sample Kolmogorov-Smirnov test\n#&gt; \n#&gt; data:  x and y\n#&gt; D = 0.18, p-value = 0.3959\n#&gt; alternative hypothesis: two-sided\n\n\n\n3.3.4 二项分布近似正态分布\n当\\(n\\pi(1-\\pi)≥5 且X\\sim B(n,\\pi)\\)时，\\(P(a≤X≤b)近似等于X\\sim N(n\\pi,n\\pi(1-\\pi))在区间(a-0.5,b+0.5)上的曲线下面积\\)。\n\\[\nZ=\\frac{x-\\mu}{\\sigma}=\\frac{x-n\\pi}{\\sqrt{n\\pi(1-\\pi)}}\n\\]\n\nCodelibrary(patchwork)\nbinom(30,0.5)|norm(mu=15,sigma = 7.5)\n\n\n\n\n\n\n\n\n3.3.5 泊松分布近似正态分布\n当\\(\\lambda≥10 且X\\sim P(\\lambda)\\)时，\\(P(a≤X≤b)近似等于X\\sim N(\\lambda,\\lambda)在区间(a-0.5,b+0.5)上的曲线下面积\\)。\n\\[\nZ=\\frac{x-\\mu}{\\sigma}=\\frac{x-\\lambda}{\\sqrt{\\lambda}}\n\\]\n\n3.3.6 医学参考区间",
    "crumbs": [
      "概率论与数理统计",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>概率论基础</span>"
    ]
  },
  {
    "objectID": "SamplingDistribution.html",
    "href": "SamplingDistribution.html",
    "title": "\n4  抽样分布\n",
    "section": "",
    "text": "4.1 均值（mean）的抽样分布\n假设 \\(X_1,X_2,...,X_n\\)是来自均值为\\(μ\\)，有限方差为\\(σ^2\\)的总体为 \\(X\\)的一组样本量为n的随机样本。\n\\(\\bar X\\) 的抽样分布是指从总体 \\(X\\)中选择的样本量为\\(n\\)的所有可能样本的 \\(\\bar x\\)值（\\(\\bar x=\\frac{1}{n}\\sum_{i}x_i\\)）的分布。\nCode# 标准正态分布\nnorm &lt;- function(mu = 0, sigma = 1, ...) {\n    ggplot() +\n        geom_function(\n            aes(color = \"pdf\"),\n            fun = dnorm,\n            args = list(mean = mu, sd = sigma),\n            linewidth = 1\n        ) +\n        geom_function(\n            aes(color = \"cdf\"),\n            fun = pnorm,\n            linewidth = 1,\n            linetype = \"dashed\"\n        ) +\n        scale_color_manual(values = c(\"pdf\" = \"red\", \"cdf\" = \"blue\")) +\n        scale_x_continuous(name = \"x\",\n                           limits = c(mu - 4 * sigma, mu + 4 * sigma)) +\n        scale_y_continuous(name = \"Density/Probability\", limits = c(0, 1)) +\n        labs(title = paste(\"normal distribution N( \", mu, \", \", sigma, \")\", sep = \"\")) +\n        theme(plot.title = element_text(hjust = 0.5)) +\n        guides(color = guide_legend(title = \"Type\"))\n}\nnorm()",
    "crumbs": [
      "概率论与数理统计",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>抽样分布</span>"
    ]
  },
  {
    "objectID": "SamplingDistribution.html#均值mean的抽样分布",
    "href": "SamplingDistribution.html#均值mean的抽样分布",
    "title": "\n4  抽样分布\n",
    "section": "",
    "text": "4.1.1 \\(N( 0, 1)\\)——σ2 已知的正态总体\n\\[\n\\bar X \\sim N(μ,\\frac{σ^2}{n})\n\\]\n标准化\\(\\bar X\\)\n\\[\nZ=\\frac{\\bar X-\\mu}{\\sigma_{\\bar X}}=\\frac{\\bar X-\\mu}{\\sigma /\\sqrt n} \\sim N(0,1)\n\\]\n均值的标准差即标准误 \\(\\sigma _{\\bar X} =\\frac {\\sigma}{\\sqrt n}\\) 可以用 \\(S _{\\bar X} =\\frac {S}{\\sqrt n}\\) 估计。\n\n4.1.2 \\(N(μ,\\frac{σ^2}{n})\\)——大样本量的非正态总体\n\n中心极限定理（central limit theorem）\n\n当样本量n足够大（n≥30）时，即使随机样本并非来自正态分布总体，样本均值\\(\\bar X\\) 的抽样分布也会近似服从均值为\\(\\mu\\) ，方差为\\(\\sigma^2/n\\) 的正态分布，即\n\\[ \\bar X \\dot{\\sim}  N(μ,\\frac{σ^2}{n}) \\]\n\n\n4.1.3 t分布——σ2 未知的正态分布\n\\(Z\\sim N(0,1)\\)，\\(X\\sim \\chi^2(n)\\) 且X与Z相互独立，则称\n\\[ T=\\frac{Z}{\\sqrt{X/n}} \\]\n为自由度为n 的\\(t\\)分布，记为\\(T\\sim t(n)\\)\n如果\\(Z\\sim N(\\delta,1)\\) ，则称T为非中心化的t分布。记为\\(T\\sim t(n,\\delta)\\) ，称δ为非中心化参数。\nt分布的数学期望和方差：\n\\[\\begin{aligned} E(X)=&0,\\ \\ \\ n\\ge2 \\\\ Var(X)=&\\frac{n}{n-2},\\ \\ \\ n\\ge3 \\end{aligned} \\]\n统计量的分布：\n\\[ t=\\frac{\\bar X-\\mu}{S_{\\bar X}}=\\frac{\\bar X-\\mu}{S /\\sqrt n} \\sim t(\\nu) \\]\n其中自由度（degrees of freedom）\\(\\nu=n-1\\) 。当 \\(\\nu \\to +\\infty 时,t\\sim N(0,1)\\) 。\n\nCodet_distribution &lt;- function(df = 1, ...) {\n  # Generate sequence of x values\n  x &lt;- seq(-10, 10, length.out = 1000)\n  \n  # Calculate the probability density function (PDF) and cumulative distribution function (CDF)  values\n  pdf_values &lt;- dt(x, df) \n  cdf_values &lt;- pt(x, df)\n  \n  # Create the ggplot\n  ggplot(data.frame(x, pdf_values, cdf_values), aes(x = x)) +\n    geom_line(aes(y = pdf_values, color = \"PDF\"), linewidth = 1) +\n    geom_line(aes(y = cdf_values, color = \"CDF\"), linewidth = 1, linetype = \"dashed\") +\n    scale_color_manual(values = c(\"PDF\" = \"red\", \"CDF\" = \"blue\")) +\n    scale_y_continuous(name = \"Density/Probability\") +\n    scale_x_continuous(name = \"x\") +\n    labs(title = paste(\"Student's t-distribution (df =\", df, \")\", sep = \"\")) +\n    guides(color = guide_legend(title = \"Type\"))\n}\nlibrary(patchwork)\nt_distribution(df=10)|norm()",
    "crumbs": [
      "概率论与数理统计",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>抽样分布</span>"
    ]
  },
  {
    "objectID": "SamplingDistribution.html#方差variance的抽样分布",
    "href": "SamplingDistribution.html#方差variance的抽样分布",
    "title": "\n4  抽样分布\n",
    "section": "\n4.2 方差（variance）的抽样分布",
    "text": "4.2 方差（variance）的抽样分布\n\n4.2.1 \\(\\chi^2\\)分布\n\\(Z_i\\sim N(0,1)\\),且\\(Z_i\\)相互独立，则称\n\\[\nX=Z_1^2+Z_2^2+...+Z_n^2\n\\]\n为自由度为n的\\(\\chi^2\\)分布，记为\\(X\\sim \\chi^2(n)\\)\n如果\\(Z_i\\sim N(\\delta,1)\\) ，则称X为非中心化的卡方分布。记为\\(X\\sim \\chi^2(n,\\delta)\\) ，称δ为非中心化参数。\n卡方分布的数学期望和方差：\n\\[\n\\begin{aligned}\nE(X)=&n\\\\\nVar(X)=&2n\n\\end{aligned}\n\\]\n假设 \\(X_1,X_2,...,X_n\\)是独立同分布于均值为\\(μ\\)，有限方差为\\(σ^2\\)的一组样本量为n的随机样本。统计量的分布：\n\\[\n\\frac {(n-1)S^2}{\\sigma^2}\\sim \\chi^2(\\nu)\n\\]\n其中自由度（degrees of freedom）\\(\\nu=n-1\\) 。\n\nCodechisq_distribution &lt;- function(df = 1, ...) {\n  # Generate sequence of x values\n  x &lt;- seq(0, 20, length.out = 1000)\n  \n  # Calculate the probability density function (PDF) and cumulative distribution function (CDF)  values\n  pdf_values &lt;- dchisq(x, df) \n  cdf_values &lt;- pchisq(x, df)\n  \n  # Create the ggplot\n  ggplot(data.frame(x, pdf_values, cdf_values), aes(x = x)) +\n    geom_line(aes(y = pdf_values, color = \"PDF\"), size = 1) +\n    geom_line(aes(y = cdf_values, color = \"CDF\"), size = 1, linetype = \"dashed\") +\n    scale_color_manual(values = c(\"PDF\" = \"red\", \"CDF\" = \"blue\")) +\n    scale_y_continuous(name = \"Density/Probability\") +\n    scale_x_continuous(name = \"x\") +\n    labs(title = paste(\"Chi square distribution (df =\", df, \")\", sep = \"\")) +\n    guides(color = guide_legend(title = \"Type\"))\n}\n(chisq_distribution(df=1)+chisq_distribution(df=2))/\n(chisq_distribution(df=4)+chisq_distribution(df=10))+plot_layout(guides = \"collect\")\n\n\n\n\n\n\n\n\n4.2.2 F分布\n\\(X\\sim \\chi^2(n_1)\\) ，\\(Y\\sim \\chi^2(n_2)\\)且相互独立，则称\n\\[ F=\\frac{X/n1}{Y/n2}\\]\n为第一个自由度为n1和第二个自由度为n2的\\(F\\)分布，记为\\(F\\sim F(n_1,n_2)\\)\n如果\\(X\\sim \\chi^2(n_1,\\delta)\\) ，则称F为非中心化的F分布。记为\\(F\\sim F(n_1,n_2;\\delta)\\) ，称δ为非中心化参数。\n卡方分布的数学期望和方差：\n\\[\\begin{aligned} E(X)=&n\\\\ Var(X)=&2n \\end{aligned} \\]\n\nCodeF_distribution &lt;- function(df1 = 1,df2 = 1, ...) {\n  # Generate sequence of x values\n  x &lt;- seq(0, 10, length.out = 1000)\n  \n  # Calculate the probability density function (PDF) and cumulative distribution function (CDF)  values\n  pdf_values &lt;- df(x, df1,df2) \n  cdf_values &lt;- pchisq(x, df1,df2)\n  \n  # Create the ggplot\n  ggplot(data.frame(x, pdf_values, cdf_values), aes(x = x)) +\n    geom_line(aes(y = pdf_values, color = \"PDF\"), size = 1) +\n    geom_line(aes(y = cdf_values, color = \"CDF\"), size = 1, linetype = \"dashed\") +\n    scale_color_manual(values = c(\"PDF\" = \"red\", \"CDF\" = \"blue\")) +\n    scale_y_continuous(name = \"Density/Probability\") +\n    scale_x_continuous(name = \"x\") +\n    labs(title = paste(\"F distribution (df1 =\", df1,\", \",\"df2 = \",df2, \")\", sep = \"\")) +\n    guides(color = guide_legend(title = \"Type\"))\n}\n(F_distribution(1,1)+F_distribution(3,1))/\n    (F_distribution(3,15)+F_distribution(7,15))+plot_layout(guides = \"collect\")\n\n\n\n\n\n\n\n\n4.2.3 比率（rate）抽样分布——分类数据\n假设 \\(X\\sim B(n,\\pi)\\) ，一组样本量为n的随机样本。列出样本量为\\(n\\)的所有可能随机样本。\n样本比率\\(p=X/n\\) ，则 \\[\nE(p)=E(X/n)=\\frac{1}{n}E(X)=\\pi\n\\]\n\\[\nVar(p)=Var(X/n)=\\frac{1}{n^2}Var(X)=\\frac{\\pi(1-\\pi)}{n}\n\\]\n比率的标准误 \\(\\sigma_p =\\sqrt{\\frac{\\pi(1-\\pi)}{n}}\\) 可以用 \\(S _p =\\sqrt{\\frac{p(1-p)}{n}}\\) 估计。\n当\\(n\\pi(1-\\pi)≥5 且X\\sim B(n,\\pi)\\)时，率的抽样分布\n\\[\np\\dot\\sim N(\\pi,\\frac{\\pi(1-\\pi)}{n})\n\\]",
    "crumbs": [
      "概率论与数理统计",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>抽样分布</span>"
    ]
  },
  {
    "objectID": "ParameterEstimation.html",
    "href": "ParameterEstimation.html",
    "title": "5  参数估计",
    "section": "",
    "text": "5.1 一个总体的参数估计",
    "crumbs": [
      "概率论与数理统计",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>参数估计</span>"
    ]
  },
  {
    "objectID": "ParameterEstimation.html#一个总体的参数估计",
    "href": "ParameterEstimation.html#一个总体的参数估计",
    "title": "5  参数估计",
    "section": "",
    "text": "5.1.0.1 点估计\n假设 \\(\\theta\\)是总体\\(X\\)的一个参数，\\(\\hat\\theta=\\hat\\theta(X_1,X_2,...,X_n)\\)是代表\\(\\theta\\)的数值估计的一个统计量。任何可能的\\(\\hat\\theta\\)称为\\(\\theta\\)的点估计。\n\n无偏性（unbiasedness）\n如果\\(E(\\hat\\theta)=\\theta\\),就说参数\\(\\theta\\)的一个估计\\(\\hat\\theta\\)是无偏的。\n\\[\n\\bar X=\\sum_{i=1}^{n}X_i/n\n\\]\n\\[\nE(\\bar X)=\\frac{1}{n}E(\\sum_{i=1}^{n}X_i)=\\frac{n\\mu}{\\mu}=\\mu\n\\]\n所以样本均值\\(\\bar X\\)是总体均值\\(\\mu\\)的一个无偏估计。\n\\[\nS^2=\\frac{1}{n-1}\\sum_{i=1}^{n}(X_i-\\bar X)^2\n\\]\n\\[\nE(S^2)=E(\\frac{n}{n-1}S_n^2)=\\frac{n}{n-1}E(S_n^2)=\\frac{n}{n-1}E(\\frac {1}{n}\\sum_{i=1}^{n}(X_i-\\bar X)^2\\\\=\\frac{n}{n-1}\\times\\frac{n-1}{n}\\sigma^2=\\sigma^2\n\\] 所以样本方差\\(S^2\\)是总体方差\\(\\sigma^2\\)的一个无偏估计。\n\n\n最小方差无偏估计（MVUE）\n\\(\\hat\\theta\\)无偏且最小方差\n\n\n一致性（consistency）\n对于任意一个\\(\\epsilon＞0\\) ，如果 \\[\\lim_{n\\to \\infty}P(|\\hat\\theta_n-\\theta|＜\\epsilon)=1\\] 那么\\(\\hat\\theta_n\\)是总体参数\\(\\theta\\)的一个一致估计。\n\n\n\n5.1.1 区间估计\n\n5.1.1.1 均值的区间估计\n\n\\(\\sigma^2\\)已知的正态分布\n\\(X_1,X_2,...,X_n\\)是来自\\(N(\\mu,\\sigma^2)\\)的随机样本,则\\(\\bar X\\sim N(\\mu,\\frac{\\sigma^2}{n})\\),变换\\(Z=\\frac{\\bar X-\\mu}{\\sigma/\\sqrt n}\\sim N(0,1)\\)。\n对于给定的\\(\\alpha\\)，称\\(z_{\\alpha/2}\\)和\\(z_{1-\\alpha/2}\\)为临界值（critical value）。当\\(Z\\)分布是对称的，\\(z_{\\alpha/2}=-z_{1-\\alpha/2}\\)。\n区间估计的置信水平（confidence level）：\\(1-\\alpha\\)\n总体均值的置信区间（confidence interval）：\\(\\bar X \\pm z_{1-\\alpha/2}\\frac{\\sigma}{\\sqrt n}\\)\n\n\n大样本量的非正态分布\n\\(X_1,X_2,...,X_n\\)是来自非正态分布的随机样本,当样本量足够大时，\\(\\bar X \\dot{\\sim} N(μ,\\frac{σ^2}{n})\\), 变换\\(Z=\\frac{\\bar X-\\mu}{S/\\sqrt n}\\dot\\sim N(0,1)\\)。\n总体均值的置信区间（confidence interval）：\\(\\bar X \\pm z_{1-\\alpha/2}\\frac{S}{\\sqrt n}\\)\n\n\n\\(\\sigma^2\\)未知的正态分布\n\\(X_1,X_2,...,X_n\\)是来自\\(N(\\mu,\\sigma^2)\\)的随机样本,则\\(t=\\frac{\\bar X-\\mu}{S /\\sqrt n} \\sim t(\\nu),\\nu=n-1\\)。\n对于给定的\\(\\alpha\\)，称\\(t_{\\nu,\\alpha/2}\\)和\\(t_{\\nu,1-\\alpha/2}\\)为临界值（critical value）。\\(t_{\\alpha/2}=-t_{1-\\alpha/2}\\)。\n总体均值的置信区间（confidence interval）：\\([\\bar X- t_{\\nu,1-\\alpha/2}\\frac{S}{\\sqrt n},\\bar X+ t_{\\nu,1-\\alpha/2}\\frac{S}{\\sqrt n}]\\)\n\n\n\n5.1.1.2 方差的区间估计\n\\(X_1,X_2,...,X_n\\)是来自\\(N(\\mu,\\sigma^2)\\)的随机样本,则\\(\\frac {(n-1)S^2}{\\sigma^2}\\sim \\chi^2(\\nu),\\nu=n-1\\)\n对于给定的\\(\\alpha\\)，称\\(\\chi^2_{\\nu,\\alpha/2}\\)和\\(\\chi^2_{\\nu,1-\\alpha/2}\\)为临界值（critical value）。\n区间估计的置信水平（confidence level）：\\(1-\\alpha\\)\n总体方差的置信区间（confidence interval）：\\([\\frac {(n-1)S^2}{\\chi^2_{\\nu,1-\\alpha/2}},\\frac {(n-1)S^2}{\\chi^2_{\\nu,\\alpha/2}}]\\)\n\n\n5.1.1.3 比率的区间估计\n\\(X_1,X_2,...,X_n\\)是来自\\(B(n,\\pi)\\)的随机样本, 当\\(n\\pi(1-\\pi)≥5\\)时，比率的抽样分布 \\(p\\dot\\sim N(\\pi,\\frac{\\pi(1-\\pi)}{n})\\)，则变换\\(Z=\\frac{p-\\pi}{\\sqrt{p(1-p)/n}}\\dot\\sim N(0,1)\\)。\n总体率的置信区间（confidence interval）：\\(\\bar p \\pm z_{1-\\alpha/2}\\sqrt{\\frac{p(1-p)}{n}}\\)",
    "crumbs": [
      "概率论与数理统计",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>参数估计</span>"
    ]
  },
  {
    "objectID": "ParameterEstimation.html#两个总体的参数估计",
    "href": "ParameterEstimation.html#两个总体的参数估计",
    "title": "5  参数估计",
    "section": "5.2 两个总体的参数估计",
    "text": "5.2 两个总体的参数估计\n\n5.2.1 均值差值的估计\n\n5.2.1.1 点估计\n\\[E(\\bar X_1-\\bar X_2)=\\mu_1-\\mu_2\\]\n\\[Var(\\bar X_1-\\bar X_2)=\\frac{\\sigma^2_1}{n_1}+\\frac{\\sigma^2_2}{n_2}\\]\n统计量\\(\\bar X_1-\\bar X_2\\)是\\(\\mu_1-\\mu_2\\)的MVUE。\n\n\n5.2.1.2 区间估计\n\n正态分布或中心极限定理成立\n当\\(n_1＞30\\ \\&\\ n_2＞30\\)时，\n\\[\n(\\bar X_1-\\bar X_2) \\dot\\sim N(\\mu_1-\\mu_2,\\frac{\\sigma^2_1}{n_1}+\\frac{\\sigma^2_2}{n_2})\n\\] 标准化变换 \\[\nZ=\\frac{(\\bar X_1-\\bar X_2)-(\\mu_1-\\mu_2)}{\\sqrt{\\frac{\\sigma^2_1}{n_1}+\\frac{\\sigma^2_2}{n_2}}}\\dot\\sim N(0,1)\n\\] 用样本方差代替总体方差，总体均值的置信区间（confidence interval）：\\(\\bar X_1-\\bar X_2 \\pm z_{1-\\alpha/2}\\sqrt{\\frac{S^2_1}{n_1}+\\frac{S^2_2}{n_2}}\\)\n\n\n方差相等的未知正态分布\n\\[\nt=\\frac{(\\bar X_1-\\bar X_2)-(\\mu_1-\\mu_2)}{S_{\\bar X_1-\\bar X_2}}\\sim t(\\nu)\n\\]\n其中\\(v=n_1+n_2-2\\) 和 \\[\nS_{\\bar X_1-\\bar X_2}=\\sqrt{S_C^2(\\frac{1}{n_1}+\\frac{1}{n_2})}\n\\]\n其中\\(S_C^2=\\frac {(n_1-1)S_1^2+(n_2-1)S_2^2}{n_1+n_2-2}\\)是\\(S_1^2\\)和\\(S_2^2\\)的加权平均，也称为合并样本方差（pooled sample variance）\n总体均值的置信区间（confidence interval）：\\(\\bar X_1-\\bar X_2 \\pm t_{\\nu,1-\\alpha/2} S_{\\bar X_1-\\bar X_2}\\)\n\n\n方差不等的未知正态分布\n\\[\nt'=\\frac{(\\bar X_1-\\bar X_2)-(\\mu_1-\\mu_2)}{\\sqrt{\\frac{S_1^2}{n_1}+\\frac{S_2^2}{n_2}}}\\sim t(\\nu ')\n\\]\n其中 \\[\nv'=\\frac{(\\frac{S_1^2}{n_1}+\\frac{S_2^2}{n_2})^2}{\\frac{(\\frac{S_1^2}{n_1})^2}{n_1-1}+\\frac{(\\frac{S_2^2}{n_2})^2}{n_2-1}}(舍入到最近整数)\n\\]\n总体均值的置信区间（confidence interval）：\\(\\bar X_1-\\bar X_2 \\pm t_{\\nu ',1-\\alpha/2} \\sqrt{\\frac{S_1^2}{n_1}+\\frac{S_2^2}{n_2}}\\)\n\n\n\n\n5.2.2 方差比的估计\n\n5.2.2.1 点估计\n\\[X_1\\sim N(\\mu_1,\\sigma_1^2)\\]\n\\[X_2\\sim N(\\mu_2,\\sigma_2^2)\\]\n统计量\\(S_1^2/S_2^2\\)是\\(\\sigma_1^2/\\sigma_2^2\\)的MVUE。\n\n\n5.2.2.2 区间估计\n\\[\nF=\\frac{\\frac {(n_1-1)S_1^2}{\\sigma_1^2}/(n_1-1)}{\\frac {(n_2-1)S_2^2}{\\sigma_2^2}/(n_2-1)}=(\\frac{S_1^2}{S_2^2})(\\frac{\\sigma_2^2}{\\sigma_1^2})\\sim F(\\nu_1,\\nu_2),\\nu_1=n_1-1,\\nu_2=n_2-1\n\\] 对于给定的\\(\\alpha\\)，称\\(F_{(\\nu_1,\\nu_2),\\alpha/2}\\)和\\(F_{(\\nu_1,\\nu_2),1-\\alpha/2}\\)为临界值（critical value）。\\(F_{(\\nu_1,\\nu_2),\\alpha/2}=\\frac{1}{F_{(\\nu_1,\\nu_2),1-\\alpha/2}}\\)\n总体方差的置信区间（confidence interval）：\\([\\frac{S_1^2}{S_2^2}\\times \\frac{1}{F_{(\\nu_1,\\nu_2),1-\\alpha/2}},\\frac{S_1^2}{S_2^2}\\times \\frac{1}{F_{(\\nu_1,\\nu_2),\\alpha/2}}]\\)\n\n\n\n5.2.3 比率差异的估计\n\n5.2.3.1 点估计\n当\\(n_ip_i(1-p_i)≥5,(i=1,2)\\)时，\\(p_i\\dot\\sim N(\\pi_i,\\frac{\\pi_i(1-\\pi_i)}{n_i})\\)\n\\(E(p_1-p_2)=\\pi_1-\\pi_2\\)\n\\(Var(p_1-p_2)=\\frac{\\pi_1(1-\\pi_1)}{n_1}+\\frac{\\pi_2(1-\\pi_2)}{n_2}\\)\n统计量\\(p_1-p_2\\)是\\(\\pi_1-\\pi_2\\)的MVUE。\n\n\n5.2.3.2 区间估计\n\\[\n(p_1-p_2)\\dot\\sim N(\\pi_1-\\pi_2,\\frac{\\pi_1(1-\\pi_1)}{n_1}+\\frac{\\pi_2(1-\\pi_2)}{n_2})\n\\] 标准化变换 \\[\nZ=\\frac{(p_1-p_2)-(\\pi_1-\\pi_2)}{S_{p_1-p_2}}\\dot\\sim N(0,1)\n\\] 其中\\(S_{p_1-p_2}=\\sqrt{\\frac{p_1(1-p_1)}{n_1}+\\frac{p_2(1-p_2)}{n_2}}\\)",
    "crumbs": [
      "概率论与数理统计",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>参数估计</span>"
    ]
  },
  {
    "objectID": "hypothesis_test.html",
    "href": "hypothesis_test.html",
    "title": "6  假设检验",
    "section": "",
    "text": "6.1 标准流程",
    "crumbs": [
      "概率论与数理统计",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>假设检验</span>"
    ]
  },
  {
    "objectID": "hypothesis_test.html#标准流程",
    "href": "hypothesis_test.html#标准流程",
    "title": "6  假设检验",
    "section": "",
    "text": "建立假设和确定显著性水平\n\nnull hypothesis：\\(H_0\\)\nalternative hypothesis：\\(H_1\\)\n显著性水平/犯第\\(Ⅰ\\)类错误（拒绝真\\(H_0\\)）的概率/拒绝域的概率：\\(α\\)\n\n选择检验方法和计算检验统计量\n\n\\(t\\)检验，\\(z\\)检验，\\(\\chi^2\\)检验，\\(F\\)检验，非参数检验等\n\n根据P值做出统计推断\n\np≤α，拒绝\\(H_0\\)，接受\\(H_1\\)\np＞α，不拒绝\\(H_0\\)",
    "crumbs": [
      "概率论与数理统计",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>假设检验</span>"
    ]
  },
  {
    "objectID": "hypothesis_test.html#功效分析",
    "href": "hypothesis_test.html#功效分析",
    "title": "6  假设检验",
    "section": "6.2 功效分析",
    "text": "6.2 功效分析\nhttps://www.statmethods.net/stats/power.html\n\n第\\(Ⅰ\\)类错误：拒绝真\\(H_0\\)，犯第Ⅰ类错误的概率\\(\\alpha=P(reject\\  H_0|H_0\\ is\\ True)\\)\n第\\(Ⅱ\\)类错误：不拒绝假\\(H_0\\)，犯第Ⅱ类错误的概率\\(\\beta=(not\\ reject\\  H_0|H_1\\ is\\ True)\\)\n功效 \\(power=1-β=P(reject\\  H0|H1 \\ is\\  True)\\)\n效应值 effect size 备择假设下的效应值\n样本量 sample size",
    "crumbs": [
      "概率论与数理统计",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>假设检验</span>"
    ]
  },
  {
    "objectID": "hypothesis_test.html#假设检验与区间估计",
    "href": "hypothesis_test.html#假设检验与区间估计",
    "title": "6  假设检验",
    "section": "6.3 假设检验与区间估计",
    "text": "6.3 假设检验与区间估计\n如果参数\\(θ\\)的\\((1-α)×100\\%\\)置信区间CI包含参数\\(\\theta_0\\)所有的估计值，那么不拒绝\\(H_0\\);\n如果参数\\(θ\\)的\\((1-α)×100\\%\\)置信区间CI不包含参数\\(\\theta_0\\)任意一个估计值，那么拒绝\\(H_0\\);\np value 和 CI 对于统计推断同等重要，尤其是大样本量。",
    "crumbs": [
      "概率论与数理统计",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>假设检验</span>"
    ]
  },
  {
    "objectID": "normality_test.html",
    "href": "normality_test.html",
    "title": "\n7  正态性检验\n",
    "section": "",
    "text": "7.1 描述性统计方法",
    "crumbs": [
      "概率论与数理统计",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>正态性检验</span>"
    ]
  },
  {
    "objectID": "normality_test.html#描述性统计方法",
    "href": "normality_test.html#描述性统计方法",
    "title": "\n7  正态性检验\n",
    "section": "",
    "text": "7.1.1 密度图\n密度图提供了关于分布是否为钟形的视觉判断\n\nCodeggdensity(df$ctrl, fill = \"lightgray\") +\n   #  stat_overlay_normal_density(color = \"red\", linetype = \"dashed\")+\n    xlim(c(mean(df$ctrl) - 3 * sd(df$ctrl), \n           mean(df$ctrl) + 3 * sd(df$ctrl)))\n\n\n\n\n\n\n\n\n7.1.2 Q-Q图\nQ-Q图（或分位数-分位数图）绘制给定样本与正态分布之间的相关性。还绘制了一条 45 度参考线。在 QQ 图中，每个观测值都绘制为一个点。如果数据是正常的，则点应形成一条直线。\n\nCodeggqqplot(df$ctrl)\n\n\n\n\n\n\n\n\nCodenorm &lt;- rnorm(1000,10,3)\nggqqplot(norm)\n\n\n\n\n\n\nCodeunif &lt;- runif(1000,5,15)\nggqqplot(unif)\n\n\n\n\n\n\nCode\nexp &lt;- rexp(1000,1)\nggqqplot(exp)",
    "crumbs": [
      "概率论与数理统计",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>正态性检验</span>"
    ]
  },
  {
    "objectID": "normality_test.html#基于卡方分布",
    "href": "normality_test.html#基于卡方分布",
    "title": "\n7  正态性检验\n",
    "section": "\n7.2 基于卡方分布",
    "text": "7.2 基于卡方分布\n\n7.2.1 D’Agostino-Pearson Omnibus Test\nD’Agostino-Pearson test\nD’Agostino-Pearson 综合检验 是基于数据的偏度和峰度来评估数据是否接近正态分布的。\n\n首先计算偏斜度和峰度，以量化分布在不对称性和形状方面与高斯分布的差距。然后，其计算这些值中的每一个与高斯分布的预期值之间的差异，并基于这些差异的总和，计算各P值。这是一种通用和强大的正态性检验，通常推荐使用。但值得注意的是，该建议也有例外。具体而言，当该分布的偏度和峰度非常接近正态分布的偏度和峰度，但肯定是非正态分布时，该检验将无法将该分布确定为非正态分布。\n\n\n\n\n在R语言中，可以使用 moments 包中的 agostino.test() 函数来执行此检验。此检验的原假设是数据来自正态分布，如果检验的p值小于显著性水平（通常是0.05），则可以拒绝原假设，认为数据不服从正态分布。\n\nCodemoments::agostino.test(df$ctrl)\n#&gt; \n#&gt;  D'Agostino skewness test\n#&gt; \n#&gt; data:  df$ctrl\n#&gt; skew = -0.20140, z = -0.41707, p-value = 0.6766\n#&gt; alternative hypothesis: data have a skewness\nmoments::agostino.test(df$trt)\n#&gt; \n#&gt;  D'Agostino skewness test\n#&gt; \n#&gt; data:  df$trt\n#&gt; skew = 0.15146, z = 0.31410, p-value = 0.7534\n#&gt; alternative hypothesis: data have a skewness\n\n# 样本偏度和峰度\nskewness &lt;- moments::skewness(df$ctrl,na.rm = T)\nkurtosis &lt;- moments::kurtosis(df$ctrl,na.rm = T)\n# D'Agostino's K² 检验\nK2 &lt;- length(df$ctrl) * (skewness^2 / 6 + (kurtosis - 3)^2 / 24)\np_value &lt;- 1 - pchisq(K2, df = 2)\n\nK2\n#&gt; [1] 0.8247351\np_value\n#&gt; [1] 0.6620809\n\n\n\n7.2.2 Jarque-Bera 正态性检验\nJarque-Bera检验也是一种基于样本偏度和峰度的正态性检验方法。\n\n\n\n\n\nCodeif(!require(tseries)){install.packages('tseries')}\ntseries::jarque.bera.test(df$ctrl)\n#&gt; \n#&gt;  Jarque Bera Test\n#&gt; \n#&gt; data:  df$ctrl\n#&gt; X-squared = 0.82474, df = 2, p-value = 0.6621\ntseries::jarque.bera.test(df$trt)\n#&gt; \n#&gt;  Jarque Bera Test\n#&gt; \n#&gt; data:  df$trt\n#&gt; X-squared = 0.69681, df = 2, p-value = 0.7058\n\n\n\n7.2.3 Pearson’s X2 test\n\nCode\n\nnortest::pearson.test(df$ctrl)\n#&gt; \n#&gt;  Pearson chi-square normality test\n#&gt; \n#&gt; data:  df$ctrl\n#&gt; P = 2.375, p-value = 0.6671\nnortest::pearson.test(df$trt)\n#&gt; \n#&gt;  Pearson chi-square normality test\n#&gt; \n#&gt; data:  df$trt\n#&gt; P = 3.25, p-value = 0.5169",
    "crumbs": [
      "概率论与数理统计",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>正态性检验</span>"
    ]
  },
  {
    "objectID": "normality_test.html#基于回归和相关",
    "href": "normality_test.html#基于回归和相关",
    "title": "\n7  正态性检验\n",
    "section": "\n7.3 基于回归和相关",
    "text": "7.3 基于回归和相关\n\n7.3.1 Shapiro-Wilk’s test\nShapiro-Wilk检验而是将数据的实际SD与根据数据的QQ图斜率计算的SD进行比较，并计算其比率。如果数据从高斯分布中采样，则两个值将相似，因此比率将接近1.0，而比率与1相差很大则表明为非正态分布。如果每个值均唯一，则Shapiro-Wilk检验非常有效，但如果几个值均相同，则不那么有效。推荐样本量 7~2000。\n这些检验的原假设是“样本分布是正态的”。如果检验显著，则分布为非正态分布。Shapiro-Wilk 方法被广泛推荐用于正态性检验，它提供了比 K-S 更好的功率。 它基于数据与相应的正常分数之间的相关性。\n\n\n\n\n\n\nNote\n\n\n\n正态性检验对样本量很敏感。小样本通常通过正态性检验。因此，为了做出正确的决定，将图示法和显著性检验结合起来是很重要的。如果样本数量大于 50，则首选正态 QQ 图，因为在较大的样本量下，Shapiro-Wilk 检验变得非常敏感，即使与正态的微小偏差也是如此。\n\n\n\nCodemap_df(df,~ shapiro.test(.x)[c(\"statistic\",\"p.value\")])\n\n\n\n\nstatistic\np.value\n\n\n\n0.9607632\n0.6756693\n\n\n0.9655983\n0.7632600\n\n\n\n\n\nCodedf %&gt;% shapiro_test(ctrl,trt)\n\n\n\n\nvariable\nstatistic\np\n\n\n\nctrl\n0.9607632\n0.6756693\n\n\ntrt\n0.9655983\n0.7632600\n\n\n\n\n\n\n\nCodeToothGrowth %&gt;%\n  group_by(dose) %&gt;%\n  shapiro_test(len)\n\n\n\n\ndose\nvariable\nstatistic\np\n\n\n\n0.5\nlen\n0.9406451\n0.2466015\n\n\n1.0\nlen\n0.9313431\n0.1638821\n\n\n2.0\nlen\n0.9777535\n0.9019115\n\n\n\n\n\n\n\nCode# Shapiro Wilk normality test for two variables\niris %&gt;% shapiro_test(Sepal.Length, Petal.Width)\n\n\n\n\nvariable\nstatistic\np\n\n\n\nPetal.Width\n0.9018349\n0.0000000\n\n\nSepal.Length\n0.9760903\n0.0101812\n\n\n\n\n\n\n\nCode# Multivariate normality test\nmshapiro_test(iris[, 1:3])\n\n\n\n\nstatistic\np.value\n\n\n0.9908412\n0.4426676",
    "crumbs": [
      "概率论与数理统计",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>正态性检验</span>"
    ]
  },
  {
    "objectID": "normality_test.html#基于经验分布函数empirical-distribution-function",
    "href": "normality_test.html#基于经验分布函数empirical-distribution-function",
    "title": "\n7  正态性检验\n",
    "section": "\n7.4 基于经验分布函数（empirical distribution function）",
    "text": "7.4 基于经验分布函数（empirical distribution function）\n\n7.4.1 Kolmogorov-Smirnov (K-S) test\nKolmogorov-Smirnov检验（K-S检验），这是一种非参数检验方法，用于比较一个样本的累积分布函数（CDF）与某个理论CDF的差异。需要指定总体的均值和方差\n不建议使用Kolmogorov-Smirnov检验。但在大样本（&gt;2000）实用\n\nCodeks.test(df$ctrl,\"pnorm\",mean=mean(df$ctrl),sd=sd(df$ctrl))\n#&gt; Warning in ks.test.default(df$ctrl, \"pnorm\", mean = mean(df$ctrl), sd =\n#&gt; sd(df$ctrl)): ties should not be present for the one-sample Kolmogorov-Smirnov\n#&gt; test\n#&gt; \n#&gt;  Asymptotic one-sample Kolmogorov-Smirnov test\n#&gt; \n#&gt; data:  df$ctrl\n#&gt; D = 0.13004, p-value = 0.9496\n#&gt; alternative hypothesis: two-sided\n\n\n在执行单样本Kolmogorov-Smirnov检验时，数据中不应该存在“ties”，即不应该有重复的数值。如果存在重复的数值，它会影响检验的有效性，因为K-S检验对数据中的“ties”敏感。此时，可以考虑使用其他对“ties”不敏感的检验方法，例如Shapiro-Wilk检验或Lilliefors检验。\n\n7.4.2 Lilliefors test\nLilliefors test 是一个修改版的K-S检验，它使用样本均值和标准差来标准化数据，然后与标准正态分布进行比较\n\nCodenortest::lillie.test(df$ctrl)\n#&gt; \n#&gt;  Lilliefors (Kolmogorov-Smirnov) normality test\n#&gt; \n#&gt; data:  df$ctrl\n#&gt; D = 0.13004, p-value = 0.6656\nnortest::lillie.test(df$trt)\n#&gt; \n#&gt;  Lilliefors (Kolmogorov-Smirnov) normality test\n#&gt; \n#&gt; data:  df$trt\n#&gt; D = 0.11011, p-value = 0.87\n\n\n\n7.4.3 Anderson-Darling test\nAnderson-Darling test 是基于累积分布函数（CDF）的比较，通过计算观测值与理论分布之间的差异程度来评估数据的拟合程度。在R语言中，可以使用 nortest 包中的 ad.test() 函数来执行此检验291011。此检验的原假设同样是数据服从正态分布，如果p值小于显著性水平，则拒绝原假设，认为数据不服从正态分布。对尾部敏感，适用于中等样本量的数据\n\nCodenortest::ad.test(df$ctrl)\n#&gt; \n#&gt;  Anderson-Darling normality test\n#&gt; \n#&gt; data:  df$ctrl\n#&gt; A = 0.24254, p-value = 0.7247\nnortest::ad.test(df$trt)\n#&gt; \n#&gt;  Anderson-Darling normality test\n#&gt; \n#&gt; data:  df$trt\n#&gt; A = 0.24294, p-value = 0.7233",
    "crumbs": [
      "概率论与数理统计",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>正态性检验</span>"
    ]
  },
  {
    "objectID": "normality_test.html#数据变换",
    "href": "normality_test.html#数据变换",
    "title": "\n7  正态性检验\n",
    "section": "\n7.5 数据变换",
    "text": "7.5 数据变换\n\n7.5.1 中度偏度-平方根变换\n\nCodelibrary(moments)\nskewness(iris$Sepal.Length, na.rm = TRUE)\n#&gt; [1] 0.3117531\ne1071::skewness(iris$Sepal.Length, na.rm = TRUE)\n#&gt; [1] 0.3086407\n\n\n\nsqrt(x)对于正偏态数据，\nsqrt(max(x+1) - x)对于负偏态数据\n\n7.5.2 更偏态-对数变换\n\nlog10(x)对于正偏态数据，\nlog10(max(x+1) - x)对于负偏态数据\n\n7.5.3 非常偏态-倒数\n\n1/x对于正偏态数据\n1/(max(x+1) - x)对于负偏态数据\n\n7.5.4 线性度和异方差性\nLinearity and heteroscedasticity\n\n首先，在因变量随着自变量值的增加而开始更快地增加的情况下尝试log 变换\n如果数据与此相反（因变量值随着自变量值的增加而减少得更快）可以考虑square变换\n\n\nCodelibrary(ggpubr)\nlibrary(moments)\ndata(\"USJudgeRatings\")\ndf &lt;- USJudgeRatings\nhead(df)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCONT\nINTG\nDMNR\nDILG\nCFMG\nDECI\nPREP\nFAMI\nORAL\nWRIT\nPHYS\nRTEN\n\n\n\nAARONSON,L.H.\n5.7\n7.9\n7.7\n7.3\n7.1\n7.4\n7.1\n7.1\n7.1\n7.0\n8.3\n7.8\n\n\nALEXANDER,J.M.\n6.8\n8.9\n8.8\n8.5\n7.8\n8.1\n8.0\n8.0\n7.8\n7.9\n8.5\n8.7\n\n\nARMENTANO,A.J.\n7.2\n8.1\n7.8\n7.8\n7.5\n7.6\n7.5\n7.5\n7.3\n7.4\n7.9\n7.8\n\n\nBERDON,R.I.\n6.8\n8.8\n8.5\n8.8\n8.3\n8.5\n8.7\n8.7\n8.4\n8.5\n8.8\n8.7\n\n\nBRACKEN,J.J.\n7.3\n6.4\n4.3\n6.5\n6.0\n6.2\n5.7\n5.7\n5.1\n5.3\n5.5\n4.8\n\n\nBURNS,E.B.\n6.2\n8.8\n8.7\n8.5\n7.9\n8.0\n8.1\n8.0\n8.0\n8.0\n8.6\n8.6\n\n\n\n\n\n\n\nCode# Distribution of CONT variable\nggdensity(df, x = \"CONT\", fill = \"lightgray\", title = \"CONT\") +\n  scale_x_continuous(limits = c(3, 12)) +\n  stat_overlay_normal_density(color = \"red\", linetype = \"dashed\")\n\n\n\n\n\n\nCode\n# Distribution of PHYS variable\nggdensity(df, x = \"PHYS\", fill = \"lightgray\", title = \"PHYS\") +\n  scale_x_continuous(limits = c(3, 12)) +\n  stat_overlay_normal_density(color = \"red\", linetype = \"dashed\")\n\n\n\n\n\n\n\n\nCodeskewness(df$CONT, na.rm = TRUE)\n#&gt; [1] 1.085972\nskewness(df$PHYS, na.rm = TRUE)\n#&gt; [1] -1.558215\n\n\n\n7.5.5 Box-Cox 幂次变换\n\nCodebc &lt;- car::powerTransform(df)\n\nbc\n#&gt; Estimated transformation parameters \n#&gt;       CONT       INTG       DMNR       DILG       CFMG       DECI       PREP \n#&gt; -0.9819079  3.8646573  3.1866054  3.0071768  3.2197291  2.8949756  2.2797376 \n#&gt;       FAMI       ORAL       WRIT       PHYS       RTEN \n#&gt;  2.0508085  2.4118066  2.2521739  4.9918792  3.3428550\nsummary(bc)\n#&gt; bcPower Transformations to Multinormality \n#&gt;      Est Power Rounded Pwr Wald Lwr Bnd Wald Upr Bnd\n#&gt; CONT   -0.9819        0.00      -2.7096       0.7458\n#&gt; INTG    3.8647        3.86       2.3656       5.3637\n#&gt; DMNR    3.1866        3.19       2.1669       4.2063\n#&gt; DILG    3.0072        2.00       1.9536       4.0607\n#&gt; CFMG    3.2197        3.22       2.1068       4.3326\n#&gt; DECI    2.8950        2.00       1.6568       4.1332\n#&gt; PREP    2.2797        2.00       1.5568       3.0026\n#&gt; FAMI    2.0508        2.00       1.1463       2.9553\n#&gt; ORAL    2.4118        2.00       1.8057       3.0180\n#&gt; WRIT    2.2522        2.00       1.5698       2.9346\n#&gt; PHYS    4.9919        4.99       3.1346       6.8491\n#&gt; RTEN    3.3429        3.34       2.5902       4.0955\n#&gt; \n#&gt; Likelihood ratio test that transformation parameters are equal to 0\n#&gt;  (all log transformations)\n#&gt;                                                  LRT df       pval\n#&gt; LR test, lambda = (0 0 0 0 0 0 0 0 0 0 0 0) 121.8881 12 &lt; 2.22e-16\n#&gt; \n#&gt; Likelihood ratio test that no transformations are needed\n#&gt;                                                  LRT df       pval\n#&gt; LR test, lambda = (1 1 1 1 1 1 1 1 1 1 1 1) 61.75316 12 1.0794e-08",
    "crumbs": [
      "概率论与数理统计",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>正态性检验</span>"
    ]
  },
  {
    "objectID": "variance_homogeneity_test.html",
    "href": "variance_homogeneity_test.html",
    "title": "\n8  方差齐性检验\n",
    "section": "",
    "text": "8.1 两样本",
    "crumbs": [
      "概率论与数理统计",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>方差齐性检验</span>"
    ]
  },
  {
    "objectID": "variance_homogeneity_test.html#两样本",
    "href": "variance_homogeneity_test.html#两样本",
    "title": "\n8  方差齐性检验\n",
    "section": "",
    "text": "8.1.1 F 检验\nF 检验：比较两组的方差。数据必须呈正态分布。\n步骤：\n\n检查数据是否呈正态分布（例如使用 Shapiro-Wilk 检验）。\n进行 F 检验以比较两组的方差。\n\n\nCodedf &lt;- tibble(\n    ctrl=c(2,6,13,5,8,9,12,11,8,10,12,14,13,6,7,4),\n    trt=c(8,6,8,9,12,12,14,15,16,17,14,12,11,8,10,10)\n)\ndf %&gt;% \n    DT::datatable()\n\n\n\n\nCodevar.test(df$ctrl,df$trt)\n#&gt; \n#&gt;  F test to compare two variances\n#&gt; \n#&gt; data:  df$ctrl and df$trt\n#&gt; F = 1.2553, num df = 15, denom df = 15, p-value = 0.6653\n#&gt; alternative hypothesis: true ratio of variances is not equal to 1\n#&gt; 95 percent confidence interval:\n#&gt;  0.4385898 3.5927405\n#&gt; sample estimates:\n#&gt; ratio of variances \n#&gt;           1.255285\n\nres &lt;- var.test(len ~ supp, data = ToothGrowth)\nres\n#&gt; \n#&gt;  F test to compare two variances\n#&gt; \n#&gt; data:  len by supp\n#&gt; F = 0.6386, num df = 29, denom df = 29, p-value = 0.2331\n#&gt; alternative hypothesis: true ratio of variances is not equal to 1\n#&gt; 95 percent confidence interval:\n#&gt;  0.3039488 1.3416857\n#&gt; sample estimates:\n#&gt; ratio of variances \n#&gt;          0.6385951\n\n\np 值为 p = 0.2，大于显著性水平 0.05，可以认为两个方差之间没有显著差异。",
    "crumbs": [
      "概率论与数理统计",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>方差齐性检验</span>"
    ]
  },
  {
    "objectID": "variance_homogeneity_test.html#多样本",
    "href": "variance_homogeneity_test.html#多样本",
    "title": "\n8  方差齐性检验\n",
    "section": "\n8.2 多样本",
    "text": "8.2 多样本\n\n8.2.1 Bartlett 检验\nBartlett 检验：比较两组或多组的方差。数据必须呈正态分布。\n具有一个自变量的 Bartlett 检验\n\nCoderes &lt;- bartlett.test(weight ~ group, data = PlantGrowth)\nres\n#&gt; \n#&gt;  Bartlett test of homogeneity of variances\n#&gt; \n#&gt; data:  weight by group\n#&gt; Bartlett's K-squared = 2.8786, df = 2, p-value = 0.2371\n\n\n具有多个自变量的 Bartlett 检验：必须使用interaction（） 函数将多个因子折叠成一个包含因子所有组合的变量\n\nCode\nwith(ToothGrowth,interaction(supp,dose)) |&gt; levels()\n#&gt; [1] \"OJ.0.5\" \"VC.0.5\" \"OJ.1\"   \"VC.1\"   \"OJ.2\"   \"VC.2\"\n\n\n\nbartlett.test(len ~ interaction(supp,dose), data=ToothGrowth)\n#&gt; \n#&gt;  Bartlett test of homogeneity of variances\n#&gt; \n#&gt; data:  len by interaction(supp, dose)\n#&gt; Bartlett's K-squared = 6.9273, df = 5, p-value = 0.2261\n\n\n\n8.2.2 Levene’s 检验\nLevene’s 检验：Bartlett 检验的可靠替代方案，对偏离正态不太敏感。\n\n\nLevene 检验有三个版本：\n\n使用平均值（原始）\n使用中位数（Brown-Forsythe扩展）\n10% trimmed mean（Brown-Forsythe扩展）\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nLevene 检验是文献中最常用的检验。\n\n\n\nCodelibrary(car)\n# Levene's test with one independent variable\nleveneTest(weight ~ group, data = PlantGrowth,center=mean)\n\n\n\n\n\nDf\nF value\nPr(&gt;F)\n\n\n\ngroup\n2\n1.236963\n0.3061949\n\n\n\n27\nNA\nNA\n\n\n\n\n\nCodeleveneTest(weight ~ group, data = PlantGrowth,center=mean,trim=0.1)\n\n\n\n\n\nDf\nF value\nPr(&gt;F)\n\n\n\ngroup\n2\n1.277734\n0.2949851\n\n\n\n27\nNA\nNA\n\n\n\n\n\nCodeleveneTest(weight ~ group, data = PlantGrowth,center=median)\n\n\n\n\n\nDf\nF value\nPr(&gt;F)\n\n\n\ngroup\n2\n1.119186\n0.3412266\n\n\n\n27\nNA\nNA\n\n\n\n\n\nCode\nrstatix::levene_test(PlantGrowth,weight ~ group,center = mean)\n\n\n\n\ndf1\ndf2\nstatistic\np\n\n\n2\n27\n1.236963\n0.3061949\n\n\n\n\n\n\nCode# Levene's test with multiple independent variables\nToothGrowth$dose &lt;- factor(ToothGrowth$dose)\nleveneTest(len ~ supp*dose, data = ToothGrowth)\n\n\n\n\n\nDf\nF value\nPr(&gt;F)\n\n\n\ngroup\n5\n1.708578\n0.1483606\n\n\n\n54\nNA\nNA\n\n\n\n\n\n\n\nBrown-Forsythe 检验 作为 Levene 检验的扩展，特别适用于处理非正态数据。\n\n\nCodeleveneTest(weight ~ group, data = PlantGrowth,center=median)\n\n\n\n\n\nDf\nF value\nPr(&gt;F)\n\n\n\ngroup\n2\n1.119186\n0.3412266\n\n\n\n27\nNA\nNA\n\n\n\n\n\nCodeHH::hov(weight ~ group, data = PlantGrowth)\n#&gt; \n#&gt;  hov: Brown-Forsyth\n#&gt; \n#&gt; data:  weight\n#&gt; F = 1.1192, df:group = 2, df:Residuals = 27, p-value = 0.3412\n#&gt; alternative hypothesis: variances are not identical\n\n\n\n8.2.3 Fligner-Killeen 检验\nFligner-Killeen 检验：一种非参数检验，对偏离正态非常稳健。\n\nCodefligner.test(weight ~ group, data = PlantGrowth)\n#&gt; \n#&gt;  Fligner-Killeen test of homogeneity of variances\n#&gt; \n#&gt; data:  weight by group\n#&gt; Fligner-Killeen:med chi-squared = 2.3499, df = 2, p-value = 0.3088",
    "crumbs": [
      "概率论与数理统计",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>方差齐性检验</span>"
    ]
  },
  {
    "objectID": "t_test.html",
    "href": "t_test.html",
    "title": "\n9  t 检验\n",
    "section": "",
    "text": "9.1 假设",
    "crumbs": [
      "概率论与数理统计",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>t 检验</span>"
    ]
  },
  {
    "objectID": "t_test.html#假设",
    "href": "t_test.html#假设",
    "title": "\n9  t 检验\n",
    "section": "",
    "text": "正态性假设 (Normality)：\n\n两组数据应来自正态分布的总体。对于大样本（通常 n &gt; 30），由于中心极限定理，即使数据不完全符合正态分布，t 检验通常仍然稳健。\n\n\n\n方差齐性假设 (Homoscedasticity)：\n\n两组数据的方差应该相等。如果方差不相等，需使用 Welch’s t-test，它不假设方差齐性。\n\n\n\n独立性假设 (Independence)：\n\n样本中的观测应相互独立，一个观测的值不应影响另一个观测的值。",
    "crumbs": [
      "概率论与数理统计",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>t 检验</span>"
    ]
  },
  {
    "objectID": "t_test.html#t检验类型",
    "href": "t_test.html#t检验类型",
    "title": "\n9  t 检验\n",
    "section": "\n9.2 t检验类型",
    "text": "9.2 t检验类型\n\n单样本t检验 (One-sample t-test): 用于比较单个样本的均值与已知的总体均值之间的差异。\n独立样本t检验 (Independent samples t-test): 用于比较两个独立样本的均值差异。\n配对样本t检验 (Paired samples t-test): 用于比较同一组受试者在两个不同条件下的均值差异。\n\n\nCodeggplot() + xlim(-10,10) +\n    geom_function(mapping = aes(color=\"normal Distribution\"),\n                  fun = dnorm, args = list(mean = 0, sd = 1),\n                   )+\n    geom_function(mapping = aes(color=\"t Distribution\"),\n                  fun = dt, args = list(df = 1 ,ncp=0), \n                 )+\n    scale_color_manual(values = c(\"normal Distribution\" = \"red\",\n                                  \"t Distribution\" = \"blue\"))+\n    labs(color = \"Distribution\")\n\n\n\n\n\n\n\nt 检验（Student‘s t test），主要用于小样本（n&lt;30），标准差未知的正态分布总体。在进行t检验之前，可以先通过正态性检验 shapiro.test()",
    "crumbs": [
      "概率论与数理统计",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>t 检验</span>"
    ]
  },
  {
    "objectID": "t_test.html#单样本-t-检验",
    "href": "t_test.html#单样本-t-检验",
    "title": "\n9  t 检验\n",
    "section": "\n9.3 单样本 t 检验",
    "text": "9.3 单样本 t 检验\n在数据符合正态分布的前提下使用单样本t-test来比较一组样本的均值和已知(理论/总体)均值，所谓的已知均值能来自于之前的实验数据或者理论值。根据研究问题(原假设)的不同又分为双尾(不等)和单尾检验(大于或者小于)\n\\[t=\\frac{\\bar X-\\mu_0}{S /\\sqrt n} \\sim t(\\nu=n-1) \\]\n它是一种参数检验，用于检验样本均值是否可以合理地为总体均值或特定值。\n\nCodex&lt;- dplyr::filter(PlantGrowth,group==\"ctrl\")\nsummary(x$weight)\n#&gt;    Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n#&gt;   4.170   4.550   5.155   5.032   5.293   6.110\n\nshapiro.test(x$weight)\n#&gt; \n#&gt;  Shapiro-Wilk normality test\n#&gt; \n#&gt; data:  x$weight\n#&gt; W = 0.95668, p-value = 0.7475\nt.test(x$weight, mu=5)\n#&gt; \n#&gt;  One Sample t-test\n#&gt; \n#&gt; data:  x$weight\n#&gt; t = 0.17355, df = 9, p-value = 0.8661\n#&gt; alternative hypothesis: true mean is not equal to 5\n#&gt; 95 percent confidence interval:\n#&gt;  4.614882 5.449118\n#&gt; sample estimates:\n#&gt; mean of x \n#&gt;     5.032\n\n\n\nCodet_test_two_sided &lt;- function(data,mu,level=0.95,...){\n    \n    bar_X &lt;- mean(data,na.rm = T)\n    sd &lt;- sd(data, na.rm = T)\n    n=length(data)\n    se=sd/sqrt(n)\n    t_statistic &lt;- (bar_X-mu)/se\n    p_value &lt;- 2*(1-pt(abs(t_statistic),df=n-1))\n    t_critical &lt;- qt((1-(1-level)/2),df = n-1)\n    CI_lower &lt;- bar_X - t_critical * se\n    CI_upper &lt;- bar_X+ t_critical * se\n    CI &lt;- paste0(level*100,\"%置信区间: \",\"[\",CI_lower,\",\",CI_upper,\"]\",sep = \"\")\n    \n    output &lt;- list(\n        均值=bar_X,\n        标准差=sd,\n        标准误=se,\n        t=t_statistic,\n        df=n-1,\n        p_value=p_value,\n        CI=CI\n\n    )\n    return(output)\n    \n}\n\n\nt_test_two_sided(x$weight,mu = 5)\n#&gt; $均值\n#&gt; [1] 5.032\n#&gt; \n#&gt; $标准差\n#&gt; [1] 0.5830914\n#&gt; \n#&gt; $标准误\n#&gt; [1] 0.1843897\n#&gt; \n#&gt; $t\n#&gt; [1] 0.1735455\n#&gt; \n#&gt; $df\n#&gt; [1] 9\n#&gt; \n#&gt; $p_value\n#&gt; [1] 0.8660633\n#&gt; \n#&gt; $CI\n#&gt; [1] \"95%置信区间: [4.61488155565504,5.44911844434496]\"",
    "crumbs": [
      "概率论与数理统计",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>t 检验</span>"
    ]
  },
  {
    "objectID": "t_test.html#配对样本t检验",
    "href": "t_test.html#配对样本t检验",
    "title": "\n9  t 检验\n",
    "section": "\n9.4 配对样本t检验",
    "text": "9.4 配对样本t检验\n\\[\nH_0:\\mu_{\\bar d}=0\n\\] \\[\nt=\\frac{\\bar d- \\mu_{\\bar d}}{S_d /\\sqrt n} \\sim t(\\nu)\n\\] 其中\\(d= X_2-X_1,\\mu_{\\bar d}=0\\)。\n\nCodedf &lt;- tribble(\n    ~id,~baseline,~ten_days_later,~d,\n    1,58.27,120.61,62.34,\n    2,59.51,126.33,66.82,\n    3,53.84,108.35,54.51,\n    4,54.70,139.99,85.29,\n    5,54.03,115.29,61.26,\n    6,61.29,146.96,85.67,\n    7,54.72,115.64,60.92,\n    8,70.43,124.62,54.19,\n    9,66.45,121.40,54.95,\n    10,59.31,134.81,75.50,\n    11,63.48,130.73,67.25,\n    12,67.19,118.37,51.18,\n    13,52.92,129.28,76.36,\n    14,71.99,117.40,45.41\n)\nd_mean &lt;- mean(df$d)\nd_sd &lt;- sd(df$d)\nd_se &lt;- d_sd/sqrt(length(df$d))\nt_statistic &lt;- d_mean/d_se\nn &lt;- 14\n\n# p值\np_value &lt;- 2 * (1 - pt(abs(t_statistic),df = n-1 ))\n\n# 查找95%置信水平下的t分布的临界值\nt_critical &lt;- qt(0.975, df=n-1)\n\n# 计算95%置信区间\nCI_lower &lt;- d_mean - t_critical * d_se\nCI_upper &lt;- d_mean + t_critical * d_se\n\n# 输出结果\ncat(\"95% Confidence Interval:\", CI_lower, \"to\", CI_upper)\n#&gt; 95% Confidence Interval: 57.20275 to 71.6044\n\n\n\nCode\nshapiro.test(df$baseline)\n#&gt; \n#&gt;  Shapiro-Wilk normality test\n#&gt; \n#&gt; data:  df$baseline\n#&gt; W = 0.91419, p-value = 0.1813\nshapiro.test(df$ten_days_later)\n#&gt; \n#&gt;  Shapiro-Wilk normality test\n#&gt; \n#&gt; data:  df$ten_days_later\n#&gt; W = 0.96676, p-value = 0.8306\nshapiro.test(df$d)\n#&gt; \n#&gt;  Shapiro-Wilk normality test\n#&gt; \n#&gt; data:  df$d\n#&gt; W = 0.94337, p-value = 0.4632\nt.test(df$ten_days_later,df$baseline,paired = TRUE)\n#&gt; \n#&gt;  Paired t-test\n#&gt; \n#&gt; data:  df$ten_days_later and df$baseline\n#&gt; t = 19.322, df = 13, p-value = 5.866e-11\n#&gt; alternative hypothesis: true mean difference is not equal to 0\n#&gt; 95 percent confidence interval:\n#&gt;  57.20275 71.60440\n#&gt; sample estimates:\n#&gt; mean difference \n#&gt;        64.40357\n#t.test(Pair(df$ten_days_later,df$baseline)~1,data=df)",
    "crumbs": [
      "概率论与数理统计",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>t 检验</span>"
    ]
  },
  {
    "objectID": "t_test.html#两独立样本的均值差异",
    "href": "t_test.html#两独立样本的均值差异",
    "title": "\n9  t 检验\n",
    "section": "\n9.5 两独立样本的均值差异",
    "text": "9.5 两独立样本的均值差异\n\n9.5.1 方差相等——t检验\n\\[H_0:\\mu_1-\\mu_2=0\\]\n\\[\nt=\\frac{(\\bar X_1-\\bar X_2)-(\\mu_1-\\mu_2)}{S_{\\bar X_1-\\bar X_2}}=\\frac{\\bar X_1-\\bar X_2}{S_C\\sqrt{(\\frac{1}{n_1}+\\frac{1}{n_2})}}\n\\]\n其中，\\(S_c^2=\\frac{(n_1-1)S_1^2+(n_2-1)S_2^2}{n_1+n_2-2}\\)\n\nCodedf2 &lt;- tibble(\n    experimental=c(120.61 ,126.33 ,108.35 ,139.99 ,115.29 ,146.96 ,115.64,\n                   124.62 ,121.40 ,134.81 ,130.73 ,118.37 ,129.28 ,117.45),\n    control=c(58.23 ,54.50 ,59.47 ,59.64 ,53.77 ,43.48 ,\n              54.63 ,71.91 ,53.97 ,49.72 ,61.26 ,78.17,NA,NA)\n)\n\ne_mean &lt;- mean(df2$experimental)\ne_sd &lt;- sd(df2$experimental)\nn1 &lt;- length(df2$experimental)\n\nctrl_mean &lt;- mean(df2$control,na.rm = TRUE)\nctrl_sd &lt;- sd(df2$control,na.rm = TRUE)\nn2 &lt;- length(df2$control)-sum(is.na(df2$control))\n\nSc_2 &lt;- ((n1-1)*e_sd^2+(n2-1)*ctrl_sd^2)/(n1+n2-2)\n\nt2 &lt;- (e_mean-ctrl_mean)/sqrt(Sc_2*(1/14+1/12))\n\nt.test(df2$experimental,df2$control,var.equal = TRUE)\n#&gt; \n#&gt;  Two Sample t-test\n#&gt; \n#&gt; data:  df2$experimental and df2$control\n#&gt; t = 16.967, df = 24, p-value = 7.215e-15\n#&gt; alternative hypothesis: true difference in means is not equal to 0\n#&gt; 95 percent confidence interval:\n#&gt;  58.63784 74.87954\n#&gt; sample estimates:\n#&gt; mean of x mean of y \n#&gt; 124.98786  58.22917\n\n\n\n9.5.2 方差是否相等——F检验\n\\[H_0:\\frac{\\sigma_1^2}{\\sigma_2^2}=1\\]\n\\[\nF=\\frac{\\frac {(n_1-1)S_1^2}{\\sigma_1^2}/(n_1-1)}{\\frac {(n_2-1)S_2^2}{\\sigma_2^2}/(n_2-1)}=(\\frac{S_1^2}{S_2^2})(\\frac{\\sigma_2^2}{\\sigma_1^2})=\\frac{S_1^2}{S_2^2}\\sim F(\\nu_1,\\nu_2),\\nu_1=n_1-1,\\nu_2=n_2-1\n\\]\n\nCode# 检验两个样本的方差是否相等\nvar.test(df2$experimental,df2$control)\n#&gt; \n#&gt;  F test to compare two variances\n#&gt; \n#&gt; data:  df2$experimental and df2$control\n#&gt; F = 1.287, num df = 13, denom df = 11, p-value = 0.6831\n#&gt; alternative hypothesis: true ratio of variances is not equal to 1\n#&gt; 95 percent confidence interval:\n#&gt;  0.3794599 4.1152566\n#&gt; sample estimates:\n#&gt; ratio of variances \n#&gt;           1.287025\n\n\n\nCodeF_stats &lt;- (e_sd^2)/(ctrl_sd^2)\nF_stats\n#&gt; [1] 1.287025\n\n# 计算p值\np_value &lt;- 1 - pf(F_stats, df1=13, df2=11, lower.tail =F)\n# p_value &lt;- pf(F_stats, df1=13, df2=11)\n\n\n\nalpha &lt;- 0.05\nconfidence_level &lt;- 1 - alpha\n\n# 计算F分布的临界值\nf_critical_lower &lt;- qf((1 - confidence_level) / 2, df1 = 13, df2 = 11)\nf_critical_upper &lt;- qf(confidence_level, df1 = 13, df2 = 11)\n\n# 计算方差比率的置信区间\nci_lower &lt;- sqrt(f_critical_lower * (ctrl_sd^2 / e_sd^2))\nci_upper &lt;- sqrt(f_critical_upper * (ctrl_sd^2 / e_sd^2))\n\n# 输出结果\ncat(\"95% CI for variances ratio:\", ci_lower, \"to\", ci_upper)\n#&gt; 95% CI for variances ratio: 0.4929485 to 1.464781\n\n\n\n9.5.3 方差不等—— Approximation t 检验\n\\[H_0:\\mu_1-\\mu_2=0\\]\n\\[\nt'=\\frac{(\\bar X_1-\\bar X_2)-(\\mu_1-\\mu_2)}{\\sqrt{\\frac{S_1^2}{n_1}+\\frac{S_2^2}{n_2}}}=\\frac{\\bar X_1-\\bar X_2}{\\sqrt{\\frac{S_1^2}{n_1}+\\frac{S_2^2}{n_2}}}\\sim t(\\nu ')\n\\]\n\n9.5.3.1 Cochran & Cox Approximation t-test\n强调方差的变异\n因为\\(t'\\)既不遵循t分布，也不遵循正态分布，因此t’的临界值需要特定的计算方法。\n\\[\nt'_{\\alpha/2}=\\frac{S^2_{\\bar X_1}t_{\\nu_1,\\alpha/2}+S^2_{\\bar X_2}t_{\\nu_2,\\alpha/2}}{S^2_{\\bar X_1}+S^2_{\\bar X_2}}\n\\]\n\\[\nt'_{1-\\alpha/2}=\\frac{S^2_{\\bar X_1}t_{\\nu_1,1-\\alpha/2}+S^2_{\\bar X_2}t_{\\nu_2,1-\\alpha/2}}{S^2_{\\bar X_1}+S^2_{\\bar X_2}}\n\\] 其中\\(\\nu_1=n_1-1,\\nu_2=n_2-1,t_{\\nu_1,1-\\alpha/2}和t_{\\nu_2,1-\\alpha/2}\\)分别是\\(t_{\\nu_1}和t_{\\nu_2}\\)的临界值。\n因为t分布是对称的，\\(t_{\\nu,\\alpha/2}=-t_{\\nu,1-\\alpha/2}\\)，所以\\(t'_{\\alpha/2}=t'_{1-\\alpha/2}\\)。\n\n9.5.3.2 Satterthwaite Approximation t-test\n强调自由度\n\\[\nv'=\\frac{(\\frac{S_1^2}{n_1}+\\frac{S_2^2}{n_2})^2}{\\frac{(\\frac{S_1^2}{n_1})^2}{n_1-1}+\\frac{(\\frac{S_2^2}{n_2})^2}{n_2-1}}(舍入到最近整数)\n\\]\n\n9.5.4 中心极限定理 大样本量—— Z检验\n当\\(n_1＞30\\ \\&\\ n_2＞30\\)时，\n\\[\n\\bar X_1\\dot\\sim N(\\mu_1,\\frac{\\sigma^2_1}{n_1})\n\\]\n\\[\n\\bar X_2\\dot\\sim N(\\mu_2,\\frac{\\sigma^2_2}{n_2})\n\\]\n\\[H_0:\\mu_1-\\mu_2=0\\]\n\\[\nZ=\\frac{(\\bar X_1-\\bar X_2)-(\\mu_1-\\mu_2)}{\\sqrt{\\frac{\\sigma^2_1}{n_1}+\\frac{\\sigma^2_2}{n_2}}}=\\frac{\\bar X_1-\\bar X_2}{\\sqrt{\\frac{\\sigma^2_1}{n_1}+\\frac{\\sigma^2_2}{n_2}}}\\dot\\sim N(0,1)\n\\]\n实际应用中，总体方差未知，使用t 检验，提供了对总体方差不确定性的自然估计。",
    "crumbs": [
      "概率论与数理统计",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>t 检验</span>"
    ]
  },
  {
    "objectID": "t_test.html#批量t检验",
    "href": "t_test.html#批量t检验",
    "title": "\n9  t 检验\n",
    "section": "\n9.6 批量t检验",
    "text": "9.6 批量t检验",
    "crumbs": [
      "概率论与数理统计",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>t 检验</span>"
    ]
  },
  {
    "objectID": "t_test.html#功效分析",
    "href": "t_test.html#功效分析",
    "title": "\n9  t 检验\n",
    "section": "\n9.7 功效分析",
    "text": "9.7 功效分析\n功效(power) \\(1-β\\approx\\Phi(-z_{1-\\alpha/2}+\\frac{|\\mu_1-\\mu_2|}{\\sqrt {\\sigma_1^2/n_1+\\sigma_2^2/n_2}})\\)\n样本量\n\n两组样本量相等 \\[\nn=\\frac{(\\sigma_1^2+\\sigma_1^2)(z_{1-\\alpha/2}+z_{1-\\beta})^2}{(\\mu_1-\\mu_2)^2}\n\\]\n\n两组样本量不等（\\(n_2=kn_1\\)） \\[\nn_1=\\frac{(\\sigma_1^2+\\sigma_1^2/k)(z_{1-\\alpha/2}+z_{1-\\beta})^2}{(\\mu_1-\\mu_2)^2}\n\\]\n\\[\nn_2=\\frac{(k\\sigma_1^2+\\sigma_1^2)(z_{1-\\alpha/2}+z_{1-\\beta})^2}{(\\mu_1-\\mu_2)^2}\n\\]",
    "crumbs": [
      "概率论与数理统计",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>t 检验</span>"
    ]
  },
  {
    "objectID": "ANOVA.html",
    "href": "ANOVA.html",
    "title": "\n10  方差分析\n",
    "section": "",
    "text": "10.1 单因素组间方差分析",
    "crumbs": [
      "概率论与数理统计",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>方差分析</span>"
    ]
  },
  {
    "objectID": "ANOVA.html#单因素组间方差分析",
    "href": "ANOVA.html#单因素组间方差分析",
    "title": "\n10  方差分析\n",
    "section": "",
    "text": "10.1.1 计算公式\n\n\n\n\n因子A有\\(A_1,A_2,...,A_k\\)共k个水平\ntotal sum of squares\n\\[\nSS_T=\\sum_{j=1}^{k}\\sum_{i=1}^{n_j}X_{ij}^2-\\frac{(\\sum_{j=1}^{k}\\sum_{i=1}^{n_j}X_{ij})^2}{n}=SS_{组间}+SS_{组内}\n\\]\nbetween groups sum of squares \\[\nSS_{组间}=\\sum_{j=1}^{k}\\frac{(\\sum_{i=1}^{n_j}X_{ij})^2}{n_j}-\\frac{(\\sum_{j=1}^{k}\\sum_{i=1}^{n_j}X_{ij})^2}{n}\n\\]\n自由度\\(\\nu=n-1,\\nu_{组间}=k-1,\\nu_{组内}=\\sum_{j=1}^{k}(n_j-1)=n-k\\)\nBetween groups mean square \\(MS_{组间}=\\frac{SS_{组间}}{k-1}\\)\nWithin groups mean square \\(MS_{组内}=\\frac{SS_{组内}}{n-k}\\)\n\\[H_0:\\mu_1=\\mu_2=...=\\mu_k\\]\n\\[\n\\frac{SS_T}{\\sigma^2}\\sim \\chi^2(\\nu),\\nu=n-1\n\\] \\[\n\\frac{SS_{组内}}{\\sigma^2}\\sim \\chi^2(\\nu),\\nu=n-k\n\\] 因此，\n\\[\n\\frac{SS_{组间}}{\\sigma^2}=\\frac{SS_T}{\\sigma^2}-\\frac{SS_{组内}}{\\sigma^2}\\ \\ \\ \\sim \\chi^2(\\nu),\\nu=k-1\n\\]\n检验统计量\n\\[\nF=\\frac{\\frac{SS_{组间}}{(k-1)\\sigma^2}}{\\frac{SS_{组内}}{(n-k)\\sigma^2}}=\\frac{\\frac{SS_{组间}}{k-1}}{\\frac{SS_{组内}}{n-k}}=\\frac{MS_{组间}}{MS_{组内}}\\ \\ \\ \\sim \\chi^2(\\nu),\\nu=k-1\n\\]\n\n\n\n\n\nCodedf &lt;- tibble(\n    low=c(53.5,43.7,46.5,50.3,56.1),\n    medium=c(33.2,30.6,23.9,26.4,35.9),\n    high=c(11.5,21.9,18.6,13.6,9.5)\n)\n\n\n\n10.1.2 手算\n\nCodek &lt;- 3\ndf_sum &lt;- sum(df)\ndf_sum_square &lt;- sum(df^2)\nn &lt;- 15\nC &lt;- df_sum^2/n\n\nSS_T &lt;- df_sum_square-C\nSS_between &lt;- apply(df, 2, function(x) sum(sum(x)^2/length(x))) |&gt; sum()-C\n\nSS_within &lt;- SS_T-SS_between\n\nMS_between &lt;- SS_between/(k-1)\nMS_within &lt;- SS_within/(n-k)\nF_stat &lt;-MS_between/MS_within \n\np_value &lt;- pf(F_stat,2,12,lower.tail = F)\n\n\n\n10.1.3 stats::aov()\n\n\nCodedf_long &lt;- df |&gt; pivot_longer(cols = everything(),\n                              names_to = \"level\",\n                              values_to = \"value\")\ndf_long$level &lt;- factor(df_long$level)\ndf_aov &lt;- aov(value~level,data = df_long)\n\nanova(df_aov)\n\n\n\n\n\nDf\nSum Sq\nMean Sq\nF value\nPr(&gt;F)\n\n\n\nlevel\n2\n3083.668\n1541.83400\n61.24546\n5e-07\n\n\nResiduals\n12\n302.096\n25.17467\nNA\nNA\n\n\n\n\n\n\n\n10.1.4 ez::ezANOVA()\n\n\nCodedf_long &lt;- df_long |&gt; rowid_to_column(var = \"id\") |&gt; \n    relocate(id,.before = 1) |&gt; mutate(id=factor(id))\n\nez::ezANOVA(data = df_long,\n            dv = value,\n            wid = id,\n            between = level,\n            type = 3,\n            detailed = T)\n#&gt; $ANOVA\n#&gt;        Effect DFn DFd       SSn     SSd         F            p p&lt;.05       ges\n#&gt; 1 (Intercept)   1  12 15054.336 302.096 597.99545 1.318663e-11     * 0.9803277\n#&gt; 2       level   2  12  3083.668 302.096  61.24546 5.045797e-07     * 0.9107746\n#&gt; \n#&gt; $`Levene's Test for Homogeneity of Variance`\n#&gt;   DFn DFd        SSn   SSd           F         p p&lt;.05\n#&gt; 1   2  12 0.05733333 92.36 0.003724556 0.9962835\n\n\n\n10.1.5 stats::lm()\n\n\nCodelm_aov &lt;- lm(formula = value ~  level, data = df_long)\nlm_aov\n#&gt; \n#&gt; Call:\n#&gt; lm(formula = value ~ level, data = df_long)\n#&gt; \n#&gt; Coefficients:\n#&gt; (Intercept)     levellow  levelmedium  \n#&gt;       15.02        35.00        14.98\n\nanova(lm_aov)\n\n\n\n\n\nDf\nSum Sq\nMean Sq\nF value\nPr(&gt;F)\n\n\n\nlevel\n2\n3083.668\n1541.83400\n61.24546\n5e-07\n\n\nResiduals\n12\n302.096\n25.17467\nNA\nNA\n\n\n\n\n\nCode\nmodel.matrix(~ level, data = df_long)\n#&gt;    (Intercept) levellow levelmedium\n#&gt; 1            1        1           0\n#&gt; 2            1        0           1\n#&gt; 3            1        0           0\n#&gt; 4            1        1           0\n#&gt; 5            1        0           1\n#&gt; 6            1        0           0\n#&gt; 7            1        1           0\n#&gt; 8            1        0           1\n#&gt; 9            1        0           0\n#&gt; 10           1        1           0\n#&gt; 11           1        0           1\n#&gt; 12           1        0           0\n#&gt; 13           1        1           0\n#&gt; 14           1        0           1\n#&gt; 15           1        0           0\n#&gt; attr(,\"assign\")\n#&gt; [1] 0 1 1\n#&gt; attr(,\"contrasts\")\n#&gt; attr(,\"contrasts\")$level\n#&gt; [1] \"contr.treatment\"\nlm(formula = value ~ 0 + level, data = df_long)\n#&gt; \n#&gt; Call:\n#&gt; lm(formula = value ~ 0 + level, data = df_long)\n#&gt; \n#&gt; Coefficients:\n#&gt;   levelhigh     levellow  levelmedium  \n#&gt;       15.02        50.02        30.00\nmodel.matrix(~ 0 + level, data = df_long)\n#&gt;    levelhigh levellow levelmedium\n#&gt; 1          0        1           0\n#&gt; 2          0        0           1\n#&gt; 3          1        0           0\n#&gt; 4          0        1           0\n#&gt; 5          0        0           1\n#&gt; 6          1        0           0\n#&gt; 7          0        1           0\n#&gt; 8          0        0           1\n#&gt; 9          1        0           0\n#&gt; 10         0        1           0\n#&gt; 11         0        0           1\n#&gt; 12         1        0           0\n#&gt; 13         0        1           0\n#&gt; 14         0        0           1\n#&gt; 15         1        0           0\n#&gt; attr(,\"assign\")\n#&gt; [1] 1 1 1\n#&gt; attr(,\"contrasts\")\n#&gt; attr(,\"contrasts\")$level\n#&gt; [1] \"contr.treatment\"\n\n\n\n10.1.6 事后检验\n成对比较的数量 \\(N=\\frac{k!}{2!(k-2)!},k≥3\\)，导致犯第Ⅰ类错误的概率迅速增加，\\([1-(1-\\alpha)^N]\\)。\n\n10.1.6.1 Tukey’s test\nTukey’s test 也被称为Tukey’s honestly significant difference (Tukey’s HSD) test。\n\nk个均值从大到小排列；\n均值最大的组依次与均值最小，第二小，……，第二大比较；\n均值第二大的组以同样的方式比较；\n以此类推\n在各组样本量相等的情况下，如果在两个均值之间未发现显著差异，则推断这两个均值所包含的任何均值之间不存在显著差异，并且不再检验所包含均值之间的差异。\n\nstudentized range statistic \\(q=\\frac{\\bar X_{max}-\\bar X_{min}}{S_{\\bar X_{max}-\\bar X_{min}}}\\)，其中\\(S_{\\bar X_{max}-\\bar X_{min}}=\\sqrt{\\frac{MS_{组内}}{n}}\\)，\\(n\\)是每一个治疗组的样本量。\n如果各组样本量不等,则\\(S_{\\bar X_{max}-\\bar X_{min}}=\\sqrt{\\frac{MS_{组内}}{2}(\\frac{1}{n_i}+\\frac{1}{n_j})}\\)\n检验统计量\n\\[\nHSD=q_{(k,\\nu_{组内}),1-\\alpha} \\times S_{\\bar X_{max}-\\bar X_{min}},\\nu_{组内}=k(n_j-1)\n\\]\n对于任意i,j且\\(\\bar X_i＞\\bar X_j\\)，如果\\(\\bar X_i-\\bar X_j＞HSD\\)，那么拒绝\\(H_0\\)，说明这两组存在显著差异。\n\\[\nH_0:\\mu_i=\\mu_j(i≠j)\n\\]\n\nCodek_means &lt;- apply(df,2,mean) |&gt; sort(,decreasing = TRUE)\nk_means\n#&gt;    low medium   high \n#&gt;  50.02  30.00  15.02\n\n# 附录q  q(3,12),1-0.05  3(5-1)=12\nq_critical_value &lt;- 3.77\nnj &lt;- 5\nHSD &lt;- q_critical_value*sqrt(MS_within/nj)\n\nk_means\n#&gt;    low medium   high \n#&gt;  50.02  30.00  15.02\ndiff_means &lt;- c()\nnames_diff_means &lt;- c()\n\nfor(i in 1:(length(k_means)-1)){\n    for(j in length(k_means):(i+1)){\n        diff_value &lt;- k_means[i] - k_means[j]\n        diff_means &lt;- c(diff_means, diff_value)\n        names_diff_means &lt;- c(names_diff_means, paste(names(k_means)[i], \"vs.\", names(k_means)[j],sep = \"_\"))\n    }\n}\nnames(diff_means) &lt;- names_diff_means\ndiff_means\n#&gt;    low_vs._high  low_vs._medium medium_vs._high \n#&gt;           35.00           20.02           14.98\n#全为真，3组成对比较都存在显著差异\ndiff_means &gt; HSD \n#&gt;    low_vs._high  low_vs._medium medium_vs._high \n#&gt;            TRUE            TRUE            TRUE\n\n\n\nCodepairwise &lt;- TukeyHSD(df_aov)\npairwise\n#&gt;   Tukey multiple comparisons of means\n#&gt;     95% family-wise confidence level\n#&gt; \n#&gt; Fit: aov(formula = value ~ level, data = df_long)\n#&gt; \n#&gt; $level\n#&gt;               diff        lwr       upr     p adj\n#&gt; low-high     35.00  26.534054  43.46595 0.0000003\n#&gt; medium-high  14.98   6.514054  23.44595 0.0013315\n#&gt; medium-low  -20.02 -28.485946 -11.55405 0.0001069\n\n\n\n10.1.6.2 Dunnett’s test\nDunnett’s test也称为q’-test,是两独立样本t-test的一种修正。Dunnett’s test 假设数据符合正态分布，并且各组的方差相等。 控制对照组（C）与其他每个实验组（T）比较。\n\\(H_0:\\mu_C=\\mu_T\\)\n\\[\nq'=\\frac{\\bar X_T-\\bar X_C}{\\sqrt{MS_{组内}(\\frac{1}{n_T}+\\frac{1}{n_C})}} \\sim q'(\\nu,a) \\ \\ \\nu=\\nu_{组内},a=k\n\\]\n临界值 \\(q'_{(a,\\nu_E),1-\\alpha/2}\\)\n\nCodenT &lt;- nC &lt;- 5 \n\nSE_mean_diff &lt;- sqrt(MS_within*(1/nT+1/nC))\n\nk_means\n#&gt;    low medium   high \n#&gt;  50.02  30.00  15.02\ndiff_means &lt;- c()\nnames_diff_means &lt;- c()\n\n# 以 low 作控制组\nfor(i in 2:length(k_means)){\n        diff_value &lt;- k_means[i] - k_means[1]\n        diff_means &lt;- c(diff_means, diff_value)\n        names_diff_means &lt;- c(names_diff_means, paste(names(k_means)[1], \"vs.\", names(k_means)[i],sep = \"_\"))\n}\nnames(diff_means) &lt;- names_diff_means\ndiff_means\n#&gt; low_vs._medium   low_vs._high \n#&gt;         -20.02         -35.00\n\nq撇_stat &lt;- diff_means/SE_mean_diff\n\n# 附录q'  q'(3,12),1-0.05/2  \nabs(q撇_stat)&gt;2.50  \n#&gt; low_vs._medium   low_vs._high \n#&gt;           TRUE           TRUE\n#全为真，各实验组与控制组均存在显著差异\n\n\n\nCodelibrary(multcomp)\ndunnett_result &lt;- glht(df_aov, linfct =mcp(level =c(\"medium - low = 0\", \"high - low = 0\")))\n\n# 查看 Dunnett's test 结果\nsummary(dunnett_result)\n#&gt; \n#&gt;   Simultaneous Tests for General Linear Hypotheses\n#&gt; \n#&gt; Multiple Comparisons of Means: User-defined Contrasts\n#&gt; \n#&gt; \n#&gt; Fit: aov(formula = value ~ level, data = df_long)\n#&gt; \n#&gt; Linear Hypotheses:\n#&gt;                   Estimate Std. Error t value Pr(&gt;|t|)    \n#&gt; medium - low == 0  -20.020      3.173  -6.309 7.46e-05 ***\n#&gt; high - low == 0    -35.000      3.173 -11.030 2.38e-07 ***\n#&gt; ---\n#&gt; Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n#&gt; (Adjusted p values reported -- single-step method)\n\n\n\n10.1.6.3 LSD-t test\nleast significant difference t-test\n挑选任意感兴趣的两组进行比较\n\\[\nH_0:\\mu_i=\\mu_j(i≠j)\n\\]\n\\[\nLSD-t=\\frac{\\bar X_i-\\bar X_j}{\\sqrt{MS_{组内}(\\frac{1}{n_i}+\\frac{1}{n_j})}} \\sim t(\\nu) \\ ,\\ \\nu=\\nu_{组内}=n-k,a=k\n\\]\n\nCode# medium high\nLSD &lt;- (k_means[2]-k_means[3])/sqrt(MS_within*(1/5+1/5))\n\n# 附录 t(12,1-0.05/2)=2.719",
    "crumbs": [
      "概率论与数理统计",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>方差分析</span>"
    ]
  },
  {
    "objectID": "ANOVA.html#方差分析假设",
    "href": "ANOVA.html#方差分析假设",
    "title": "\n10  方差分析\n",
    "section": "\n10.2 方差分析假设",
    "text": "10.2 方差分析假设\nhttps://www.statmethods.net/stats/rdiagnostics.html\n\n10.2.1 独立性\n\n10.2.2 正态性\n\nCode# 异常观测点\n\ncar::outlierTest(df_aov) \n#&gt; No Studentized residuals with Bonferroni p &lt; 0.05\n#&gt; Largest |rstudent|:\n#&gt;   rstudent unadjusted p-value Bonferroni p\n#&gt; 6  1.63682            0.12993           NA\n\n\n\n10.2.2.1 直方图/茎叶图\n\n10.2.2.2 P-P图/Q-Q图\n\n10.2.2.3 偏度和峰度\n\\[\nH_0:总体偏度系数\\gamma_1=0 或者总体峰度系数\\gamma_2=0\n\\]\n\\[\nz_i=\\frac{g_i-0}{\\sigma_{g_i}}  \\ \\ \\ \\ 临界值z_{1-\\alpha/2}\n\\]\n\n10.2.2.4 Shapiro-Wilk检验（小样本）\n\nCodeshapiro.test(df$low)  \n#&gt; \n#&gt;  Shapiro-Wilk normality test\n#&gt; \n#&gt; data:  df$low\n#&gt; W = 0.9718, p-value = 0.8867\nshapiro.test(df$medium)  \n#&gt; \n#&gt;  Shapiro-Wilk normality test\n#&gt; \n#&gt; data:  df$medium\n#&gt; W = 0.96762, p-value = 0.8598\nshapiro.test(df$high)  \n#&gt; \n#&gt;  Shapiro-Wilk normality test\n#&gt; \n#&gt; data:  df$high\n#&gt; W = 0.94361, p-value = 0.6916\n\n# 因为观测太少，也可以同时检验\nshapiro.test(c(df$low,df$medium,df$high))  \n#&gt; \n#&gt;  Shapiro-Wilk normality test\n#&gt; \n#&gt; data:  c(df$low, df$medium, df$high)\n#&gt; W = 0.94559, p-value = 0.4578\n\n\n\n10.2.2.5 Kolmogorov-Smirnov检验（Lilliefors correction 大样本）\n\nCodeks.test(c(df$low,df$medium,df$high),\"pnorm\")\n#&gt; \n#&gt;  Exact one-sample Kolmogorov-Smirnov test\n#&gt; \n#&gt; data:  c(df$low, df$medium, df$high)\n#&gt; D = 1, p-value &lt; 2.2e-16\n#&gt; alternative hypothesis: two-sided\nks.test(rnorm(1000),\"pnorm\")\n#&gt; \n#&gt;  Asymptotic one-sample Kolmogorov-Smirnov test\n#&gt; \n#&gt; data:  rnorm(1000)\n#&gt; D = 0.031901, p-value = 0.2607\n#&gt; alternative hypothesis: two-sided\n\n\n\nCodex &lt;- rnorm(50) \ny &lt;- runif(50) \nks.test(x, y)  # perform ks test\n#&gt; \n#&gt;  Exact two-sample Kolmogorov-Smirnov test\n#&gt; \n#&gt; data:  x and y\n#&gt; D = 0.56, p-value = 1.453e-07\n#&gt; alternative hypothesis: two-sided\n\nx &lt;- rnorm(50)\ny &lt;- rnorm(50)\nks.test(x, y) \n#&gt; \n#&gt;  Exact two-sample Kolmogorov-Smirnov test\n#&gt; \n#&gt; data:  x and y\n#&gt; D = 0.2, p-value = 0.2719\n#&gt; alternative hypothesis: two-sided\n\n\n\n10.2.3 方差齐性\nhttp://www.cookbook-r.com/Statistical_analysis/Homogeneity_of_variance/\n\n10.2.3.1 Bartlett’s test\n数据满足正态性\n比较每一组方差的加权算术均值和几何均值。\n\\[\nH_0:\\sigma_1^2=\\sigma_2^2=...=\\sigma_k^2\n\\] 当样本量\\(n_j\\)≥5时，检验统计量(各组样本量相等)\n\\[\nB=\\frac{(n-1)[kln\\bar S^2-\\sum_{j=1}^{k}lnS_j^2]}{1+\\frac{k+1}{3k(n-1)}} \\sim\\ \\chi^2(\\nu)\\ ,\\nu=k-1\n\\] 其中n是每一组的样本量，\\(S_j^2\\)是某一组的样本方差，\\(\\bar S^2\\)是所有k个组样本方差的平均值。\n当各组样本量不等时，\n\\[\nB=\\frac{\\sum_{j=1}^{k}(n_j-1)ln\\frac{\\bar S^2}{S_j^2}}{1+\\frac{1}{3(k-1)}(\\sum_{j=1}^{k}\\frac {1}{n_j-1}-\\frac{1}{\\sum_{j=1}^{k}(n_j-1)})} \\sim\\ \\chi^2(\\nu)\\ ,\\nu=k-1\n\\] 其中\\(h_j\\)是某一组的样本量，\\(\\bar S^2=(\\sum_{j=1}^{k}(n_j-1)S_j^2)/(\\sum_{j=1}^{k}(n_j-1))\\)是所有k个组样本方差的加权平均值。\n\nCoden1=n2=n3=5\nk=3\nS2 &lt;- apply(df,2,var)\nS2\n#&gt;    low medium   high \n#&gt; 25.372 23.895 26.257\n\nlnS2 &lt;- log(S2)\nlnS2\n#&gt;      low   medium     high \n#&gt; 3.233646 3.173669 3.267933\n\nS2_mean &lt;- (5-1)*(sum(S2))/(3*(5-1))\nS2_mean\n#&gt; [1] 25.17467\n\n\n\nB &lt;- ((5-1)*(3*log(S2_mean)-sum(lnS2)))/(1+(3+1)/(3*3*(5-1)))\nB\n#&gt; [1] 0.008159536\n\n\n\nCodebartlett.test(df)\n#&gt; \n#&gt;  Bartlett test of homogeneity of variances\n#&gt; \n#&gt; data:  df\n#&gt; Bartlett's K-squared = 0.0081595, df = 2, p-value = 0.9959\n\n\n\n10.2.3.2 Levene’s test\n数据不满足正态性\n\nk个随机样本是独立的\n随机变量X是连续的\n\nLevene 变换：\n\\[\nZ_{ij}=|X_{ij}-\\bar X_{.\\ j}|(i=1,2...,n_j;\\ j=1,2,...,k)\n\\]\n\nCodeoptions(digits = 2)\nz_df &lt;- bind_cols(\n    low=df[1]-k_means[1],\n    medium=df[2]-k_means[2],\n    high=df[3]-k_means[3]\n) |&gt; abs()\n    \n\nz_df\n\n\n\n\nlow\nmedium\nhigh\n\n\n\n3.48\n3.2\n3.5\n\n\n6.32\n0.6\n6.9\n\n\n3.52\n6.1\n3.6\n\n\n0.28\n3.6\n1.4\n\n\n6.08\n5.9\n5.5\n\n\n\n\n\n\n检验统计量（基于变换后的F检验）\n\\[\nW=\\frac{MS_{组间}}{MS_{组内}}=\\frac{\\sum_jn_j(\\bar Z_{.j}-\\bar Z_{..})^2/(k-1)}{\\sum_j\\sum_i(Z_{ij}-\\bar Z_{.j})^2/(n-k)}  \\sim F(\\nu_1,\\nu_2)   \\ \\ \\ \\ \\nu_1=k-1,\\nu_2=n-k\n\\]\n\nCodev1=3-1\nv2=15-3\n\n\nz.j_mean &lt;- apply(z_df, 2, mean)\nz.j_mean\n#&gt;    low medium   high \n#&gt;    3.9    3.9    4.2\n\nz_mean &lt;- mean(z.j_mean)\nz_mean \n#&gt; [1] 4\n\noptions(digits = 4)\nW &lt;- 12*sum(5*(z.j_mean-z_mean)^2)/(2*(sum((z_df$low-z.j_mean[1])^2)+sum((z_df$medium-z.j_mean[2])^2)+sum((z_df$high-z.j_mean[3])^2)))\n\nW\n#&gt; [1] 0.0254",
    "crumbs": [
      "概率论与数理统计",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>方差分析</span>"
    ]
  },
  {
    "objectID": "ANOVA.html#welchs-anova-test",
    "href": "ANOVA.html#welchs-anova-test",
    "title": "\n10  方差分析\n",
    "section": "\n10.3 Welch’s ANOVA Test",
    "text": "10.3 Welch’s ANOVA Test",
    "crumbs": [
      "概率论与数理统计",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>方差分析</span>"
    ]
  },
  {
    "objectID": "ANOVA.html#数据变换",
    "href": "ANOVA.html#数据变换",
    "title": "\n10  方差分析\n",
    "section": "\n10.4 数据变换",
    "text": "10.4 数据变换\n当方差分析的正态性假设或方差齐性假设不为真时，通常使用(1)数据变换方法；(2)非参数检验方法 比较均值差异\n\n10.4.1 平方根变换\n当每个水平组的方差与均值成比例，尤其是样本来自泊松分布\n\\[\nY=\\sqrt{X}\n\\]\n当数据中有零或非常小的值时，\n\\[\nY=\\sqrt{X+a} \\ \\ \\ \\ a=0.5或0.1\n\\]\n\n10.4.2 对数变换\n当数据方差不齐且每个水平组标准差与均值成比例时\n\\[\nY=\\log{X} \\ \\ \\ \\ base=e或10\n\\]\n当数据中有零或负值时，\n\\[\nY=\\log{(X+a)} \\ \\ \\ \\ a为实数，使得X+a&gt;0\n\\]\n\n10.4.3 反正弦平方根变换\n率，服从二项分布\\(B(n,\\pi)\\)\n\\[\nY=\\arcsin {\\sqrt{\\pi}} \\ \\ \\ \\\n\\]",
    "crumbs": [
      "概率论与数理统计",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>方差分析</span>"
    ]
  },
  {
    "objectID": "repeated_measures_ANOVA.html",
    "href": "repeated_measures_ANOVA.html",
    "title": "\n11  重复测量方差分析\n",
    "section": "",
    "text": "11.1 假设条件",
    "crumbs": [
      "概率论与数理统计",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>重复测量方差分析</span>"
    ]
  },
  {
    "objectID": "repeated_measures_ANOVA.html#假设条件",
    "href": "repeated_measures_ANOVA.html#假设条件",
    "title": "\n11  重复测量方差分析\n",
    "section": "",
    "text": "独立性假设，即不同受试者之间的观测值是独立的。\n观测值在每个时间点或条件下的正态分布。\n各组内的方差齐性（sphericity），即组内相关性结构是已知的，通常假设为复合对称（compound symmetry）。协方差矩阵的球形检验（W=1）\n\n\n\n\n\n\n\nNote\n\n\n\n\n复合对称假设：RM-ANOVA假设误差项具有复合对称性，即组内相关性和方差齐性。如果复合对称假设不成立，结果可能不准确，可以使用更为灵活的线性混合模型（LMM）或广义估计方程（GEE）进行分析。\n检验方法：RM-ANOVA的主要检验方法包括F检验，用于检验组效应、时间效应和交互作用是否显著。",
    "crumbs": [
      "概率论与数理统计",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>重复测量方差分析</span>"
    ]
  },
  {
    "objectID": "repeated_measures_ANOVA.html#单因素重复测量方差分析",
    "href": "repeated_measures_ANOVA.html#单因素重复测量方差分析",
    "title": "\n11  重复测量方差分析\n",
    "section": "\n11.2 单因素重复测量方差分析",
    "text": "11.2 单因素重复测量方差分析\n\n11.2.1 原理公式\n\\[\nSS_T=\\sum_{j=1}^{t}\\sum_{i=1}^{n}X_{ij}^2-\\frac{(\\sum_{j=1}^{t}\\sum_{i=1}^{n}X_{ij})^2}{nt}=SS_{受试者间}+SS_{不同时间点}+SS_{E\\ \\ 随机误差}，\\nu_T=nt-1\n\\]\n\\[\nSS_{受试者间}=\\frac{\\sum_{i}(\\sum_{j}X_{ij})^2}{t}-C，\\nu_{受试者}=n-1\n\\]反映了在受试者间的变异。\n\\[\nSS_{不同时间点}=\\frac{\\sum_{j}(\\sum_{i}X_{ij})^2}{n}-C ，\\nu_{时间点}=t-1\n\\]反映了在每个受试者内不同时间点的重复测量变异。\n\\[\nSS_E=SS_T-SS_{受试者间}-SS_{不同时间点}，\\nu_E=(n-1)(t-1)\n\\]\n\\(H_0:\\mu_1=\\mu_2=...=\\mu_t\\)，检验统计量\n\\[\nF=\\frac{MS_{不同时间点}}{MS_E}=\\frac{SS_{不同时间点}/(t-1)}{SS_E/((n-1)(t-1))}\n\\]\n\nCodedf &lt;- tribble(\n    ~id,~zero,~ten,~twenty,~thirty,\n    1,186,122,134,110,\n    2,345,312,268,176,\n    3,98,84,52,61,\n    4,288,98,91,85,\n    5,176,86,130,99,\n    6,210,188,143,120,\n    7,271,322,86,65,\n    8,415,332,265,186,\n    9,171,126,130,135,\n    10,243,330,95,64,\n)\ndf_long &lt;-\n    df |&gt; pivot_longer(cols = -1,\n                       names_to = \"week\",\n                       values_to = \"ALT\") |&gt; mutate(week = factor(week))\n\n\n# 假设检验\nshapiro.test(df$zero)\n#&gt; \n#&gt;  Shapiro-Wilk normality test\n#&gt; \n#&gt; data:  df$zero\n#&gt; W = 0.97166, p-value = 0.9058\nshapiro.test(df$ten)\n#&gt; \n#&gt;  Shapiro-Wilk normality test\n#&gt; \n#&gt; data:  df$ten\n#&gt; W = 0.7963, p-value = 0.01307\nshapiro.test(df$twenty)\n#&gt; \n#&gt;  Shapiro-Wilk normality test\n#&gt; \n#&gt; data:  df$twenty\n#&gt; W = 0.83443, p-value = 0.03783\nshapiro.test(df$thirty)\n#&gt; \n#&gt;  Shapiro-Wilk normality test\n#&gt; \n#&gt; data:  df$thirty\n#&gt; W = 0.90722, p-value = 0.2624\nbartlett.test(df[-1])\n#&gt; \n#&gt;  Bartlett test of homogeneity of variances\n#&gt; \n#&gt; data:  df[-1]\n#&gt; Bartlett's K-squared = 6.7482, df = 3, p-value = 0.08037\n    \n# 总变异\nxij_sum &lt;- sum(df_long$ALT)\nxij_square_sum &lt;- sum(df_long$ALT^2)\nC &lt;- xij_sum^2/40\nSS_T &lt;- xij_square_sum-C\n\n# 受试者间  \nxi._sum &lt;- rowSums(df[,-1])\nxi._sum\n#&gt;  [1]  552 1101  295  562  491  661  744 1198  562  732\nSS_B &lt;- sum(xi._sum^2)/4-C #行和平方和\nMS_B &lt;- SS_B/9\n\n# 不同时间点\nx.j_sum &lt;- colSums(df[,-1])\nx.j_sum\n#&gt;   zero    ten twenty thirty \n#&gt;   2403   2000   1394   1101\nSS_W &lt;- sum(x.j_sum^2)/10-C #列和平方和\nMS_W &lt;- SS_W/3\n\n\n\nSS_E &lt;- SS_T-SS_B-SS_W\nMS_E &lt;- SS_E/(9*3)\n\nF_stat &lt;- MS_W/MS_E\n\n\n\n11.2.2 线性混合模型nlme::lme()\n\n\nCodelibrary(nlme)\nmodel &lt;- lme(fixed=ALT ~ week, random = ~1| id/week, data = df_long)\nsummary(model)\n#&gt; Linear mixed-effects model fit by REML\n#&gt;   Data: df_long \n#&gt;        AIC      BIC    logLik\n#&gt;   431.0046 442.0892 -208.5023\n#&gt; \n#&gt; Random effects:\n#&gt;  Formula: ~1 | id\n#&gt;         (Intercept)\n#&gt; StdDev:    62.83357\n#&gt; \n#&gt;  Formula: ~1 | week %in% id\n#&gt;         (Intercept) Residual\n#&gt; StdDev:     50.6942 22.91705\n#&gt; \n#&gt; Fixed effects:  ALT ~ week \n#&gt;             Value Std.Error DF   t-value p-value\n#&gt; (Intercept) 200.0  26.53893 27  7.536098  0.0000\n#&gt; weekthirty  -89.9  24.88008 27 -3.613332  0.0012\n#&gt; weektwenty  -60.6  24.88008 27 -2.435683  0.0217\n#&gt; weekzero     40.3  24.88008 27  1.619770  0.1169\n#&gt;  Correlation: \n#&gt;            (Intr) wkthrt wktwnt\n#&gt; weekthirty -0.469              \n#&gt; weektwenty -0.469  0.500       \n#&gt; weekzero   -0.469  0.500  0.500\n#&gt; \n#&gt; Standardized Within-Group Residuals:\n#&gt;         Min          Q1         Med          Q3         Max \n#&gt; -0.55743919 -0.26471921 -0.01206831  0.19777410  0.89724666 \n#&gt; \n#&gt; Number of Observations: 40\n#&gt; Number of Groups: \n#&gt;           id week %in% id \n#&gt;           10           40\nanova_results &lt;- anova(model)\nanova_results\n\n\n\n\n\nnumDF\ndenDF\nF-value\np-value\n\n\n\n(Intercept)\n1\n27\n62.98194\n0.00e+00\n\n\nweek\n3\n27\n11.13855\n6.17e-05\n\n\n\n\n\n\n\n11.2.3 事后检验\n\nCodelibrary(multcomp)\nglht_result &lt;-glht(model, linfct = mcp(week =c(\"ten - zero = 0 \",\n                                               \"twenty - zero == 0\",\n                                               \"thirty - zero = 0 \")))\nsummary(glht_result)\n#&gt; \n#&gt;   Simultaneous Tests for General Linear Hypotheses\n#&gt; \n#&gt; Multiple Comparisons of Means: User-defined Contrasts\n#&gt; \n#&gt; \n#&gt; Fit: lme.formula(fixed = ALT ~ week, data = df_long, random = ~1 | \n#&gt;     id/week)\n#&gt; \n#&gt; Linear Hypotheses:\n#&gt;                    Estimate Std. Error z value Pr(&gt;|z|)    \n#&gt; ten - zero == 0      -40.30      24.88  -1.620    0.248    \n#&gt; twenty - zero == 0  -100.90      24.88  -4.055   &lt;0.001 ***\n#&gt; thirty - zero == 0  -130.20      24.88  -5.233   &lt;0.001 ***\n#&gt; ---\n#&gt; Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n#&gt; (Adjusted p values reported -- single-step method)\nglht_result\n#&gt; \n#&gt;   General Linear Hypotheses\n#&gt; \n#&gt; Multiple Comparisons of Means: User-defined Contrasts\n#&gt; \n#&gt; \n#&gt; Linear Hypotheses:\n#&gt;                    Estimate\n#&gt; ten - zero == 0       -40.3\n#&gt; twenty - zero == 0   -100.9\n#&gt; thirty - zero == 0   -130.2\n\n\n\n11.2.4 第二个示例\n\nCodedf2 &lt;- tribble(\n    ~Participant,~A1,~A2,~A3,\n    \"P1\",5  ,6  ,7,\n    \"P2\",7  ,13 ,13,\n    \"P3\",2  ,4  ,6,\n    \"P4\",6  ,9  ,12\n)\ndf2\n\n\n\n\nParticipant\nA1\nA2\nA3\n\n\n\nP1\n5\n6\n7\n\n\nP2\n7\n13\n13\n\n\nP3\n2\n4\n6\n\n\nP4\n6\n9\n12\n\n\n\n\n\n\n自由度\n\nCodedf_A &lt;- 3-1\n\ndf_P &lt;- 4-1\n\ndf_error &lt;- df_A * df_P\n\n\ndf_total &lt;- df_A + df_P + df_error\n# 或者\ndf_total &lt;- 3*4-1 \n\n\n均方和\nSStotal ，SSA，SSP",
    "crumbs": [
      "概率论与数理统计",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>重复测量方差分析</span>"
    ]
  },
  {
    "objectID": "repeated_measures_ANOVA.html#含组间因子和组内因子的重复测量",
    "href": "repeated_measures_ANOVA.html#含组间因子和组内因子的重复测量",
    "title": "\n11  重复测量方差分析\n",
    "section": "\n11.3 含组间因子和组内因子的重复测量",
    "text": "11.3 含组间因子和组内因子的重复测量\n\\[\n\\begin{aligned}\nSS_总&= SS_{受试对象间}+SS_{受试对象内}  \\\\\n&=（SS_{处理方法}+SS_{个体间差异}）+（SS_{时间}+SS_{处理与时间交互}+SS_{个体内差异}）\n\\end{aligned}\n\\]\nhttps://personality-project.org/r/r.guide/r.anova.html#oneway\n\n11.3.1 第一个案例\n\nCodedf &lt;- read_rds(\"data/SLAMF6+-PBS.rds\")\n\ndf %&gt;% \n    DT::datatable()\n\n\n\n\n\n\nCode# 2x2 mixed: 独立变量（被试间） : age\n# 独立变量（被试内） : time 依赖变量: value\n# aov_age_time &lt;- aov(value ~ age * time + Error(subject/time),\n#   data = data_long)\n# summary(aov_age_time)\n\n# 两个被试内变量 \n#aov.ww &lt;- aov(y ~ w1*w2 +Error(subject/(w1*w2)), data=data_long) \n\n# 1个被试间变量，两个被试内变量 \n#aov.bww &lt;- aov(y ~b1*w1*w2 + Error(subject/(w1*w2)) + b1,data=data_long) \n\n# 两个被试间变量，一个被试内变量\n# aov.bww &lt;- aov(y ~ b1*b2*w1 + Error(subject/(w1)) + b1*b2, data=data_long)\n\n\n\n11.3.1.1 stats::aov()\n\n\nCode# 第一种  有混合效应无法事后检验\n\naov_1 &lt;- aov(volume ~ method*Days+Error(id/Days),data = df)\nsummary(aov_1)\n#&gt; \n#&gt; Error: id\n#&gt;           Df Sum Sq Mean Sq F value   Pr(&gt;F)    \n#&gt; method     2   3572  1786.0   13.13 0.000953 ***\n#&gt; Residuals 12   1633   136.1                     \n#&gt; ---\n#&gt; Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n#&gt; \n#&gt; Error: id:Days\n#&gt;             Df Sum Sq Mean Sq F value   Pr(&gt;F)    \n#&gt; Days         2    301   150.3   1.893    0.172    \n#&gt; method:Days  4   4363  1090.8  13.742 5.81e-06 ***\n#&gt; Residuals   24   1905    79.4                     \n#&gt; ---\n#&gt; Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\n\n11.3.1.2 nlme::lme()\n\n\nCode# 第二种 最好\nlibrary(nlme)\nmodel &lt;- lme(volume ~ method*Days, random = ~1|id/Days, data = df)\nsummary(model)\n#&gt; Linear mixed-effects model fit by REML\n#&gt;   Data: df \n#&gt;        AIC      BIC    logLik\n#&gt;   304.5845 323.5868 -140.2923\n#&gt; \n#&gt; Random effects:\n#&gt;  Formula: ~1 | id\n#&gt;         (Intercept)\n#&gt; StdDev:    4.346709\n#&gt; \n#&gt;  Formula: ~1 | Days %in% id\n#&gt;         (Intercept) Residual\n#&gt; StdDev:    8.366812 3.060766\n#&gt; \n#&gt; Fixed effects:  volume ~ method * Days \n#&gt;                                           Value Std.Error DF   t-value p-value\n#&gt; (Intercept)                            25.43718  4.433186 24  5.737900  0.0000\n#&gt; methodSLAMF6+ PD-1+ CD8+ cells         10.81993  6.269472 12  1.725813  0.1100\n#&gt; methodSLAMF6- PD-1+ CD8+ cells          4.63341  6.269472 12  0.739043  0.4741\n#&gt; Days7                                   9.55505  5.634601 24  1.695781  0.1029\n#&gt; Days14                                 22.41864  5.634601 24  3.978745  0.0006\n#&gt; methodSLAMF6+ PD-1+ CD8+ cells:Days7  -37.58056  7.968529 24 -4.716123  0.0001\n#&gt; methodSLAMF6- PD-1+ CD8+ cells:Days7   -8.90525  7.968529 24 -1.117552  0.2748\n#&gt; methodSLAMF6+ PD-1+ CD8+ cells:Days14 -55.79891  7.968529 24 -7.002410  0.0000\n#&gt; methodSLAMF6- PD-1+ CD8+ cells:Days14 -14.68420  7.968529 24 -1.842774  0.0777\n#&gt;  Correlation: \n#&gt;                                       (Intr) mtSLAMF6+PD-1+CD8+c\n#&gt; methodSLAMF6+ PD-1+ CD8+ cells        -0.707                    \n#&gt; methodSLAMF6- PD-1+ CD8+ cells        -0.707  0.500             \n#&gt; Days7                                 -0.636  0.449             \n#&gt; Days14                                -0.636  0.449             \n#&gt; methodSLAMF6+ PD-1+ CD8+ cells:Days7   0.449 -0.636             \n#&gt; methodSLAMF6- PD-1+ CD8+ cells:Days7   0.449 -0.318             \n#&gt; methodSLAMF6+ PD-1+ CD8+ cells:Days14  0.449 -0.636             \n#&gt; methodSLAMF6- PD-1+ CD8+ cells:Days14  0.449 -0.318             \n#&gt;                                       mtSLAMF6-PD-1+CD8+c Days7  Days14\n#&gt; methodSLAMF6+ PD-1+ CD8+ cells                                         \n#&gt; methodSLAMF6- PD-1+ CD8+ cells                                         \n#&gt; Days7                                  0.449                           \n#&gt; Days14                                 0.449               0.500       \n#&gt; methodSLAMF6+ PD-1+ CD8+ cells:Days7  -0.318              -0.707 -0.354\n#&gt; methodSLAMF6- PD-1+ CD8+ cells:Days7  -0.636              -0.707 -0.354\n#&gt; methodSLAMF6+ PD-1+ CD8+ cells:Days14 -0.318              -0.354 -0.707\n#&gt; methodSLAMF6- PD-1+ CD8+ cells:Days14 -0.636              -0.354 -0.707\n#&gt;                                       mSLAMF6+PD-1+CD8+c:D7\n#&gt; methodSLAMF6+ PD-1+ CD8+ cells                             \n#&gt; methodSLAMF6- PD-1+ CD8+ cells                             \n#&gt; Days7                                                      \n#&gt; Days14                                                     \n#&gt; methodSLAMF6+ PD-1+ CD8+ cells:Days7                       \n#&gt; methodSLAMF6- PD-1+ CD8+ cells:Days7   0.500               \n#&gt; methodSLAMF6+ PD-1+ CD8+ cells:Days14  0.500               \n#&gt; methodSLAMF6- PD-1+ CD8+ cells:Days14  0.250               \n#&gt;                                       mSLAMF6-PD-1+CD8+c:D7\n#&gt; methodSLAMF6+ PD-1+ CD8+ cells                             \n#&gt; methodSLAMF6- PD-1+ CD8+ cells                             \n#&gt; Days7                                                      \n#&gt; Days14                                                     \n#&gt; methodSLAMF6+ PD-1+ CD8+ cells:Days7                       \n#&gt; methodSLAMF6- PD-1+ CD8+ cells:Days7                       \n#&gt; methodSLAMF6+ PD-1+ CD8+ cells:Days14  0.250               \n#&gt; methodSLAMF6- PD-1+ CD8+ cells:Days14  0.500               \n#&gt;                                       mSLAMF6+PD-1+CD8+c:D1\n#&gt; methodSLAMF6+ PD-1+ CD8+ cells                             \n#&gt; methodSLAMF6- PD-1+ CD8+ cells                             \n#&gt; Days7                                                      \n#&gt; Days14                                                     \n#&gt; methodSLAMF6+ PD-1+ CD8+ cells:Days7                       \n#&gt; methodSLAMF6- PD-1+ CD8+ cells:Days7                       \n#&gt; methodSLAMF6+ PD-1+ CD8+ cells:Days14                      \n#&gt; methodSLAMF6- PD-1+ CD8+ cells:Days14  0.500               \n#&gt; \n#&gt; Standardized Within-Group Residuals:\n#&gt;         Min          Q1         Med          Q3         Max \n#&gt; -0.62401382 -0.15515176 -0.03440848  0.17260010  0.72287328 \n#&gt; \n#&gt; Number of Observations: 45\n#&gt; Number of Groups: \n#&gt;           id Days %in% id \n#&gt;           15           45\ndf_aov &lt;- anova(model)\ndf_aov\n\n\n\n\n\nnumDF\ndenDF\nF-value\np-value\n\n\n\n(Intercept)\n1\n24\n263.954417\n0.0000000\n\n\nmethod\n2\n12\n13.127286\n0.0009528\n\n\nDays\n2\n24\n1.893203\n0.1724036\n\n\nmethod:Days\n4\n24\n13.742424\n0.0000058\n\n\n\n\n\nCode\n#成对比较\nlibrary(emmeans)\nmethod_means &lt;- emmeans(model, ~method)  \nprint(method_means)  \n#&gt;  method                   emmean   SE df lower.CL upper.CL\n#&gt;  PBS                        36.1 3.01 14    29.64     42.6\n#&gt;  SLAMF6+ PD-1+ CD8+ cells   15.8 3.01 12     9.23     22.4\n#&gt;  SLAMF6- PD-1+ CD8+ cells   32.9 3.01 12    26.30     39.4\n#&gt; \n#&gt; Results are averaged over the levels of: Days \n#&gt; Degrees-of-freedom method: containment \n#&gt; Confidence level used: 0.95\nmethod_comparisons &lt;- pairs(method_means)  \nprint(method_comparisons)\n#&gt;  contrast                                                estimate   SE df\n#&gt;  PBS - (SLAMF6+ PD-1+ CD8+ cells)                           20.31 4.26 12\n#&gt;  PBS - (SLAMF6- PD-1+ CD8+ cells)                            3.23 4.26 12\n#&gt;  (SLAMF6+ PD-1+ CD8+ cells) - (SLAMF6- PD-1+ CD8+ cells)   -17.08 4.26 12\n#&gt;  t.ratio p.value\n#&gt;    4.768  0.0012\n#&gt;    0.758  0.7345\n#&gt;   -4.009  0.0046\n#&gt; \n#&gt; Results are averaged over the levels of: Days \n#&gt; Degrees-of-freedom method: containment \n#&gt; P value adjustment: tukey method for comparing a family of 3 estimates\n\n\n\n11.3.1.3 afex::aov_*()\n\n\nCodelibrary(\"afex\")     # needed for ANOVA functions.\nlibrary(\"emmeans\")  # emmeans must now be loaded explicitly for follow-up tests.\nlibrary(\"multcomp\") # for advanced control for multiple testing/Type 1 errors.\nlibrary(\"ggplot2\")  # for customizing plots.\n\n\na1 &lt;- aov_ez(id = \"id\",dv = \"volume\", df, between =\"method\" , within = c(\"Days\"))\na1\n#&gt; Anova Table (Type 3 tests)\n#&gt; \n#&gt; Response: volume\n#&gt;        Effect          df    MSE         F  ges p.value\n#&gt; 1      method       2, 12 136.05 13.13 *** .502   &lt;.001\n#&gt; 2        Days 1.33, 15.94 119.49      1.89 .078    .188\n#&gt; 3 method:Days 2.66, 15.94 119.49 13.74 *** .552   &lt;.001\n#&gt; ---\n#&gt; Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '+' 0.1 ' ' 1\n#&gt; \n#&gt; Sphericity correction method: GG\n\naov_car(volume ~ method + Error(id/Days), data = df)\n#&gt; Anova Table (Type 3 tests)\n#&gt; \n#&gt; Response: volume\n#&gt;        Effect          df    MSE         F  ges p.value\n#&gt; 1      method       2, 12 136.05 13.13 *** .502   &lt;.001\n#&gt; 2        Days 1.33, 15.94 119.49      1.89 .078    .188\n#&gt; 3 method:Days 2.66, 15.94 119.49 13.74 *** .552   &lt;.001\n#&gt; ---\n#&gt; Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '+' 0.1 ' ' 1\n#&gt; \n#&gt; Sphericity correction method: GG\naov_4(volume ~ method + (Days|id), data = df)\n#&gt; Anova Table (Type 3 tests)\n#&gt; \n#&gt; Response: volume\n#&gt;        Effect          df    MSE         F  ges p.value\n#&gt; 1      method       2, 12 136.05 13.13 *** .502   &lt;.001\n#&gt; 2        Days 1.33, 15.94 119.49      1.89 .078    .188\n#&gt; 3 method:Days 2.66, 15.94 119.49 13.74 *** .552   &lt;.001\n#&gt; ---\n#&gt; Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '+' 0.1 ' ' 1\n#&gt; \n#&gt; Sphericity correction method: GG\n\n\n\n# 事后检验\nm1 &lt;- emmeans(a1, ~ method)\nm1\n#&gt;  method                   emmean   SE df lower.CL upper.CL\n#&gt;  PBS                        36.1 3.01 12    29.53     42.7\n#&gt;  SLAMF6+ PD-1+ CD8+ cells   15.8 3.01 12     9.23     22.4\n#&gt;  SLAMF6- PD-1+ CD8+ cells   32.9 3.01 12    26.30     39.4\n#&gt; \n#&gt; Results are averaged over the levels of: Days \n#&gt; Confidence level used: 0.95\npairs(m1)\n#&gt;  contrast                                                estimate   SE df\n#&gt;  PBS - (SLAMF6+ PD-1+ CD8+ cells)                           20.31 4.26 12\n#&gt;  PBS - (SLAMF6- PD-1+ CD8+ cells)                            3.23 4.26 12\n#&gt;  (SLAMF6+ PD-1+ CD8+ cells) - (SLAMF6- PD-1+ CD8+ cells)   -17.08 4.26 12\n#&gt;  t.ratio p.value\n#&gt;    4.768  0.0012\n#&gt;    0.758  0.7345\n#&gt;   -4.009  0.0046\n#&gt; \n#&gt; Results are averaged over the levels of: Days \n#&gt; P value adjustment: tukey method for comparing a family of 3 estimates\n\n\n\n11.3.2 第二个案例\n\nCode# 医学统计学 人卫版 第7版\ndf &lt;- read_delim(\"data/麻醉诱导时相.txt\")\ndf\n\n\n\n\nid\ngroup\nt0\nt1\nt2\nt3\nt4\n\n\n\n1\nA\n120\n108\n112\n120\n117\n\n\n2\nA\n118\n109\n115\n126\n123\n\n\n3\nA\n119\n112\n119\n124\n118\n\n\n4\nA\n121\n112\n119\n126\n120\n\n\n5\nA\n127\n121\n127\n133\n126\n\n\n6\nB\n121\n120\n118\n131\n137\n\n\n7\nB\n122\n121\n119\n129\n133\n\n\n8\nB\n128\n129\n126\n135\n142\n\n\n9\nB\n117\n115\n111\n123\n131\n\n\n10\nB\n118\n114\n116\n123\n133\n\n\n11\nC\n131\n119\n118\n135\n129\n\n\n12\nC\n129\n128\n121\n148\n132\n\n\n13\nC\n123\n123\n120\n143\n136\n\n\n14\nC\n123\n121\n116\n145\n126\n\n\n15\nC\n125\n124\n118\n142\n130\n\n\n\n\n\nCodedf_long &lt;- df |&gt; pivot_longer(cols = starts_with(\"t\"),\n                              names_to = \"time\",\n                              values_to = \"BP\") |&gt; \n    mutate(\n        id=factor(id),\n        group=factor(group),\n        time=factor(time)\n    )\ndf_long %&gt;% \n    DT::datatable()\n\n\n\n\n\n\n11.3.2.1 nlme::lme()\n\n\nCode# 第一种方法\nlibrary(nlme)\nmodel &lt;- lme(BP ~ group*time, random = ~1 |id/time, data = df_long)\nsummary(model)\n#&gt; Linear mixed-effects model fit by REML\n#&gt;   Data: df_long \n#&gt;       AIC      BIC   logLik\n#&gt;   364.496 402.1942 -164.248\n#&gt; \n#&gt; Random effects:\n#&gt;  Formula: ~1 | id\n#&gt;         (Intercept)\n#&gt; StdDev:    3.831231\n#&gt; \n#&gt;  Formula: ~1 | time %in% id\n#&gt;         (Intercept) Residual\n#&gt; StdDev:    2.100669 1.033856\n#&gt; \n#&gt; Fixed effects:  BP ~ group * time \n#&gt;               Value Std.Error DF  t-value p-value\n#&gt; (Intercept)   121.0  2.007984 48 60.25944  0.0000\n#&gt; groupB          0.2  2.839718 12  0.07043  0.9450\n#&gt; groupC          5.2  2.839718 12  1.83117  0.0920\n#&gt; timet1         -8.6  1.480766 48 -5.80781  0.0000\n#&gt; timet2         -2.6  1.480766 48 -1.75585  0.0855\n#&gt; timet3          4.8  1.480766 48  3.24157  0.0022\n#&gt; timet4         -0.2  1.480766 48 -0.13507  0.8931\n#&gt; groupB:timet1   7.2  2.094119 48  3.43820  0.0012\n#&gt; groupC:timet1   5.4  2.094119 48  2.57865  0.0130\n#&gt; groupB:timet2  -0.6  2.094119 48 -0.28652  0.7757\n#&gt; groupC:timet2  -5.0  2.094119 48 -2.38764  0.0209\n#&gt; groupB:timet3   2.2  2.094119 48  1.05056  0.2987\n#&gt; groupC:timet3  11.6  2.094119 48  5.53932  0.0000\n#&gt; groupB:timet4  14.2  2.094119 48  6.78090  0.0000\n#&gt; groupC:timet4   4.6  2.094119 48  2.19663  0.0329\n#&gt;  Correlation: \n#&gt;               (Intr) groupB groupC timet1 timet2 timet3 timet4 grpB:1 grpC:1\n#&gt; groupB        -0.707                                                        \n#&gt; groupC        -0.707  0.500                                                 \n#&gt; timet1        -0.369  0.261  0.261                                          \n#&gt; timet2        -0.369  0.261  0.261  0.500                                   \n#&gt; timet3        -0.369  0.261  0.261  0.500  0.500                            \n#&gt; timet4        -0.369  0.261  0.261  0.500  0.500  0.500                     \n#&gt; groupB:timet1  0.261 -0.369 -0.184 -0.707 -0.354 -0.354 -0.354              \n#&gt; groupC:timet1  0.261 -0.184 -0.369 -0.707 -0.354 -0.354 -0.354  0.500       \n#&gt; groupB:timet2  0.261 -0.369 -0.184 -0.354 -0.707 -0.354 -0.354  0.500  0.250\n#&gt; groupC:timet2  0.261 -0.184 -0.369 -0.354 -0.707 -0.354 -0.354  0.250  0.500\n#&gt; groupB:timet3  0.261 -0.369 -0.184 -0.354 -0.354 -0.707 -0.354  0.500  0.250\n#&gt; groupC:timet3  0.261 -0.184 -0.369 -0.354 -0.354 -0.707 -0.354  0.250  0.500\n#&gt; groupB:timet4  0.261 -0.369 -0.184 -0.354 -0.354 -0.354 -0.707  0.500  0.250\n#&gt; groupC:timet4  0.261 -0.184 -0.369 -0.354 -0.354 -0.354 -0.707  0.250  0.500\n#&gt;               grpB:2 grpC:2 grpB:3 grpC:3 grpB:4\n#&gt; groupB                                          \n#&gt; groupC                                          \n#&gt; timet1                                          \n#&gt; timet2                                          \n#&gt; timet3                                          \n#&gt; timet4                                          \n#&gt; groupB:timet1                                   \n#&gt; groupC:timet1                                   \n#&gt; groupB:timet2                                   \n#&gt; groupC:timet2  0.500                            \n#&gt; groupB:timet3  0.500  0.250                     \n#&gt; groupC:timet3  0.250  0.500  0.500              \n#&gt; groupB:timet4  0.500  0.250  0.500  0.250       \n#&gt; groupC:timet4  0.250  0.500  0.250  0.500  0.500\n#&gt; \n#&gt; Standardized Within-Group Residuals:\n#&gt;         Min          Q1         Med          Q3         Max \n#&gt; -1.11748859 -0.15879013 -0.03722313  0.17409704  1.22118250 \n#&gt; \n#&gt; Number of Observations: 75\n#&gt; Number of Groups: \n#&gt;           id time %in% id \n#&gt;           15           75\ndf_aov &lt;- anova(model)\ndf_aov\n\n\n\n\n\nnumDF\ndenDF\nF-value\np-value\n\n\n\n(Intercept)\n1\n48\n14649.223399\n0.0000000\n\n\ngroup\n2\n12\n5.782943\n0.0174335\n\n\ntime\n4\n48\n106.557616\n0.0000000\n\n\ngroup:time\n8\n48\n19.100638\n0.0000000\n\n\n\n\n\nCode\n#成对比较\nlibrary(emmeans)\nmethod_means &lt;- emmeans(model, ~group)  \nprint(method_means)  \n#&gt;  group emmean   SE df lower.CL upper.CL\n#&gt;  A        120 1.78 14      116      123\n#&gt;  B        124 1.78 12      121      128\n#&gt;  C        128 1.78 12      124      132\n#&gt; \n#&gt; Results are averaged over the levels of: time \n#&gt; Degrees-of-freedom method: containment \n#&gt; Confidence level used: 0.95\nmethod_comparisons &lt;- pairs(method_means)  \nprint(method_comparisons)\n#&gt;  contrast estimate   SE df t.ratio p.value\n#&gt;  A - B       -4.80 2.51 12  -1.911  0.1780\n#&gt;  A - C       -8.52 2.51 12  -3.392  0.0137\n#&gt;  B - C       -3.72 2.51 12  -1.481  0.3338\n#&gt; \n#&gt; Results are averaged over the levels of: time \n#&gt; Degrees-of-freedom method: containment \n#&gt; P value adjustment: tukey method for comparing a family of 3 estimates\n\n\n\n11.3.2.2 rstatix::anova_test()\n\n\nCodelibrary(rstatix)\na2 &lt;- anova_test(data = df_long,\n           dv = BP,\n           wid = id,\n           within = time,\n           between = group\n           )\n\na2\n#&gt; ANOVA Table (type II tests)\n#&gt; \n#&gt; $ANOVA\n#&gt;       Effect DFn DFd       F        p p&lt;.05   ges\n#&gt; 1      group   2  12   5.783 1.70e-02     * 0.430\n#&gt; 2       time   4  48 106.558 3.02e-23     * 0.659\n#&gt; 3 group:time   8  48  19.101 1.62e-12     * 0.409\n#&gt; \n#&gt; $`Mauchly's Test for Sphericity`\n#&gt;       Effect     W     p p&lt;.05\n#&gt; 1       time 0.293 0.178      \n#&gt; 2 group:time 0.293 0.178      \n#&gt; \n#&gt; $`Sphericity Corrections`\n#&gt;       Effect   GGe      DF[GG]    p[GG] p[GG]&lt;.05   HFe      DF[HF]    p[HF]\n#&gt; 1       time 0.679 2.71, 32.58 1.87e-16         * 0.896 3.59, 43.03 4.65e-21\n#&gt; 2 group:time 0.679 5.43, 32.58 4.26e-09         * 0.896 7.17, 43.03 2.04e-11\n#&gt;   p[HF]&lt;.05\n#&gt; 1         *\n#&gt; 2         *\n\n\n\n11.3.2.3 afex::aov_*()\n\nhttps://cran.r-project.org/web/packages/afex/vignettes/afex_anova_example.html\n\nCodelibrary(\"afex\")     # needed for ANOVA functions.\nlibrary(\"emmeans\")  # emmeans must now be loaded explicitly for follow-up tests.\nlibrary(\"multcomp\") # for advanced control for multiple testing/Type 1 errors.\nlibrary(\"ggplot2\")  # for customizing plots.\n\n\n\na3 &lt;- aov_ez(\"id\", \"BP\", df_long, between =\"group\" , \n       within = c(\"time\"))\na3\n#&gt; Anova Table (Type 3 tests)\n#&gt; \n#&gt; Response: BP\n#&gt;       Effect          df   MSE          F  ges p.value\n#&gt; 1      group       2, 12 78.87     5.78 * .430    .017\n#&gt; 2       time 2.71, 32.58  8.08 106.56 *** .659   &lt;.001\n#&gt; 3 group:time 5.43, 32.58  8.08  19.10 *** .409   &lt;.001\n#&gt; ---\n#&gt; Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '+' 0.1 ' ' 1\n#&gt; \n#&gt; Sphericity correction method: GG\n\n\naov_car(BP ~ group + Error(id/time), data = df_long)\n#&gt; Anova Table (Type 3 tests)\n#&gt; \n#&gt; Response: BP\n#&gt;       Effect          df   MSE          F  ges p.value\n#&gt; 1      group       2, 12 78.87     5.78 * .430    .017\n#&gt; 2       time 2.71, 32.58  8.08 106.56 *** .659   &lt;.001\n#&gt; 3 group:time 5.43, 32.58  8.08  19.10 *** .409   &lt;.001\n#&gt; ---\n#&gt; Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '+' 0.1 ' ' 1\n#&gt; \n#&gt; Sphericity correction method: GG\naov_4(BP ~ group + (time|id), data = df_long)\n#&gt; Anova Table (Type 3 tests)\n#&gt; \n#&gt; Response: BP\n#&gt;       Effect          df   MSE          F  ges p.value\n#&gt; 1      group       2, 12 78.87     5.78 * .430    .017\n#&gt; 2       time 2.71, 32.58  8.08 106.56 *** .659   &lt;.001\n#&gt; 3 group:time 5.43, 32.58  8.08  19.10 *** .409   &lt;.001\n#&gt; ---\n#&gt; Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '+' 0.1 ' ' 1\n#&gt; \n#&gt; Sphericity correction method: GG\n\n\n# 事后检验\nm3 &lt;- emmeans(a3, ~ group)\nm3\n#&gt;  group emmean   SE df lower.CL upper.CL\n#&gt;  A        120 1.78 12      116      124\n#&gt;  B        124 1.78 12      121      128\n#&gt;  C        128 1.78 12      124      132\n#&gt; \n#&gt; Results are averaged over the levels of: time \n#&gt; Confidence level used: 0.95\npairs(m3)\n#&gt;  contrast estimate   SE df t.ratio p.value\n#&gt;  A - B       -4.80 2.51 12  -1.911  0.1780\n#&gt;  A - C       -8.52 2.51 12  -3.392  0.0137\n#&gt;  B - C       -3.72 2.51 12  -1.481  0.3338\n#&gt; \n#&gt; Results are averaged over the levels of: time \n#&gt; P value adjustment: tukey method for comparing a family of 3 estimates\nsummary(as.glht(pairs(m1)), test=adjusted(\"fdr\"))\n#&gt; \n#&gt;   Simultaneous Tests for General Linear Hypotheses\n#&gt; \n#&gt; Linear Hypotheses:\n#&gt;                                                              Estimate\n#&gt; PBS - (SLAMF6+ PD-1+ CD8+ cells) == 0                          20.307\n#&gt; PBS - (SLAMF6- PD-1+ CD8+ cells) == 0                           3.230\n#&gt; (SLAMF6+ PD-1+ CD8+ cells) - (SLAMF6- PD-1+ CD8+ cells) == 0  -17.077\n#&gt;                                                              Std. Error t value\n#&gt; PBS - (SLAMF6+ PD-1+ CD8+ cells) == 0                             4.259   4.768\n#&gt; PBS - (SLAMF6- PD-1+ CD8+ cells) == 0                             4.259   0.758\n#&gt; (SLAMF6+ PD-1+ CD8+ cells) - (SLAMF6- PD-1+ CD8+ cells) == 0      4.259  -4.009\n#&gt;                                                              Pr(&gt;|t|)   \n#&gt; PBS - (SLAMF6+ PD-1+ CD8+ cells) == 0                         0.00137 **\n#&gt; PBS - (SLAMF6- PD-1+ CD8+ cells) == 0                         0.46290   \n#&gt; (SLAMF6+ PD-1+ CD8+ cells) - (SLAMF6- PD-1+ CD8+ cells) == 0  0.00260 **\n#&gt; ---\n#&gt; Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n#&gt; (Adjusted p values reported -- fdr method)\np1 &lt;- afex_plot(a3, x = \"time\",# trace = \"BP\",\n                panel = \"group\", error = \"none\",\n                mapping = c(\"color\", \"fill\"),\n                data_geom = geom_boxplot, data_arg = list(width = 0.4),\n                point_arg = list(size = 1.5), line_arg = list(size = 1))\np1\n\n\n\n\n\n\n\n\\[\n\\begin{aligned}\nSS_总&= SS_{受试对象间}+SS_{受试对象内}  \\\\\n&=（SS_{处理方法}+SS_{个体间差异}）+（SS_{时间}+SS_{处理与时间交互}+SS_{个体内差异}）\n\\end{aligned}\n\\]\n\\[\n\\begin{aligned}\n\\nu_总&= \\nu_{受试对象间}+\\nu_{受试对象内}  \\\\\n&=（\\nu_{处理方法}+\\nu_{个体差异}）+（\\nu_{时间}+\\nu_{处理与时间交互}+\\nu_{个体差异}）\n\\end{aligned}\n\\]\n\n\n\n\n\n\n\n\n\n\n\nPage 86-87\n变异\nSS\nv\nMS\nF\nCP\n\n\n\n受试对象间\n处理\n912.24\n2\n456.12\n5.78\n0.0174\n\n\n\n个体差异\n946.48\n12\n78.87\n\n\n\n\n\n\n1858.72\n\n\n\n\n\n\n受试对象内\n时间\n2336.45\n4\n584.11\n106.56\n&lt;0.0001\n\n\n\n处理与时间交互\n837.63\n8\n104.70\n19.10\n&lt;0.0001\n\n\n\n个体差异\n263.12\n48\n5.48\n\n\n\n\n\n\n3437.2\n\n\n\n\n\n\n总\n\n5295.92\n3×15-1=74\n\n\n\n\n\n\n11.3.2.4 SS总\n\n\\[\nSS_总=\\sum_i^n{（X_i-\\bar X）^2}\n\\]\n其中，n是观测值的总数，Xi 为每个观测值，\\(\\bar X\\) 是所有观测值的均值。\n\nCodeoptions(digits = 4)\nBP &lt;- c(df$t0,df$t1,df$t2,df$t3,df$t4)\nBP_mean &lt;- mean(BP) \nSS_total &lt;- sum((BP-BP_mean)^2)\n\nSS_total    \n#&gt; [1] 5296\n\n\n\n11.3.2.5 SS受试对象间\n\n\\[\nSS_{受试对象间}=\\sum_{j=1}^m n_{.j}(\\bar X_{.j}-\\bar X)^2\n\\]\n其中，m是受试者数量（15），n.j 是第j 个受试对象的观测值数量，\\bar X.j 是第j 个受试对象的观测值的均值，\\bar X 是所有观测值的均值。\n\nCodeid_mean &lt;- df |&gt; dplyr::select(c(-1,-2)) |&gt; rowMeans()\n\nSS_between &lt;- 0\nfor (i in 1:nrow(df)) {\n    SS_between &lt;- SS_between + 5*(id_mean[i]-BP_mean)^2\n}\nSS_between\n#&gt; [1] 1859\n\n\n\nCodegroup__summary &lt;- df_long |&gt; group_by(group) |&gt; \n    summarise(n=n(),mean=mean(BP),sum=sum(BP))\ngroup__summary \n\n\n\n\ngroup\nn\nmean\nsum\n\n\n\nA\n25\n119.68\n2992\n\n\nB\n25\n124.48\n3112\n\n\nC\n25\n128.20\n3205\n\n\n\n\n\n\nSS处理\n\n\\[\nSS_{处理}= \\sum_i^k n_k (\\bar X_k - \\bar X)^2\n\\]\n其中，k为不同处理组的组数，nk 为第 k 处理组观测值的总数，\\(\\bar  X_k\\) 为第k 处理组观测值的均数，\\(\\bar X\\) 是所有观测值的均值。\n\nCodeSS_处理 &lt;- 25*( (group__summary$mean[1] - BP_mean )^2 + \n                       (group__summary$mean[2] - BP_mean )^2 +\n                       (group__summary$mean[3] - BP_mean )^2) \nSS_处理\n#&gt; [1] 912.2\n\n\n\nCodeSS_between_error &lt;- SS_between-SS_处理\n\nSS_between_error\n#&gt; [1] 946.5\n\n\n\n11.3.2.6 SS受试对象内\n\n\\[\nSS_{受试对象内}=SS_总-SS_{受试对象间}\n\\]\n\nCodeSS_within &lt;- SS_total-SS_between\nSS_within\n#&gt; [1] 3437\n\n\nSS时间\n\n\\[\nSS_{时间}=\\sum _{t=1}^T n_t （\\bar X_{.t}-\\bar X）^2\n\\]\n其中，T是时间点的数量，nt 是在时间点t的观测值数量，\\bar X.t 是在时间点 t 的均值。\n\nCodet_mean &lt;- df |&gt; dplyr::select(c(-1,-2)) |&gt; colMeans()\n\nSS_time &lt;- 0\nfor (i in seq_along(t_mean)) {\n    \n    SS_time &lt;- SS_time + 15*(t_mean[i]-BP_mean)^2\n    \n}\nnames(SS_time) &lt;- \"SS_time\"\nSS_time\n#&gt; SS_time \n#&gt;    2336\n\n\nSS处理与时间交互\n\n\\[\nSS_{处理与时间交互}=\\sum_{i=1}^{k}\\sum_{j=1}^{T}n_{ij}\\left (\\bar X_{ij.} -\\bar X_{i..}-\\bar X_{.j.} + \\bar X_{...} \\right )^2\n\\]\n其中，\n\nk 是处理方法的数量，3\nT 是时间点的数量，5\nnij 是第 i 个处理方法和第 j 个时间点的观测次数，25/5=5\nXij . 是第 i 个处理方法、第 j 个时间点的观测值的平均值\nXi . . 是第 i 个处理方法观测值的平均值，不考虑时间点\nX. j . 是第 j 个时间点观测值的平均值，不考虑处理方法\nX. . . 是所有观测值的平均值，不考虑处理方法和时间点\n\n\nCodeinteraction_effect_summary &lt;- df_long |&gt;\n    summarise(\n        #n = n(),\n        mean = mean(BP),\n       # sum = sum(BP),\n        .by = c(group , time)\n    )\ninteraction_effect_mean &lt;- interaction_effect_summary |&gt; pivot_wider(names_from = c(\"time\"),values_from = \"mean\")\n\n\n\nSS_interaction_effect &lt;- 0\nfor (i in 1:3) {\n    for (j in 1:5) {\n        SS_interaction_effect &lt;- SS_interaction_effect + 5 * (interaction_effect_mean[i, j + 1] -group__summary$mean[i] - t_mean[j] + BP_mean) ^ 2\n    }\n    \n}\nnames(SS_interaction_effect) &lt;- \"SS_interaction_effect\"\nSS_interaction_effect\n\n\n\n\nSS_interaction_effect\n\n\n837.6\n\n\n\n\n\n\nCodeSS_within_error &lt;- SS_within-SS_time-SS_interaction_effect\n\nnames(SS_within_error) &lt;- \"SS_within_error\"\nSS_within_error \n\n\n\n\nSS_within_error\n\n\n263.1",
    "crumbs": [
      "概率论与数理统计",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>重复测量方差分析</span>"
    ]
  },
  {
    "objectID": "repeated_measures_ANOVA.html#球形度检验-sphericity",
    "href": "repeated_measures_ANOVA.html#球形度检验-sphericity",
    "title": "\n11  重复测量方差分析\n",
    "section": "\n11.4 球形度检验 sphericity",
    "text": "11.4 球形度检验 sphericity\n重复测量方差分析假设相关条件（或组水平）的所有组合之间的差异方差相等。这被称为球形度假设。\nR中球形度检验\n球度仅针对具有两个以上水平的变量进行评估，因为球形度必然适用于只有两个水平的条件。\n违反球形度假设可能会扭曲方差计算，从而导致更宽松的重复测量方差分析检验（即 I 类错误率增加）。在这种情况下，必须根据违反球形度的程度适当校正重复测量方差分析。文献中使用了两种常见的校正：Greenhouse-Geisser epsilon （GGe） 和 Huynh-Feldt epsilon （HFe）。\n球形度的 Mauchly 检验用于评估是否满足球形度的假设。使用rstatix::anova_test() 时，会自动报告此问题。尽管该方法受到严厉批评，通常无法检测到小样本中的球形偏离，而在大样本中则过度检测到它们，但它仍然是一种常用的方法。\n\nCodelibrary(tidyverse)\nlibrary(ggpubr)\nlibrary(rstatix)\n\n\n\n\n11.4.1 计算 sphericity 和 Mauchly 检验\n具体操作步骤如下：\n\n计算相关组的每个组合之间的差异\n计算每个组差的方差\n\n\n\nCoded &lt;- df |&gt; mutate(\n    `t0-t1`=t0-t1,\n    `t0-t2`=t0-t2,\n    `t0-t3`=t0-t3,\n    `t0-t4`=t0-t4,\n    `t1-t2`=t1-t2,\n    `t1-t3`=t1-t3,\n    `t1-t4`=t1-t4,\n    `t2-t3`=t2-t3,\n    `t2-t4`=t2-t4,\n    `t3-t4`=t3-t4,\n) |&gt; select(8:17)\nd\n\n\n\n\nt0-t1\nt0-t2\nt0-t3\nt0-t4\nt1-t2\nt1-t3\nt1-t4\nt2-t3\nt2-t4\nt3-t4\n\n\n\n12\n8\n0\n3\n-4\n-12\n-9\n-8\n-5\n3\n\n\n9\n3\n-8\n-5\n-6\n-17\n-14\n-11\n-8\n3\n\n\n7\n0\n-5\n1\n-7\n-12\n-6\n-5\n1\n6\n\n\n9\n2\n-5\n1\n-7\n-14\n-8\n-7\n-1\n6\n\n\n6\n0\n-6\n1\n-6\n-12\n-5\n-6\n1\n7\n\n\n1\n3\n-10\n-16\n2\n-11\n-17\n-13\n-19\n-6\n\n\n1\n3\n-7\n-11\n2\n-8\n-12\n-10\n-14\n-4\n\n\n-1\n2\n-7\n-14\n3\n-6\n-13\n-9\n-16\n-7\n\n\n2\n6\n-6\n-14\n4\n-8\n-16\n-12\n-20\n-8\n\n\n4\n2\n-5\n-15\n-2\n-9\n-19\n-7\n-17\n-10\n\n\n12\n13\n-4\n2\n1\n-16\n-10\n-17\n-11\n6\n\n\n1\n8\n-19\n-3\n7\n-20\n-4\n-27\n-11\n16\n\n\n0\n3\n-20\n-13\n3\n-20\n-13\n-23\n-16\n7\n\n\n2\n7\n-22\n-3\n5\n-24\n-5\n-29\n-10\n19\n\n\n1\n7\n-17\n-5\n6\n-18\n-6\n-24\n-12\n12\n\n\n\n\n\nCode\nd|&gt; map(var)\n#&gt; $`t0-t1`\n#&gt; [1] 19.54286\n#&gt; \n#&gt; $`t0-t2`\n#&gt; [1] 12.8381\n#&gt; \n#&gt; $`t0-t3`\n#&gt; [1] 45.25714\n#&gt; \n#&gt; $`t0-t4`\n#&gt; [1] 49.6381\n#&gt; \n#&gt; $`t1-t2`\n#&gt; [1] 24.49524\n#&gt; \n#&gt; $`t1-t3`\n#&gt; [1] 27.31429\n#&gt; \n#&gt; $`t1-t4`\n#&gt; [1] 23.12381\n#&gt; \n#&gt; $`t2-t3`\n#&gt; [1] 65.55238\n#&gt; \n#&gt; $`t2-t4`\n#&gt; [1] 47.98095\n#&gt; \n#&gt; $`t3-t4`\n#&gt; [1] 77.38095\n \n### 单因素\nt &lt;- df |&gt; select(3:7) |&gt; as.matrix()\nt\n#&gt;        t0  t1  t2  t3  t4\n#&gt;  [1,] 120 108 112 120 117\n#&gt;  [2,] 118 109 115 126 123\n#&gt;  [3,] 119 112 119 124 118\n#&gt;  [4,] 121 112 119 126 120\n#&gt;  [5,] 127 121 127 133 126\n#&gt;  [6,] 121 120 118 131 137\n#&gt;  [7,] 122 121 119 129 133\n#&gt;  [8,] 128 129 126 135 142\n#&gt;  [9,] 117 115 111 123 131\n#&gt; [10,] 118 114 116 123 133\n#&gt; [11,] 131 119 118 135 129\n#&gt; [12,] 129 128 121 148 132\n#&gt; [13,] 123 123 120 143 136\n#&gt; [14,] 123 121 116 145 126\n#&gt; [15,] 125 124 118 142 130\n\nmauchly.test(lm(t~1),X = ~1)\n#&gt; \n#&gt;  Mauchly's test of sphericity\n#&gt;  Contrasts orthogonal to\n#&gt;  ~1\n#&gt; \n#&gt; \n#&gt; data:  SSD matrix from lm(formula = t ~ 1)\n#&gt; W = 0.11312, p-value = 0.0015\n\n\n### 双因素\n\ndf_split &lt;- df |&gt; group_split(group)\n\ndf[1:5,3:7]\n\n\n\n\nt0\nt1\nt2\nt3\nt4\n\n\n\n120\n108\n112\n120\n117\n\n\n118\n109\n115\n126\n123\n\n\n119\n112\n119\n124\n118\n\n\n121\n112\n119\n126\n120\n\n\n127\n121\n127\n133\n126\n\n\n\n\n\nCode\ndf2 &lt;- as.matrix(cbind(df_split[[1]][3:7],df_split[[2]][3:7],df_split[[3]][3:7]))\ntimes &lt;- ordered(rep(1:5,3))\ngroup &lt;- factor(rep(c(\"A\",\"B\",\"C\"),each=5))\n\n\n\n\n\nmauchly.test(lm(df2~1),M=~group+times,X=~ times)\n#&gt; \n#&gt;  Mauchly's test of sphericity\n#&gt;  Contrasts orthogonal to\n#&gt;  ~times\n#&gt; \n#&gt;  Contrasts spanned by\n#&gt;  ~group + times\n#&gt; \n#&gt; \n#&gt; data:  SSD matrix from lm(formula = df2 ~ 1)\n#&gt; W = 0.427, p-value = 0.279\n\n\n\n11.4.2 方差分析\n\n11.4.2.1 rstatix::anova_test()\n\n\nCode\na2 &lt;- rstatix::anova_test(data = df_long,\n           dv = BP,\n           wid = id,\n           within = time,\n           between = group\n           )\n\na2\n#&gt; ANOVA Table (type II tests)\n#&gt; \n#&gt; $ANOVA\n#&gt;       Effect DFn DFd       F        p p&lt;.05   ges\n#&gt; 1      group   2  12   5.783 1.70e-02     * 0.430\n#&gt; 2       time   4  48 106.558 3.02e-23     * 0.659\n#&gt; 3 group:time   8  48  19.101 1.62e-12     * 0.409\n#&gt; \n#&gt; $`Mauchly's Test for Sphericity`\n#&gt;       Effect     W     p p&lt;.05\n#&gt; 1       time 0.293 0.178      \n#&gt; 2 group:time 0.293 0.178      \n#&gt; \n#&gt; $`Sphericity Corrections`\n#&gt;       Effect   GGe      DF[GG]    p[GG] p[GG]&lt;.05   HFe      DF[HF]    p[HF]\n#&gt; 1       time 0.679 2.71, 32.58 1.87e-16         * 0.896 3.59, 43.03 4.65e-21\n#&gt; 2 group:time 0.679 5.43, 32.58 4.26e-09         * 0.896 7.17, 43.03 2.04e-11\n#&gt;   p[HF]&lt;.05\n#&gt; 1         *\n#&gt; 2         *\n\n\n输出是一个包含三个表的列表：\n\n方差分析结果显示标有（generalized eta squared，ges）的列上的 p 值和效应大小;效应大小本质上是由于受试者内因素而忽略受试者效应而导致的变异量。\nMauchly Sphericity检验。仅报告具有 &gt;2 水平的变量或效应，因为球形度必然适用于只有 2 个水平的效应。原假设是组差的方差相等。因此，显著的 p 值 （p &lt;= 0.05） 表示组差的方差不相等。\n球度校正结果，以防我们无法维持球形度假设。提供了文献中使用的两种常见校正：Greenhouse-Geisser epsilon （GGe） 和 Huynh-Feldt epsilon （HFe） 及其相应的 p 值\n\n11.4.2.2 ez::ezANOVA()\n\n\nCodelibrary(ez)\n\n# 进行重复测量方差分析\naov_ez &lt;- ezANOVA(data = df_long,\n                   dv = BP,\n                   wid = id,\n                   within = time,\n                   between = group,\n                   detailed = TRUE)\n\n# 查看球形检验结果\nprint(aov_ez)\n#&gt; $ANOVA\n#&gt;        Effect DFn DFd          SSn    SSd            F            p p&lt;.05\n#&gt; 1 (Intercept)   1  12 1155433.0800 946.48 14649.223396 6.784700e-20     *\n#&gt; 2       group   2  12     912.2400 946.48     5.782943 1.743351e-02     *\n#&gt; 3        time   4  48    2336.4533 263.12   106.557616 3.017101e-23     *\n#&gt; 4  group:time   8  48     837.6267 263.12    19.100638 1.621310e-12     *\n#&gt;         ges\n#&gt; 1 0.9989542\n#&gt; 2 0.4299287\n#&gt; 3 0.6588884\n#&gt; 4 0.4091519\n#&gt; \n#&gt; $`Mauchly's Test for Sphericity`\n#&gt;       Effect         W         p p&lt;.05\n#&gt; 3       time 0.2930746 0.1776608      \n#&gt; 4 group:time 0.2930746 0.1776608      \n#&gt; \n#&gt; $`Sphericity Corrections`\n#&gt;       Effect      GGe        p[GG] p[GG]&lt;.05      HFe        p[HF] p[HF]&lt;.05\n#&gt; 3       time 0.678693 1.867336e-16         * 0.896371 4.649080e-21         *\n#&gt; 4 group:time 0.678693 4.262529e-09         * 0.896371 2.041727e-11         *\n\n\n\n11.4.3 当满足球形度假设时\n\n球形度的 Mauchly 检验不显著 （p &gt; 0.05）;这表明，受试者内因素水平之间的差异方差是相等的。因此，我们可以假设协方差矩阵的球形度，并解释方差分析表中可用的标准输出。\n\nCode# Display ANOVA table\na2$ANOVA\n\n\n\n\nEffect\nDFn\nDFd\nF\np\np&lt;.05\nges\n\n\n\ngroup\n2\n12\n5.783\n0.017\n*\n0.430\n\n\ntime\n4\n48\n106.558\n0.000\n*\n0.659\n\n\ngroup:time\n8\n48\n19.101\n0.000\n*\n0.409\n\n\n\n\n\n\n\nF表示我们正在与 F 分布（F 检验）进行比较; 分别表示 time 和 Error（time） 的自由度; 表示得到的 F 统计量值(2, 18)81.8\np指定 p 值\nges（广义 eta 平方，eta2[g]）是效应大小（由于受试者内因素引起的变异量）\n\n11.4.4 当违反球形度假设时\n\n如果数据违反了球形度假设（即 Mauchly 检验，p &lt;= 0.05），则应解释表sphericity corrections中的结果，其中对自由度进行了调整，这会影响检验的统计显著性（即 p 值）。校正通过乘法和校正估计值（Greenhouse-Geisser （GG） 和 Huynh-Feldt （HF） ε 值）来应用。\n\n\n\n\n\n\nNote\n\n\n\nepsilon 提供了球形度被侵犯的程度的度量。值为 1 表示不偏离球形度（组差的所有方差均相等）。违反球形度会导致 epsilon 值低于 1。epsilon 离 1 越远，违规越严重。\n\n\n\nCodea2$`Sphericity Corrections`\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nEffect\nGGe\nDF[GG]\np[GG]\np[GG]&lt;.05\nHFe\nDF[HF]\np[HF]\np[HF]&lt;.05\n\n\n\ntime\n0.679\n2.71, 32.58\n0\n*\n0.896\n3.59, 43.03\n0\n*\n\n\ngroup:time\n0.679\n5.43, 32.58\n0\n*\n0.896\n7.17, 43.03\n0\n*\n\n\n\n\n\n\n可以看出，即使在球形度校正（p[GG] &lt; 0.001，p[HF] &lt; 0.001）之后，平均自尊得分在不同时间点仍存在统计学差异。\n在两种球形度校正方法中，Huynh-Feldt 校正被认为是最不保守的（高估了 epsilon），而 Greenhouse-Geisser 被认为是更保守的（当 epsilon 接近 1 时低估了 epsilon）。\n一般建议使用 Greenhouse-Geisser 校正，特别是当 epsilon &lt; 0.75 时。在 epsilon 大于 0.75 的情况下，一些统计学家建议使用 Huynh-Feldt 校正 （Girden 1992）。\n\nCode# correction = \"auto\"\nget_anova_table(a2)\n\n\n\n\nEffect\nDFn\nDFd\nF\np\np&lt;.05\nges\n\n\n\ngroup\n2\n12\n5.783\n0.017\n*\n0.430\n\n\ntime\n4\n48\n106.558\n0.000\n*\n0.659\n\n\ngroup:time\n8\n48\n19.101\n0.000\n*\n0.409\n\n\n\n\n\n\n\nCode# correction = \"GG\"\nget_anova_table(a2, correction = \"GG\")\n\n\n\n\nEffect\nDFn\nDFd\nF\np\np&lt;.05\nges\n\n\n\ngroup\n2.00\n12.00\n5.783\n0.017\n*\n0.430\n\n\ntime\n2.71\n32.58\n106.558\n0.000\n*\n0.659\n\n\ngroup:time\n5.43\n32.58\n19.101\n0.000\n*\n0.409\n\n\n\n\n\n\n\n11.4.5 post-hoc test\n\nCodedf_long |&gt; pairwise_t_test(BP~time,paired = T,p.adjust.method = \"bonferroni\")\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n.y.\ngroup1\ngroup2\nn1\nn2\nstatistic\ndf\np\np.adj\np.adj.signif\n\n\n\nBP\nt0\nt1\n15\n15\n3.8548215\n14\n2.00e-03\n1.80e-02\n*\n\n\nBP\nt0\nt2\n15\n15\n4.8281291\n14\n2.68e-04\n3.00e-03\n**\n\n\nBP\nt0\nt3\n15\n15\n-5.4116527\n14\n9.17e-05\n9.17e-04\n***\n\n\nBP\nt0\nt4\n15\n15\n-3.3349414\n14\n5.00e-03\n4.90e-02\n*\n\n\nBP\nt1\nt2\n15\n15\n0.0521691\n14\n9.59e-01\n1.00e+00\nns\n\n\nBP\nt1\nt3\n15\n15\n-10.2265652\n14\n1.00e-07\n7.00e-07\n****\n\n\nBP\nt1\nt4\n15\n15\n-8.4299370\n14\n7.00e-07\n7.40e-06\n****\n\n\nBP\nt2\nt3\n15\n15\n-6.6332058\n14\n1.13e-05\n1.13e-04\n***\n\n\nBP\nt2\nt4\n15\n15\n-5.8894810\n14\n3.94e-05\n3.94e-04\n***\n\n\nBP\nt3\nt4\n15\n15\n1.4675988\n14\n1.64e-01\n1.00e+00\nns",
    "crumbs": [
      "概率论与数理统计",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>重复测量方差分析</span>"
    ]
  },
  {
    "objectID": "rate_proportion_test.html",
    "href": "rate_proportion_test.html",
    "title": "\n12  比例检验\n",
    "section": "",
    "text": "12.1 单总体\n如果样本比较小，则使用二项分布进行统计. 在R中，对于小样本，采用 binom.test()，对于大样本使用正态分布近似二项分布，利用 prop.test()进行分析。 在单样本比例检验中，我们关心的是具有同种特性的两个群体，在该特性总体中所占有的比例情况。\n\\[\nZ=\\frac{p-\\pi_0}{\\sqrt{\\pi_0(1-\\pi_0)/n}}\\sim N(0,1)\n\\]\nCI：\\(\\bar p \\pm z_{1-\\alpha/2}\\sqrt{\\frac{p(1-p)}{n}}\\)\n对于小样本，可以连续校正\n\\[\nZ_{corr}=\\frac{|p-\\pi_0|-1/(2n)}{\\sqrt{\\pi_0(1-\\pi_0)/n}}\\sim N(0,1)\n\\]\n例如，小鼠中公鼠母鼠各有一半，有100只患有某种疾病，其中有公鼠60只，母鼠40只。想知道是否公鼠患病率比母鼠高。在该问题中成功次数为公鼠患病数60，总次数为100，预期比例为50% ( 公母鼠数量相等)\nCodep &lt;- 0.6\npi_0 &lt;- 0.5\nn &lt;- 100\nZ &lt;- (p-pi_0)/sqrt(pi_0*(1-pi_0)/n)\nZ_corr &lt;- (p-pi_0-1/(2*n))/sqrt(pi_0*(1-pi_0)/n)\nCode# 示例数据\nsuccesses &lt;- 60\ntotal &lt;- 100\np0 &lt;- 0.5\n\n# 使用 prop.test() 函数进行比例检验\nprop.test(\n    x = successes,\n    n = total,\n    p = p0,\n    alternative = \"greater\",\n    correct = F\n)\n#&gt; \n#&gt;  1-sample proportions test without continuity correction\n#&gt; \n#&gt; data:  successes out of total, null probability p0\n#&gt; X-squared = 4, df = 1, p-value = 0.02275\n#&gt; alternative hypothesis: true p is greater than 0.5\n#&gt; 95 percent confidence interval:\n#&gt;  0.5178095 1.0000000\n#&gt; sample estimates:\n#&gt;   p \n#&gt; 0.6\nCodeprop.test(\n    x = successes,\n    n = total,\n    p = p0,\n    alternative = \"greater\",\n    correct = T\n)\n#&gt; \n#&gt;  1-sample proportions test with continuity correction\n#&gt; \n#&gt; data:  successes out of total, null probability p0\n#&gt; X-squared = 3.61, df = 1, p-value = 0.02872\n#&gt; alternative hypothesis: true p is greater than 0.5\n#&gt; 95 percent confidence interval:\n#&gt;  0.5127842 1.0000000\n#&gt; sample estimates:\n#&gt;   p \n#&gt; 0.6",
    "crumbs": [
      "概率论与数理统计",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>比例检验</span>"
    ]
  },
  {
    "objectID": "rate_proportion_test.html#两总体",
    "href": "rate_proportion_test.html#两总体",
    "title": "\n12  比例检验\n",
    "section": "\n12.2 两总体",
    "text": "12.2 两总体\n当样本量较小时(所有np和n(1-p)都小于5)，通常采用非参数检验 Fisher Exact probability test 进行分析。当样本量较大时，使用近似正态分布z检验来进行预测。\n当\\(n_ip_i(1-p_i)≥5,(i=1,2)\\)时，\\(p_i\\dot\\sim N(\\pi_i,\\frac{\\pi_i(1-\\pi_i)}{n_i})\\)\n\\[\n(p_1-p_2)\\dot\\sim N(\\pi_1-\\pi_2,\\frac{\\pi_1(1-\\pi_1)}{n_1}+\\frac{\\pi_2(1-\\pi_2)}{n_2})\n\\]\n\\(H_0:\\pi_1=\\pi_2\\)\n\\[\nZ=\\frac{(p_1-p_2)-(\\pi_1-\\pi_2)}{S_{p_1-p_2}}=\\frac{p_1-p_2}{\\sqrt{p_C(1-p_C)(\\frac{1}{n_1}+\\frac{1}{n_2})}}\\dot\\sim N(0,1)\n\\]\n其中,合并比例\\(p_C=\\frac{n_1p_1+n_2p_2}{n_1+n_2}\\) 。\n如果我们已知两组具有不同特性(A和B)样本的样本量和这两样本中具有某种共同特性(C)的个体数量(也就是知道了C特性各自群体比例和总体比例)，想要计算具有C特性的个体在A特性群体和B特性群体中的比例是否一样，就需要用到双比例检验。\n例如，男生500人，女生500人，其中喜欢阅读的男生有400人，喜欢阅读的女生有460人。男生喜欢阅读的比例是否比女生高。我们假设男生喜欢阅读的比例比女生高，则备择假设是男生喜欢阅读的比例比女生低。\n\nCode# 示例数据\nsuccesses1 &lt;- 400\ntotal1 &lt;- 500\nsuccesses2 &lt;- 460\ntotal2 &lt;- 500\n\n# 使用 prop.test() 函数进行两总体比例检验\nprop.test(x = c(successes1, successes2), n = c(total1, total2), alternative = \"less\")\n#&gt; \n#&gt;  2-sample test for equality of proportions with continuity correction\n#&gt; \n#&gt; data:  c(successes1, successes2) out of c(total1, total2)\n#&gt; X-squared = 28.912, df = 1, p-value = 3.787e-08\n#&gt; alternative hypothesis: less\n#&gt; 95 percent confidence interval:\n#&gt;  -1.0000000 -0.0824468\n#&gt; sample estimates:\n#&gt; prop 1 prop 2 \n#&gt;   0.80   0.92\n\n\n功效分析\n\n\\(1-\\beta\\)\n\\(n1,n_2=kn_1\\)",
    "crumbs": [
      "概率论与数理统计",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>比例检验</span>"
    ]
  },
  {
    "objectID": "chi-square_test.html",
    "href": "chi-square_test.html",
    "title": "\n13  \\(\\chi^2\\) 检验\n",
    "section": "",
    "text": "13.1 卡方分布\n卡方分布可以通过原假设，得到一个统计量来表示期望结果和实际结果之间的偏离程度，进而根据分布，自由度和假设成立的情况，得出观察频率极值的发生概率（比当前统计结果更加极端的概率）。计算方法是对概率分布中的每个频率，用期望频数和实际频数差的平方除以期望频数，最后把所有结果相加。\n\\[ \\chi^2=\\sum \\frac {(O-E)^2} {E} \\]\n得到的统计量结果越大，说明差别越显著，数值越小说明观察和期望的差别越小，当观察频数和期望频数一致是卡方为0。其实就是在比较观测到的比例和期望的比例的关系。\nCodeggplot() + xlim(-10,10) +\n    geom_function(mapping = aes(color=\"normal Distribution\"),\n                  fun = dnorm, args = list(mean = 0, sd = 1),\n                   )+\n    geom_function(mapping = aes(color=\"chi-square Distribution\"),\n                  fun = dchisq, args = list(df = 1 ,ncp=0), \n                 )+\n    scale_color_manual(values = c(\"normal Distribution\" = \"red\",\n                                  \"chi-square Distribution\" = \"blue\"))+\n    labs(color = \"Distribution\")\n卡方分布就可以用来检验某个分类变量各类的出现概率是否等于指定概率，可以检验数据的拟合优度（指定的一组数据与指定分布的吻合度），也可以用来检验两个变量的独立性（两个变量之间是否存在某种关联）。\n在使用卡方检验时，需要的一个参数被称为自由度，指的是独立变量的个数（组数减去限制数）。通常，二项分布已知 \\(\\pi\\) ，泊松分布已知 \\(\\lambda\\) ，正态分布已知 \\(\\mu\\) 和 \\(\\sigma^2\\) 时的自由度是n-1。进行独立性检验时，n行m列联列表的自由度是(n-1) x (m-1)。\nPearson’s \\(\\chi^2\\) 检验 用于检验涉及双向无序多分类变量的概率或比例。",
    "crumbs": [
      "概率论与数理统计",
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>$\\chi^2$ 检验</span>"
    ]
  },
  {
    "objectID": "chi-square_test.html#列联表",
    "href": "chi-square_test.html#列联表",
    "title": "\n13  \\(\\chi^2\\) 检验\n",
    "section": "\n13.2 2×2列联表",
    "text": "13.2 2×2列联表\n独立性：判断两个或多个分类变量之间是否存在关联或取值互不影响，分析联合概率分布是否可以分解为各自概率分布的乘积。\n\n13.2.1 卡方检验\n对于频数表中每个单元格的期望频数都比较大（大于 5）的大样本，correct设为FALSE,不进行连续校正。\n\nCodex &lt;- matrix(c(97,73,7,30),2,dimnames = list(c(\"experiment\",\"control\"),c(\"+\",\"-\")))\nx\n#&gt;             +  -\n#&gt; experiment 97  7\n#&gt; control    73 30\n\n(k1 &lt;- chisq.test(x,correct = F))\n#&gt; \n#&gt;  Pearson's Chi-squared test\n#&gt; \n#&gt; data:  x\n#&gt; X-squared = 17.681, df = 1, p-value = 2.612e-05\n\n# 期望频数列联表\nk1$expected\n#&gt;                   +        -\n#&gt; experiment 85.41063 18.58937\n#&gt; control    84.58937 18.41063\n\nk1$parameter # degrees of freedom\n#&gt; df \n#&gt;  1\n\n\n\n13.2.2 Yate’s 校正\n某些单元格的期望频数接近于或小于 5 时，进行 Yates’ 连续校正以修正卡方统计量提高准确性。\n\nCodex &lt;- matrix(c(1004, 325, 20, 1), 2, \n            dimnames = list(c(\"experiment\", \"control\"), c(\"+\", \"-\")))\nx\n#&gt;               +  -\n#&gt; experiment 1004 20\n#&gt; control     325  1\n\nchisq.test(x,correct = F)$expected\n#&gt;                    +         -\n#&gt; experiment 1008.0711 15.928889\n#&gt; control     320.9289  5.071111\n\n# 校正\n(k2 &lt;- chisq.test(x,correct = T))\n#&gt; \n#&gt;  Pearson's Chi-squared test with Yates' continuity correction\n#&gt; \n#&gt; data:  x\n#&gt; X-squared = 3.3678, df = 1, p-value = 0.06648\n\n\n\n13.2.3 Fisher’s Exact 检验\nFisher 精确概率检验（Fisher’s Exact Test）通常在以下情况中使用：\n\n总样本数 n 小于 40；\n列联表中任何一个单元格的期望频数小于 5。\n\n\nCodex &lt;- matrix(c(7,2,7,17),2,dimnames = list(c(\"A\",\"B\"),c(\"Yes\",\"No\")))\nx\n#&gt;   Yes No\n#&gt; A   7  7\n#&gt; B   2 17\n\n(k5 &lt;- fisher.test(x))\n#&gt; \n#&gt;  Fisher's Exact Test for Count Data\n#&gt; \n#&gt; data:  x\n#&gt; p-value = 0.01914\n#&gt; alternative hypothesis: true odds ratio is not equal to 1\n#&gt; 95 percent confidence interval:\n#&gt;   1.134346 96.442876\n#&gt; sample estimates:\n#&gt; odds ratio \n#&gt;   7.892809\n chisq.test(x)\n#&gt; \n#&gt;  Pearson's Chi-squared test with Yates' continuity correction\n#&gt; \n#&gt; data:  x\n#&gt; X-squared = 4.4985, df = 1, p-value = 0.03393\n\nE &lt;- chisq.test(x)$expected\n\nchisq &lt;- sum((x-E)^2/E)\nchisq \n#&gt; [1] 6.332237\n\np_value_asymptotic &lt;- 1 - pchisq(chisq, df = 1)\n\n\n\n13.2.4 超几何分布\n\n\nCode\ntibble(\n    x = -10:10,\n    y_hyper = dhyper(x, m = 10,n = 7,k = 8),\n) %&gt;% \n    ggplot()+\n    geom_col(aes(x=x,y = y_hyper,color=\"Hypergeometric Distribution\"),fill=NA)+\n    geom_function(aes(color=\"Normal Distribution\"),\n                  fun= dnorm, args = list(mean = 0, sd = 1))+\n    scale_color_manual(values = c(\"Normal Distribution\" = \"red\",\n                                  \"Hypergeometric Distribution\" = \"blue\"))+\n    labs(color = \"Distribution\")",
    "crumbs": [
      "概率论与数理统计",
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>$\\chi^2$ 检验</span>"
    ]
  },
  {
    "objectID": "chi-square_test.html#配对四格表",
    "href": "chi-square_test.html#配对四格表",
    "title": "\n13  \\(\\chi^2\\) 检验\n",
    "section": "\n13.3 配对四格表",
    "text": "13.3 配对四格表\n\n13.3.1 二项分布\n\nCode\ntibble(\n    x = -5:15,\n    y_binom = dbinom(x, size = 10,prob = 0.5),\n) %&gt;% \nggplot()+\n    geom_col(aes(x=x,y=y_binom,color=\"binomal Distribution\"),fill=NA)+\n    geom_function(mapping = aes(color=\"normal Distribution\"),\n                  fun = dnorm, args = list(mean = 5, sd = 1),\n                   )+\n    scale_color_manual(values = c(\"normal Distribution\" = \"red\",\n                                  \"binomal Distribution\" = \"blue\"))+\n    labs(color = \"Distribution\")\n\n\n\n\n\n\n\n\n13.3.2 McNemar’s 检验\n20 &lt; b+c =5 + 34 &lt; 40\n\nCodex &lt;- matrix(c(36,34,5,135),2,dimnames = list(c(\"A+\",\"A-\"),c(\"B+\",\"B-\")))\nx\n#&gt;    B+  B-\n#&gt; A+ 36   5\n#&gt; A- 34 135\n\n(k3 &lt;- mcnemar.test(x,correct = F))\n#&gt; \n#&gt;  McNemar's Chi-squared test\n#&gt; \n#&gt; data:  x\n#&gt; McNemar's chi-squared = 21.564, df = 1, p-value = 3.422e-06\n\n\n# 对于配对四格表，如果样本量较小（不一致的结果的总数小于 40 ） ，则需要进行连续性校正。\n(k4 &lt;- mcnemar.test(x,correct = T))\n#&gt; \n#&gt;  McNemar's Chi-squared test with continuity correction\n#&gt; \n#&gt; data:  x\n#&gt; McNemar's chi-squared = 20.103, df = 1, p-value = 7.34e-06\n\n\n\nCode#　　某实验室分别用免疫荧光法和乳胶凝集法对 58 名疑似系统性红斑狼疮患者血清中抗 核抗体进行测定\nresult&lt;- matrix(c(11, 2, 12, 33), nrow = 2,dimnames = list(c(\"+\",\"-\"),c(\"+\",\"-\")))\nresult\n#&gt;    +  -\n#&gt; + 11 12\n#&gt; -  2 33\n\n#　　对于配对四格表，如果样本量较小（不一致的结果的总数小于 40 ） ，则需要进行连续性校正。\nmcnemar.test(result,correct = TRUE)\n#&gt; \n#&gt;  McNemar's Chi-squared test with continuity correction\n#&gt; \n#&gt; data:  result\n#&gt; McNemar's chi-squared = 5.7857, df = 1, p-value = 0.01616\n\n\n\n13.3.3 精确 McNemar’s 检验\nb+c = 7 + 1 &lt;20\n二项分布B（b+c，0.5），k=min（b，c）\n\\[\nP=\\sum_{i≤k} p_i\n\\]\n\nCodex &lt;- matrix(c(3,1,7,9),2,dimnames = list(c(\"A+\",\"A-\"),c(\"B+\",\"B-\")))\nx\n#&gt;    B+ B-\n#&gt; A+  3  7\n#&gt; A-  1  9\n\nP_two_sided &lt;- 2*sum(dbinom(x=0:1,size = 8,prob = 0.5))\nP_two_sided\n#&gt; [1] 0.0703125",
    "crumbs": [
      "概率论与数理统计",
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>$\\chi^2$ 检验</span>"
    ]
  },
  {
    "objectID": "chi-square_test.html#rc列联表",
    "href": "chi-square_test.html#rc列联表",
    "title": "\n13  \\(\\chi^2\\) 检验\n",
    "section": "\n13.4 R×C列联表",
    "text": "13.4 R×C列联表\n\n13.4.1 卡方检验\n在 R×C 列联表的情况下，如果表中的单元格期望频数满足以下条件：\n\n期望频数 T &lt; 5 的单元格不超过 1/5。\n没有单元格期望频数 T &lt; 1 。\n\n那么可以选择不进行连续校正\n\nCodex &lt;- matrix(c(150,184,198,50,16,2),3,dimnames = list(c(\"A\",\"B\",\"C\"),c(\"Yes\",\"No\")))\nx\n#&gt;   Yes No\n#&gt; A 150 50\n#&gt; B 184 16\n#&gt; C 198  2\n\n(k &lt;- chisq.test(x,correct = F))\n#&gt; \n#&gt;  Pearson's Chi-squared test\n#&gt; \n#&gt; data:  x\n#&gt; X-squared = 60.637, df = 2, p-value = 6.806e-14\n\n\n\nCode(k &lt;- chisq.test(x,correct = T))\n#&gt; \n#&gt;  Pearson's Chi-squared test\n#&gt; \n#&gt; data:  x\n#&gt; X-squared = 60.637, df = 2, p-value = 6.806e-14\nk$expected\n#&gt;        Yes       No\n#&gt; A 177.3333 22.66667\n#&gt; B 177.3333 22.66667\n#&gt; C 177.3333 22.66667\n\n\n\n13.4.2 多重比较\n\\[\n\\alpha'=\\frac {\\alpha}{比较的次数=\\frac{k(k-1)}{2}}\n\\]\n\n13.4.2.1 卡方分割法\n卡方分割法与Bonferroni方法调整p值是两种不同的统计分析方法，主要用于处理多重比较问题。它们的区别如下： 1. 卡方分割法 - 定义：卡方分割法通常用于对卡方检验结果进行后续分析，以确定哪些具体的类别或组之间存在显著差异。该方法基于检验统计量在每对比较中的分布进行分析。 - 应用：常用于发现哪些特定组（行或列）之间存在差异，通常需要进行后续的成对比较。 - 目的：帮助识别在显著性结果中，具体是哪些组之间存在显著差异。\n\n13.4.2.2 Bonferroni方法\n\n定义：Bonferroni方法是一种用于控制多重比较的显著性水平的校正方法。在进行多次假设检验时，原始的显著性水平（例如0.05）会被除以比较次数，从而得出新的显著性水平。\n应用：适用于多个独立检验结果的显著性水平调整，以减少因多重比较导致的假阳性率。\n目的：降低第一类错误的概率（即假阳性），确保在多次检验中保持整体的显著性水平。\n卡方分割法更侧重于分析具体的类别差异，而Bonferroni方法则专注于调整p值以控制错误率。\n如果你已经通过卡方检验发现某些组之间有显著差异，卡方分割法可以帮助你进一步了解哪些组之间有差异。而Bonferroni方法在初步检验前就帮助控制多重比较的问题，确保分析结果的可靠性。 ’\n\n\nCode\n# 创建频率矩阵\ndata &lt;- matrix(c(251, 225,\n                 368, 347,\n                 132, 16,\n                 54, 22,\n                 9, 18,\n                 21, 110,\n                 4, 30,\n                 46, 93), \n               nrow = 8, \n               byrow = TRUE)\n\n# 为矩阵添加行和列名称\nrownames(data) &lt;- c(\"团队\", \"球员\", \"教练\", \"品牌\", \"管理\", \"历史\", \"文化\", \"其他\")\ncolnames(data) &lt;- c(\"Period 1\", \"Period 2\")\n\n# 执行卡方检验\nchi_square_result &lt;- chisq.test(data, correct=T)\n\n# 显示结果\nprint(chi_square_result)\n#&gt; \n#&gt;  Pearson's Chi-squared test\n#&gt; \n#&gt; data:  data\n#&gt; X-squared = 205.38, df = 7, p-value &lt; 2.2e-16\n\n# 提取卡方值，自由度和p值\nchi_square_value &lt;- chi_square_result$statistic\ndegrees_of_freedom &lt;- chi_square_result$parameter\np_value &lt;- chi_square_result$p.value\n\n# 打印结果\ncat(\"卡方值:\", chi_square_value, \"\\n\")\n#&gt; 卡方值: 205.3786\ncat(\"自由度:\", degrees_of_freedom, \"\\n\")\n#&gt; 自由度: 7\ncat(\"显著性水平 (p值):\", p_value, \"\\n\")\n#&gt; 显著性水平 (p值): 8.326236e-41\n\n\n# 进行多重卡方检验\nchi_square_results &lt;- apply(data, 1, function(x) chisq.test(matrix(x, nrow=2)))\n\n# 提取卡方，自由度，p值\n\nX2 &lt;-  sapply(chi_square_results, function(x) x$statistic)\n\np_values &lt;- sapply(chi_square_results, function(x) x$p.value)\n\ndf &lt;- sapply(chi_square_results, function(x) x$parameter)\n\n# 多重比较调整\nadjusted_p_values &lt;- p.adjust(p_values, method = \"bonferroni\")\n\nsignifcance &lt;- case_when(\n    \n    adjusted_p_values&lt;0.001 ~ \"***\",\n    adjusted_p_values&lt;0.01 ~ \"**\",\n    adjusted_p_values&lt;0.05 ~ \"*\",\n    .default = \"ns\"\n    \n)\n    \n    \n    \nresults &lt;- tibble(\n    dimension = rownames(data),\n    chisq_statistic = X2,\n    p_value = p_values,\n    p_adjust = adjusted_p_values,\n    signifcance = signifcance\n)\n\nprint(results)\n#&gt; # A tibble: 8 × 5\n#&gt;   dimension chisq_statistic  p_value p_adjust signifcance\n#&gt;   &lt;chr&gt;               &lt;dbl&gt;    &lt;dbl&gt;    &lt;dbl&gt; &lt;chr&gt;      \n#&gt; 1 团队                1.42  2.33e- 1 1   e+ 0 ns         \n#&gt; 2 球员                0.617 4.32e- 1 1   e+ 0 ns         \n#&gt; 3 教练               90.9   1.50e-21 1.20e-20 ***        \n#&gt; 4 品牌               13.5   2.42e- 4 1.94e- 3 **         \n#&gt; 5 管理                3     8.33e- 2 6.66e- 1 ns         \n#&gt; 6 历史               60.5   7.49e-15 5.99e-14 ***        \n#&gt; 7 文化               19.9   8.24e- 6 6.59e- 5 ***        \n#&gt; 8 其他               15.9   6.71e- 5 5.36e- 4 ***",
    "crumbs": [
      "概率论与数理统计",
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>$\\chi^2$ 检验</span>"
    ]
  },
  {
    "objectID": "chi-square_test.html#拟合优度检验",
    "href": "chi-square_test.html#拟合优度检验",
    "title": "\n13  \\(\\chi^2\\) 检验\n",
    "section": "\n13.5 拟合优度检验",
    "text": "13.5 拟合优度检验\nPearson’s \\(\\chi^2\\) goodness-of-fit test",
    "crumbs": [
      "概率论与数理统计",
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>$\\chi^2$ 检验</span>"
    ]
  },
  {
    "objectID": "chi-square_test.html#cochran-mantel-haenszel-chi2-检验",
    "href": "chi-square_test.html#cochran-mantel-haenszel-chi2-检验",
    "title": "\n13  \\(\\chi^2\\) 检验\n",
    "section": "\n13.6 Cochran-Mantel-Haenszel \\(\\chi^2\\) 检验",
    "text": "13.6 Cochran-Mantel-Haenszel \\(\\chi^2\\) 检验\n又叫行均分检验，常用于按照某个变量进行分层后的检验，用于检验两个有序分类变量是否存在线性相关，但实际上用途很广泛，比如因变量是有序变量的单向有序列联表，也可以用。　　\n两个变量的关联有可能受到第三个变量的影响，因此我们有必要检验两个分类变量在 调整（控制）第三个变量的情况下是否独立。 Cochran-Mantel-Haenszel χ 2 检验常用于探索 变量间的混杂因素。其零假设是：两个分类变量在第三个变量的每一层都是条件独立的。函数 mantelhaen.test( ) 可以用来进行该检验。\n\nCodeRabbits &lt;-\narray(c(0, 0, 6, 5,\n        3, 0, 3, 6,\n        6, 2, 0, 4,\n        5, 6, 1, 0,\n        2, 5, 0, 0),\n      dim = c(2, 2, 5),\n      dimnames = list(\n          Delay = c(\"None\", \"1.5h\"),\n          Response = c(\"Cured\", \"Died\"),\n          Penicillin.Level = c(\"1/8\", \"1/4\", \"1/2\", \"1\", \"4\")))\nRabbits\n#&gt; , , Penicillin.Level = 1/8\n#&gt; \n#&gt;       Response\n#&gt; Delay  Cured Died\n#&gt;   None     0    6\n#&gt;   1.5h     0    5\n#&gt; \n#&gt; , , Penicillin.Level = 1/4\n#&gt; \n#&gt;       Response\n#&gt; Delay  Cured Died\n#&gt;   None     3    3\n#&gt;   1.5h     0    6\n#&gt; \n#&gt; , , Penicillin.Level = 1/2\n#&gt; \n#&gt;       Response\n#&gt; Delay  Cured Died\n#&gt;   None     6    0\n#&gt;   1.5h     2    4\n#&gt; \n#&gt; , , Penicillin.Level = 1\n#&gt; \n#&gt;       Response\n#&gt; Delay  Cured Died\n#&gt;   None     5    1\n#&gt;   1.5h     6    0\n#&gt; \n#&gt; , , Penicillin.Level = 4\n#&gt; \n#&gt;       Response\n#&gt; Delay  Cured Died\n#&gt;   None     2    0\n#&gt;   1.5h     5    0\n\nmantelhaen.test(Rabbits)\n#&gt; \n#&gt;  Mantel-Haenszel chi-squared test with continuity correction\n#&gt; \n#&gt; data:  Rabbits\n#&gt; Mantel-Haenszel X-squared = 3.9286, df = 1, p-value = 0.04747\n#&gt; alternative hypothesis: true common odds ratio is not equal to 1\n#&gt; 95 percent confidence interval:\n#&gt;   1.026713 47.725133\n#&gt; sample estimates:\n#&gt; common odds ratio \n#&gt;                 7",
    "crumbs": [
      "概率论与数理统计",
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>$\\chi^2$ 检验</span>"
    ]
  },
  {
    "objectID": "nonparametric_test.html",
    "href": "nonparametric_test.html",
    "title": "\n14  非参数秩检验\n",
    "section": "",
    "text": "14.1 秩\n\\[\nF(Median)=P(X\\le Median)=0.5\n\\]",
    "crumbs": [
      "概率论与数理统计",
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>非参数秩检验</span>"
    ]
  },
  {
    "objectID": "nonparametric_test.html#二项分布bn0.5",
    "href": "nonparametric_test.html#二项分布bn0.5",
    "title": "\n14  非参数秩检验\n",
    "section": "\n14.2 二项分布B(n，0.5)",
    "text": "14.2 二项分布B(n，0.5)\n\nCodetibble(\n    x = -5:15,\n    y_binom = dbinom(x, size = 10,prob = 0.5),\n) %&gt;% \nggplot()+\n    geom_col(aes(x=x,y=y_binom,color=\"binomal Distribution\"),fill=NA)+\n    geom_function(mapping = aes(color=\"normal Distribution\"),\n                  fun = dnorm, args = list(mean = 5, sd = 1),\n                   )+\n    scale_color_manual(values = c(\"normal Distribution\" = \"red\",\n                                  \"binomal Distribution\" = \"blue\"))+\n    labs(color = \"Distribution\")",
    "crumbs": [
      "概率论与数理统计",
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>非参数秩检验</span>"
    ]
  },
  {
    "objectID": "nonparametric_test.html#单样本-wilcoxon-signed-rank-exact-test",
    "href": "nonparametric_test.html#单样本-wilcoxon-signed-rank-exact-test",
    "title": "\n14  非参数秩检验\n",
    "section": "\n14.3 单样本 Wilcoxon Signed-Rank exact test",
    "text": "14.3 单样本 Wilcoxon Signed-Rank exact test\n如果样本数据没有通过正态分布检验就要采用单样本wilcoxon符号秩检验进行计算。使用该检验需要满足的条件是样本值均匀地分布在均值两侧。\n\nCodeset.seed(123)\nx &lt;- runif(n = 100,min = 6,max = 8)\nhist(x)\n\n\n\n\n\n\nCodeshapiro.test(x)\n#&gt; \n#&gt;  Shapiro-Wilk normality test\n#&gt; \n#&gt; data:  x\n#&gt; W = 0.95237, p-value = 0.001192\nwilcox.test(x, mu=7) \n#&gt; \n#&gt;  Wilcoxon signed rank test with continuity correction\n#&gt; \n#&gt; data:  x\n#&gt; V = 2518, p-value = 0.9822\n#&gt; alternative hypothesis: true location is not equal to 7",
    "crumbs": [
      "概率论与数理统计",
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>非参数秩检验</span>"
    ]
  },
  {
    "objectID": "nonparametric_test.html#双样本",
    "href": "nonparametric_test.html#双样本",
    "title": "\n14  非参数秩检验\n",
    "section": "\n14.4 双样本",
    "text": "14.4 双样本\n\n14.4.1 配对 Wilcoxon’s signed-rank test(Mann-Whitney U 检验)\n\\[\nT_++T_-=\\frac{n(n+1)}{2},n为非零配对差值的数量\n\\]\n\\[\nT=min{(T_+,T_-)}\n\\]\n5 ≤ n ≤30，附表T0\nn＞16，正态近似法\n\nCode\ndf &lt;- tibble(\n    low=c(958.5,838.4,612.2,812.9,739.0,899.4,758.5,695.0,749.7,815.5),\n    high=c(958.5,866.5,788.9,815.2,783.2,910.9,760.8,870.8,862.3,799.9),\n)\n\nshapiro.test(df$high-df$low)\n#&gt; \n#&gt;  Shapiro-Wilk normality test\n#&gt; \n#&gt; data:  df$high - df$low\n#&gt; W = 0.79689, p-value = 0.01329\n\n# 忽略 差值为0的值对\nwilcox.test(df$low[-1],df$high[-1],exact = T,paired = T)\n#&gt; \n#&gt;  Wilcoxon signed rank exact test\n#&gt; \n#&gt; data:  df$low[-1] and df$high[-1]\n#&gt; V = 4, p-value = 0.02734\n#&gt; alternative hypothesis: true location shift is not equal to 0\n\n\n\n14.4.2 独立 Wilcoxon’s Rank-Sum 检验\n当两个样本不满足正态分布时，使用Wilcoxon秩和检验进行非参数检验\n用于比较两个独立样本的中位数是否相等。\n\\[\nT=T_{min(n1,n2)}=T_1\n\\]\n\nCodeMVR = c(38, 29, 35, 33, 38, 41, 31)\nMVP = c(32, 43, 44, 81, 35, 46, 37, 45, 44)\nshapiro.test(c(MVR,MVP))\n#&gt; \n#&gt;  Shapiro-Wilk normality test\n#&gt; \n#&gt; data:  c(MVR, MVP)\n#&gt; W = 0.70443, p-value = 0.0001889\n\ncombined_data &lt;- c(MVR, MVP)\nranked_data &lt;- rank(combined_data)\nranked_data \n#&gt;  [1]  8.5  1.0  5.5  4.0  8.5 10.0  2.0  3.0 11.0 12.5 16.0  5.5 15.0  7.0 14.0\n#&gt; [16] 12.5\n\nMVR_ranks &lt;- ranked_data[1:length(MVR)]\nMVP_ranks &lt;- ranked_data[(length(MVR)+1):length(combined_data)]\n\nT1 &lt;- sum(MVR_ranks)\nT2 &lt;- sum(MVP_ranks)\n\nW &lt;- T1-length(MVR)*(length(MVR)+1)/2\n\n\n曼-惠特尼 U 统计量\n\\[\n曼-惠特尼U统计量\\ \\ W= 威尔科克森W秩和\\  \\ \\  T_1-\\frac{n_1(n_1+1)}{2}\n\\]\nn1&lt;10,n2-n1&lt;10，附录\nn1&gt;10,n2&gt;10，正态近似法\n\nCodewilcox.test(MVR,MVP,exact = F,correct = F)\n#&gt; \n#&gt;  Wilcoxon rank sum test\n#&gt; \n#&gt; data:  MVR and MVP\n#&gt; W = 11.5, p-value = 0.03386\n#&gt; alternative hypothesis: true location shift is not equal to 0\n\n\n\n14.4.3 Wilcoxon Distribution\n\nCode\ntibble(\n    x = 0:100,\n    y =dwilcox(x,m = 7,n = 9)\n) %&gt;% \n    ggplot() +\n    geom_col(aes(x,y),fill=\"lightblue\",color=\"black\")+\n    ggtitle(\"Wilcoxon Distribution\")",
    "crumbs": [
      "概率论与数理统计",
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>非参数秩检验</span>"
    ]
  },
  {
    "objectID": "nonparametric_test.html#多样本",
    "href": "nonparametric_test.html#多样本",
    "title": "\n14  非参数秩检验\n",
    "section": "\n14.5 多样本",
    "text": "14.5 多样本\n\n14.5.1 独立 Kruskal-Wallis 检验\n用于比较三个或更多独立样本的中位数是否相等。\n假设：\n\n随机，独立\n每个样本至少5个观测\n能够计算秩次\n\n\nCodekruskal.test(weight~group,data = PlantGrowth)\n#&gt; \n#&gt;  Kruskal-Wallis rank sum test\n#&gt; \n#&gt; data:  weight by group\n#&gt; Kruskal-Wallis chi-squared = 7.9882, df = 2, p-value = 0.01842\n\n\n\n14.5.1.1 多重比较\n\nCodepairwise.wilcox.test(PlantGrowth$weight,PlantGrowth$group,p.adjust.method = \"fdr\",exact=F)\n#&gt; \n#&gt;  Pairwise comparisons using Wilcoxon rank sum test with continuity correction \n#&gt; \n#&gt; data:  PlantGrowth$weight and PlantGrowth$group \n#&gt; \n#&gt;      ctrl  trt1 \n#&gt; trt1 0.199 -    \n#&gt; trt2 0.096 0.034\n#&gt; \n#&gt; P value adjustment method: fdr\n\n\n\n14.5.2 相关 Friedman 检验\n用于比较三个或更多相关样本的中位数是否相等。\n\nCode# 假设有三个相关样本 x, y, z\nx &lt;- c(14, 17, 20, 23, 25)\ny &lt;- c(15, 18, 21, 24, 26)\nz &lt;- c(16, 19, 22, 25, 27)\n\n# 将样本合并成一个数据框，并指定组别和受试者\ndata &lt;- data.frame(\n  value = c(x, y, z),\n  group = factor(rep(c(\"x\", \"y\", \"z\"), each = 5)),\n  subject = factor(rep(1:5, 3))\n)\n\n# 使用 friedman.test() 函数进行检验\nresult &lt;- friedman.test(value ~ group | subject, data = data)\n\n# 输出检验结果\nprint(result)\n#&gt; \n#&gt;  Friedman rank sum test\n#&gt; \n#&gt; data:  value and group and subject\n#&gt; Friedman chi-squared = 10, df = 2, p-value = 0.006738",
    "crumbs": [
      "概率论与数理统计",
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>非参数秩检验</span>"
    ]
  },
  {
    "objectID": "nonparametric_test.html#kendalls-tau-检验",
    "href": "nonparametric_test.html#kendalls-tau-检验",
    "title": "\n14  非参数秩检验\n",
    "section": "\n14.6 Kendall’s Tau 检验",
    "text": "14.6 Kendall’s Tau 检验\n用途：用于检验两个变量之间的相关性。\n\nCode# 假设有两个变量 x 和 y\nx &lt;- c(14, 17, 20, 23, 25)\ny &lt;- c(15, 18, 21, 24, 26)\n\n# 使用 cor.test() 函数进行 Kendall's Tau 检验\nresult &lt;- cor.test(x, y, method = \"kendall\")\n\n# 输出检验结果\nprint(result)\n#&gt; \n#&gt;  Kendall's rank correlation tau\n#&gt; \n#&gt; data:  x and y\n#&gt; T = 10, p-value = 0.01667\n#&gt; alternative hypothesis: true tau is not equal to 0\n#&gt; sample estimates:\n#&gt; tau \n#&gt;   1",
    "crumbs": [
      "概率论与数理统计",
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>非参数秩检验</span>"
    ]
  },
  {
    "objectID": "nonparametric_test.html#spearmans-rank-correlation-检验",
    "href": "nonparametric_test.html#spearmans-rank-correlation-检验",
    "title": "\n14  非参数秩检验\n",
    "section": "\n14.7 Spearman’s Rank Correlation 检验",
    "text": "14.7 Spearman’s Rank Correlation 检验\n用途：用于检验两个变量之间的相关性，适用于数据非线性关系。\n\nCode# 假设有两个变量 x 和 y\nx &lt;- c(14, 17, 20, 23, 25)\ny &lt;- c(15, 18, 21, 24, 26)\n\n# 使用 cor.test() 函数进行 Spearman's Rank Correlation 检验\nresult &lt;- cor.test(x, y, method = \"spearman\")\n\n# 输出检验结果\nprint(result)\n#&gt; \n#&gt;  Spearman's rank correlation rho\n#&gt; \n#&gt; data:  x and y\n#&gt; S = 4.4409e-15, p-value = 0.01667\n#&gt; alternative hypothesis: true rho is not equal to 0\n#&gt; sample estimates:\n#&gt; rho \n#&gt;   1",
    "crumbs": [
      "概率论与数理统计",
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>非参数秩检验</span>"
    ]
  },
  {
    "objectID": "correlation.html",
    "href": "correlation.html",
    "title": "\n15  相关性\n",
    "section": "",
    "text": "15.1 分类变量\n如果独立性检验的结果表明两个变量之间不独立，那么如何量化它们之间相关性的强弱?",
    "crumbs": [
      "概率论与数理统计",
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>相关性</span>"
    ]
  },
  {
    "objectID": "correlation.html#分类变量",
    "href": "correlation.html#分类变量",
    "title": "\n15  相关性\n",
    "section": "",
    "text": "15.1.1 Phi 系数、列联系数和 Cramer’s V 系数\n\nvcd 包里的函数 assocstats( )可以用来计算列联表的 Phi 系数、列联系数和 Cramer’s V 系数。其中， Phi 系数只适用于四格表。 　　\n\nCodelibrary(vcd)\nmytable &lt;- table(Arthritis$Sex, Arthritis$Treatment)\nassocstats(mytable)\n#&gt;                      X^2 df P(&gt; X^2)\n#&gt; Likelihood Ratio 0.73748  1  0.39047\n#&gt; Pearson          0.73653  1  0.39078\n#&gt; \n#&gt; Phi-Coefficient   : 0.094 \n#&gt; Contingency Coeff.: 0.093 \n#&gt; Cramer's V        : 0.094\n\n\n\n15.1.2 Kappa 统计量\n对于配对列联表，可以计算一致性指标 Kappa 统计量。 epiDisplay 包里的函数 kap( )可以用于计算一致性的比例以及 Kappa 统计量的值 　　 　　\n\nCodemy.matrix &lt;- matrix(c(11, 2, 12, 33), nrow = 2)\nsum(my.matrix)\n#&gt; [1] 58\nvcd::Kappa(my.matrix)\n#&gt;            value    ASE     z Pr(&gt;|z|)\n#&gt; Unweighted 0.455 0.1153 3.945 7.97e-05\n#&gt; Weighted   0.455 0.1153 3.945 7.97e-05\nepiDisplay::kap(my.matrix)\n#&gt; \n#&gt;  Table for calculation of kappa\n#&gt;    A  B\n#&gt; A 11 12\n#&gt; B  2 33\n#&gt; \n#&gt; Observed agreement = 75.86 % \n#&gt; Expected agreement = 55.71 % \n#&gt; Kappa = 0.455 \n#&gt; Standard error = 0.121 , Z = 3.762 , P value = &lt; 0.001 \n#&gt; \n\n\n　　共 58 个对象，每一对象用两种检测方法检测，其中11 个对象的两种检测结果都为阳性， 33 个对象的两种检测结果都是阴性，所以总一致性为 (11 + 33)/58 ≈ 75.86% 。\n\nCodechisq.test(my.matrix)$expected\n#&gt;          [,1]     [,2]\n#&gt; [1,] 5.155172 17.84483\n#&gt; [2,] 7.844828 27.15517\n\n\n　为了解释期望一致性和 Kappa 值的含义，先计算各个单元格的期望频数。 对角线上的这两个单元格对应的期望频数分别约为5.155172 和27.15517 ，因此期望一致性为 (5.155172+27.15517)/58≈ 55.71% 。期望一致性是假定两种方法的检测结果都是完全随机的情况下的 一致性。也就是说，即使两种检测方法都毫无作用，平均也能达到 55.71% 的一致性。 Kappa 统计量是超出随机的一致性的部分占最大可能超出随机的一致性的比例。在本例中，前者为 75.86% − 55.71% ， 后者为 100% − 55.71% 。 因此， Kappa 值为 (75.86 - 55.71)/(100 - 55.71) ≈ 0.455\n\n15.1.3 马赛克图\n　　马赛克图中的矩形面积正比于多维列联表中单元格的频率 　　\n\nCodemosaicplot(mytable,xlab =\"Sex\",ylab =  \"Treatment\",las = 1)\n\n\n\n\n\n\nCodemosaicplot(my.matrix)",
    "crumbs": [
      "概率论与数理统计",
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>相关性</span>"
    ]
  },
  {
    "objectID": "correlation.html#连续变量",
    "href": "correlation.html#连续变量",
    "title": "\n15  相关性\n",
    "section": "\n15.2 连续变量",
    "text": "15.2 连续变量\n如果两个连续变量不相互独立时，使用协方差（covariance）来描述两个变量的关系。\n协方差（或相关系数）为零，不相关，不存在线性关系，但可能存在非线性关系。\n\nCodedf &lt;- mpg[,c(3,8,9)]\ncov(df)    # 协方差矩阵\n#&gt;           displ      cty       hwy\n#&gt; displ  1.669158 -4.39069 -5.893111\n#&gt; cty   -4.390690 18.11307 24.225432\n#&gt; hwy   -5.893111 24.22543 35.457779\n\n\n\n15.2.0.1 相关系数\n相关系数的取值范围： \\([-1,1]\\)\n\\[\nr(X,Y)=\\frac {\\sum_{i=1}^n (x_i-\\bar x)(y_i-\\bar y)}{\\sqrt{\\sum_{i=1}^n (x_i-\\bar x)^2 \\sum_{i=1}^n (y_i-\\bar y)^2}}\n\\]\n\nCode# Pearson's 积差相关系数 　　一般要求两个连续变量都服从正态分布\ncor(df,use = \"everything\",method=\"pearson\") # default\n#&gt;           displ        cty        hwy\n#&gt; displ  1.000000 -0.7985240 -0.7660200\n#&gt; cty   -0.798524  1.0000000  0.9559159\n#&gt; hwy   -0.766020  0.9559159  1.0000000\n\ncorrelation::correlation(df,method = \"pearson\",p_adjust = \"holm\")\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nParameter1\nParameter2\nr\nCI\nCI_low\nCI_high\nt\ndf_error\np\nMethod\nn_Obs\n\n\n\ndispl\ncty\n-0.7985240\n0.95\n-0.8406782\n-0.7467508\n-20.20515\n232\n0\nPearson correlation\n234\n\n\ndispl\nhwy\n-0.7660200\n0.95\n-0.8142727\n-0.7072539\n-18.15085\n232\n0\nPearson correlation\n234\n\n\ncty\nhwy\n0.9559159\n0.95\n0.9433129\n0.9657663\n49.58470\n232\n0\nPearson correlation\n234\n\n\n\n\n\nCode\n# Spearman's rank相关系数  　　非参数\ncor(df,method = \"spearman\")\n#&gt;            displ        cty        hwy\n#&gt; displ  1.0000000 -0.8809049 -0.8266576\n#&gt; cty   -0.8809049  1.0000000  0.9542104\n#&gt; hwy   -0.8266576  0.9542104  1.0000000\n\ncorrelation::correlation(df,method = \"spearman\",p_adjust = \"holm\")\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nParameter1\nParameter2\nrho\nCI\nCI_low\nCI_high\nS\np\nMethod\nn_Obs\n\n\n\ndispl\ncty\n-0.8809049\n0.95\n-0.9073926\n-0.8474471\n4016568.96\n0\nSpearman correlation\n234\n\n\ndispl\nhwy\n-0.8266576\n0.95\n-0.8643401\n-0.7797446\n3900726.77\n0\nSpearman correlation\n234\n\n\ncty\nhwy\n0.9542104\n0.95\n0.9406973\n0.9647003\n97781.21\n0\nSpearman correlation\n234\n\n\n\n\n\nCode\n# Kendall's tau相关系数  　　非参数\ncor(df,method = \"kendall\")\n#&gt;            displ        cty        hwy\n#&gt; displ  1.0000000 -0.7210828 -0.6536974\n#&gt; cty   -0.7210828  1.0000000  0.8628045\n#&gt; hwy   -0.6536974  0.8628045  1.0000000\ncorrelation::correlation(df,method = \"kendall\",p_adjust = \"holm\")\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nParameter1\nParameter2\ntau\nCI\nCI_low\nCI_high\nz\np\nMethod\nn_Obs\n\n\n\ndispl\ncty\n-0.7210828\n0.95\n-0.7596258\n-0.6774923\n-15.53533\n0\nKendall correlation\n234\n\n\ndispl\nhwy\n-0.6536974\n0.95\n-0.6999287\n-0.6020109\n-14.13933\n0\nKendall correlation\n234\n\n\ncty\nhwy\n0.8628045\n0.95\n0.8392948\n0.8830936\n18.39871\n0\nKendall correlation\n234\n\n\n\n\n\n\n\n15.2.0.2 相关图（correlogram）\n\nCodeggcorrplot::ggcorrplot(\n    corr = cor(df,use = \"everything\",method=\"pearson\") ,\n    lab = T\n)\n\n\n\n\n\n\n\n\n15.2.0.3 显著性检验\n　　零假设为变量之间不相关（即两个总体的相关系数为 0 ） 。函数 cor.test( ) 可用于对相关系数进行显著性检 验。\n统计量\n\\[\nt=\\frac{r\\sqrt{n-2}}{\\sqrt{1-r^2}}\n\\]\n\nCodecor.test(df$displ,df$hwy)\n#&gt; \n#&gt;  Pearson's product-moment correlation\n#&gt; \n#&gt; data:  df$displ and df$hwy\n#&gt; t = -18.151, df = 232, p-value &lt; 2.2e-16\n#&gt; alternative hypothesis: true correlation is not equal to 0\n#&gt; 95 percent confidence interval:\n#&gt;  -0.8142727 -0.7072539\n#&gt; sample estimates:\n#&gt;      cor \n#&gt; -0.76602\n\n\npsych包corr.test() 计算相关系数矩阵和显著性检验\n\nCodepsych::corr.test(df)\n#&gt; Call:psych::corr.test(x = df)\n#&gt; Correlation matrix \n#&gt;       displ   cty   hwy\n#&gt; displ  1.00 -0.80 -0.77\n#&gt; cty   -0.80  1.00  0.96\n#&gt; hwy   -0.77  0.96  1.00\n#&gt; Sample Size \n#&gt; [1] 234\n#&gt; Probability values (Entries above the diagonal are adjusted for multiple tests.) \n#&gt;       displ cty hwy\n#&gt; displ     0   0   0\n#&gt; cty       0   0   0\n#&gt; hwy       0   0   0\n#&gt; \n#&gt;  To see confidence intervals of the correlations, print with the short=FALSE option\n\nprint(psych::corr.test(df), short = FALSE)\n#&gt; Call:psych::corr.test(x = df)\n#&gt; Correlation matrix \n#&gt;       displ   cty   hwy\n#&gt; displ  1.00 -0.80 -0.77\n#&gt; cty   -0.80  1.00  0.96\n#&gt; hwy   -0.77  0.96  1.00\n#&gt; Sample Size \n#&gt; [1] 234\n#&gt; Probability values (Entries above the diagonal are adjusted for multiple tests.) \n#&gt;       displ cty hwy\n#&gt; displ     0   0   0\n#&gt; cty       0   0   0\n#&gt; hwy       0   0   0\n#&gt; \n#&gt;  Confidence intervals based upon normal theory.  To get bootstrapped values, try cor.ci\n#&gt;           raw.lower raw.r raw.upper raw.p lower.adj upper.adj\n#&gt; displ-cty     -0.84 -0.80     -0.75     0     -0.85     -0.74\n#&gt; displ-hwy     -0.81 -0.77     -0.71     0     -0.81     -0.71\n#&gt; cty-hwy        0.94  0.96      0.97     0      0.94      0.97",
    "crumbs": [
      "概率论与数理统计",
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>相关性</span>"
    ]
  },
  {
    "objectID": "LinearRegression.html",
    "href": "LinearRegression.html",
    "title": "\n16  线性回归\n",
    "section": "",
    "text": "16.1 一元线性回归",
    "crumbs": [
      "推断统计模型",
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>线性回归</span>"
    ]
  },
  {
    "objectID": "LinearRegression.html#一元线性回归",
    "href": "LinearRegression.html#一元线性回归",
    "title": "\n16  线性回归\n",
    "section": "",
    "text": "16.1.1 lm\n\nCode#linear model specification 线性模型规范\nlm_spec &lt;-linear_reg() %&gt;%\n  set_mode(\"regression\") %&gt;%\n  set_engine(\"lm\")  \nlm_spec\n#&gt; Linear Regression Model Specification (regression)\n#&gt; \n#&gt; Computational engine: lm\n\n\nlinear regression model：\n\\[\nY_i=\\beta_0+ \\beta_1 X_i+\\epsilon_i,其中\\epsilon_i\\sim N(0,\\sigma^2)\n\\]\n\nCodep_sales&lt;-function(x){\n  ggplot(advertising,aes({{x}},sales))+\n           geom_point(shape=21,color=\"red\")+\n           geom_smooth(formula = 'y ~ x',method = \"lm\",se=FALSE)\n}\np_sales(TV)|p_sales(radio)|p_sales(newspaper)\n\n\n\n\n\n\n\n\nCodelm_sales_tv &lt;- lm_spec %&gt;%  fit(sales ~ TV, data = advertising)\n# 模型摘要\nlm_sales_tv  # lm_sales_tv %&gt;%  pluck(\"fit\")\n#&gt; parsnip model object\n#&gt; \n#&gt; \n#&gt; Call:\n#&gt; stats::lm(formula = sales ~ TV, data = data)\n#&gt; \n#&gt; Coefficients:\n#&gt; (Intercept)           TV  \n#&gt;     7.03259      0.04754\nsummary(lm_sales_tv$fit)  # lm_sales_tv %&gt;%pluck(\"fit\") %&gt;%summary()\n#&gt; \n#&gt; Call:\n#&gt; stats::lm(formula = sales ~ TV, data = data)\n#&gt; \n#&gt; Residuals:\n#&gt;     Min      1Q  Median      3Q     Max \n#&gt; -8.3860 -1.9545 -0.1913  2.0671  7.2124 \n#&gt; \n#&gt; Coefficients:\n#&gt;             Estimate Std. Error t value Pr(&gt;|t|)    \n#&gt; (Intercept) 7.032594   0.457843   15.36   &lt;2e-16 ***\n#&gt; TV          0.047537   0.002691   17.67   &lt;2e-16 ***\n#&gt; ---\n#&gt; Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n#&gt; \n#&gt; Residual standard error: 3.259 on 198 degrees of freedom\n#&gt; Multiple R-squared:  0.6119, Adjusted R-squared:  0.6099 \n#&gt; F-statistic: 312.1 on 1 and 198 DF,  p-value: &lt; 2.2e-16\n\n\n# 参数估计值、标准误、统计量、p值\nbroom::tidy(lm_sales_tv)\n\n\n\n\nterm\nestimate\nstd.error\nstatistic\np.value\n\n\n\n(Intercept)\n7.0325935\n0.4578429\n15.36028\n0\n\n\nTV\n0.0475366\n0.0026906\n17.66763\n0\n\n\n\n\n\nCode# 模型统计信息\nbroom::glance(lm_sales_tv) \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nr.squared\nadj.r.squared\nsigma\nstatistic\np.value\ndf\nlogLik\nAIC\nBIC\ndeviance\ndf.residual\nnobs\n\n\n0.6118751\n0.6099148\n3.258656\n312.145\n0\n1\n-519.0457\n1044.091\n1053.986\n2102.531\n198\n200\n\n\n\n\n\n\n16.1.2 预测\n\nCode# 预测\nstats::predict(lm_sales_tv, new_data = advertising) %&gt;% \n    head(n = 10)\n\n\n\n\n.pred\n\n\n\n17.970775\n\n\n9.147974\n\n\n7.850224\n\n\n14.234395\n\n\n15.627218\n\n\n7.446162\n\n\n9.765950\n\n\n12.746498\n\n\n7.441409\n\n\n16.530414\n\n\n\n\n\nCodepredict(lm_sales_tv, new_data = advertising, type = \"conf_int\") %&gt;% \n    head(n = 10)\n\n\n\n\n.pred_lower\n.pred_upper\n\n\n\n17.337774\n18.603775\n\n\n8.439101\n9.856848\n\n\n7.024932\n8.675515\n\n\n13.779384\n14.689405\n\n\n15.138794\n16.115642\n\n\n6.582865\n8.309460\n\n\n9.108530\n10.423370\n\n\n12.270304\n13.222691\n\n\n6.577660\n8.305157\n\n\n15.996715\n17.064114\n\n\n\n\n\nCode\n\n\n# 比较观测值与预测值\nbind_cols(predict(lm_sales_tv, new_data = advertising), advertising) %&gt;%\n    head(n = 10)\n\n\n\n\n.pred\nid\nTV\nradio\nnewspaper\nsales\n\n\n\n17.970775\n1\n230.1\n37.8\n69.2\n22.1\n\n\n9.147974\n2\n44.5\n39.3\n45.1\n10.4\n\n\n7.850224\n3\n17.2\n45.9\n69.3\n9.3\n\n\n14.234395\n4\n151.5\n41.3\n58.5\n18.5\n\n\n15.627218\n5\n180.8\n10.8\n58.4\n12.9\n\n\n7.446162\n6\n8.7\n48.9\n75.0\n7.2\n\n\n9.765950\n7\n57.5\n32.8\n23.5\n11.8\n\n\n12.746498\n8\n120.2\n19.6\n11.6\n13.2\n\n\n7.441409\n9\n8.6\n2.1\n1.0\n4.8\n\n\n16.530414\n10\n199.8\n2.6\n21.2\n10.6\n\n\n\n\n\nCode\nbind_cols(predict(lm_sales_tv, new_data = advertising), advertising) %&gt;%\n    select(sales, .pred) %&gt;%\n    head(n = 10)\n\n\n\n\nsales\n.pred\n\n\n\n22.1\n17.970775\n\n\n10.4\n9.147974\n\n\n9.3\n7.850224\n\n\n18.5\n14.234395\n\n\n12.9\n15.627218\n\n\n7.2\n7.446162\n\n\n11.8\n9.765950\n\n\n13.2\n12.746498\n\n\n4.8\n7.441409\n\n\n10.6\n16.530414\n\n\n\n\n\nCode\naugment(lm_sales_tv, new_data = advertising) %&gt;%\n    select(sales, .pred) %&gt;%\n    head(n = 10)\n\n\n\n\nsales\n.pred\n\n\n\n22.1\n17.970775\n\n\n10.4\n9.147974\n\n\n9.3\n7.850224\n\n\n18.5\n14.234395\n\n\n12.9\n15.627218\n\n\n7.2\n7.446162\n\n\n11.8\n9.765950\n\n\n13.2\n12.746498\n\n\n4.8\n7.441409\n\n\n10.6\n16.530414\n\n\n\n\n\n\n\n16.1.3 最小二乘法\n保证各实测点到回归直线的纵向距离的平方和最小，即使得残差平方和\n\\[\nQ=\\sum (Y-\\hat Y)^2\n\\]\n最小。\n\nCode# 可视化\nbind_cols(predict(lm_sales_tv, new_data = advertising), advertising) %&gt;%\n    ggplot(aes(x = TV)) +\n    geom_linerange(aes(ymin = sales, ymax = .pred)) +\n    geom_point(aes(y = sales), color = \"red\") +\n    geom_abline(\n        intercept = coef(lm_sales_tv$fit)[1],\n        slope = coef(lm_sales_tv$fit)[2],\n        color = \"blue\",\n        size = 1\n    )\n\n\n\n\n\n\n\n\n16.1.4 回归诊断\n\n16.1.4.1 残差图\n\nCodeplot(lm_sales_tv$fit,1)  \n\n\n\n\n\n\n\n\nCode# 检查线性回归模型的残差是否与拟合值无关，即残差的分布是否随机。\n# 残差应该随机分布在0附近\ntibble(\n    `Fitted values`=lm_sales_tv$fit$fitted.values,\n    Residuals = lm_sales_tv$fit$residuals\n) %&gt;% ggplot(aes(x = `Fitted values` , y = Residuals)) +\n  geom_point(pch=21) +\n    geom_smooth(formula = \"y~x\",color=\"red\",lwd=0.5)+\n  geom_hline(yintercept = 0,lty=2) +\n  labs(x = \"Fitted Values\", y = \"Residuals\")\n\n\n\n\n\n\n\n\nCode# 检查线性回归模型的残差是否与观测值无关，即残差的分布是否随机。\ntibble(Sales = lm_sales_tv$fit$model$sales,\n       Residuals = lm_sales_tv$fit$residuals,) %&gt;% \n    ggplot(aes(x = Sales , y = Residuals)) +\n    geom_point(pch=21) +\n    geom_smooth(,color=\"red\",lwd=0.5) +\n    labs(x = \"Observed Values\", y = \"Residuals\")\n\n\n\n\n\n\n\n\nCodeplot(lm_sales_tv$fit,3)  \n\n\n\n\n\n\n\n\nCodetibble(\n    fitted_values=lm_sales_tv$fit$fitted.values,\n    StandardizedResiduals = rstudent(lm_sales_tv$fit) ,\n) %&gt;%\n    ggplot(aes(x = fitted_values, y = sqrt(abs(StandardizedResiduals)))) +\n    geom_point(pch=21) +\n    geom_smooth(color=\"red\",lwd=0.5)+\n    labs(x = \"Fitted Values\", y = \"√|Standardized residuals|\")\n\n\n\n\n\n\n\n\n16.1.4.2 Q-Q图\n\nCodeplot(lm_sales_tv$fit,2)  \n\n\n\n\n\n\n\n\nCodetibble(\n       StandardizedResiduals =rstandard(lm_sales_tv$fit) ) %&gt;% \n    ggplot(aes(sample=StandardizedResiduals)) +\n    stat_qq(pch=21)+\n    stat_qq_line(color=\"red\",lty=2)+\n    labs(x = \"Theoretical Quantiles\", y = \"Standardized residuals\")\n\n\n\n\n\n\n\n\n16.1.4.3 Cook’s距离\n\nCodeplot(lm_sales_tv$fit,4)  \n\n\n\n\n\n\n\n\nCodethreshold &lt;- 4 / (nrow(lm_sales_tv$fit$model) - length(coef(lm_sales_tv$fit)) - 2)\n\ntibble(x = 1:nrow(advertising),\n       CooksD = cooks.distance(lm_sales_tv$fit),\n       Threshold = CooksD &gt; threshold)%&gt;%\n    ggplot() +\n    geom_segment(aes(x=x,xend=x,y=0,yend=CooksD,color=Threshold)) +\n    geom_text(aes(x=x,y=CooksD,label=if_else(Threshold,x,NA)),vjust=-0.2)+\n    labs(x = \"Observation Index\", y = \"Cook's Distance\")\n\n\n\n\n\n\n\n\n16.1.4.4 杠杆值图\n\nCodeplot(lm_sales_tv$fit,5)  \n\n\n\n\n\n\n\n\nCodetibble(\n    leverage = hatvalues(lm_sales_tv$fit),\n    StandardizedResiduals = rstandard(lm_sales_tv$fit) ,\n) %&gt;%\n    ggplot(aes(x = leverage, y = StandardizedResiduals)) +\n    geom_point(pch=21) +\n    geom_smooth(color=\"red\",lwd=0.5)+\n    scale_x_continuous(limits = c(0, NA)) +\n    geom_vline(xintercept = 0, lty = 2) +\n    geom_hline(yintercept = 0, lty = 2) +\n    labs(x = \"Leverage Values\", y = \"Standardized residuals\")\n\n\n\n\n\n\n\n\nCodeplot(lm_sales_tv$fit,6)  \n\n\n\n\n\n\n\n\nCode\n\nthreshold &lt;- 4 / (nrow(lm_sales_tv$fit$model) - length(coef(lm_sales_tv$fit)) - 2)\n\ndf &lt;- tibble(\n    x = 1:nrow(advertising),\n    leverage = hatvalues(lm_sales_tv$fit),\n    CooksD = cooks.distance(lm_sales_tv$fit),\n    Threshold = CooksD &gt; threshold,\n) \n\n    ggplot(df,aes(leverage, CooksD)) +\n    geom_point(pch=21) +\n    xlim(c(0,NA))+\n    geom_text(aes(label=if_else(Threshold,as.character(x),NA)),vjust=-0.5)+\n    geom_abline(intercept = 0, slope = seq(0,6,by=1), \n                linetype = \"dotted\", color = \"black\")+\n    geom_abline(intercept = 0, slope = 0.5, \n                linetype = 1, color = \"red\")+\n    labs(x = \"Leverage\", y = \"Cook's Distance\")",
    "crumbs": [
      "推断统计模型",
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>线性回归</span>"
    ]
  },
  {
    "objectID": "LinearRegression.html#逐步回归",
    "href": "LinearRegression.html#逐步回归",
    "title": "\n16  线性回归\n",
    "section": "\n16.2 逐步回归",
    "text": "16.2 逐步回归\n逐步回归是筛选变量，有向前、向后和两个方向同时进行三个方法。\n\ndirection = \"both\"双向\ndirection = \"backward\"向后\ndirection = \"forward\"向前\n\n\nCode\nfit_lm &lt;- lm(sales~.,data = advertising[-1])\n\nfit_step &lt;- stats::step(fit_lm, direction = \"both\")\n#&gt; Start:  AIC=212.79\n#&gt; sales ~ TV + radio + newspaper\n#&gt; \n#&gt;             Df Sum of Sq    RSS    AIC\n#&gt; - newspaper  1      0.09  556.9 210.82\n#&gt; &lt;none&gt;                    556.8 212.79\n#&gt; - radio      1   1361.74 1918.6 458.20\n#&gt; - TV         1   3058.01 3614.8 584.90\n#&gt; \n#&gt; Step:  AIC=210.82\n#&gt; sales ~ TV + radio\n#&gt; \n#&gt;             Df Sum of Sq    RSS    AIC\n#&gt; &lt;none&gt;                    556.9 210.82\n#&gt; + newspaper  1      0.09  556.8 212.79\n#&gt; - radio      1   1545.62 2102.5 474.52\n#&gt; - TV         1   3061.57 3618.5 583.10\nsummary(fit_step)\n#&gt; \n#&gt; Call:\n#&gt; lm(formula = sales ~ TV + radio, data = advertising[-1])\n#&gt; \n#&gt; Residuals:\n#&gt;     Min      1Q  Median      3Q     Max \n#&gt; -8.7977 -0.8752  0.2422  1.1708  2.8328 \n#&gt; \n#&gt; Coefficients:\n#&gt;             Estimate Std. Error t value Pr(&gt;|t|)    \n#&gt; (Intercept)  2.92110    0.29449   9.919   &lt;2e-16 ***\n#&gt; TV           0.04575    0.00139  32.909   &lt;2e-16 ***\n#&gt; radio        0.18799    0.00804  23.382   &lt;2e-16 ***\n#&gt; ---\n#&gt; Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n#&gt; \n#&gt; Residual standard error: 1.681 on 197 degrees of freedom\n#&gt; Multiple R-squared:  0.8972, Adjusted R-squared:  0.8962 \n#&gt; F-statistic: 859.6 on 2 and 197 DF,  p-value: &lt; 2.2e-16",
    "crumbs": [
      "推断统计模型",
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>线性回归</span>"
    ]
  },
  {
    "objectID": "LinearRegression.html#多元线性回归",
    "href": "LinearRegression.html#多元线性回归",
    "title": "\n16  线性回归\n",
    "section": "\n16.3 多元线性回归",
    "text": "16.3 多元线性回归\n\\[\nY_i=\\beta_0+\\sum_{i=1}^p \\beta_p X_{pi}+\\epsilon_i,其中\\epsilon_i\\sim N(0,\\sigma^2)\n\\]\n\n16.3.1 rms::ols()\n\n\nCodeacl &lt;- read_rds(\"data/icpsr/advanced_acl_data.rds\")\nols_mlm &lt;- rms::ols(SWL_W1 ~ Sex + AGE_W1 + SESCategory ,data = acl)\n\ntexreg::texreg(ols_mlm)\n#&gt; \n#&gt; \\begin{table}\n#&gt; \\begin{center}\n#&gt; \\begin{tabular}{l c}\n#&gt; \\hline\n#&gt;  & Model 1 \\\\\n#&gt; \\hline\n#&gt; Intercept                                                                                                                               & $-0.71^{***}$ \\\\\n#&gt;                                                                                                                                         & $(0.08)$      \\\\\n#&gt; Sex=(2) FEMALE                                                                                                                          & $0.03$        \\\\\n#&gt;                                                                                                                                         & $(0.04)$      \\\\\n#&gt; AGE\\_W1                                                                                                                                 & $0.01^{***}$  \\\\\n#&gt;                                                                                                                                         & $(0.00)$      \\\\\n#&gt; SESCategory=(2) Lower-Middle SES 0-11 yrs of education and income $20, or more OR 12 or more yrs of education and income less than $20, & $-0.01$       \\\\\n#&gt;                                                                                                                                         & $(0.04)$      \\\\\n#&gt; SESCategory=(3) Upper-Middle SES... 12-15 years of education and income $20, or more.                                                   & $0.26^{***}$  \\\\\n#&gt;                                                                                                                                         & $(0.05)$      \\\\\n#&gt; SESCategory=(4) High SES...16 or more years of education and income $20, or more.                                                       & $0.27^{***}$  \\\\\n#&gt;                                                                                                                                         & $(0.06)$      \\\\\n#&gt; \\hline\n#&gt; Num. obs.                                                                                                                               & $3617$        \\\\\n#&gt; R$^2$                                                                                                                                   & $0.03$        \\\\\n#&gt; Adj. R$^2$                                                                                                                              & $0.03$        \\\\\n#&gt; L.R.                                                                                                                                    & $118.62$      \\\\\n#&gt; \\hline\n#&gt; \\multicolumn{2}{l}{\\scriptsize{$^{***}p&lt;0.001$; $^{**}p&lt;0.01$; $^{*}p&lt;0.05$}}\n#&gt; \\end{tabular}\n#&gt; \\caption{Statistical models}\n#&gt; \\label{table:coefficients}\n#&gt; \\end{center}\n#&gt; \\end{table}\n\ncar::vif(ols_mlm)\n#&gt;                  GVIF Df GVIF^(1/(2*Df))\n#&gt; Sex          2.733167  1        1.653229\n#&gt; AGE_W1      12.000335  1        3.464150\n#&gt; SESCategory  3.745646  3        1.246200\nanova(ols_mlm)\n#&gt;                 Analysis of Variance          Response: SWL_W1 \n#&gt; \n#&gt;  Factor      d.f. Partial SS   MS          F     P     \n#&gt;  Sex            1    0.7854499   0.7854499  0.73 0.3921\n#&gt;  AGE_W1         1  101.8301250 101.8301250 94.98 &lt;.0001\n#&gt;  SESCategory    3   53.6731656  17.8910552 16.69 &lt;.0001\n#&gt;  REGRESSION     5  129.0786440  25.8157288 24.08 &lt;.0001\n#&gt;  ERROR       3611 3871.6006314   1.0721685\n\n\n\n16.3.2 lm()\n\n\nCodelm_mlm &lt;- lm_spec %&gt;% \n    fit(SWL_W1 ~ Sex + AGE_W1 + SESCategory ,data = acl)\n\nlm_mlm %&gt;% glance()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nr.squared\nadj.r.squared\nsigma\nstatistic\np.value\ndf\nlogLik\nAIC\nBIC\ndeviance\ndf.residual\nnobs\n\n\n0.0322642\n0.0309242\n1.035456\n24.07805\n0\n5\n-5255.32\n10524.64\n10567.99\n3871.601\n3611\n3617\n\n\n\n\nCodelm_mlm %&gt;% tidy()\n\n\n\n\n\n\n\n\n\n\n\nterm\nestimate\nstd.error\nstatistic\np.value\n\n\n\n(Intercept)\n-0.7056523\n0.0754901\n-9.3476094\n0.0000000\n\n\nSex(2) FEMALE\n0.0308272\n0.0360169\n0.8559092\n0.3921048\n\n\nAGE_W1\n0.0102952\n0.0010564\n9.7455557\n0.0000000\n\n\nSESCategory(2) Lower-Middle SES 0-11 yrs of education and income $20, or more OR 12 or more yrs of education and income less than $20,\n-0.0133284\n0.0446720\n-0.2983617\n0.7654443\n\n\nSESCategory(3) Upper-Middle SES… 12-15 years of education and income $20, or more.\n0.2557878\n0.0481855\n5.3083984\n0.0000001\n\n\nSESCategory(4) High SES…16 or more years of education and income $20, or more.\n0.2654396\n0.0635256\n4.1784695\n0.0000300\n\n\n\n\n\nCode\n\nlogLik(lm_mlm$fit)\n#&gt; 'log Lik.' -5255.32 (df=7)\ncar::vif(lm_mlm$fit)\n#&gt;                 GVIF Df GVIF^(1/(2*Df))\n#&gt; Sex         1.026165  1        1.012998\n#&gt; AGE_W1      1.168708  1        1.081068\n#&gt; SESCategory 1.182617  3        1.028349\n\n\n\n16.3.3 glm()\n\n\nCodeglm_mlm &lt;- linear_reg() %&gt;%\n    set_engine('glm',family=gaussian(link = \"identity\")) %&gt;% \n    fit(SWL_W1 ~ Sex + AGE_W1 + SESCategory ,data = acl)\n\nglm_mlm %&gt;% glance()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nnull.deviance\ndf.null\nlogLik\nAIC\nBIC\ndeviance\ndf.residual\nnobs\n\n\n4000.679\n3616\n-5255.32\n10524.64\n10567.99\n3871.601\n3611\n3617\n\n\n\n\nCodeglm_mlm %&gt;% tidy()\n\n\n\n\n\n\n\n\n\n\n\nterm\nestimate\nstd.error\nstatistic\np.value\n\n\n\n(Intercept)\n-0.7056523\n0.0754901\n-9.3476094\n0.0000000\n\n\nSex(2) FEMALE\n0.0308272\n0.0360169\n0.8559092\n0.3921048\n\n\nAGE_W1\n0.0102952\n0.0010564\n9.7455557\n0.0000000\n\n\nSESCategory(2) Lower-Middle SES 0-11 yrs of education and income $20, or more OR 12 or more yrs of education and income less than $20,\n-0.0133284\n0.0446720\n-0.2983617\n0.7654443\n\n\nSESCategory(3) Upper-Middle SES… 12-15 years of education and income $20, or more.\n0.2557878\n0.0481855\n5.3083984\n0.0000001\n\n\nSESCategory(4) High SES…16 or more years of education and income $20, or more.\n0.2654396\n0.0635256\n4.1784695\n0.0000300\n\n\n\n\n\nCode\nsummary(glm_mlm$fit)\n#&gt; \n#&gt; Call:\n#&gt; stats::glm(formula = SWL_W1 ~ Sex + AGE_W1 + SESCategory, family = ~gaussian(link = \"identity\"), \n#&gt;     data = data)\n#&gt; \n#&gt; Coefficients:\n#&gt;                                                                                                                                         Estimate\n#&gt; (Intercept)                                                                                                                            -0.705652\n#&gt; Sex(2) FEMALE                                                                                                                           0.030827\n#&gt; AGE_W1                                                                                                                                  0.010295\n#&gt; SESCategory(2) Lower-Middle SES 0-11 yrs of education and income $20, or more OR 12 or more yrs of education and income less than $20, -0.013328\n#&gt; SESCategory(3) Upper-Middle SES... 12-15 years of education and income $20, or more.                                                    0.255788\n#&gt; SESCategory(4) High SES...16 or more years of education and income $20, or more.                                                        0.265440\n#&gt;                                                                                                                                        Std. Error\n#&gt; (Intercept)                                                                                                                              0.075490\n#&gt; Sex(2) FEMALE                                                                                                                            0.036017\n#&gt; AGE_W1                                                                                                                                   0.001056\n#&gt; SESCategory(2) Lower-Middle SES 0-11 yrs of education and income $20, or more OR 12 or more yrs of education and income less than $20,   0.044672\n#&gt; SESCategory(3) Upper-Middle SES... 12-15 years of education and income $20, or more.                                                     0.048186\n#&gt; SESCategory(4) High SES...16 or more years of education and income $20, or more.                                                         0.063526\n#&gt;                                                                                                                                        t value\n#&gt; (Intercept)                                                                                                                             -9.348\n#&gt; Sex(2) FEMALE                                                                                                                            0.856\n#&gt; AGE_W1                                                                                                                                   9.746\n#&gt; SESCategory(2) Lower-Middle SES 0-11 yrs of education and income $20, or more OR 12 or more yrs of education and income less than $20,  -0.298\n#&gt; SESCategory(3) Upper-Middle SES... 12-15 years of education and income $20, or more.                                                     5.308\n#&gt; SESCategory(4) High SES...16 or more years of education and income $20, or more.                                                         4.178\n#&gt;                                                                                                                                        Pr(&gt;|t|)\n#&gt; (Intercept)                                                                                                                             &lt; 2e-16\n#&gt; Sex(2) FEMALE                                                                                                                             0.392\n#&gt; AGE_W1                                                                                                                                  &lt; 2e-16\n#&gt; SESCategory(2) Lower-Middle SES 0-11 yrs of education and income $20, or more OR 12 or more yrs of education and income less than $20,    0.765\n#&gt; SESCategory(3) Upper-Middle SES... 12-15 years of education and income $20, or more.                                                   1.17e-07\n#&gt; SESCategory(4) High SES...16 or more years of education and income $20, or more.                                                       3.00e-05\n#&gt;                                                                                                                                           \n#&gt; (Intercept)                                                                                                                            ***\n#&gt; Sex(2) FEMALE                                                                                                                             \n#&gt; AGE_W1                                                                                                                                 ***\n#&gt; SESCategory(2) Lower-Middle SES 0-11 yrs of education and income $20, or more OR 12 or more yrs of education and income less than $20,    \n#&gt; SESCategory(3) Upper-Middle SES... 12-15 years of education and income $20, or more.                                                   ***\n#&gt; SESCategory(4) High SES...16 or more years of education and income $20, or more.                                                       ***\n#&gt; ---\n#&gt; Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n#&gt; \n#&gt; (Dispersion parameter for gaussian family taken to be 1.072169)\n#&gt; \n#&gt;     Null deviance: 4000.7  on 3616  degrees of freedom\n#&gt; Residual deviance: 3871.6  on 3611  degrees of freedom\n#&gt; AIC: 10525\n#&gt; \n#&gt; Number of Fisher Scoring iterations: 2\n\n\n\nCode#第一步，检测变量相关关系\nad &lt;- advertising %&gt;% select(-1)\ncor(ad)\n#&gt;                   TV      radio  newspaper     sales\n#&gt; TV        1.00000000 0.05480866 0.05664787 0.7822244\n#&gt; radio     0.05480866 1.00000000 0.35410375 0.5762226\n#&gt; newspaper 0.05664787 0.35410375 1.00000000 0.2282990\n#&gt; sales     0.78222442 0.57622257 0.22829903 1.0000000\n\n#第二步，多元线性回归\nlm_sales_multi&lt;- lm_spec %&gt;% fit(sales~TV+radio+newspaper,data = advertising)\nsummary(lm_sales_multi$fit)\n#&gt; \n#&gt; Call:\n#&gt; stats::lm(formula = sales ~ TV + radio + newspaper, data = data)\n#&gt; \n#&gt; Residuals:\n#&gt;     Min      1Q  Median      3Q     Max \n#&gt; -8.8277 -0.8908  0.2418  1.1893  2.8292 \n#&gt; \n#&gt; Coefficients:\n#&gt;              Estimate Std. Error t value Pr(&gt;|t|)    \n#&gt; (Intercept)  2.938889   0.311908   9.422   &lt;2e-16 ***\n#&gt; TV           0.045765   0.001395  32.809   &lt;2e-16 ***\n#&gt; radio        0.188530   0.008611  21.893   &lt;2e-16 ***\n#&gt; newspaper   -0.001037   0.005871  -0.177     0.86    \n#&gt; ---\n#&gt; Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n#&gt; \n#&gt; Residual standard error: 1.686 on 196 degrees of freedom\n#&gt; Multiple R-squared:  0.8972, Adjusted R-squared:  0.8956 \n#&gt; F-statistic: 570.3 on 3 and 196 DF,  p-value: &lt; 2.2e-16\n\ntidy(lm_sales_multi)\n\n\n\n\nterm\nestimate\nstd.error\nstatistic\np.value\n\n\n\n(Intercept)\n2.9388894\n0.3119082\n9.4222884\n0.0000000\n\n\nTV\n0.0457646\n0.0013949\n32.8086244\n0.0000000\n\n\nradio\n0.1885300\n0.0086112\n21.8934961\n0.0000000\n\n\nnewspaper\n-0.0010375\n0.0058710\n-0.1767146\n0.8599151\n\n\n\n\n\nCodeglance(lm_sales_multi)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nr.squared\nadj.r.squared\nsigma\nstatistic\np.value\ndf\nlogLik\nAIC\nBIC\ndeviance\ndf.residual\nnobs\n\n\n0.8972106\n0.8956373\n1.68551\n570.2707\n0\n3\n-386.1811\n782.3622\n798.8538\n556.8253\n196\n200",
    "crumbs": [
      "推断统计模型",
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>线性回归</span>"
    ]
  },
  {
    "objectID": "LinearRegression.html#交互项",
    "href": "LinearRegression.html#交互项",
    "title": "\n16  线性回归\n",
    "section": "\n16.4 交互项",
    "text": "16.4 交互项\n\nCodelm_sales_tv_radio &lt;- lm_spec %&gt;%  fit(sales ~ TV*radio, data = advertising)\n\nlm_sales_tv_radio\n#&gt; parsnip model object\n#&gt; \n#&gt; \n#&gt; Call:\n#&gt; stats::lm(formula = sales ~ TV * radio, data = data)\n#&gt; \n#&gt; Coefficients:\n#&gt; (Intercept)           TV        radio     TV:radio  \n#&gt;    6.750220     0.019101     0.028860     0.001086\n\n\n\nCode# pre-processing specification\n\nrec_spec_interact &lt;- recipe(sales ~ TV+radio, data = advertising) %&gt;%  \n  step_interact(~ TV:radio) \n\nrec_spec_interact\n\n# combine the linear regression model specification with the pre-processing specification\nlm_sales_tv_radio_interact &lt;- workflow() %&gt;%  \n  add_model(lm_spec) %&gt;%  \n  add_recipe(rec_spec_interact)  \n\nlm_sales_tv_radio_interact\n#&gt; ══ Workflow ════════════════════════════════════════════════════════════════════\n#&gt; Preprocessor: Recipe\n#&gt; Model: linear_reg()\n#&gt; \n#&gt; ── Preprocessor ────────────────────────────────────────────────────────────────\n#&gt; 1 Recipe Step\n#&gt; \n#&gt; • step_interact()\n#&gt; \n#&gt; ── Model ───────────────────────────────────────────────────────────────────────\n#&gt; Linear Regression Model Specification (regression)\n#&gt; \n#&gt; Computational engine: lm\n\nlm &lt;- lm_sales_tv_radio_interact %&gt;% fit(advertising)\ntidy(lm)\n\n\n\n\nterm\nestimate\nstd.error\nstatistic\np.value\n\n\n\n(Intercept)\n6.7502202\n0.2478714\n27.232755\n0.0000000\n\n\nTV\n0.0191011\n0.0015041\n12.698954\n0.0000000\n\n\nradio\n0.0288603\n0.0089053\n3.240815\n0.0014005\n\n\nTV_x_radio\n0.0010865\n0.0000524\n20.726564\n0.0000000\n\n\n\n\n\nCodeglance(lm)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nr.squared\nadj.r.squared\nsigma\nstatistic\np.value\ndf\nlogLik\nAIC\nBIC\ndeviance\ndf.residual\nnobs\n\n\n0.9677905\n0.9672975\n0.9435154\n1963.057\n0\n3\n-270.1389\n550.2778\n566.7694\n174.4834\n196\n200",
    "crumbs": [
      "推断统计模型",
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>线性回归</span>"
    ]
  },
  {
    "objectID": "LinearRegression.html#变换",
    "href": "LinearRegression.html#变换",
    "title": "\n16  线性回归\n",
    "section": "\n16.5 变换",
    "text": "16.5 变换\n\n16.5.1 非线性变换\n\nCode\nrec_spec_square &lt;- recipe(sales ~ TV, data = advertising) %&gt;%  \n  step_mutate(`TV^2` = TV^2)  \nrec_spec_square\n\nlm_wf_square &lt;- workflow() %&gt;%  \n  add_model(lm_spec) %&gt;%  \n  add_recipe(rec_spec_square)  \n\nlm_wf_square %&gt;%\n  fit(advertising)\n#&gt; ══ Workflow [trained] ══════════════════════════════════════════════════════════\n#&gt; Preprocessor: Recipe\n#&gt; Model: linear_reg()\n#&gt; \n#&gt; ── Preprocessor ────────────────────────────────────────────────────────────────\n#&gt; 1 Recipe Step\n#&gt; \n#&gt; • step_mutate()\n#&gt; \n#&gt; ── Model ───────────────────────────────────────────────────────────────────────\n#&gt; \n#&gt; Call:\n#&gt; stats::lm(formula = ..y ~ ., data = data)\n#&gt; \n#&gt; Coefficients:\n#&gt; (Intercept)           TV       `TV^2`  \n#&gt;   6.114e+00    6.727e-02   -6.847e-05\n\n\n\n16.5.2 对数变换\n\nCoderec_spec_log &lt;- recipe(sales ~ TV, data = advertising) %&gt;%  \n  step_log(TV)  \n\nlm_wf_log &lt;- workflow() %&gt;% \n  add_model(lm_spec) %&gt;%  \n  add_recipe(rec_spec_log) \n\nlm_wf_log %&gt;%\n  fit(advertising)\n#&gt; ══ Workflow [trained] ══════════════════════════════════════════════════════════\n#&gt; Preprocessor: Recipe\n#&gt; Model: linear_reg()\n#&gt; \n#&gt; ── Preprocessor ────────────────────────────────────────────────────────────────\n#&gt; 1 Recipe Step\n#&gt; \n#&gt; • step_log()\n#&gt; \n#&gt; ── Model ───────────────────────────────────────────────────────────────────────\n#&gt; \n#&gt; Call:\n#&gt; stats::lm(formula = ..y ~ ., data = data)\n#&gt; \n#&gt; Coefficients:\n#&gt; (Intercept)           TV  \n#&gt;      -4.203        3.901",
    "crumbs": [
      "推断统计模型",
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>线性回归</span>"
    ]
  },
  {
    "objectID": "LinearRegression.html#回归诊断-1",
    "href": "LinearRegression.html#回归诊断-1",
    "title": "\n16  线性回归\n",
    "section": "\n16.6 回归诊断",
    "text": "16.6 回归诊断\nhttps://www.statmethods.net/stats/rdiagnostics.html\n\nCodelibrary(car)\n#回归检验\ncar::scatterplotMatrix(ad)  # 多重共线性\n\n\n\n\n\n\nCodeconfint(lm_sales_multi$fit)  # 95%置信区间\n#&gt;                   2.5 %     97.5 %\n#&gt; (Intercept)  2.32376228 3.55401646\n#&gt; TV           0.04301371 0.04851558\n#&gt; radio        0.17154745 0.20551259\n#&gt; newspaper   -0.01261595 0.01054097\nplot(lm_sales_multi$fit) #回归诊断图\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n16.6.0.1 线性假设\n残差图\n\nCodeplot(lm_sales_multi$fit,1)  \n\n\n\n\n\n\nCodecrPlots(lm_sales_multi$fit)\n\n\n\n\n\n\n\n\n16.6.0.2 正态性假设Q-Q图\nStandardized Residuals\n\nCodeplot(lm_sales_multi$fit,2) \n\n\n\n\n\n\nCodesummary(powerTransform(lm_sales_multi$fit))  \n#&gt; bcPower Transformation to Normality \n#&gt;    Est Power Rounded Pwr Wald Lwr Bnd Wald Upr Bnd\n#&gt; Y1    0.9074           1       0.7569       1.0578\n#&gt; \n#&gt; Likelihood ratio test that transformation parameter is equal to 0\n#&gt;  (log transformation)\n#&gt;                            LRT df       pval\n#&gt; LR test, lambda = (0) 147.1578  1 &lt; 2.22e-16\n#&gt; \n#&gt; Likelihood ratio test that no transformation is needed\n#&gt;                           LRT df    pval\n#&gt; LR test, lambda = (1) 1.41991  1 0.23342\n\n\n\nCodeplot(lm_sales_tv$fit,3)\n\n\n\n\n\n\n\n\n16.6.0.3 误差相关性\n\nCodedurbinWatsonTest(lm_sales_multi$fit)      #结果表明rho=0\n#&gt;  lag Autocorrelation D-W Statistic p-value\n#&gt;    1     -0.04687792      2.083648   0.554\n#&gt;  Alternative hypothesis: rho != 0\n\n\n\n16.6.0.4 误差项的方差齐性\n\nCodencvTest(lm_sales_multi$fit)\n#&gt; Non-constant Variance Score Test \n#&gt; Variance formula: ~ fitted.values \n#&gt; Chisquare = 5.355982, Df = 1, p = 0.020651\nspreadLevelPlot(lm_sales_multi$fit)\n\n\n\n\n\n\n#&gt; \n#&gt; Suggested power transformation:  1.499852\n\n\nCodetibble(\n    abs_studentized_residuals=abs(rstudent(lm_sales_multi$fit)),\n    fitted_values=lm_sales_multi$fit$model$sales\n) %&gt;% ggplot(aes(fitted_values,abs_studentized_residuals))+\n    geom_point(pch=21)+\n    geom_smooth()\n\n\n\n\n\n\n\n\n16.6.0.5 异常观测点\n\nCode# studentized residual Plot\nresidplot&lt;-function(fit,nbreaks=10){\n  z&lt;-rstudent(fit)\n  hist(z,breaks=nbreaks,freq=FALSE)     #密度直方图\n  title(xlab=\"Studentized Residual\")\n  rug(z,col=\"brown\")                    #轴须图\n  curve(dnorm(x,mean=mean(z),sd=sd(z)),add=TRUE,col=\"blue\",lwd=2) #正态密度曲线\n  lines(density(z)$x,density(z)$y,col=\"red\",lwd=2)       #样本密度曲线\n  legend(\"topright\",c(\"Normal Curve\",\"Kernel Density Curve\"),#图例\n  lty = c(3,2),pch = c(21,22),col=c(\"blue\",\"red\"),cex=.7)\n}\nresidplot(lm_sales_tv$fit)\n\n\n\n\n\n\n\n\nCode#######################################################################\nlibrary(car)\noutlierTest(lm_sales_tv$fit)            #离群点\n#高杠杆值点\nhat.plot&lt;-function(fit){\n  p&lt;-length(coefficients(fit)) #模型估计的参数数目（包含截距项）\n  n&lt;-length(fitted(fit))       #样本量\n  plot(hatvalues(fit),main=\"Index Plot of Hat Values\")#帽子值\n  abline(h=c(2,3)*p/n,col=\"red\",lty=2)  #大于帽子均值p/n的2或3倍被认为是高杠杆值\n  identity(1:n,hatvalues(fit),names(hatvalues(fit)))\n}\nhat.plot(lm_sales_tv$fit)\n####强影响点\n#Cook's D图形    大于4/(n-k-1)  k为预测变量数目\ncutoff&lt;-4/(nrow(advertising)-length(lm_sales_tv$fit$coefficients)-2)\n{plot(lm_sales_tv$fit,which=4,cook.levels=cutoff)\nabline(h=cutoff,lty=2,col=\"red\")}\n#变量添加图\navPlots(lm_sales_tv$fit,ask=FALSE,id.method=\"identity\")\n\n###\ninfluencePlot(lm_sales_tv$fit,id.method=\"identity\",main=\"Influence Plot\")\n\n\nCook’s distance\n\nCodeplot(lm_sales_tv$fit,4)\n\n\n\n\n\n\n\nLeverage\n\nCodeplot(lm_sales_tv$fit,5)\n\n\n\n\n\n\n\n\nCodeplot(lm_sales_tv$fit,6)\n\n\n\n\n\n\n\n\n16.6.0.6 多重共线性\n\nCodevif(lm_sales_multi$fit)\n#&gt;        TV     radio newspaper \n#&gt;  1.004611  1.144952  1.145187\n\nsqrt(vif(lm_sales_multi$fit))&gt;=2       #vif平方根 ≥2 存在\n#&gt;        TV     radio newspaper \n#&gt;     FALSE     FALSE     FALSE",
    "crumbs": [
      "推断统计模型",
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>线性回归</span>"
    ]
  },
  {
    "objectID": "LinearRegression.html#模型选择和优化",
    "href": "LinearRegression.html#模型选择和优化",
    "title": "\n16  线性回归\n",
    "section": "\n16.7 模型选择和优化",
    "text": "16.7 模型选择和优化\n\nCode########################两模型比较\nlm1 &lt;- lm_spec %&gt;% fit(sales~TV+radio+newspaper,data = advertising)\nlm2 &lt;- lm_spec %&gt;% fit(sales~TV*radio*newspaper,data = advertising[-1])\n\nanova(lm2$fit,lm1$fit) #anova() 嵌套模型\n\n\n\n\nRes.Df\nRSS\nDf\nSum of Sq\nF\nPr(&gt;F)\n\n\n\n192\n169.8597\nNA\nNA\nNA\nNA\n\n\n196\n556.8253\n-4\n-386.9656\n109.3511\n0\n\n\n\n\n\nCode\n\n##########################################            AIC \nAIC(lm2$fit,lm1$fit)  # 赤池信息准则  AIC值小的优先选择\n\n\n\n\n\ndf\nAIC\n\n\nlm2\\(fit |  9| 552.9065|\n|lm1\\)fit\n5\n782.3622\n\n\n\n\nCode#BIC\n\n\n####################################相对重要性##################################\nad &lt;- scale(advertising[-1])\nad\n#&gt;                 TV        radio    newspaper        sales\n#&gt;   [1,]  0.96742460  0.979065591  1.774492530  1.548168135\n#&gt;   [2,] -1.19437904  1.080097401  0.667902716 -0.694303815\n#&gt;   [3,] -1.51235985  1.524637364  1.779084189 -0.905134512\n#&gt;   [4,]  0.05191939  1.214806480  1.283185019  0.858176766\n#&gt;   [5,]  0.39319551 -0.839506984  1.278593360 -0.215143142\n#&gt;   [6,] -1.61136487  1.726700983  2.040808751 -1.307629477\n#&gt;   [7,] -1.04295960  0.642292892 -0.323895625 -0.425973838\n#&gt;   [8,] -0.31265202 -0.246787034 -0.870303044 -0.157643861\n#&gt;   [9,] -1.61252963 -1.425491481 -1.357018896 -1.767623723\n#&gt;  [10,]  0.61450084 -1.391814211 -0.429503781 -0.655970962\n#&gt;  [11,] -0.94278982 -1.176279684 -0.291754012 -1.039299500\n#&gt;  [12,]  0.78805080  0.049572941 -1.219269126  0.647346069\n#&gt;  [13,] -1.43548537  0.797208333  1.622967784 -0.924300938\n#&gt;  [14,] -0.57705364 -1.055041512 -1.072336039 -0.828468804\n#&gt;  [15,]  0.66458573  0.649028346  0.709227646  0.954008900\n#&gt;  [16,]  0.56325118  1.645875535  1.026052116  1.605667416\n#&gt;  [17,] -0.92298882  0.898240143  3.831555755 -0.291808850\n#&gt;  [18,]  1.56494899  1.100303763  1.159210227  1.988995954\n#&gt;  [19,] -0.90668211 -0.186167948 -0.562661892 -0.521805973\n#&gt;  [20,]  0.00299927  0.042837487 -0.525928620  0.110686115\n#&gt;  [21,]  0.83114711  0.298784739  1.049010411  0.762344631\n#&gt;  [22,]  1.05245243 -1.223427861 -0.323895625 -0.291808850\n#&gt;  [23,] -1.55895045 -0.495998831  0.874527370 -1.614292308\n#&gt;  [24,]  0.94645883 -0.428644291 -0.199920832  0.283183958\n#&gt;  [25,] -0.98705089 -0.718268813 -0.562661892 -0.828468804\n#&gt;  [26,]  1.34946748 -1.331195125 -0.507561984 -0.387640985\n#&gt;  [27,] -0.04825039  0.406552002 -0.824386454  0.187351823\n#&gt;  [28,]  1.08390109 -0.442115199 -0.351445579  0.359849666\n#&gt;  [29,]  1.18523563  0.258372015 -0.351445579  0.934842473\n#&gt;  [30,] -0.89037540 -0.489263377  0.470461379 -0.675137388\n#&gt;  [31,]  1.69889695  0.339197463  0.580661195  1.414003146\n#&gt;  [32,] -0.39767985 -0.394967022  0.369444882 -0.406807411\n#&gt;  [33,] -0.58054794 -1.465904205 -0.025437791 -0.847635231\n#&gt;  [34,]  1.38091613 -0.219845218 -1.389160509  0.647346069\n#&gt;  [35,] -0.59801941 -1.472639659 -1.063152721 -0.866801658\n#&gt;  [36,]  1.67327212 -1.290782401 -1.012644472 -0.234309569\n#&gt;  [37,]  1.39605808  1.383192830 -1.173352536  2.180660223\n#&gt;  [38,] -0.84262004  1.760378253  0.695452669  0.129852542\n#&gt;  [39,] -1.21068574  0.231430199  0.208736817 -0.751803096\n#&gt;  [40,]  0.94296453  0.972330137  0.066395389  1.433169573\n#&gt;  [41,]  0.64594949 -0.064929776  0.048028753  0.494014654\n#&gt;  [42,]  0.34893444  0.682705616  0.374036541  0.589846789\n#&gt;  [43,]  1.70705030  0.298784739 -1.320285624  1.279838158\n#&gt;  [44,]  0.69719914 -1.001157880 -0.190737514 -0.215143142\n#&gt;  [45,] -1.42034342  0.164075659  0.585252854 -1.058465927\n#&gt;  [46,]  0.32680391 -0.051458868  0.043437094  0.168185396\n#&gt;  [47,] -0.66790531 -0.900126070  0.236286771 -0.655970962\n#&gt;  [48,]  1.08157156  1.228277388 -0.553478574  1.758998831\n#&gt;  [49,]  0.93364642 -0.502734285  0.888302347  0.149018969\n#&gt;  [50,] -0.93347170 -0.778887899  0.286795020 -0.828468804\n#&gt;  [51,]  0.61450084 -1.358136941  0.185778522 -0.502639546\n#&gt;  [52,] -0.54327546 -0.920332432 -1.237635762 -0.636804535\n#&gt;  [53,]  0.80785181  1.241748296  0.415361472  1.644000269\n#&gt;  [54,]  0.41416128  1.544843726  1.292368337  1.375670293\n#&gt;  [55,]  1.34713795  0.372874732 -0.672861707  1.184006023\n#&gt;  [56,]  0.60401795  1.760378253  1.352059904  1.854830966\n#&gt;  [57,] -1.62767157  0.325726555  0.498011333 -1.633458735\n#&gt;  [58,] -0.12628963 -0.273728850 -0.640720094 -0.157643861\n#&gt;  [59,]  0.74262497  1.773849161  0.328119951  1.873997393\n#&gt;  [60,]  0.74146021  0.420022910 -0.975911200  0.839010339\n#&gt;  [61,] -1.08955020 -1.432226935 -0.420320463 -1.135131635\n#&gt;  [62,]  1.33083124  1.309102836  1.108701978  1.950663100\n#&gt;  [63,]  1.07458297 -0.522940647 -0.149412583  0.321516812\n#&gt;  [64,] -0.51648587  0.426758364 -1.017236131 -0.004312446\n#&gt;  [65,] -0.18569264  1.315838290 -0.075946040  0.762344631\n#&gt;  [66,] -0.90901164 -0.940538794 -1.361610555 -0.905134512\n#&gt;  [67,] -1.34579847  0.089985665 -1.301918988 -0.866801658\n#&gt;  [68,] -0.09018192 -0.590295187 -0.934586269 -0.119311008\n#&gt;  [69,]  1.05245243  0.285313831 -0.897852997  0.934842473\n#&gt;  [70,]  0.81251087  1.389928284 -0.154004242  1.586500989\n#&gt;  [71,]  0.60634748  0.494112904  0.374036541  0.819843912\n#&gt;  [72,] -0.43378756 -0.603766095  0.052620412 -0.310975277\n#&gt;  [73,] -1.40054242  0.655763800 -0.516745302 -1.000966646\n#&gt;  [74,] -0.20549365 -1.183015138  0.034253776 -0.579305254\n#&gt;  [75,]  0.77290886  0.089985665 -0.801428159  0.570680362\n#&gt;  [76,] -1.51585415  1.376457376  2.702007645 -1.020133073\n#&gt;  [77,] -1.39238907 -1.459168751 -0.452462076 -1.365128758\n#&gt;  [78,] -0.30915772  0.352668371 -0.750919910  0.034020408\n#&gt;  [79,] -1.64980211  0.446964726 -0.971319541 -1.671791589\n#&gt;  [80,] -0.36157214 -1.048306058 -0.342262261 -0.579305254\n#&gt;  [81,] -0.82281904  0.231430199 -0.378995532 -0.425973838\n#&gt;  [82,]  1.08040679 -1.290782401  0.291386679 -0.330141704\n#&gt;  [83,] -0.83563145 -0.199638856  0.089353684 -0.521805973\n#&gt;  [84,] -0.91600023  1.430341008  0.231695112 -0.080978154\n#&gt;  [85,]  0.77407363  1.329309198  0.149045251  1.471502427\n#&gt;  [86,]  0.53762635 -0.327612482  1.613784466  0.225684677\n#&gt;  [87,] -0.82398380  0.285313831 -0.668270048 -0.387640985\n#&gt;  [88,] -0.42330468  1.167658302  1.498992991  0.379016092\n#&gt;  [89,] -0.68421201  0.150604751  1.967342208 -0.215143142\n#&gt;  [90,] -0.43378756  1.652610989  0.957177231  0.513181081\n#&gt;  [91,] -0.14842017 -1.236898769 -0.975911200 -0.540972400\n#&gt;  [92,] -1.37957665 -1.465904205  0.112311979 -1.288463050\n#&gt;  [93,]  0.82299375  0.689441070  1.306143314  1.030674608\n#&gt;  [94,]  1.20969569  0.891504689  1.916833959  1.567334562\n#&gt;  [95,] -0.46174192 -0.623972457 -0.902444656 -0.483473119\n#&gt;  [96,]  0.18936165  0.561467444  1.026052116  0.551513935\n#&gt;  [97,]  0.58887601 -1.331195125 -1.132027606 -0.445140265\n#&gt;  [98,]  0.44095087 -0.152490678 -0.392770509  0.283183958\n#&gt;  [99,]  1.66162447  1.282161020  0.947993914  2.180660223\n#&gt; [100,] -0.13793728  1.241748296  0.704635987  0.609013216\n#&gt; [101,]  0.87773770 -1.277311493  0.883710688 -0.445140265\n#&gt; [102,]  1.73966372  0.878033781  3.230048428  1.873997393\n#&gt; [103,]  1.55097181 -0.886655162 -0.420320463  0.149018969\n#&gt; [104,]  0.47589381 -0.408437930 -0.581028528  0.129852542\n#&gt; [105,]  1.06177055  0.743324702 -1.159577559  1.279838158\n#&gt; [106,] -0.10648863  1.558314633  1.306143314  0.992341754\n#&gt; [107,] -1.42150819 -0.826036076 -0.039212768 -1.307629477\n#&gt; [108,] -0.65975195 -1.546729653 -0.337670602 -1.020133073\n#&gt; [109,] -1.56011521 -1.539994199 -0.227470786 -1.671791589\n#&gt; [110,]  1.26211011  0.244901107 -1.150394241  1.107340316\n#&gt; [111,]  0.91733971 -1.014628788  1.191351840 -0.119311008\n#&gt; [112,]  1.10253732  0.992536499 -0.337670602  1.490668854\n#&gt; [113,]  0.33379250 -0.529676101 -1.292735670  0.014853981\n#&gt; [114,]  0.72864780 -0.179432494 -0.911627974  0.359849666\n#&gt; [115,] -0.80185327  1.585256449  0.181186863  0.110686115\n#&gt; [116,] -0.83796098  0.790472879  1.016868798 -0.272642423\n#&gt; [117,] -0.09134669 -0.603766095 -0.227470786 -0.349308131\n#&gt; [118,] -0.82281904 -1.513052383 -0.723369956 -0.885968085\n#&gt; [119,] -0.24858995  0.918446505  2.233658429  0.359849666\n#&gt; [120,] -1.48673502 -0.489263377 -0.378995532 -1.422628038\n#&gt; [121,] -0.06688662  0.238165653  0.718410964  0.283183958\n#&gt; [122,] -1.49372361 -0.105342500  0.911260642 -1.345962331\n#&gt; [123,]  0.89637394 -1.405285119 -0.686636684 -0.464306692\n#&gt; [124,] -0.27887383  0.763531064 -0.833569772  0.225684677\n#&gt; [125,]  0.96043601  0.608615622  2.004075480  1.088173889\n#&gt; [126,] -0.69702443 -0.772152445 -0.213695809 -0.655970962\n#&gt; [127,] -1.62184775  1.053155585  0.920443960 -1.422628038\n#&gt; [128,] -0.77855797 -1.566936015 -0.980502859 -1.000966646\n#&gt; [129,]  0.85327764  1.733436437 -1.256002398  2.046495235\n#&gt; [130,] -1.01849954 -0.758681537  0.576069536 -0.828468804\n#&gt; [131,] -1.70454606  1.100303763 -1.003461154 -2.380949385\n#&gt; [132,]  1.37625707 -1.371607849  0.571477877 -0.253475996\n#&gt; [133,] -1.61485916  0.265107469 -1.306510647 -1.595125881\n#&gt; [134,]  0.84745381  0.689441070  0.667902716  1.069007462\n#&gt; [135,] -1.28290117  1.032949223  1.609192807 -0.617638108\n#&gt; [136,] -1.15011797  1.598727357 -1.012644472 -0.464306692\n#&gt; [137,] -1.41451960  1.059891039 -0.975911200 -0.866801658\n#&gt; [138,]  1.47526209  0.379610186  1.338284927  1.299004585\n#&gt; [139,] -1.21185051  0.177546567 -0.461645394 -0.847635231\n#&gt; [140,]  0.44095087  1.389928284 -1.324877283  1.279838158\n#&gt; [141,] -0.85776198 -0.421908837 -0.810611477 -0.598471681\n#&gt; [142,]  0.54345018  0.817414695  2.068358705  0.992341754\n#&gt; [143,]  0.85560717  0.669234708  0.337303269  1.164839596\n#&gt; [144,] -0.49435534 -1.183015138  0.176595204 -0.694303815\n#&gt; [145,] -0.59219559 -0.570088825  0.383219859 -0.502639546\n#&gt; [146,] -0.07853427 -1.438962389 -0.989686177 -0.713470242\n#&gt; [147,]  1.08390109 -1.075247874 -1.003461154 -0.157643861\n#&gt; [148,]  1.12000880  1.733436437  0.631169444  2.180660223\n#&gt; [149,] -1.27008875  1.147451941 -0.856528067 -0.598471681\n#&gt; [150,] -1.19204951  0.170811113 -0.457053735 -0.751803096\n#&gt; [151,]  1.55679563 -0.630707911  0.295978338  0.398182519\n#&gt; [152,] -0.30333390 -1.001157880  0.833202439 -0.464306692\n#&gt; [153,]  0.58887601  0.002424763 -0.750919910  0.494014654\n#&gt; [154,]  0.28254284  1.107039217  0.328119951  0.954008900\n#&gt; [155,]  0.47472905 -0.145755224 -0.966727882  0.302350385\n#&gt; [156,] -1.66494405 -0.785623353 -1.141210924 -2.074286554\n#&gt; [157,] -0.61898518  1.362986468  0.915852301  0.244851104\n#&gt; [158,]  0.03211839 -1.479375113 -0.287162353 -0.751803096\n#&gt; [159,] -1.57642192  0.918446505  0.672494375 -1.288463050\n#&gt; [160,] -0.17870405 -0.327612482  0.185778522 -0.215143142\n#&gt; [161,]  0.29652002 -0.347818844  0.006703822  0.072353262\n#&gt; [162,] -0.71449590  0.844356511  0.860752393 -0.138477435\n#&gt; [163,]  0.48171764 -0.347818844 -0.227470786  0.168185396\n#&gt; [164,]  0.19169118  0.911711051 -1.063152721  0.762344631\n#&gt; [165,] -0.34759496 -0.576824279 -1.154985900 -0.406807411\n#&gt; [166,]  1.01867425 -1.337930579  2.490791332 -0.406807411\n#&gt; [167,] -1.50420650  0.965594683 -0.411137145 -1.154298062\n#&gt; [168,]  0.69603438 -1.216692407 -0.512153643 -0.349308131\n#&gt; [169,]  0.79620416  0.022631125  1.241860088  0.589846789\n#&gt; [170,]  1.59872717 -0.852977892 -1.109069311  0.187351823\n#&gt; [171,] -1.13031697 -0.785623353 -0.558070233 -1.077632354\n#&gt; [172,]  0.20333883 -0.159226132  0.773510872  0.091519689\n#&gt; [173,] -1.48440549 -0.213109764 -0.622353458 -1.230963769\n#&gt; [174,]  0.24876466 -1.088718782 -0.815203136 -0.445140265\n#&gt; [175,]  0.87773770 -1.337930579 -0.801428159 -0.483473119\n#&gt; [176,]  1.51253457  1.726700983  0.516377969  2.487323054\n#&gt; [177,]  1.18057657  0.467171088 -0.470828712  1.184006023\n#&gt; [178,]  0.26973043 -1.041570604  0.213328476 -0.445140265\n#&gt; [179,]  1.51020504 -1.412020573 -0.314712307 -0.425973838\n#&gt; [180,]  0.21615124 -0.893390616 -0.594803505 -0.272642423\n#&gt; [181,]  0.11132240 -1.391814211 -1.021827790 -0.675137388\n#&gt; [182,]  0.83231187 -1.203221500 -0.144820924 -0.349308131\n#&gt; [183,] -1.05810154 -1.183015138 -0.039212768 -1.020133073\n#&gt; [184,]  1.63716441  1.329309198  1.893875664  2.333991639\n#&gt; [185,]  1.24347388 -0.132284316 -0.025437791  0.685678923\n#&gt; [186,]  0.67506861  1.470753732 -0.502970325  1.644000269\n#&gt; [187,] -0.08785239 -1.425491481 -0.181554196 -0.713470242\n#&gt; [188,]  0.51316629  0.366139279 -0.567253551  0.628179642\n#&gt; [189,]  1.61852817 -0.630707911 -1.233044103  0.359849666\n#&gt; [190,] -1.49488838 -0.751946083 -0.328487284 -1.403461612\n#&gt; [191,] -1.25261728  1.201335572 -1.136619265 -0.617638108\n#&gt; [192,] -0.83330192 -0.839506984 -1.127435947 -0.790135950\n#&gt; [193,] -1.51235985 -1.290782401  0.048028753 -1.556793027\n#&gt; [194,]  0.23012842  1.261954658 -1.237635762  1.069007462\n#&gt; [195,]  0.03095363  0.830885603 -1.127435947  0.628179642\n#&gt; [196,] -1.26775922 -1.317724217 -0.769286546 -1.230963769\n#&gt; [197,] -0.61549089 -1.236898769 -1.031011108 -0.828468804\n#&gt; [198,]  0.34893444 -0.940538794 -1.109069311 -0.234309569\n#&gt; [199,]  1.59057381  1.261954658  1.636742761  2.199826650\n#&gt; [200,]  0.99071990 -0.987686972 -1.003461154 -0.119311008\n#&gt; attr(,\"scaled:center\")\n#&gt;        TV     radio newspaper     sales \n#&gt;  147.0425   23.2640   30.5540   14.0225 \n#&gt; attr(,\"scaled:scale\")\n#&gt;        TV     radio newspaper     sales \n#&gt; 85.854236 14.846809 21.778621  5.217457\n#R平方贡献率  #相对权重 \nrelweights&lt;-function(fit,...){\n  R&lt;-cor(fit$model)\n  nvar&lt;-ncol(R)\n  rxx&lt;-R[2:nvar,2:nvar]\n  rxy&lt;-R[2:nvar,1]\n  svd&lt;-eigen(rxx)\n  evec&lt;-svd$vectors\n  ev&lt;-svd$values\n  delta&lt;-diag(sqrt(ev))\n  lambda&lt;-evec %*%delta %*% t(evec)\n  lambdaasq&lt;-lambda^2\n  beta&lt;-solve(lambda) %*% rxy\n  r2&lt;-colSums(beta^2)\n  rawwgt&lt;-lambdaasq%*%beta^2\n  import&lt;-(rawwgt/r2)*100            #计算相对权重\n  import&lt;-data.frame(Weights=import)  #数据框化\n  row.names(import)&lt;-names(fit$model[2:nvar])\n  import&lt;-import[order(import$Weights),1,drop=FALSE] #升序排序\n  dotchart(import$Weights,labels=row.names(import),   #点图\n           xlab = \"% of R-Square\",pch=19,\n           main=\"Relative Importiance of Predictor Variables \",\n           sub=paste(\"Total R-Square =\",round(r2,digits = 3)),\n  ...)\nreturn(import)\n}\nrelweights(lm1$fit,col=\"blue\")\n\n\n\n\n\n\n\n\n\n\n\nWeights\n\n\n\nnewspaper\n2.468097\n\n\nradio\n32.198236\n\n\nTV\n65.333667",
    "crumbs": [
      "推断统计模型",
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>线性回归</span>"
    ]
  },
  {
    "objectID": "LinearRegression.html#线性可加模型",
    "href": "LinearRegression.html#线性可加模型",
    "title": "\n16  线性回归\n",
    "section": "\n16.8 线性可加模型",
    "text": "16.8 线性可加模型\nadditive model\n\\[\nY_i=\\beta_0+ \\beta_1 X_i+  \\beta_2 X_i^2+\\epsilon_i\n\\]\n\\[\nY_i=\\beta_0+ \\beta_1\\times \\log(X_i)+\\epsilon_i\n\\]\n\\[\nY_i=\\beta_0+ \\beta_1 (X_i\\times W_i)+\\epsilon_i\n\\]\n\\[\nY_i=\\beta_0+ \\beta_1\\times \\exp(X_i)+\\epsilon_i\n\\]\n\\[\nY_i=\\beta_0+ \\beta_1\\times \\sin(X_i)+\\epsilon_i\n\\]",
    "crumbs": [
      "推断统计模型",
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>线性回归</span>"
    ]
  },
  {
    "objectID": "LME.html",
    "href": "LME.html",
    "title": "\n17  线性混合模型\n",
    "section": "",
    "text": "17.1 lme4::lmer()\nCodelme4::lmer\n#&gt; function (formula, data = NULL, REML = TRUE, control = lmerControl(), \n#&gt;     start = NULL, verbose = 0L, subset, weights, na.action, offset, \n#&gt;     contrasts = NULL, devFunOnly = FALSE) \n#&gt; {\n#&gt;     mc &lt;- mcout &lt;- match.call()\n#&gt;     missCtrl &lt;- missing(control)\n#&gt;     if (!missCtrl && !inherits(control, \"lmerControl\")) {\n#&gt;         if (!is.list(control)) \n#&gt;             stop(\"'control' is not a list; use lmerControl()\")\n#&gt;         warning(\"passing control as list is deprecated: please use lmerControl() instead\", \n#&gt;             immediate. = TRUE)\n#&gt;         control &lt;- do.call(lmerControl, control)\n#&gt;     }\n#&gt;     mc$control &lt;- control\n#&gt;     mc[[1]] &lt;- quote(lme4::lFormula)\n#&gt;     lmod &lt;- eval(mc, parent.frame(1L))\n#&gt;     mcout$formula &lt;- lmod$formula\n#&gt;     lmod$formula &lt;- NULL\n#&gt;     if (is.matrix(y &lt;- model.response(lmod$fr)) && ncol(y) &gt; \n#&gt;         1) {\n#&gt;         stop(\"can't handle matrix-valued responses: consider using refit()\")\n#&gt;     }\n#&gt;     devfun &lt;- do.call(mkLmerDevfun, c(lmod, list(start = start, \n#&gt;         verbose = verbose, control = control)))\n#&gt;     if (devFunOnly) \n#&gt;         return(devfun)\n#&gt;     if (identical(control$optimizer, \"none\")) \n#&gt;         stop(\"deprecated use of optimizer=='none'; use NULL instead\")\n#&gt;     opt &lt;- if (length(control$optimizer) == 0) {\n#&gt;         s &lt;- getStart(start, environment(devfun)$pp)\n#&gt;         list(par = s, fval = devfun(s), conv = 1000, message = \"no optimization\")\n#&gt;     }\n#&gt;     else {\n#&gt;         optimizeLmer(devfun, optimizer = control$optimizer, restart_edge = control$restart_edge, \n#&gt;             boundary.tol = control$boundary.tol, control = control$optCtrl, \n#&gt;             verbose = verbose, start = start, calc.derivs = control$calc.derivs, \n#&gt;             use.last.params = control$use.last.params)\n#&gt;     }\n#&gt;     cc &lt;- checkConv(attr(opt, \"derivs\"), opt$par, ctrl = control$checkConv, \n#&gt;         lbound = environment(devfun)$lower)\n#&gt;     mkMerMod(environment(devfun), opt, lmod$reTrms, fr = lmod$fr, \n#&gt;         mc = mcout, lme4conv = cc)\n#&gt; }\n#&gt; &lt;bytecode: 0x0000021bb56bef28&gt;\n#&gt; &lt;environment: namespace:lme4&gt;\nlmer() 的表达式如下：\n\\[\nlmer (data,formual= DV ~ Fixed\\_Factor + (Random\\_intercept + Random\\_slope | Random\\_Factor))\n\\]\n截距中，1表示随机截距，0表示固定截距，默认截距为1。",
    "crumbs": [
      "推断统计模型",
      "<span class='chapter-number'>17</span>  <span class='chapter-title'>线性混合模型</span>"
    ]
  },
  {
    "objectID": "LME.html#lme4lmer",
    "href": "LME.html#lme4lmer",
    "title": "\n17  线性混合模型\n",
    "section": "",
    "text": "LME\n表达式\n简写\n\n\n\n随机截距+随机斜率\ny~x+( 1+x | id )\ny~x+( x | id )\n\n\n随机截距+固定斜率\ny~x+( 1+1 | id )\ny~x+( 1 | id )\n\n\n固定截距+随机斜率\ny~x+( 0+x | id )\nNA\n\n\n线性模型：固定截距+固定斜率\ny~x\nNA",
    "crumbs": [
      "推断统计模型",
      "<span class='chapter-number'>17</span>  <span class='chapter-title'>线性混合模型</span>"
    ]
  },
  {
    "objectID": "LME.html#nlmelme",
    "href": "LME.html#nlmelme",
    "title": "\n17  线性混合模型\n",
    "section": "\n17.2 nlme::lme()\n",
    "text": "17.2 nlme::lme()\n\n\nCodenlme::nlme\n#&gt; function (model, data = sys.frame(sys.parent()), fixed, random = fixed, \n#&gt;     groups, start, correlation = NULL, weights = NULL, subset, \n#&gt;     method = c(\"ML\", \"REML\"), na.action = na.fail, naPattern, \n#&gt;     control = list(), verbose = FALSE) \n#&gt; {\n#&gt;     UseMethod(\"nlme\")\n#&gt; }\n#&gt; &lt;bytecode: 0x0000021bb8b7b550&gt;\n#&gt; &lt;environment: namespace:nlme&gt;",
    "crumbs": [
      "推断统计模型",
      "<span class='chapter-number'>17</span>  <span class='chapter-title'>线性混合模型</span>"
    ]
  },
  {
    "objectID": "LME.html#随机截距随机斜率",
    "href": "LME.html#随机截距随机斜率",
    "title": "\n17  线性混合模型\n",
    "section": "\n17.3 随机截距+随机斜率",
    "text": "17.3 随机截距+随机斜率\n\nCodedf_long &lt;- read_delim(\"data/AED/RIKZ.txt\")\ndf_long$Beach &lt;- factor(df_long$Beach)\ndf_long$Exposure &lt;- factor(df_long$Exposure)\nhead(df_long)\n\n\n\n\nSample\nRichness\nExposure\nNAP\nBeach\n\n\n\n1\n11\n10\n0.045\n1\n\n\n2\n10\n10\n-1.036\n1\n\n\n3\n13\n10\n-1.336\n1\n\n\n4\n11\n10\n0.616\n1\n\n\n5\n10\n10\n-0.684\n1\n\n\n6\n8\n8\n1.190\n2\n\n\n\n\n\n\n\\[\n\\eta_{(nrow \\times 1)} = \\mathbf{X}_{nrow \\times 1} \\beta_{1 \\times 1} + \\mathbf{Z}_{nrow \\times 2n_{subjects}} \\mathbf{\\gamma}_{2n_{subjects} \\times 1} + \\epsilon_i\n\\]\nZ有两倍于受试者数量的列，每个受试者的随机截距和随机斜率\n\nCodelibrary(lme4)\nlme1 &lt;- lmer(Richness ~ 1 + NAP * Exposure+ (1 +NAP |Beach) ,data = df_long)\nsummary(lme1)\n#&gt; Linear mixed model fit by REML ['lmerMod']\n#&gt; Formula: Richness ~ 1 + NAP * Exposure + (1 + NAP | Beach)\n#&gt;    Data: df_long\n#&gt; \n#&gt; REML criterion at convergence: 207.2\n#&gt; \n#&gt; Scaled residuals: \n#&gt;      Min       1Q   Median       3Q      Max \n#&gt; -1.92384 -0.36066 -0.13343  0.09819  2.84228 \n#&gt; \n#&gt; Random effects:\n#&gt;  Groups   Name        Variance Std.Dev. Corr \n#&gt;  Beach    (Intercept) 3.758    1.938         \n#&gt;           NAP         2.837    1.684    -1.00\n#&gt;  Residual             6.535    2.556         \n#&gt; Number of obs: 45, groups:  Beach, 9\n#&gt; \n#&gt; Fixed effects:\n#&gt;                Estimate Std. Error t value\n#&gt; (Intercept)     13.3457     2.2784   5.858\n#&gt; NAP             -4.1753     2.1243  -1.965\n#&gt; Exposure10      -5.3273     2.5556  -2.085\n#&gt; Exposure11      -9.7660     2.5653  -3.807\n#&gt; NAP:Exposure10   0.1646     2.3621   0.070\n#&gt; NAP:Exposure11   2.7273     2.3715   1.150\n#&gt; \n#&gt; Correlation of Fixed Effects:\n#&gt;             (Intr) NAP    Exps10 Exps11 NAP:E10\n#&gt; NAP         -0.770                             \n#&gt; Exposure10  -0.892  0.686                      \n#&gt; Exposure11  -0.888  0.683  0.792               \n#&gt; NAP:Expsr10  0.692 -0.899 -0.775 -0.615        \n#&gt; NAP:Expsr11  0.689 -0.896 -0.615 -0.779  0.806 \n#&gt; optimizer (nloptwrap) convergence code: 0 (OK)\n#&gt; boundary (singular) fit: see help('isSingular')\nAIC(lme1)\n#&gt; [1] 227.1558\nBIC(lme1)\n#&gt; [1] 245.2224\nlogLik(lme1)\n#&gt; 'log Lik.' -103.5779 (df=10)\n\n2*(1-pt(-3.914605,35,lower.tail = F))\n#&gt; [1] 0.0003993968\n\nlibrary(nlme)\n\nnlme1 &lt;- lme(Richness ~ 1 + NAP * Exposure,\n             random = ~ 1 + NAP | Beach ,\n             data = df_long,\n             control = lmeControl(opt = \"optim\", msMaxIter = 100, msMaxEval = 5000))\nsummary(nlme1)\n#&gt; Linear mixed-effects model fit by REML\n#&gt;   Data: df_long \n#&gt;        AIC      BIC    logLik\n#&gt;   227.2046 243.8402 -103.6023\n#&gt; \n#&gt; Random effects:\n#&gt;  Formula: ~1 + NAP | Beach\n#&gt;  Structure: General positive-definite, Log-Cholesky parametrization\n#&gt;             StdDev   Corr  \n#&gt; (Intercept) 1.939709 (Intr)\n#&gt; NAP         1.689580 -0.996\n#&gt; Residual    2.554676       \n#&gt; \n#&gt; Fixed effects:  Richness ~ 1 + NAP * Exposure \n#&gt;                    Value Std.Error DF   t-value p-value\n#&gt; (Intercept)    13.345694  2.278989 33  5.855970  0.0000\n#&gt; NAP            -4.175271  2.128084 33 -1.961986  0.0582\n#&gt; Exposure10     -5.323695  2.556406  6 -2.082492  0.0825\n#&gt; Exposure11     -9.765613  2.566035  6 -3.805720  0.0089\n#&gt; NAP:Exposure10  0.167146  2.366467 33  0.070631  0.9441\n#&gt; NAP:Exposure11  2.726865  2.375786 33  1.147774  0.2593\n#&gt;  Correlation: \n#&gt;                (Intr) NAP    Exps10 Exps11 NAP:E10\n#&gt; NAP            -0.767                             \n#&gt; Exposure10     -0.891  0.684                      \n#&gt; Exposure11     -0.888  0.682  0.792               \n#&gt; NAP:Exposure10  0.690 -0.899 -0.772 -0.613        \n#&gt; NAP:Exposure11  0.687 -0.896 -0.613 -0.777  0.806 \n#&gt; \n#&gt; Standardized Within-Group Residuals:\n#&gt;        Min         Q1        Med         Q3        Max \n#&gt; -1.9251786 -0.3608959 -0.1327685  0.0992999  2.8420571 \n#&gt; \n#&gt; Number of Observations: 45\n#&gt; Number of Groups: 9\n\n\n这个模型的公式可以分解为：\n\n固定效应部分：Richness 的预测由截距、NAP（数值变量）和 Exposure（分类变量，包含 Exposure10 和 Exposure11）及其交互项构成。\n随机效应部分：Beach 作为随机因子，包含随机截距和随机斜率（NAP）。\n\n\nCode# 标准化模型残差分布\nquantile(residuals(lme1,type=\"pearson\",scaled=T))\n#&gt;         0%        25%        50%        75%       100% \n#&gt; -1.9238372 -0.3606612 -0.1334336  0.0981939  2.8422803\n\n# 随机因子随机效应和显著性检验\nranef(lme1)\n#&gt; $Beach\n#&gt;     (Intercept)           NAP\n#&gt; 1 -4.274356e-02  3.713708e-02\n#&gt; 2 -2.709479e-14  2.354089e-14\n#&gt; 3  3.819348e-03 -3.318381e-03\n#&gt; 4 -2.741786e-01  2.382158e-01\n#&gt; 5  3.269522e+00 -2.840673e+00\n#&gt; 6  2.736093e-01 -2.377212e-01\n#&gt; 7 -3.250033e-03  2.823741e-03\n#&gt; 8 -2.148947e+00  1.867079e+00\n#&gt; 9 -1.077831e+00  9.364564e-01\n#&gt; \n#&gt; with conditional variances for \"Beach\"\nlmerTest::ranova(lme1)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nnpar\nlogLik\nAIC\nLRT\nDf\nPr(&gt;Chisq)\n\n\n\n\n10\n-103.5779\n227.1558\nNA\nNA\nNA\n\n\nNAP in (1 + NAP | Beach)\n8\n-105.6747\n227.3493\n4.193538\n2\n0.1228527\n\n\n\n\n\nCode\n# 查看固定效应和显著性检验\ncoef(lme1)\n#&gt; $Beach\n#&gt;   (Intercept)       NAP Exposure10 Exposure11 NAP:Exposure10 NAP:Exposure11\n#&gt; 1    13.30295 -4.138134  -5.327265  -9.766048      0.1646123       2.727307\n#&gt; 2    13.34569 -4.175271  -5.327265  -9.766048      0.1646123       2.727307\n#&gt; 3    13.34951 -4.178590  -5.327265  -9.766048      0.1646123       2.727307\n#&gt; 4    13.07152 -3.937055  -5.327265  -9.766048      0.1646123       2.727307\n#&gt; 5    16.61522 -7.015944  -5.327265  -9.766048      0.1646123       2.727307\n#&gt; 6    13.61930 -4.412992  -5.327265  -9.766048      0.1646123       2.727307\n#&gt; 7    13.34244 -4.172447  -5.327265  -9.766048      0.1646123       2.727307\n#&gt; 8    11.19675 -2.308192  -5.327265  -9.766048      0.1646123       2.727307\n#&gt; 9    12.26786 -3.238815  -5.327265  -9.766048      0.1646123       2.727307\n#&gt; \n#&gt; attr(,\"class\")\n#&gt; [1] \"coef.mer\"\nanova(lme1)\n\n\n\n\n\nnpar\nSum Sq\nMean Sq\nF value\n\n\n\nNAP\n1\n124.27890\n124.27890\n19.017821\n\n\nExposure\n2\n142.98343\n71.49172\n10.940045\n\n\nNAP:Exposure\n2\n22.30791\n11.15395\n1.706838\n\n\n\n\n\nCode\n#  查看 类和方法\nclass(lme1)\n#&gt; [1] \"lmerMod\"\n#&gt; attr(,\"package\")\n#&gt; [1] \"lme4\"\n# methods(class = \"lmerMod\")\n\n# confint(lme1,level = 0.95)",
    "crumbs": [
      "推断统计模型",
      "<span class='chapter-number'>17</span>  <span class='chapter-title'>线性混合模型</span>"
    ]
  },
  {
    "objectID": "LME.html#随机截距固定斜率",
    "href": "LME.html#随机截距固定斜率",
    "title": "\n17  线性混合模型\n",
    "section": "\n17.4 随机截距+固定斜率",
    "text": "17.4 随机截距+固定斜率\n\\[\n\\eta_{(nrow \\ \\times 1)}=\\mathbf{X_{nrow×1}}\\beta_{1\\times1} +Z_{nrow\\times n_{subjects}} \\mathbf{\\gamma}_{n_{subjects}\\times 1}+\\epsilon_i\n\\]\nZ有一倍于受试者数量的列，每个受试者的随机截距。\n\nCodelme2 &lt;- lmer(Richness ~ 1 + NAP+ (1 |Beach) ,data = df_long)\nsummary(lme2)\n#&gt; Linear mixed model fit by REML ['lmerMod']\n#&gt; Formula: Richness ~ 1 + NAP + (1 | Beach)\n#&gt;    Data: df_long\n#&gt; \n#&gt; REML criterion at convergence: 239.5\n#&gt; \n#&gt; Scaled residuals: \n#&gt;     Min      1Q  Median      3Q     Max \n#&gt; -1.4227 -0.4848 -0.1576  0.2519  3.9794 \n#&gt; \n#&gt; Random effects:\n#&gt;  Groups   Name        Variance Std.Dev.\n#&gt;  Beach    (Intercept) 8.668    2.944   \n#&gt;  Residual             9.362    3.060   \n#&gt; Number of obs: 45, groups:  Beach, 9\n#&gt; \n#&gt; Fixed effects:\n#&gt;             Estimate Std. Error t value\n#&gt; (Intercept)   6.5819     1.0958   6.007\n#&gt; NAP          -2.5684     0.4947  -5.192\n#&gt; \n#&gt; Correlation of Fixed Effects:\n#&gt;     (Intr)\n#&gt; NAP -0.157\nAIC(lme2)\n#&gt; [1] 247.4802\nBIC(lme2)\n#&gt; [1] 254.7069\nlogLik(lme2)\n#&gt; 'log Lik.' -119.7401 (df=4)\n\n2*(1-pt(6.007,35,lower.tail = T))\n#&gt; [1] 7.558855e-07\n\n\n\nnlme2 &lt;- lme(Richness ~ 1 + NAP * Exposure,random= ~ 1 |Beach ,data = df_long)\nsummary(nlme2)\n#&gt; Linear mixed-effects model fit by REML\n#&gt;   Data: df_long \n#&gt;        AIC      BIC    logLik\n#&gt;   227.3493 240.6578 -105.6747\n#&gt; \n#&gt; Random effects:\n#&gt;  Formula: ~1 | Beach\n#&gt;         (Intercept) Residual\n#&gt; StdDev:   0.5138683 2.971793\n#&gt; \n#&gt; Fixed effects:  Richness ~ 1 + NAP * Exposure \n#&gt;                    Value Std.Error DF   t-value p-value\n#&gt; (Intercept)    13.345694  1.483557 33  8.995739  0.0000\n#&gt; NAP            -4.175271  1.505110 33 -2.774063  0.0090\n#&gt; Exposure10     -5.544983  1.657659  6 -3.345069  0.0155\n#&gt; Exposure11     -9.730595  1.670518  6 -5.824898  0.0011\n#&gt; NAP:Exposure10  0.671731  1.643864 33  0.408629  0.6855\n#&gt; NAP:Exposure11  2.688806  1.656743 33  1.622947  0.1141\n#&gt;  Correlation: \n#&gt;                (Intr) NAP    Exps10 Exps11 NAP:E10\n#&gt; NAP            -0.278                             \n#&gt; Exposure10     -0.895  0.249                      \n#&gt; Exposure11     -0.888  0.247  0.795               \n#&gt; NAP:Exposure10  0.255 -0.916 -0.276 -0.226        \n#&gt; NAP:Exposure11  0.253 -0.908 -0.226 -0.296  0.832 \n#&gt; \n#&gt; Standardized Within-Group Residuals:\n#&gt;        Min         Q1        Med         Q3        Max \n#&gt; -1.5652904 -0.4386841 -0.1164805  0.1783113  4.1098230 \n#&gt; \n#&gt; Number of Observations: 45\n#&gt; Number of Groups: 9",
    "crumbs": [
      "推断统计模型",
      "<span class='chapter-number'>17</span>  <span class='chapter-title'>线性混合模型</span>"
    ]
  },
  {
    "objectID": "LME.html#固定截距随机斜率",
    "href": "LME.html#固定截距随机斜率",
    "title": "\n17  线性混合模型\n",
    "section": "\n17.5 固定截距+随机斜率",
    "text": "17.5 固定截距+随机斜率\n\\[\n\\eta_{(nrow \\times 1)} = \\mathbf{X}_{nrow \\times 1} \\beta_{1 \\times 1} + \\mathbf{Z}_{nrow \\times n_{subjects}} \\mathbf{\\gamma}_{n_{subjects} \\times 1} + \\epsilon_i\n\\]\nZ 有一倍于受试者数量的列，每个受试者的随机斜率。\n\nCodelme3 &lt;- lmer(Richness ~ 1 +  NAP+ (0 + NAP |Beach) ,data = df_long)\nsummary(lme3)\n#&gt; Linear mixed model fit by REML ['lmerMod']\n#&gt; Formula: Richness ~ 1 + NAP + (0 + NAP | Beach)\n#&gt;    Data: df_long\n#&gt; \n#&gt; REML criterion at convergence: 252.2\n#&gt; \n#&gt; Scaled residuals: \n#&gt;     Min      1Q  Median      3Q     Max \n#&gt; -1.2182 -0.6636 -0.1930  0.3253  3.3347 \n#&gt; \n#&gt; Random effects:\n#&gt;  Groups   Name Variance Std.Dev.\n#&gt;  Beach    NAP   0.00    0.00    \n#&gt;  Residual      17.31    4.16    \n#&gt; Number of obs: 45, groups:  Beach, 9\n#&gt; \n#&gt; Fixed effects:\n#&gt;             Estimate Std. Error t value\n#&gt; (Intercept)   6.6857     0.6578  10.164\n#&gt; NAP          -2.8669     0.6307  -4.545\n#&gt; \n#&gt; Correlation of Fixed Effects:\n#&gt;     (Intr)\n#&gt; NAP -0.333\n#&gt; optimizer (nloptwrap) convergence code: 0 (OK)\n#&gt; boundary (singular) fit: see help('isSingular')\n\nnlme3 &lt;- lme(Richness ~ 1 + NAP,random= ~ 0+NAP |Beach ,data = df_long)\nsummary(nlme3)\n#&gt; Linear mixed-effects model fit by REML\n#&gt;   Data: df_long \n#&gt;       AIC      BIC    logLik\n#&gt;   260.201 267.2458 -126.1005\n#&gt; \n#&gt; Random effects:\n#&gt;  Formula: ~0 + NAP | Beach\n#&gt;                  NAP Residual\n#&gt; StdDev: 0.0001127408 4.159929\n#&gt; \n#&gt; Fixed effects:  Richness ~ 1 + NAP \n#&gt;                 Value Std.Error DF   t-value p-value\n#&gt; (Intercept)  6.685662 0.6577579 35 10.164320   0e+00\n#&gt; NAP         -2.866853 0.6307186 35 -4.545376   1e-04\n#&gt;  Correlation: \n#&gt;     (Intr)\n#&gt; NAP -0.333\n#&gt; \n#&gt; Standardized Within-Group Residuals:\n#&gt;        Min         Q1        Med         Q3        Max \n#&gt; -1.2181663 -0.6636488 -0.1930031  0.3253447  3.3347473 \n#&gt; \n#&gt; Number of Observations: 45\n#&gt; Number of Groups: 9",
    "crumbs": [
      "推断统计模型",
      "<span class='chapter-number'>17</span>  <span class='chapter-title'>线性混合模型</span>"
    ]
  },
  {
    "objectID": "LME.html#随机效应模型",
    "href": "LME.html#随机效应模型",
    "title": "\n17  线性混合模型\n",
    "section": "\n17.6 随机效应模型",
    "text": "17.6 随机效应模型\n\nCode\nlme4 &lt;- lmer(Richness ~ 1 + (1|Beach) ,data = df_long)\nsummary(lme4)\n#&gt; Linear mixed model fit by REML ['lmerMod']\n#&gt; Formula: Richness ~ 1 + (1 | Beach)\n#&gt;    Data: df_long\n#&gt; \n#&gt; REML criterion at convergence: 261.1\n#&gt; \n#&gt; Scaled residuals: \n#&gt;     Min      1Q  Median      3Q     Max \n#&gt; -1.7797 -0.5070 -0.0980  0.2547  3.8063 \n#&gt; \n#&gt; Random effects:\n#&gt;  Groups   Name        Variance Std.Dev.\n#&gt;  Beach    (Intercept) 10.48    3.237   \n#&gt;  Residual             15.51    3.938   \n#&gt; Number of obs: 45, groups:  Beach, 9\n#&gt; \n#&gt; Fixed effects:\n#&gt;             Estimate Std. Error t value\n#&gt; (Intercept)    5.689      1.228   4.631\n\nnlme4 &lt;- lme(Richness ~ 1 ,random= ~ 1 |Beach ,data = df_long)\nsummary(nlme4)\n#&gt; Linear mixed-effects model fit by REML\n#&gt;   Data: df_long \n#&gt;        AIC      BIC    logLik\n#&gt;   267.1142 272.4668 -130.5571\n#&gt; \n#&gt; Random effects:\n#&gt;  Formula: ~1 | Beach\n#&gt;         (Intercept) Residual\n#&gt; StdDev:    3.237112 3.938415\n#&gt; \n#&gt; Fixed effects:  Richness ~ 1 \n#&gt;                Value Std.Error DF  t-value p-value\n#&gt; (Intercept) 5.688889  1.228419 36 4.631066       0\n#&gt; \n#&gt; Standardized Within-Group Residuals:\n#&gt;         Min          Q1         Med          Q3         Max \n#&gt; -1.77968689 -0.50704111 -0.09795286  0.25468670  3.80631705 \n#&gt; \n#&gt; Number of Observations: 45\n#&gt; Number of Groups: 9",
    "crumbs": [
      "推断统计模型",
      "<span class='chapter-number'>17</span>  <span class='chapter-title'>线性混合模型</span>"
    ]
  },
  {
    "objectID": "LME.html#线性模型固定截距-固定斜率",
    "href": "LME.html#线性模型固定截距-固定斜率",
    "title": "\n17  线性混合模型\n",
    "section": "\n17.7 线性模型：固定截距+ 固定斜率",
    "text": "17.7 线性模型：固定截距+ 固定斜率\n\nCodelm &lt;- lm(Richness ~ 1 + NAP ,data = df_long)\nlm\n#&gt; \n#&gt; Call:\n#&gt; lm(formula = Richness ~ 1 + NAP, data = df_long)\n#&gt; \n#&gt; Coefficients:\n#&gt; (Intercept)          NAP  \n#&gt;       6.686       -2.867",
    "crumbs": [
      "推断统计模型",
      "<span class='chapter-number'>17</span>  <span class='chapter-title'>线性混合模型</span>"
    ]
  },
  {
    "objectID": "LME.html#模型选择",
    "href": "LME.html#模型选择",
    "title": "\n17  线性混合模型\n",
    "section": "\n17.8 模型选择",
    "text": "17.8 模型选择\n限制最大似然法REML\n\n\n赤池信息准则（AIC）\n\\[ kIC=−2log(\\mathcal{L})+2k\\]\n其中：\n\n\\(\\mathcal{L}\\) 是似然函数。\n\\(k\\) 是模型参数的数量。\n\n\n\n贝叶斯信息准则（BIC）\n\\[ BIC=−2log(\\mathcal{L})+klog(n) \\]\n其中：\n\n\n\\(n\\) 是样本量。\n\n\n\n\nCode\nplot_lme &lt;- function(model, title) {\n    ggplot(df_long, aes(NAP, Richness, group = Beach, color = Beach)) +\n        geom_point() +\n        geom_line(\n            data =  bind_cols(df_long, .pred = predict(model, df_long)),\n            mapping = aes(y = .pred),\n            linewidth = 1\n        ) +\n        labs(title = title)+\n        scale_x_continuous(expand = (mult=c(0,.1)))+\n        scale_y_continuous(expand = (mult=c(0,.1)))+\n    ggsci::scale_color_jco() +\n        ggpubr::theme_pubr() +\n        theme(legend.position = \"right\",\n              plot.title = element_text(hjust = .5))\n}\n\n\nlme_plot &lt;- map2(list(lme1,lme2,lme3,lm),list(\"随机截距+随机斜率\",\"随机截距+固定斜率\",\"固定截距+随机斜率\",\"固定截距+固定斜率\"),plot_lme)\n\n\nlme_plot\n#&gt; [[1]]\n\n\n\n\n\n\n#&gt; \n#&gt; [[2]]\n\n\n\n\n\n\n#&gt; \n#&gt; [[3]]\n\n\n\n\n\n\n#&gt; \n#&gt; [[4]]\n\n\n\n\n\n\n\n\nCodeanova(lme1,lme2,lme3)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nnpar\nAIC\nBIC\nlogLik\ndeviance\nChisq\nDf\nPr(&gt;Chisq)\n\n\n\nlme2\n4\n249.8291\n257.0557\n-120.9145\n241.8291\nNA\nNA\nNA\n\n\nlme3\n4\n261.9535\n269.1801\n-126.9767\n253.9535\n0.00000\n0\nNA\n\n\nlme1\n10\n238.1993\n256.2660\n-109.0997\n218.1993\n35.75415\n6\n3.1e-06\n\n\n\n\n\nCodeanova(lme1,lme2,lme3,lme4,lm)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nnpar\nAIC\nBIC\nlogLik\ndeviance\nChisq\nDf\nPr(&gt;Chisq)\n\n\n\nlme4\n3\n269.3035\n274.7235\n-131.6518\n263.3035\nNA\nNA\nNA\n\n\nlm\n3\n259.9535\n265.3735\n-126.9767\n253.9535\n9.350043\n0\nNA\n\n\nlme2\n4\n249.8291\n257.0557\n-120.9145\n241.8291\n12.124401\n1\n0.0004977\n\n\nlme3\n4\n261.9535\n269.1801\n-126.9767\n253.9535\n0.000000\n0\nNA\n\n\nlme1\n10\n238.1993\n256.2660\n-109.0997\n218.1993\n35.754147\n6\n0.0000031\n\n\n\n\n\nCode\n# p小于0.05,说明全模型与简化后模型存在差异，最终采用lme1,AIC最小",
    "crumbs": [
      "推断统计模型",
      "<span class='chapter-number'>17</span>  <span class='chapter-title'>线性混合模型</span>"
    ]
  },
  {
    "objectID": "GLM.html",
    "href": "GLM.html",
    "title": "\n18  广义线性模型\n",
    "section": "",
    "text": "18.1 广义线性模型组件\n广义线性模型是对线性模型的扩展，适用于非正态分布的数据，假设观测值之间是独立的，不能处理组内相关性。模型形式为：\n\\[\ng(E(Y))=\\mathbf{X} \\beta\n\\]\n\\[\n\\eta = \\mathbf{X} \\beta\n\\]\n\\[\nE(y)=\\mu\n\\]\n\\[\n\\eta =g(\\mu)=g(E(y))\n\\]\n\\[\nE(y)=g^{-1}(\\eta)\n\\]\nCodelibrary(tidymodels)\nlibrary(poissonreg)\nlibrary(patchwork)",
    "crumbs": [
      "推断统计模型",
      "<span class='chapter-number'>18</span>  <span class='chapter-title'>广义线性模型</span>"
    ]
  },
  {
    "objectID": "GLM.html#广义线性模型组件",
    "href": "GLM.html#广义线性模型组件",
    "title": "\n18  广义线性模型\n",
    "section": "",
    "text": "线性预测函数：\n\n\n\n因变量的期望值与线性预测函数的关系：\n\n\n\n连接函数 g(.) ：\n\n\n\n反连接函数g-1 (.)：",
    "crumbs": [
      "推断统计模型",
      "<span class='chapter-number'>18</span>  <span class='chapter-title'>广义线性模型</span>"
    ]
  },
  {
    "objectID": "GLM.html#高斯线性回归",
    "href": "GLM.html#高斯线性回归",
    "title": "\n18  广义线性模型\n",
    "section": "\n18.2 高斯线性回归",
    "text": "18.2 高斯线性回归\n高斯线性回归是一种简单的线性回归模型，其中假设响应变量服从正态分布，并且使用恒等连接函数（identity link function）。t-statistic\n\nCode\n# 使用 glm() 函数进行高斯线性回归\nglm1 &lt;- linear_reg() %&gt;% \n  set_engine(\"glm\", family = stats::gaussian(link = \"identity\")) %&gt;% \n  fit(Fertility ~ Agriculture + Education + Catholic + Infant.Mortality,\n      data = swiss)\n\n# 查看模型的系数\ntidy(glm1)\n\n\n\n\nterm\nestimate\nstd.error\nstatistic\np.value\n\n\n\n(Intercept)\n62.1013116\n9.6048861\n6.465596\n0.0000001\n\n\nAgriculture\n-0.1546175\n0.0681899\n-2.267454\n0.0285697\n\n\nEducation\n-0.9802638\n0.1481367\n-6.617293\n0.0000001\n\n\nCatholic\n0.1246664\n0.0288935\n4.314686\n0.0000950\n\n\nInfant.Mortality\n1.0784422\n0.3818662\n2.824136\n0.0072204\n\n\n\n\n\nCode\n# 查看模型的 AIC 和 Deviance\nglance(glm1) %&gt;% dplyr::select(AIC, deviance)\n\n\n\n\nAIC\ndeviance\n\n\n325.2408\n2158.069",
    "crumbs": [
      "推断统计模型",
      "<span class='chapter-number'>18</span>  <span class='chapter-title'>广义线性模型</span>"
    ]
  },
  {
    "objectID": "GLM.html#逻辑回归",
    "href": "GLM.html#逻辑回归",
    "title": "\n18  广义线性模型\n",
    "section": "\n18.3 逻辑回归",
    "text": "18.3 逻辑回归\n逻辑回归用于处理二元分类问题。其模型假设响应变量的对数优势（log odds）服从线性模型。\nSigmoid 激活函数：\n\\[\nf(x)=\\frac{1}{1+e^{-x}}=\\frac{e^x}{1+e^x}\n\\]\n\nCodesigmoid &lt;- tibble(\n    x=seq(-6,6,length.out=1000),\n    y=1/(1+exp(-x)),\n)\nggplot(sigmoid,aes(x,y))+\n    geom_line()\n\n\n\n\n\n\n\n逻辑回归( logistic regression )的一般数学方程：\n\\[\n\\pi(Y=k|X=(X_1,X_2,...,X_p)=\\frac{e^{\\beta_{k0}+\\beta_{k1}X_1+\\beta_{k2}X_2+...+\\beta_{kp}X_p}}{1+\\sum_{l=1}^{K-1} e^{\\beta_{l0}+\\beta_{l1}X_1+\\beta_{l2}X_2+...+\\beta_{lp}X_p}}\n\\] 其中\\(\\pi\\) 是成功概率，\\(k=1,2,...,K-1\\)是因变量的水平数，\\(p\\) 是自变量个数。\n逻辑回归一般需要引入虚拟变量（哑变量，dummy variable），通常取值伪0或1。\n\n\n当\\(K=2\\)时，\\(k=l=p=1\\)即简单逻辑回归。\n极大似然法（maximum likelihood），likelihood function：\n\\[\n\\ell (\\beta_0,\\beta_1)=\\prod_{i:y_i=1}\\pi(x_i)\\prod_{i':y_{i'}=0}(1-\\pi(x_{i'}))\n\\]\n\n\n当\\(K=2\\)时，\\(k=l=1,p&gt;1\\)即多元逻辑回归（multiple logistic regression）。\n优势（odds）\n\\[\nOdds=\\frac{\\pi(X)}{1-\\pi(X)}=e^{\\beta_0+\\beta_1X_1+\\beta_2X_2+...+\\beta_pX_p}\n\\]\nlog odds (logit)\n\\[\nlogit(\\pi(X))=\\ln (\\frac{\\pi(X)}{1-\\pi(X)})=\\beta_0+\\beta_1X_1+\\beta_2X_2+...+\\beta_pX_p\n\\]\n\n\n当\\(K&gt;2\\)时，\\(k,l,p&gt;1\\)即多项逻辑回归（multinomial logistic regression）。\n\\[\n\\log (\\frac{P(Y=k|X=x)}{P(Y=K|X=x)})=\\beta_{k0}+\\beta_{k1}X_1+\\beta_{k2}X_2+...+\\beta_{kp}X_p\n\\]\n\n\n数据下载网站\n\nCodedf &lt;- read_csv(\"data/ISLR/Default.csv\")\ndf$default &lt;- factor(df$default,levels = c(\"No\",\"Yes\"),labels = c(0,1))\ndf$student&lt;- factor(df$student,levels = c(\"No\",\"Yes\"),labels = c(0,1))\n# 违约 学生 余额 收入\nhead(df)\n\n\n\n\ndefault\nstudent\nbalance\nincome\n\n\n\n0\n0\n729.5265\n44361.625\n\n\n0\n1\n817.1804\n12106.135\n\n\n0\n0\n1073.5492\n31767.139\n\n\n0\n0\n529.2506\n35704.494\n\n\n0\n0\n785.6559\n38463.496\n\n\n0\n1\n919.5885\n7491.559\n\n\n\n\n\nCodetable(df$default,df$student)\n#&gt;    \n#&gt;        0    1\n#&gt;   0 6850 2817\n#&gt;   1  206  127\n\n\n\nCodeggplot(df,aes(balance,income))+\n  geom_point(aes(shape=default,color=default),show.legend = F)|\nggplot(df,aes(default,balance,fill=default),)+\n  geom_boxplot(show.legend = F)+\nggplot(df,aes(default,income,fill=default))+\n  geom_boxplot()\n\n\n\n\n\n\n\n\n18.3.1 Binary logistic regression\n\n18.3.1.1 为什么不用线性回归\n\nCodelm_spec&lt;-linear_reg(mode =\"regression\",engine = \"lm\" )\n\nlm_default_balance&lt;-lm_spec %&gt;% \n  fit(as.numeric(default)-1~balance,data=df)\nlm_default_balance$fit\n#&gt; \n#&gt; Call:\n#&gt; stats::lm(formula = as.numeric(default) - 1 ~ balance, data = data)\n#&gt; \n#&gt; Coefficients:\n#&gt; (Intercept)      balance  \n#&gt;  -0.0751920    0.0001299\n\nggplot(df,aes(balance,as.numeric(default)-1))+\n  geom_point(color=\"orange\",size=1.25)+\n  geom_smooth(method = \"lm\",se=FALSE)+\n  geom_hline(yintercept = c(0,1),linetype=2)+\n  ggtitle(\"linear regression\")\n\n\n\n\n\n\n\n\n18.3.1.2 逻辑回归\nlogit link function\nz-statistic\n\nCodelogit_spec &lt;- logistic_reg() %&gt;%\n  set_engine(\"glm\",family= binomial(link = \"logit\")) \n\n\nlogit_default_balance &lt;- logit_spec %&gt;% fit(default~balance,data=df)\n\nlogit_default_balance %&gt;% glance()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nnull.deviance\ndf.null\nlogLik\nAIC\nBIC\ndeviance\ndf.residual\nnobs\n\n\n2920.65\n9999\n-798.2258\n1600.452\n1614.872\n1596.452\n9998\n10000\n\n\n\n\nCode\ntidy(logit_default_balance)\n\n\n\n\nterm\nestimate\nstd.error\nstatistic\np.value\n\n\n\n(Intercept)\n-10.6513306\n0.3611574\n-29.49221\n0\n\n\nbalance\n0.0054989\n0.0002204\n24.95309\n0\n\n\n\n\n\nCode\n\nggplot(df,aes(balance,as.numeric(default)-1))+\n  geom_point(color=\"orange\",size=1.25)+\n  geom_smooth(method = \"glm\",\n              method.args=list(family=binomial(link = \"logit\")),se=FALSE)+\n  geom_hline(yintercept = c(0,1),linetype=2)+\n  ggtitle(\"logistic regression\")\n\n\n\n\n\n\n\n\n18.3.1.3 自变量含分类变量\n\nCodelogit_default_student &lt;- logit_spec %&gt;%fit(default ~ student, data = df)\n\ntidy(logit_default_student)\n\n\n\n\nterm\nestimate\nstd.error\nstatistic\np.value\n\n\n\n(Intercept)\n-3.5041278\n0.0707130\n-49.554219\n0.0000000\n\n\nstudent1\n0.4048871\n0.1150188\n3.520181\n0.0004313\n\n\n\n\n\nCode\ndf %&gt;% \n  mutate(\n    prob=1/(1+exp(-(logit_default_student$fit$coefficients[1]+logit_default_student$fit$coefficients[2]*(as.numeric(student)-1)))),\n    logit=log(prob/(1-prob))\n  ) %&gt;% \n    dplyr::select(student,prob) %&gt;% \n    DT::datatable()\n\n\n\n\n\n\n18.3.2 K=2,p&gt;1 多元逻辑回归\n\nCodelogit_multiple&lt;-logit_spec %&gt;% fit(default~balance+income+student,data=df)\n\ntidy(logit_multiple)\n\n\n\n\nterm\nestimate\nstd.error\nstatistic\np.value\n\n\n\n(Intercept)\n-10.8690452\n0.4922555\n-22.080088\n0.0000000\n\n\nbalance\n0.0057365\n0.0002319\n24.737563\n0.0000000\n\n\nincome\n0.0000030\n0.0000082\n0.369815\n0.7115203\n\n\nstudent1\n-0.6467758\n0.2362525\n-2.737646\n0.0061881\n\n\n\n\n\nCode\n# confusion matrix 混淆矩阵\naugment(logit_multiple, new_data = df) %&gt;%\n  conf_mat(truth = default, estimate = .pred_class) %&gt;% \n    autoplot(type = \"heatmap\")\n\n\n\n\n\n\nCode\n#准确性 \n(9627+105)/(9627+105+40+228)\n#&gt; [1] 0.9732\naugment(logit_multiple, new_data = df) %&gt;%\n  accuracy(truth = default, estimate = .pred_class)\n\n\n\n\n.metric\n.estimator\n.estimate\n\n\naccuracy\nbinary\n0.9732\n\n\n\n\n\n减少弱相关或无关变量\n\nCodelogit_multiple_2&lt;-logit_spec %&gt;% fit(default~balance+student,data=df)\n\naugment(logit_multiple_2, new_data =df) %&gt;%\n  conf_mat(truth = default, estimate = .pred_class) \n#&gt;           Truth\n#&gt; Prediction    0    1\n#&gt;          0 9628  228\n#&gt;          1   39  105\n\n\n预测特定值\n\nCodedf_new &lt;- tibble(\n  balance = c(1000, 2000), \n  student = factor(c(1, 0)),\n)\npredict(logit_multiple_2, new_data = df_new,type=\"class\")\n\n\n\n\n.pred_class\n\n\n\n0\n\n\n1\n\n\n\n\n\nCodepredict(logit_multiple_2, new_data = df_new, type = \"prob\")\n\n\n\n\n.pred_0\n.pred_1\n\n\n\n0.9967514\n0.0032486\n\n\n0.3259166\n0.6740834\n\n\n\n\n\n\n\n18.3.3 有序逻辑回归\n\\[\n    \\log \\left(\\frac{P(Y\\le k|X=x)}{1-P(Y\\le k|X=x)}\\right)\n\\]\n\nCodeacl &lt;- read_rds(\"data/icpsr/advanced_acl_data.rds\")\nacl$PhysActCat_W1 &lt;- factor(acl$PhysActCat_W1,ordered = T)\nlevels(acl$PhysActCat_W1)\n#&gt; [1] \"(1) Low_5th\"  \"(2) 2Low_5th\" \"(3) 3Low_5th\" \"(4) 4Low_5th\" \"(5) Hi_5th\"\n\nordered_logit &lt;- MASS::polr(PhysActCat_W1 ~ SelfEfficacy_W1, data = acl,\n                            method = \"logistic\")\nordered_logit %&gt;% summary()\n#&gt; Call:\n#&gt; MASS::polr(formula = PhysActCat_W1 ~ SelfEfficacy_W1, data = acl, \n#&gt;     method = \"logistic\")\n#&gt; \n#&gt; Coefficients:\n#&gt;                  Value Std. Error t value\n#&gt; SelfEfficacy_W1 0.2431    0.02893   8.404\n#&gt; \n#&gt; Intercepts:\n#&gt;                           Value    Std. Error t value \n#&gt; (1) Low_5th|(2) 2Low_5th   -0.9332   0.0371   -25.1533\n#&gt; (2) 2Low_5th|(3) 3Low_5th  -0.2688   0.0338    -7.9606\n#&gt; (3) 3Low_5th|(4) 4Low_5th   0.8470   0.0364    23.2527\n#&gt; (4) 4Low_5th|(5) Hi_5th     1.5298   0.0435    35.1647\n#&gt; \n#&gt; Residual Deviance: 11196.86 \n#&gt; AIC: 11206.86\n\n\npredict(ordered_logit ,acl ,type = \"p\") %&gt;% \n    as_tibble() %&gt;% \n    DT::datatable()\n\n\n\n\n\n\n18.3.4 K&gt;2,p&gt;1 多分类逻辑回归\n用于处理具有多于两个类别的响应变量的情况。例如，分类问题中的三个或更多类别。\n\n18.3.4.1 nnet::multinom()\n\n\nCodemn_spec &lt;- multinom_reg(mode = \"classification\", engine = \"nnet\")\n\niris_mnlogit &lt;- mn_spec %&gt;% \n    fit(Species ~ ., data = iris)\n\niris_mnlogit %&gt;% glance()\n\n\n\n\nedf\ndeviance\nAIC\nnobs\n\n\n10\n11.89973\n31.89973\n150\n\n\n\n\nCodeiris_mnlogit %&gt;% tidy()\n\n\n\n\n\n\n\n\n\n\n\n\ny.level\nterm\nestimate\nstd.error\nstatistic\np.value\n\n\n\nversicolor\n(Intercept)\n18.690374\n34.97116\n0.5344511\n0.5930295\n\n\nversicolor\nSepal.Length\n-5.458424\n89.89215\n-0.0607219\n0.9515807\n\n\nversicolor\nSepal.Width\n-8.707401\n157.04152\n-0.0554465\n0.9557828\n\n\nversicolor\nPetal.Length\n14.244770\n60.19170\n0.2366567\n0.8129231\n\n\nversicolor\nPetal.Width\n-3.097684\n45.48852\n-0.0680981\n0.9457075\n\n\nvirginica\n(Intercept)\n-23.836276\n35.76649\n-0.6664417\n0.5051288\n\n\nvirginica\nSepal.Length\n-7.923634\n89.91153\n-0.0881270\n0.9297757\n\n\nvirginica\nSepal.Width\n-15.370769\n157.11962\n-0.0978285\n0.9220685\n\n\nvirginica\nPetal.Length\n23.659779\n60.46753\n0.3912807\n0.6955898\n\n\nvirginica\nPetal.Width\n15.135300\n45.93406\n0.3295006\n0.7417773\n\n\n\n\n\nCode\n\naugment(iris_mnlogit, new_data = iris) %&gt;%\n    conf_mat(truth = Species, estimate = .pred_class) %&gt;%\n    autoplot(type = \"heatmap\")\n\n\n\n\n\n\n\n\n18.3.4.2 glmnet::glmnet()\n\n\nCodelibrary(glmnet) # 多项回归\niris_glmnet &lt;- glmnet(x = iris[, -5], y = iris[, 5], family = \"multinomial\")\niris_glmnet\n#&gt; \n#&gt; Call:  glmnet(x = iris[, -5], y = iris[, 5], family = \"multinomial\") \n#&gt; \n#&gt;     Df  %Dev  Lambda\n#&gt; 1    0  0.00 0.43500\n#&gt; 2    1  6.56 0.39640\n#&gt; 3    1 12.05 0.36110\n#&gt; 4    1 16.73 0.32910\n#&gt; 5    1 20.78 0.29980\n#&gt; 6    2 25.37 0.27320\n#&gt; 7    2 29.66 0.24890\n#&gt; 8    2 33.54 0.22680\n#&gt; 9    2 37.10 0.20670\n#&gt; 10   2 40.40 0.18830\n#&gt; 11   2 43.47 0.17160\n#&gt; 12   3 46.47 0.15630\n#&gt; 13   3 49.57 0.14240\n#&gt; 14   3 52.38 0.12980\n#&gt; 15   3 54.97 0.11830\n#&gt; 16   3 57.36 0.10780\n#&gt; 17   3 59.60 0.09818\n#&gt; 18   3 61.71 0.08946\n#&gt; 19   3 63.72 0.08151\n#&gt; 20   3 65.70 0.07427\n#&gt; 21   3 67.65 0.06767\n#&gt; 22   3 69.54 0.06166\n#&gt; 23   3 71.38 0.05618\n#&gt; 24   3 73.12 0.05119\n#&gt; 25   3 74.71 0.04664\n#&gt; 26   3 76.24 0.04250\n#&gt; 27   3 77.67 0.03872\n#&gt; 28   3 78.99 0.03528\n#&gt; 29   3 80.21 0.03215\n#&gt; 30   3 81.33 0.02929\n#&gt; 31   3 82.36 0.02669\n#&gt; 32   3 83.31 0.02432\n#&gt; 33   3 84.18 0.02216\n#&gt; 34   3 84.99 0.02019\n#&gt; 35   3 85.73 0.01840\n#&gt; 36   3 86.53 0.01676\n#&gt; 37   3 87.34 0.01527\n#&gt; 38   3 88.06 0.01392\n#&gt; 39   3 88.73 0.01268\n#&gt; 40   3 89.34 0.01155\n#&gt; 41   3 89.89 0.01053\n#&gt; 42   3 90.40 0.00959\n#&gt; 43   4 90.87 0.00874\n#&gt; 44   4 91.34 0.00796\n#&gt; 45   4 91.77 0.00726\n#&gt; 46   4 92.16 0.00661\n#&gt; 47   4 92.52 0.00602\n#&gt; 48   4 92.85 0.00549\n#&gt; 49   4 93.16 0.00500\n#&gt; 50   4 93.44 0.00456\n#&gt; 51   4 93.69 0.00415\n#&gt; 52   4 93.92 0.00378\n#&gt; 53   4 94.14 0.00345\n#&gt; 54   4 94.34 0.00314\n#&gt; 55   4 94.52 0.00286\n#&gt; 56   4 94.68 0.00261\n#&gt; 57   4 94.83 0.00238\n#&gt; 58   4 94.97 0.00216\n#&gt; 59   4 95.10 0.00197\n#&gt; 60   4 95.22 0.00180\n#&gt; 61   4 95.33 0.00164\n#&gt; 62   4 95.43 0.00149\n#&gt; 63   4 95.52 0.00136\n#&gt; 64   4 95.60 0.00124\n#&gt; 65   4 95.68 0.00113\n#&gt; 66   4 95.75 0.00103\n#&gt; 67   4 95.81 0.00094\n#&gt; 68   4 95.87 0.00085\n#&gt; 69   4 95.92 0.00078\n#&gt; 70   4 95.97 0.00071\n#&gt; 71   4 96.01 0.00065\n#&gt; 72   4 96.05 0.00059\n#&gt; 73   4 96.09 0.00054\n#&gt; 74   4 96.12 0.00049\n#&gt; 75   4 96.15 0.00045\n#&gt; 76   4 96.18 0.00041\n#&gt; 77   4 96.20 0.00037\n#&gt; 78   4 96.22 0.00034\n#&gt; 79   4 96.24 0.00031\n#&gt; 80   4 96.26 0.00028\n#&gt; 81   4 96.27 0.00025\n#&gt; 82   4 96.29 0.00023\n#&gt; 83   4 96.30 0.00021\n#&gt; 84   4 96.31 0.00019\n#&gt; 85   4 96.32 0.00018\n#&gt; 86   4 96.33 0.00016\n#&gt; 87   4 96.33 0.00015\n#&gt; 88   4 96.34 0.00013\n#&gt; 89   4 96.35 0.00012\n#&gt; 90   4 96.35 0.00011\n#&gt; 91   4 96.35 0.00010\n#&gt; 92   4 96.36 0.00009\n#&gt; 93   4 96.36 0.00008\n#&gt; 94   4 96.36 0.00008\n#&gt; 95   4 96.37 0.00007\n#&gt; 96   4 96.37 0.00006\n#&gt; 97   4 96.37 0.00006\n#&gt; 98   4 96.37 0.00005\n#&gt; 99   4 96.38 0.00005\n#&gt; 100  4 96.38 0.00004\nsummary(iris_glmnet )\n#&gt;            Length Class  Mode     \n#&gt; a0         300    -none- numeric  \n#&gt; beta         3    -none- list     \n#&gt; dfmat      300    -none- numeric  \n#&gt; df         100    -none- numeric  \n#&gt; dim          2    -none- numeric  \n#&gt; lambda     100    -none- numeric  \n#&gt; dev.ratio  100    -none- numeric  \n#&gt; nulldev      1    -none- numeric  \n#&gt; npasses      1    -none- numeric  \n#&gt; jerr         1    -none- numeric  \n#&gt; offset       1    -none- logical  \n#&gt; classnames   3    -none- character\n#&gt; grouped      1    -none- logical  \n#&gt; call         4    -none- call     \n#&gt; nobs         1    -none- numeric\nplot(iris_glmnet)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCodeplot(iris_glmnet$lambda,\n  ylab = expression(lambda), xlab = \"迭代次数\", main = \"惩罚系数的迭代路径\"\n)\n\n\n\n\n\n\nCode\n# 选择一个迭代趋于稳定时的 lambda，比如 iris_glmnet$lambda[80]\ncoef(iris_glmnet, s = 0.0002796185)\n#&gt; $setosa\n#&gt; 5 x 1 sparse Matrix of class \"dgCMatrix\"\n#&gt;                      1\n#&gt; (Intercept)  17.015429\n#&gt; Sepal.Length  .       \n#&gt; Sepal.Width   4.486992\n#&gt; Petal.Length -3.250342\n#&gt; Petal.Width  -3.315393\n#&gt; \n#&gt; $versicolor\n#&gt; 5 x 1 sparse Matrix of class \"dgCMatrix\"\n#&gt;                     1\n#&gt; (Intercept)  8.132656\n#&gt; Sepal.Length 2.123980\n#&gt; Sepal.Width  .       \n#&gt; Petal.Length .       \n#&gt; Petal.Width  .       \n#&gt; \n#&gt; $virginica\n#&gt; 5 x 1 sparse Matrix of class \"dgCMatrix\"\n#&gt;                       1\n#&gt; (Intercept)  -25.148085\n#&gt; Sepal.Length   .       \n#&gt; Sepal.Width   -5.176029\n#&gt; Petal.Length   7.536940\n#&gt; Petal.Width   14.481524\n\niris_pred_glmnet &lt;- predict(\n  object = iris_glmnet, newx = as.matrix(iris[, -5]),\n  s = 0.0002796185, type = \"class\"\n)\n\n\n\nCodemn_spec &lt;- multinom_reg(mode = \"classification\", engine = \"glmnet\" ,penalty = tune())\n\niris_mnlogit &lt;- mn_spec %&gt;% \n    fit(Species ~ ., data = iris)\niris_mnlogit %&gt;% glance()\n\n\n\n\nnulldev\nnpasses\nnobs\n\n\n329.5837\n6546\n150\n\n\n\n\nCodeiris_mnlogit$fit %&gt;% tidy() %&gt;% DT::datatable()",
    "crumbs": [
      "推断统计模型",
      "<span class='chapter-number'>18</span>  <span class='chapter-title'>广义线性模型</span>"
    ]
  },
  {
    "objectID": "GLM.html#泊松回归",
    "href": "GLM.html#泊松回归",
    "title": "\n18  广义线性模型\n",
    "section": "\n18.4 泊松回归",
    "text": "18.4 泊松回归\n泊松回归用于计数数据，假设响应变量服从泊松分布，并使用对数连接函数（log link function）。z-statistic\nfamily=poisson(link = \"log\")\nfamily = quasipoisson(link = \"log\"))\n\\[\nP(X=x;\\lambda)=\\frac{e^{-\\lambda}\\lambda ^x}{x!}\n\\]\n\nCode\nggplot(tibble(x=0:20,\n              y1=dpois(x,lambda = 2),\n              y2=dpois(x,lambda = 6),\n              ),\n       aes(x)\n       )+\n    geom_col(aes(y=y1),fill = \"lightblue\")+\n    geom_col(aes(y=y2),fill = \"yellow\",alpha=.3)+\n    ylab(\"Poisson Density\")\n\n\n\n\n\n\n\n\nCodelibrary(poissonreg)\ndf2 &lt;- read_csv(\"data/ISLR/Bikeshare.csv\")\n\n\n\nCode# 泊松回归模型\npois_spec &lt;- poisson_reg() %&gt;% \n  set_mode(\"regression\") %&gt;% \n  set_engine(\"glm\",family=poisson(link = \"log\"))\n\npois_rec_spec &lt;- recipe(bikers ~ mnth + hr + workingday + temp + weathersit, data = df2) %&gt;% \n    step_dummy(all_nominal_predictors()) # 虚拟变量\n\npois_wf &lt;- workflow() %&gt;% \n  add_recipe(pois_rec_spec) %&gt;% \n  add_model(pois_spec)\n\npois_fit &lt;- pois_wf %&gt;% fit(data = df2)\n\n\ntidy(pois_fit)\n\n\n\n\n\n\n\n\n\n\n\nterm\nestimate\nstd.error\nstatistic\np.value\n\n\n\n(Intercept)\n3.0117662\n0.0063169\n476.780725\n0.0000000\n\n\nhr\n0.0506926\n0.0001441\n351.838257\n0.0000000\n\n\nworkingday\n-0.0128398\n0.0019533\n-6.573519\n0.0000000\n\n\ntemp\n2.5638652\n0.0099520\n257.623318\n0.0000000\n\n\nmnth_Aug\n-0.2287982\n0.0046963\n-48.718729\n0.0000000\n\n\nmnth_Dec\n0.2980823\n0.0050089\n59.511067\n0.0000000\n\n\nmnth_Feb\n-0.1015251\n0.0059163\n-17.160118\n0.0000000\n\n\nmnth_Jan\n-0.1450225\n0.0067806\n-21.387732\n0.0000000\n\n\nmnth_July\n-0.3777099\n0.0049579\n-76.183572\n0.0000000\n\n\nmnth_June\n-0.1501555\n0.0046211\n-32.493432\n0.0000000\n\n\nmnth_March\n-0.0311769\n0.0053447\n-5.833195\n0.0000000\n\n\nmnth_May\n0.0507776\n0.0043437\n11.690022\n0.0000000\n\n\nmnth_Nov\n0.2845274\n0.0046053\n61.782729\n0.0000000\n\n\nmnth_Oct\n0.2667007\n0.0043237\n61.683349\n0.0000000\n\n\nmnth_Sept\n-0.0065336\n0.0044343\n-1.473415\n0.1406391\n\n\nweathersit_cloudy.misty\n-0.0308035\n0.0021642\n-14.233203\n0.0000000\n\n\nweathersit_heavy.rain.snow\n-0.6455169\n0.1667492\n-3.871185\n0.0001083\n\n\nweathersit_light.rain.snow\n-0.4727684\n0.0040430\n-116.934850\n0.0000000\n\n\n\n\n\nCode\n\n# 绘制实际值与预测值的关系图\naugment(pois_fit, new_data = df2, type = \"response\") %&gt;%\n    ggplot(aes(bikers, .pred)) +\n    geom_point(alpha = 0.1) +\n    geom_abline(slope = 1,\n                linewidth = 1,\n                color = \"grey40\") +\n    labs(title = \"Predicting the number of bikers per hour using Poission Regression\", x = \"Actual\", y = \"Predicted\")\n\n\n\n\n\n\n\n\nCodepois_fit_coef_mnths &lt;- \n  tidy(pois_fit) %&gt;% \n  dplyr::filter(grepl(\"^mnth\", term)) %&gt;% \n  mutate(\n    term = stringr::str_replace(term, \"mnth_\", \"\"),\n    term = forcats::fct_inorder(term)\n  ) \n\npois_fit_coef_mnths %&gt;% \n  ggplot(aes(term, estimate)) +\n  geom_line(group = 1,na.rm = TRUE) +\n  geom_point(shape = 21, size = 3, stroke = 1.5, \n             fill = \"black\", color = \"white\",na.rm = TRUE) +\n  labs(title = \"Coefficient value from Poission Regression\",\n       x = \"Month\", y = \"Coefficient\")\n\n\n\n\n\n\n\n\nCodepois_acl &lt;- pois_spec %&gt;% \n    fit(NChronic12_W1 ~ SelfEfficacy_W1,data = acl)\n\npois_acl %&gt;% glance()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nnull.deviance\ndf.null\nlogLik\nAIC\nBIC\ndeviance\ndf.residual\nnobs\n\n\n5217.261\n3616\n-5161.259\n10326.52\n10338.9\n5113.99\n3615\n3617\n\n\n\n\nCode\npois_acl %&gt;% tidy()\n\n\n\n\nterm\nestimate\nstd.error\nstatistic\np.value\n\n\n\n(Intercept)\n0.0713171\n0.0161919\n4.404498\n1.06e-05\n\n\nSelfEfficacy_W1\n-0.1495381\n0.0144411\n-10.355019\n0.00e+00\n\n\n\n\n\nCode\nAIC(pois_acl$fit)\n#&gt; [1] 10326.52\nBIC(pois_acl$fit)\n#&gt; [1] 10338.9",
    "crumbs": [
      "推断统计模型",
      "<span class='chapter-number'>18</span>  <span class='chapter-title'>广义线性模型</span>"
    ]
  },
  {
    "objectID": "GLM.html#负二项回归",
    "href": "GLM.html#负二项回归",
    "title": "\n18  广义线性模型\n",
    "section": "\n18.5 负二项回归",
    "text": "18.5 负二项回归\n负二项回归用于处理计数数据且存在过度离散（overdispersion）的问题。\nlog link function，z-statistic\nprobability mass function ：\n\\[\nP(X=x;\\lambda,\\nu)=\\binom{x+\\nu - 1}{ x} \\left ( \\frac{\\lambda}{\\lambda +\\nu} \\right)^x \\left ( \\frac{\\nu}{\\nu + \\lambda} \\right)^{\\nu}\n\\]\n负二项分布的均值是 \\(\\lambda\\) ，\n方差是 \\(\\lambda + \\frac{\\lambda ^2}{\\nu}\\) 。\n\nCodelibrary(MASS)\n# 负二项回归模型\nnb_spec &lt;- linear_reg() %&gt;% \n  set_engine(\"glm\", family = MASS::negative.binomial(theta = 1, link = \"log\"))\n\nnb_acl &lt;- nb_spec %&gt;% \n  fit(NChronic12_W1 ~ SelfEfficacy_W1, data = acl)\n\n# 查看模型结果\nnb_acl %&gt;% glance()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nnull.deviance\ndf.null\nlogLik\nAIC\nBIC\ndeviance\ndf.residual\nnobs\n\n\n2945.585\n3616\n-5219.717\n10443.43\n10455.82\n2897.897\n3615\n3617\n\n\n\n\nCodenb_acl %&gt;% tidy()\n\n\n\n\nterm\nestimate\nstd.error\nstatistic\np.value\n\n\n\n(Intercept)\n0.0715048\n0.0181211\n3.945943\n8.1e-05\n\n\nSelfEfficacy_W1\n-0.1480585\n0.0169183\n-8.751399\n0.0e+00\n\n\n\n\n\nCode\n\nAIC(nb_acl$fit)\n#&gt; [1] 10443.43\nBIC(nb_acl$fit)\n#&gt; [1] 10455.82\n\n# MASS::glm.nb()",
    "crumbs": [
      "推断统计模型",
      "<span class='chapter-number'>18</span>  <span class='chapter-title'>广义线性模型</span>"
    ]
  },
  {
    "objectID": "GEE.html",
    "href": "GEE.html",
    "title": "\n19  广义估计方程\n",
    "section": "",
    "text": "19.1 数据集处理\n数据集 Analyzing ecological data\nCoderfb &lt;- read_delim(\"data/AED/RiceFieldBirds.txt\")\nrfb$richness &lt;- rowSums(rfb[, 8:56] &gt; 0)\nrfb |&gt; mutate(\n    FIELD = factor(FIELD),\n    SPTREAT = factor(SPTREAT),\n    log_AREA = log(rfb$AREA),\n    DEPTH2 = DEPTH ^ 2,\n    .after = 4\n) -&gt; rfb\n\n\nggplot(rfb, aes(Time, richness)) +\n    geom_point(pch = 21) +\n    geom_smooth(method = \"loess\", se = F) +\n    facet_wrap(vars(FIELD), labeller = \"label_both\")\nCodeowls &lt;- read_delim(\"data/AED/Owls.txt\")\n\nowls |&gt;\n    mutate(NCalls = SiblingNegotiation, log_broodsize = log(BroodSize), ) -&gt;\n    owls\nCodede &lt;- read_delim(\"data/AED/DeerEcervi.txt\")\n\nde |&gt;\n    mutate(\n        Ecervi_binary = if_else(Ecervi &gt; 0, 1, Ecervi),\n        Sex = factor(Sex),\n        Length_center = scale(Length, center = T , scale = F),\n    ) -&gt; de",
    "crumbs": [
      "推断统计模型",
      "<span class='chapter-number'>19</span>  <span class='chapter-title'>广义估计方程</span>"
    ]
  },
  {
    "objectID": "GEE.html#glm-连接函数",
    "href": "GEE.html#glm-连接函数",
    "title": "\n19  广义估计方程\n",
    "section": "\n19.2 GLM 连接函数",
    "text": "19.2 GLM 连接函数\nGLM的形式如下：\n\\[ g(\\mu_{ij})=\\beta_0+\\beta_1x_{ij_1}+\\beta_2x_{ij_2}+...+\\beta_px_{ij_p} \\]\n其中，g() 是一个连接函数，用于将自变量的线性组合与因变量的均值联系起来。常见的连接函数包括恒等连接函数（identity）、logistic连接函数（logit）、逆正弦连接函数（inverse sine）函数等。i 表示观测对象的索引，j 表示时间点或相关性结构的索引，uij 表示因变量的均值，β 表示待估计的系数，Xij 表示自变量。\n\\[\n\\eta = \\beta  \\mathbf{X}+ \\alpha\n\\]\n\\[\nE(y)=g^{-1}(\\eta)\n\\]\n对于计数数据：\n\\[\nE(y)=e^{\\eta}=e^{\\beta \\mathbf{X} +\\alpha}, 此时g(\\mu)=\\ln(\\mu)=\\mathbf{X}\\beta\n\\]\n\nCoderfb_glm &lt;- glm(richness ~ offset(log_AREA) +SPTREAT + DEPTH +DEPTH2,\n            family = quasipoisson(link = \"log\"),\n            data = rfb)\n\nowls_glm &lt;- glm(\n    NCalls ~ offset(log_broodsize) + SexParent * FoodTreatment + SexParent *\n        ArrivalTime,\n    family = poisson(link = \"log\"),\n    data = owls\n)\n\n\n对于二分类数据：\n\\[\nE(y)=\\frac{e^{\\beta \\mathbf{X} +\\alpha}}{1+e^{\\beta\\mathbf{X}+\\alpha}}, 此时g(\\mu)=\\ln(\\frac{\\mu}{1-\\mu})=logit(\\mu)\n\\]\n\nCodede_glm &lt;- glm(Ecervi_binary ~ Length_center *Sex,\n              family = binomial(link = \"logit\"),\n              data = de)\nsummary(de_glm)\n#&gt; \n#&gt; Call:\n#&gt; glm(formula = Ecervi_binary ~ Length_center * Sex, family = binomial(link = \"logit\"), \n#&gt;     data = de)\n#&gt; \n#&gt; Coefficients:\n#&gt;                    Estimate Std. Error z value Pr(&gt;|z|)    \n#&gt; (Intercept)        0.652409   0.109602   5.953 2.64e-09 ***\n#&gt; Length_center      0.025112   0.005576   4.504 6.68e-06 ***\n#&gt; Sex2               0.163873   0.174235   0.941   0.3469    \n#&gt; Length_center:Sex2 0.020109   0.009722   2.068   0.0386 *  \n#&gt; ---\n#&gt; Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n#&gt; \n#&gt; (Dispersion parameter for binomial family taken to be 1)\n#&gt; \n#&gt;     Null deviance: 1073.1  on 825  degrees of freedom\n#&gt; Residual deviance: 1003.7  on 822  degrees of freedom\n#&gt; AIC: 1011.7\n#&gt; \n#&gt; Number of Fisher Scoring iterations: 4",
    "crumbs": [
      "推断统计模型",
      "<span class='chapter-number'>19</span>  <span class='chapter-title'>广义估计方程</span>"
    ]
  },
  {
    "objectID": "GEE.html#方差",
    "href": "GEE.html#方差",
    "title": "\n19  广义估计方程\n",
    "section": "\n19.3 方差",
    "text": "19.3 方差\n\\[\nvar(Y_{is}|X_{is})=\\Phi × \\nu(\\mu_{is})\n\\]\n其中，Φ 是scale parameter （overdispersion），v() 是方差函数。",
    "crumbs": [
      "推断统计模型",
      "<span class='chapter-number'>19</span>  <span class='chapter-title'>广义估计方程</span>"
    ]
  },
  {
    "objectID": "GEE.html#相关性结构",
    "href": "GEE.html#相关性结构",
    "title": "\n19  广义估计方程\n",
    "section": "\n19.4 相关性结构",
    "text": "19.4 相关性结构\nR(α)\n\n非结构化相关：cor(Yis,Yit)=αst\n自回归相关：cor(Yis,Yit)=α|s-t|\nexchangeable 等相关：cor(Yis,Yit)=α\nindependence，独立，cor(Yis,Yit)=I",
    "crumbs": [
      "推断统计模型",
      "<span class='chapter-number'>19</span>  <span class='chapter-title'>广义估计方程</span>"
    ]
  },
  {
    "objectID": "GEE.html#gee",
    "href": "GEE.html#gee",
    "title": "\n19  广义估计方程\n",
    "section": "\n19.5 GEE",
    "text": "19.5 GEE\nGLM的期望和方差：\n\\[ E(Y_{ij})=b'(\\theta_{ij})\\\\ Var(Y_{ij})=b''(\\theta_{ij})\\ \\Phi \\]\n假定潜在的随机成分Vi ：\n\\[\nV_i=A_i^{1/2}R(\\alpha)A_i^{1/2}\\ \\Phi\n\\]\n其中，Ai =diag（b''(θi1)，...，b''(θij)） 。\nGEE的形式如下：\n\\[\nU(\\beta)=\\sum_{i=1}^{n} D'_iV_i^{-1}(y_i-\\mu_i)=0\n\\]\n其中，$U(β) $是一个包含待估计参数的函数，quasi-deviance \\(D'_i = \\left(\\frac{\\partial \\mu_i}{\\partial \\beta}\\right)'\\)，\\(V_i\\) 是方差-协方差矩阵，\\(R(\\alpha)\\) 是相关性结构矩阵，y 是观测数据，μ 是模型的均值预测值。采用迭代重复加权最小二乘法（iteratively reweighted least squares ，IWLS)），偏微分方程估计参数。",
    "crumbs": [
      "推断统计模型",
      "<span class='chapter-number'>19</span>  <span class='chapter-title'>广义估计方程</span>"
    ]
  },
  {
    "objectID": "GEE.html#gee-1",
    "href": "GEE.html#gee-1",
    "title": "\n19  广义估计方程\n",
    "section": "\n19.6 gee\n",
    "text": "19.6 gee\n\nhttps://www.statsmodels.org/stable//gee.html\n\nCodedata(epil,package = \"MASS\")\nOxboys |&gt; head(n=18)\n\n\n\n\nSubject\nage\nheight\nOccasion\n\n\n\n1\n-1.0000\n140.5\n1\n\n\n1\n-0.7479\n143.4\n2\n\n\n1\n-0.4630\n144.8\n3\n\n\n1\n-0.1643\n147.1\n4\n\n\n1\n-0.0027\n147.7\n5\n\n\n1\n0.2466\n150.2\n6\n\n\n1\n0.5562\n151.7\n7\n\n\n1\n0.7781\n153.3\n8\n\n\n1\n0.9945\n155.8\n9\n\n\n2\n-1.0000\n136.9\n1\n\n\n2\n-0.7479\n139.1\n2\n\n\n2\n-0.4630\n140.1\n3\n\n\n2\n-0.1643\n142.6\n4\n\n\n2\n-0.0027\n143.2\n5\n\n\n2\n0.2466\n144.0\n6\n\n\n2\n0.5562\n145.8\n7\n\n\n2\n0.7781\n146.8\n8\n\n\n2\n0.9945\n148.3\n9\n\n\n\n\n\nCode\n\ndf_long &lt;- Oxboys\n\n\n\nCodelibrary(gee)\n\ng1 &lt;- gee(height~age,data = df_long ,id = Subject,corstr = \"AR-M\",Mv = 1)\n#&gt; (Intercept)         age \n#&gt;  149.371801    6.521022\ng1\n#&gt; \n#&gt;  GEE:  GENERALIZED LINEAR MODELS FOR DEPENDENT DATA\n#&gt;  gee S-function, version 4.13 modified 98/01/27 (1998) \n#&gt; \n#&gt; Model:\n#&gt;  Link:                      Identity \n#&gt;  Variance to Mean Relation: Gaussian \n#&gt;  Correlation Structure:     AR-M , M = 1 \n#&gt; \n#&gt; Call:\n#&gt; gee(formula = height ~ age, id = Subject, data = df_long, corstr = \"AR-M\", \n#&gt;     Mv = 1)\n#&gt; \n#&gt; Number of observations :  234 \n#&gt; \n#&gt; Maximum cluster size   :  9 \n#&gt; \n#&gt; \n#&gt; Coefficients:\n#&gt; (Intercept)         age \n#&gt;  149.719096    6.547328 \n#&gt; \n#&gt; Estimated Scale Parameter:  65.41743\n#&gt; Number of Iterations:  2\n#&gt; \n#&gt; Working Correlation[1:4,1:4]\n#&gt;           [,1]      [,2]      [,3]      [,4]\n#&gt; [1,] 1.0000000 0.9892949 0.9787045 0.9682274\n#&gt; [2,] 0.9892949 1.0000000 0.9892949 0.9787045\n#&gt; [3,] 0.9787045 0.9892949 1.0000000 0.9892949\n#&gt; [4,] 0.9682274 0.9787045 0.9892949 1.0000000\n#&gt; \n#&gt; \n#&gt; Returned Error Value:\n#&gt; [1] 0\nsummary(g1)\n#&gt; \n#&gt;  GEE:  GENERALIZED LINEAR MODELS FOR DEPENDENT DATA\n#&gt;  gee S-function, version 4.13 modified 98/01/27 (1998) \n#&gt; \n#&gt; Model:\n#&gt;  Link:                      Identity \n#&gt;  Variance to Mean Relation: Gaussian \n#&gt;  Correlation Structure:     AR-M , M = 1 \n#&gt; \n#&gt; Call:\n#&gt; gee(formula = height ~ age, id = Subject, data = df_long, corstr = \"AR-M\", \n#&gt;     Mv = 1)\n#&gt; \n#&gt; Summary of Residuals:\n#&gt;         Min          1Q      Median          3Q         Max \n#&gt; -22.0304139  -5.4912438   0.1324571   4.3822174  18.5695861 \n#&gt; \n#&gt; \n#&gt; Coefficients:\n#&gt;               Estimate Naive S.E.  Naive z Robust S.E. Robust z\n#&gt; (Intercept) 149.719096  1.5531285 96.39840   1.5847569 94.47449\n#&gt; age           6.547328  0.3177873 20.60286   0.3042478 21.51972\n#&gt; \n#&gt; Estimated Scale Parameter:  65.41743\n#&gt; Number of Iterations:  2\n#&gt; \n#&gt; Working Correlation\n#&gt;            [,1]      [,2]      [,3]      [,4]      [,5]      [,6]      [,7]\n#&gt;  [1,] 1.0000000 0.9892949 0.9787045 0.9682274 0.9578625 0.9476085 0.9374643\n#&gt;  [2,] 0.9892949 1.0000000 0.9892949 0.9787045 0.9682274 0.9578625 0.9476085\n#&gt;  [3,] 0.9787045 0.9892949 1.0000000 0.9892949 0.9787045 0.9682274 0.9578625\n#&gt;  [4,] 0.9682274 0.9787045 0.9892949 1.0000000 0.9892949 0.9787045 0.9682274\n#&gt;  [5,] 0.9578625 0.9682274 0.9787045 0.9892949 1.0000000 0.9892949 0.9787045\n#&gt;  [6,] 0.9476085 0.9578625 0.9682274 0.9787045 0.9892949 1.0000000 0.9892949\n#&gt;  [7,] 0.9374643 0.9476085 0.9578625 0.9682274 0.9787045 0.9892949 1.0000000\n#&gt;  [8,] 0.9274287 0.9374643 0.9476085 0.9578625 0.9682274 0.9787045 0.9892949\n#&gt;  [9,] 0.9175005 0.9274287 0.9374643 0.9476085 0.9578625 0.9682274 0.9787045\n#&gt;            [,8]      [,9]\n#&gt;  [1,] 0.9274287 0.9175005\n#&gt;  [2,] 0.9374643 0.9274287\n#&gt;  [3,] 0.9476085 0.9374643\n#&gt;  [4,] 0.9578625 0.9476085\n#&gt;  [5,] 0.9682274 0.9578625\n#&gt;  [6,] 0.9787045 0.9682274\n#&gt;  [7,] 0.9892949 0.9787045\n#&gt;  [8,] 1.0000000 0.9892949\n#&gt;  [9,] 0.9892949 1.0000000\n\n\ngee1 &lt;- gee(y ~ age + trt + base,id=subject,data = epil,family = poisson,corstr =\"exchangeable\" )\n#&gt;  (Intercept)          age trtprogabide         base \n#&gt;   0.57304359   0.02234757  -0.15188049   0.02263524\nsummary(gee1)\n#&gt; \n#&gt;  GEE:  GENERALIZED LINEAR MODELS FOR DEPENDENT DATA\n#&gt;  gee S-function, version 4.13 modified 98/01/27 (1998) \n#&gt; \n#&gt; Model:\n#&gt;  Link:                      Logarithm \n#&gt;  Variance to Mean Relation: Poisson \n#&gt;  Correlation Structure:     Exchangeable \n#&gt; \n#&gt; Call:\n#&gt; gee(formula = y ~ age + trt + base, id = subject, data = epil, \n#&gt;     family = poisson, corstr = \"exchangeable\")\n#&gt; \n#&gt; Summary of Residuals:\n#&gt;        Min         1Q     Median         3Q        Max \n#&gt; -15.742906  -3.318756  -1.186874   1.295122  63.957902 \n#&gt; \n#&gt; \n#&gt; Coefficients:\n#&gt;                 Estimate  Naive S.E.   Naive z Robust S.E.   Robust z\n#&gt; (Intercept)   0.57304359 0.451797966  1.268362 0.360726141  1.5885835\n#&gt; age           0.02234757 0.013412798  1.666138 0.011400956  1.9601489\n#&gt; trtprogabide -0.15188049 0.159304397 -0.953398 0.171051111 -0.8879246\n#&gt; base          0.02263524 0.001696439 13.342795 0.001226748 18.4514092\n#&gt; \n#&gt; Estimated Scale Parameter:  5.087384\n#&gt; Number of Iterations:  1\n#&gt; \n#&gt; Working Correlation\n#&gt;           [,1]      [,2]      [,3]      [,4]\n#&gt; [1,] 1.0000000 0.3933815 0.3933815 0.3933815\n#&gt; [2,] 0.3933815 1.0000000 0.3933815 0.3933815\n#&gt; [3,] 0.3933815 0.3933815 1.0000000 0.3933815\n#&gt; [4,] 0.3933815 0.3933815 0.3933815 1.0000000",
    "crumbs": [
      "推断统计模型",
      "<span class='chapter-number'>19</span>  <span class='chapter-title'>广义估计方程</span>"
    ]
  },
  {
    "objectID": "GEE.html#geepack",
    "href": "GEE.html#geepack",
    "title": "\n19  广义估计方程\n",
    "section": "\n19.7 geepack\n",
    "text": "19.7 geepack\n\n\nCodelibrary(geepack)\n\nrfb_gee &lt;- geeglm(richness ~ offset(log_AREA) +SPTREAT + DEPTH +DEPTH2,\n            family = poisson(link = \"log\"),\n            data = rfb,\n            id=FIELD,\n            corstr = \"ar1\")\n\nsummary(rfb_gee)\n#&gt; \n#&gt; Call:\n#&gt; geeglm(formula = richness ~ offset(log_AREA) + SPTREAT + DEPTH + \n#&gt;     DEPTH2, family = poisson(link = \"log\"), data = rfb, id = FIELD, \n#&gt;     corstr = \"ar1\")\n#&gt; \n#&gt;  Coefficients:\n#&gt;                Estimate    Std.err  Wald Pr(&gt;|W|)   \n#&gt; (Intercept)  -0.6782034  0.2610088 6.752  0.00937 **\n#&gt; SPTREATrlfld -0.5223137  0.2287644 5.213  0.02242 * \n#&gt; DEPTH         0.0498238  0.0193149 6.654  0.00989 **\n#&gt; DEPTH2       -0.0011411  0.0004908 5.406  0.02007 * \n#&gt; ---\n#&gt; Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n#&gt; \n#&gt; Correlation structure = ar1 \n#&gt; Estimated Scale Parameters:\n#&gt; \n#&gt;             Estimate Std.err\n#&gt; (Intercept)    2.334  0.2927\n#&gt;   Link = identity \n#&gt; \n#&gt; Estimated Correlation Parameters:\n#&gt;       Estimate Std.err\n#&gt; alpha   0.4215 0.09034\n#&gt; Number of clusters:   11  Maximum cluster size: 10\nrfb_gee2 &lt;- geeglm(richness ~ offset(log_AREA) +SPTREAT ,\n            family = poisson(link = \"log\"),\n            data = rfb,\n            id=FIELD,\n            corstr = \"ar1\")\n\n# Wald's Test\nanova(rfb_gee,rfb_gee2)\n\n\n\n\nDf\nX2\nP(&gt;|Chi|)\n\n\n2\n6.885\n0.032\n\n\n\n\n\n\\[\nE(Y_{is})=\\mu_{is}=e^{-0.678+0.0498×DEPTH-0.001×DEPTH^2-0.522×SPTREAT_{is}}\\\\\nvar(Y_{is})= 2.33 × \\mu_{is} \\\\\ncor(Y_{is},Y_{it})=0.422^{|s-t|}\n\\]\n作业相关矩阵 corstr ，比较QIC，一般越小越好。\n\nCodeQIC(rfb_gee)\n#&gt;       QIC      QICu Quasi Lik       CIC    params      QICC \n#&gt;  -467.536  -471.921   239.961     6.193     4.000  -455.536\nQIC(rfb_gee2)\n#&gt;       QIC      QICu Quasi Lik       CIC    params      QICC \n#&gt;  -451.065  -457.436   230.718     5.185     2.000  -447.637\n\n\n\n19.7.1 示例\n\nCodedf &lt;- read_delim(\"data/麻醉诱导时相.txt\")\ndf_long &lt;- df |&gt; pivot_longer(\n    cols = starts_with(\"t\"),\n    names_to = \"time\",\n    values_to = \"SBP\"\n)\n\n\n\nCodeg3 &lt;- geeglm(SBP~ group * time,data = df_long ,id = id,corstr = \"ar1\")\n\ng3\n#&gt; \n#&gt; Call:\n#&gt; geeglm(formula = SBP ~ group * time, data = df_long, id = id, \n#&gt;     corstr = \"ar1\")\n#&gt; \n#&gt; Coefficients:\n#&gt;   (Intercept)        groupB        groupC        timet1        timet2 \n#&gt;         121.0           0.2           5.2          -8.6          -2.6 \n#&gt;        timet3        timet4 groupB:timet1 groupC:timet1 groupB:timet2 \n#&gt;           4.8          -0.2           7.2           5.4          -0.6 \n#&gt; groupC:timet2 groupB:timet3 groupC:timet3 groupB:timet4 groupC:timet4 \n#&gt;          -5.0           2.2          11.6          14.2           4.6 \n#&gt; \n#&gt; Degrees of Freedom: 75 Total (i.e. Null);  60 Residual\n#&gt; \n#&gt; Scale Link:                   identity\n#&gt; Estimated Scale Parameters:  [1] 16.13\n#&gt; \n#&gt; Correlation:  Structure = ar1    Link = identity \n#&gt; Estimated Correlation Parameters:\n#&gt;  alpha \n#&gt; 0.8464 \n#&gt; \n#&gt; Number of clusters:   15   Maximum cluster size: 5\nsummary(g3)\n#&gt; \n#&gt; Call:\n#&gt; geeglm(formula = SBP ~ group * time, data = df_long, id = id, \n#&gt;     corstr = \"ar1\")\n#&gt; \n#&gt;  Coefficients:\n#&gt;               Estimate Std.err    Wald Pr(&gt;|W|)    \n#&gt; (Intercept)    121.000   1.414 7320.50  &lt; 2e-16 ***\n#&gt; groupB           0.200   2.234    0.01  0.92867    \n#&gt; groupC           5.200   2.028    6.58  0.01034 *  \n#&gt; timet1          -8.600   0.921   87.22  &lt; 2e-16 ***\n#&gt; timet2          -2.600   1.315    3.91  0.04794 *  \n#&gt; timet3           4.800   1.180   16.55  4.7e-05 ***\n#&gt; timet4          -0.200   1.213    0.03  0.86907    \n#&gt; groupB:timet1    7.200   1.173   37.67  8.4e-10 ***\n#&gt; groupC:timet1    5.400   2.191    6.08  0.01371 *  \n#&gt; groupB:timet2   -0.600   1.470    0.17  0.68309    \n#&gt; groupC:timet2   -5.000   1.943    6.62  0.01008 *  \n#&gt; groupB:timet3    2.200   1.397    2.48  0.11534    \n#&gt; groupC:timet3   11.600   3.098   14.02  0.00018 ***\n#&gt; groupB:timet4   14.200   1.425   99.23  &lt; 2e-16 ***\n#&gt; groupC:timet4    4.600   2.498    3.39  0.06555 .  \n#&gt; ---\n#&gt; Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n#&gt; \n#&gt; Correlation structure = ar1 \n#&gt; Estimated Scale Parameters:\n#&gt; \n#&gt;             Estimate Std.err\n#&gt; (Intercept)     16.1    4.44\n#&gt;   Link = identity \n#&gt; \n#&gt; Estimated Correlation Parameters:\n#&gt;       Estimate Std.err\n#&gt; alpha    0.846  0.0661\n#&gt; Number of clusters:   15  Maximum cluster size: 5\nQIC(g3)\n#&gt;       QIC      QICu Quasi Lik       CIC    params      QICC \n#&gt;      1240      1240      -605        15        15       968",
    "crumbs": [
      "推断统计模型",
      "<span class='chapter-number'>19</span>  <span class='chapter-title'>广义估计方程</span>"
    ]
  },
  {
    "objectID": "SurvivalAnalysis.html",
    "href": "SurvivalAnalysis.html",
    "title": "\n20  生存分析\n",
    "section": "",
    "text": "20.1 生存函数\n\\[\nS(t)=P(T&gt;t)=1-F(t)=\\int_{t}^{+\\infty}f(x)dx\n\\]\n其中S(t)是累计生存概率或生存率，量化了生存时间大于t的概率。f(x)是密度函数，呈右偏态分布，反映了任意时间点 t 终点事件的瞬时发生率。F(t)=P(T&lt;t)是f(t)在区间[0,t]的累计形式，也称为分布函数或累积函数。",
    "crumbs": [
      "生存分析",
      "<span class='chapter-number'>20</span>  <span class='chapter-title'>生存分析</span>"
    ]
  },
  {
    "objectID": "SurvivalAnalysis.html#风险函数",
    "href": "SurvivalAnalysis.html#风险函数",
    "title": "\n20  生存分析\n",
    "section": "\n20.2 风险函数",
    "text": "20.2 风险函数\n\\[\n\\begin{aligned}\nh(t)=&\\lim_{\\Delta t\\to 0}\\frac{P(t\\le T&lt;t+\\Delta t|T\\ge t)}{\\Delta t}\\\\\n=&\\lim_{\\Delta t\\to 0}\\frac{P(t\\le T&lt;t+\\Delta t\\ \\&\\ T\\ge t)}{\\Delta t·P(T\\ge t) }\\\\\n=&\\lim_{\\Delta t\\to 0}\\frac{S(t)- S(t+\\Delta t)}{\\Delta t·S(t)}\\\\\n=&-\\frac{d(\\ln S(t))}{dt}\n\\end{aligned}\n\\]\n\\[S(t)=e^{-\\int_0^t h(u)du} \\]\n\\[\n\\begin{aligned}\nh(t)\\Delta t=&P(t\\le T&lt;t+\\Delta t|T\\ge t)\n=\\frac{P(t\\le T&lt;t+\\Delta t\\ \\&\\ T\\ge t)}{P(T\\ge t) }\\\\\n=&\\frac{P(t\\le T&lt;t+\\Delta t)}{P(T\\ge t) }\\\\\n=&\\frac{f(t)\\Delta t}{S(t)}\n\\end{aligned}\n\\]\n\\(f(t)=h(t)S(t)\\)",
    "crumbs": [
      "生存分析",
      "<span class='chapter-number'>20</span>  <span class='chapter-title'>生存分析</span>"
    ]
  },
  {
    "objectID": "SurvivalAnalysis.html#乘积极限法",
    "href": "SurvivalAnalysis.html#乘积极限法",
    "title": "\n20  生存分析\n",
    "section": "\n20.3 乘积极限法",
    "text": "20.3 乘积极限法\nproduct limit method 也称为Kaplan-Meier 法。\n\\(t_1&lt;t_2&lt;t_3&lt;...&lt;t_n\\)，样本量大小n，ti 代表个体i发生终点事件或右删失的时间。由于一些个体有相同的生存时间，它们被称为 tied 观测时间，生存时间的个数小于样本量n。\n\n20.3.1 点估计S(t)\n\\(n_1&gt;n_2&gt;n_3&gt;...&gt;n_n\\) ,ni d代表在时间点ti 暴露于特定事件风险的幸存者数量。\n\\(d_i\\) 代表在时间点ti 发生终点事件的数量。（如果没有 tie，di=1或0）\n生存率的KM估计计算公式：\n\\[\n\\hat S(t)=\\prod_{t_i\\le t}\\frac{n_i-d_i}{n_i}\n\\tag{20.1}\\]\nEquation 20.1 包括了删失情况，如果从ti-1 到ti 发生了删失，但没有终点事件，di =0，条件概率等于1。\n\n20.3.2 区间估计S(t)\n(1-α)×100% CI \\([\\hat S(t)-z_{1-\\alpha/2}\\sqrt{Var\\left [\\hat S(t)  \\right]},\\hat S(t)+z_{1-\\alpha/2}\\sqrt{Var\\left [\\hat S(t)  \\right]}]\\)\n其中\\(Var\\left [\\hat S(t)  \\right]=\\hat S(t)^2\\sum_{t_i\\le t}\\frac{d_i}{n_i(n_i-d_i)}\\) (Greenwood method )\n\nCodedf_raw &lt;- tibble(\n    id=1:5,\n    sex=factor(c(\"Male\",\"Male\",\"Female\",\"Male\",\"Female\")),\n    age_years=c(53,62,75,73,61),\n    outcome=c(\"Loss to follow-up\",\"Death\",\"Death\",\"Relapse\",\"Survival\"),\n    time=c(\"37.5+\",44.3,25.3,18.1,\"56.7+\")\n)\ndf &lt;- df_raw |&gt; arrange(time) |&gt; select(id,outcome,time) |&gt; \n    mutate(\n        d_i=if_else(outcome==\"Relapse\"|outcome==\"Death\",1,0),\n        time=parse_number(time),\n    )\ndf\n\n\n\n\nid\noutcome\ntime\nd_i\n\n\n\n4\nRelapse\n18.1\n1\n\n\n3\nDeath\n25.3\n1\n\n\n1\nLoss to follow-up\n37.5\n0\n\n\n2\nDeath\n44.3\n1\n\n\n5\nSurvival\n56.7\n0\n\n\n\n\n\nCode\nlibrary(survminer)\nlibrary(survival)\n\nkm_fit&lt;-survfit(Surv(time,d_i)~1,data=df)\n# t_i\nkm_fit$time\n#&gt; [1] 18.1 25.3 37.5 44.3 56.7\n# d_i\nkm_fit$n.event\n#&gt; [1] 1 1 0 1 0\n# cnesored\nkm_fit$n.censor\n#&gt; [1] 0 0 1 0 1\n# n_i\nkm_fit$n.risk\n#&gt; [1] 5 4 3 2 1\n\n# 生存率\nkm_fit$surv\n#&gt; [1] 0.8 0.6 0.6 0.3 0.3\n\nsummary(km_fit)\n#&gt; Call: survfit(formula = Surv(time, d_i) ~ 1, data = df)\n#&gt; \n#&gt;  time n.risk n.event survival std.err lower 95% CI upper 95% CI\n#&gt;  18.1      5       1      0.8   0.179       0.5161            1\n#&gt;  25.3      4       1      0.6   0.219       0.2933            1\n#&gt;  44.3      2       1      0.3   0.239       0.0631            1",
    "crumbs": [
      "生存分析",
      "<span class='chapter-number'>20</span>  <span class='chapter-title'>生存分析</span>"
    ]
  },
  {
    "objectID": "SurvivalAnalysis.html#单因素分组生存曲线的比较",
    "href": "SurvivalAnalysis.html#单因素分组生存曲线的比较",
    "title": "\n20  生存分析\n",
    "section": "\n20.4 单因素分组生存曲线的比较",
    "text": "20.4 单因素分组生存曲线的比较\n\n\n检验方法\n权重\n\n\n\nlog-rank test\n1\n\n\nWilcoxon test\nnj\n\n\n\nTarone-Ware test\n\\(\\sqrt{n_j}\\)\n\n\nPeto test\n\\(\\hat S(t_j)\\)\n\n\n\n\\[\n\\chi^2=\\frac{\\left(\\sum_jw(t_j)(m_{ij}-e_{ij})\\right)^2}{\\hat {Var}\\left(\\sum_jw(t_j)(m_{ij}-e_{ij})\\right)}\n\\]\n\n20.4.1 log-rank test\n\nH0 :两总体的生存曲线是相同的。\n\n计算当第j次发生终点事件各组终点事件的期望值（e1j ,e2j ）\n\\(e_{1j}=\\left ( \\frac{n_{1j}}{n_{1j}+n_{2j}}\\right)\\times (m_{1j}+m_{2j})\\)\n\\(e_{2j}=\\left ( \\frac{n_{2j}}{n_{1j}+n_{2j}}\\right)\\times (m_{1j}+m_{2j})\\)\n其中mij 表示在第 j 个时间点第 i 组终点事件的数量，nij 表示在第 j 个时间点第 i 组初始观测的数量\n\n\n对所有时间点对终点事件的观测值和期望值的差异求和\n\\(O_i-Ei=\\sum_j(m_{ij}-e_{ij})\\ \\ \\ (i=1,2)\\)\n计算其方差估计值\n\\(\\hat{Var}=\\sum_j\\frac{n_{1j}n_{2j}(m_{1j}+m_{2j})(n_{1j}+n_{2j}-m_{1j}-m_{2j})}{(n_{1j}+n_{2j})^2(n_{1j}+n_{2j}-1)}\\ \\ \\ (i=1,2)\\)\n\n\n计算log-rank test 的检验统计量\n\\[\n\\chi^2=\\frac{(O_1-E_1)^2}{\\hat{Var}(O_1-E_1)} \\ 或者 \\ \\chi^2=\\frac{(O_2-E_2)^2}{\\hat{Var}(O_2-E_2)}\n\\]\n也可以近似估计为\n\\[\n\\chi^2=\\sum_{i=1}^2\\frac{(O_i-E_i)^2}{E_i} \\sim \\chi^2(\\nu=1)\n\\]\n\n\n\nCodedf &lt;- read_csv(\"data/log-rank-survival.csv\")\n\n# 使用 Kaplan-Meier 方法创建一个Surv对象\nsurv_formula &lt;- Surv(Days,status)~treatment\n\nkm&lt;-survfit(surv_formula,data=df)\nsummary(km)\n#&gt; Call: survfit(formula = surv_formula, data = df)\n#&gt; \n#&gt;                 treatment=CON \n#&gt;  time n.risk n.event survival std.err lower 95% CI upper 95% CI\n#&gt;    11     14       1   0.9286  0.0688       0.8030        1.000\n#&gt;    13     13       1   0.8571  0.0935       0.6921        1.000\n#&gt;    14     12       2   0.7143  0.1207       0.5129        0.995\n#&gt;    15     10       1   0.6429  0.1281       0.4351        0.950\n#&gt;    17      9       3   0.4286  0.1323       0.2341        0.785\n#&gt;    20      6       2   0.2857  0.1207       0.1248        0.654\n#&gt;    21      4       2   0.1429  0.0935       0.0396        0.515\n#&gt;    25      2       1   0.0714  0.0688       0.0108        0.472\n#&gt;    27      1       1   0.0000     NaN           NA           NA\n#&gt; \n#&gt;                 treatment=DPVB \n#&gt;  time n.risk n.event survival std.err lower 95% CI upper 95% CI\n#&gt;    20     14       1    0.929  0.0688        0.803        1.000\n#&gt;    23     13       1    0.857  0.0935        0.692        1.000\n#&gt;    27     12       1    0.786  0.1097        0.598        1.000\n#&gt;    28     11       1    0.714  0.1207        0.513        0.995\n#&gt;    30     10       1    0.643  0.1281        0.435        0.950\n#&gt;    32      9       1    0.571  0.1323        0.363        0.899\n#&gt;    38      8       1    0.500  0.1336        0.296        0.844\n#&gt;    39      7       1    0.429  0.1323        0.234        0.785\n#&gt;    45      6       1    0.357  0.1281        0.177        0.721\n#&gt; \n#&gt;                 treatment=LDRT \n#&gt;  time n.risk n.event survival std.err lower 95% CI upper 95% CI\n#&gt;    13     14       2   0.8571  0.0935       0.6921        1.000\n#&gt;    15     12       1   0.7857  0.1097       0.5977        1.000\n#&gt;    16     11       1   0.7143  0.1207       0.5129        0.995\n#&gt;    18     10       1   0.6429  0.1281       0.4351        0.950\n#&gt;    19      9       2   0.5000  0.1336       0.2961        0.844\n#&gt;    20      7       3   0.2857  0.1207       0.1248        0.654\n#&gt;    24      4       1   0.2143  0.1097       0.0786        0.584\n#&gt;    25      3       1   0.1429  0.0935       0.0396        0.515\n#&gt;    27      2       1   0.0714  0.0688       0.0108        0.472\n#&gt;    30      1       1   0.0000     NaN           NA           NA\n#&gt; \n#&gt;                 treatment=LR_DPVB \n#&gt;  time n.risk n.event survival std.err lower 95% CI upper 95% CI\n#&gt;    30     14       1    0.929  0.0688        0.803            1\n#&gt;    40     13       1    0.857  0.0935        0.692            1\n\n# 执行Log-rank检验\nlogrank_test &lt;- survdiff(surv_formula,data = df,subset = T,na.action = \"na.omit\")\nlogrank_test$chisq\n#&gt; [1] 58.43627\nlogrank_test$pvalue\n#&gt; [1] 1.268397e-12",
    "crumbs": [
      "生存分析",
      "<span class='chapter-number'>20</span>  <span class='chapter-title'>生存分析</span>"
    ]
  },
  {
    "objectID": "CoxProportionalHazardsModel.html",
    "href": "CoxProportionalHazardsModel.html",
    "title": "\n21  Cox比例风险模型\n",
    "section": "",
    "text": "21.1 风险函数\n\\[\n\\begin{aligned} h(t)=&\\lim_{\\Delta t\\to 0}\\frac{P(t\\le T&lt;t+\\Delta t|T\\ge t)}{\\Delta t}\\\\ =&\\lim_{\\Delta t\\to 0}\\frac{P(t\\le T&lt;t+\\Delta t\\ \\&\\ T\\ge t)}{\\Delta t·P(T\\ge t) }\\\\ =&\\lim_{\\Delta t\\to 0}\\frac{S(t)- S(t+\\Delta t)}{\\Delta t·S(t)}\\\\ =&-\\frac{d(\\ln S(t))}{dt} \\end{aligned}\n\\]",
    "crumbs": [
      "生存分析",
      "<span class='chapter-number'>21</span>  <span class='chapter-title'>Cox比例风险模型</span>"
    ]
  },
  {
    "objectID": "CoxProportionalHazardsModel.html#风险率",
    "href": "CoxProportionalHazardsModel.html#风险率",
    "title": "\n21  Cox比例风险模型\n",
    "section": "\n21.2 风险率",
    "text": "21.2 风险率\n对于有风险因子\\(x_1,x_2,...,x_k\\) 的个体在时间 t 的风险率\\(h(t|x_1,x_2,...,x_k)\\)\n\\[ h(t|x_1,x_2,...,x_k)=h_0(t)g(x_1,x_2,...,x_k)=h_0(t)exp(\\sum_{j=1}^k\\beta_jx_j) \\]\n其中\n\n\\(h0 (t)\\)是给定所有风险因子（协变量）为零的随时间变化的基线风险函数。\n\\(g(X)\\)是k个独立风险因子的集合函数，代表变量的风险效应。\n\\(β_j\\)是部分回归系数，表示风险比的比例变化。",
    "crumbs": [
      "生存分析",
      "<span class='chapter-number'>21</span>  <span class='chapter-title'>Cox比例风险模型</span>"
    ]
  },
  {
    "objectID": "CoxProportionalHazardsModel.html#比例风险假设",
    "href": "CoxProportionalHazardsModel.html#比例风险假设",
    "title": "\n21  Cox比例风险模型\n",
    "section": "\n21.3 比例风险假设",
    "text": "21.3 比例风险假设\n（proportional hazards assumption）\n\\[ \\frac{h(t)}{h_0(t)}=exp(\\sum_{j=1}^k\\beta_jx_j) \\]",
    "crumbs": [
      "生存分析",
      "<span class='chapter-number'>21</span>  <span class='chapter-title'>Cox比例风险模型</span>"
    ]
  },
  {
    "objectID": "CoxProportionalHazardsModel.html#风险比hazard-ratio",
    "href": "CoxProportionalHazardsModel.html#风险比hazard-ratio",
    "title": "\n21  Cox比例风险模型\n",
    "section": "\n21.4 风险比（hazard ratio）",
    "text": "21.4 风险比（hazard ratio）\n假设有两个个体，分别具有独立变量，两个个体的风险函数之比称为风险比\n\\[ HR=\\frac{h(t|x_1,x_2,...,x_k)}{h(t|x_1^*,x_2^*,...,x_k^*)}=exp(\\sum_{j=1}^k\\beta_j(x_j-x_j^*)) \\]\n\nCodedf &lt;- read_csv(\"data/log-rank-survival.csv\")\n\n\nlibrary(survminer)\nlibrary(survival)\n# 使用 Kaplan-Meier 方法创建一个Surv对象\nsurv_formula &lt;- Surv(Days,status)~treatment\n\n# 拟合Cox比例风险模型 \ncox_model &lt;- coxph(surv_formula, data = df)  \n# 查看模型结果 \nsummary(cox_model)  \n#&gt; Call:\n#&gt; coxph(formula = surv_formula, data = df)\n#&gt; \n#&gt;   n= 56, number of events= 39 \n#&gt; \n#&gt;                       coef exp(coef)  se(coef)      z Pr(&gt;|z|)    \n#&gt; treatmentDPVB    -2.740141  0.064561  0.580664 -4.719 2.37e-06 ***\n#&gt; treatmentLDRT    -0.383558  0.681432  0.387499 -0.990    0.322    \n#&gt; treatmentLR_DPVB -4.632850  0.009727  0.878661 -5.273 1.34e-07 ***\n#&gt; ---\n#&gt; Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n#&gt; \n#&gt;                  exp(coef) exp(-coef) lower .95 upper .95\n#&gt; treatmentDPVB     0.064561     15.489  0.020688   0.20148\n#&gt; treatmentLDRT     0.681432      1.467  0.318848   1.45634\n#&gt; treatmentLR_DPVB  0.009727    102.807  0.001738   0.05444\n#&gt; \n#&gt; Concordance= 0.822  (se = 0.025 )\n#&gt; Likelihood ratio test= 61.41  on 3 df,   p=3e-13\n#&gt; Wald test            = 36.01  on 3 df,   p=7e-08\n#&gt; Score (logrank) test = 60.47  on 3 df,   p=5e-13\n# 检查比例风险假设 \ncox.zph(cox_model)\n#&gt;           chisq df    p\n#&gt; treatment 0.833  3 0.84\n#&gt; GLOBAL    0.833  3 0.84\n\n\n\n21.4.1 模型系数的估计\n条件死亡概率和局部似然函数方法\n\\[ \\ln L_p(\\beta)=\\sum_{i=1}^{d}\\left[ \\sum_{j=1}^k\\beta_jx_{ij}-\\ln\\sum_{m\\in R_i}exp( \\sum_{j=1}^k\\beta_jx_{mj})         \\right] \\]\nNewton-Raphson iterative method\n\\[  \\begin{cases}  \\frac{\\partial \\ln L_p(\\beta)}{\\partial \\beta_1}=0\\\\ \\frac{\\partial \\ln L_p(\\beta)}{\\partial \\beta_2}=0\\\\ \\vdots\\\\ \\frac{\\partial \\ln L_p(\\beta)}{\\partial \\beta_k}=0\\\\ \\end{cases} \\]\n\n21.4.2 模型系数的假设检验\n\n\nWald‘s test\n检验是否有独立变量需要被消除，统计量\\(Z=b_j/S_{b_j}\\)\n当样本量足够大时，Z服从标准正态分布，Z2 服从自由度为1 的\\(\\chi^2\\) 分布\n\\[ \\chi^2_W=(b_j/S_{b_j})^2\\sim \\chi^2(1) \\]\n\n\nPartial likelihood Ratio test\n主要用于非显著性变量的消除，新变量的引入和模型的比较。\n\\[ \\chi^2_{LR}=2\\left[ \\ln L_p(\\beta_k)-\\ln L_p(\\beta_{k-1}) \\right]\\sim\\chi^2(1) \\]\n其中分别是包含 k 个和 k-1 个（不包含要检验的第 j 个变量）独立变量的对数局部似然函数",
    "crumbs": [
      "生存分析",
      "<span class='chapter-number'>21</span>  <span class='chapter-title'>Cox比例风险模型</span>"
    ]
  },
  {
    "objectID": "PropensityScore.html",
    "href": "PropensityScore.html",
    "title": "\n22  倾向性评分\n",
    "section": "",
    "text": "22.1 分层（Stratification）",
    "crumbs": [
      "倾向性评分",
      "<span class='chapter-number'>22</span>  <span class='chapter-title'>倾向性评分</span>"
    ]
  },
  {
    "objectID": "PropensityScore.html#分层stratification",
    "href": "PropensityScore.html#分层stratification",
    "title": "\n22  倾向性评分\n",
    "section": "",
    "text": "22.1.1 估计倾向得分（逻辑回归）\n\nCodedata(lalonde, package = 'Matching')\n\n\nlalonde_formu &lt;- treat ~ age + I(age^2) + educ + I(educ^2) + black +\n    hisp + married + nodegr + re74  + I(re74^2) + re75 + I(re75^2) + u74 + u75\nlr_out &lt;- glm(formula = lalonde_formu,\n              data = lalonde,\n              family = binomial(link = 'logit'))\n\nsummary(lr_out)\n#&gt; \n#&gt; Call:\n#&gt; glm(formula = lalonde_formu, family = binomial(link = \"logit\"), \n#&gt;     data = lalonde)\n#&gt; \n#&gt; Coefficients:\n#&gt;               Estimate Std. Error z value Pr(&gt;|z|)  \n#&gt; (Intercept)  4.269e+00  2.173e+00   1.965   0.0494 *\n#&gt; age          2.143e-02  9.037e-02   0.237   0.8126  \n#&gt; I(age^2)    -3.448e-04  1.484e-03  -0.232   0.8163  \n#&gt; educ        -8.713e-01  4.150e-01  -2.099   0.0358 *\n#&gt; I(educ^2)    4.499e-02  2.330e-02   1.931   0.0535 .\n#&gt; black       -2.613e-01  3.708e-01  -0.705   0.4809  \n#&gt; hisp        -8.974e-01  5.184e-01  -1.731   0.0835 .\n#&gt; married      1.829e-01  2.831e-01   0.646   0.5183  \n#&gt; nodegr      -4.285e-01  3.930e-01  -1.090   0.2756  \n#&gt; re74        -2.168e-05  7.739e-05  -0.280   0.7793  \n#&gt; I(re74^2)   -8.553e-10  2.424e-09  -0.353   0.7242  \n#&gt; re75         6.577e-05  1.025e-04   0.642   0.5210  \n#&gt; I(re75^2)   -1.968e-09  5.042e-09  -0.390   0.6963  \n#&gt; u74         -8.315e-02  4.521e-01  -0.184   0.8541  \n#&gt; u75         -3.060e-01  3.591e-01  -0.852   0.3942  \n#&gt; ---\n#&gt; Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n#&gt; \n#&gt; (Dispersion parameter for binomial family taken to be 1)\n#&gt; \n#&gt;     Null deviance: 604.20  on 444  degrees of freedom\n#&gt; Residual deviance: 580.02  on 430  degrees of freedom\n#&gt; AIC: 610.02\n#&gt; \n#&gt; Number of Fisher Scoring iterations: 4\n\n\n倾向性得分就是模型的拟合值，查看得分的分布\n\nCodelalonde$lr_ps &lt;- fitted(lr_out)\n\nggplot(lalonde, aes(x = lr_ps, color = as.logical(treat))) + \n    geom_density() +\n    xlab('Propensity Score')\n\n\n\n\n\n\n\n\n22.1.1.1 分层\n使用五分位数进行分层\n\nCodebreaks5 &lt;- psa::get_strata_breaks(lalonde$lr_ps)\nbreaks5\n#&gt; $breaks\n#&gt;        0%       20%       40%       60%       80%      100% \n#&gt; 0.1127949 0.3299797 0.3502632 0.4295841 0.5060112 0.8175245 \n#&gt; \n#&gt; $labels\n#&gt;     strata      xmin      xmax      xmid\n#&gt; 0%       A 0.1127949 0.3299797 0.2213873\n#&gt; 20%      B 0.3299797 0.3502632 0.3401214\n#&gt; 40%      C 0.3502632 0.4295841 0.3899236\n#&gt; 60%      D 0.4295841 0.5060112 0.4677976\n#&gt; 80%      E 0.5060112 0.8175245 0.6617678\n\nlalonde$lr_strata5 &lt;- cut(x = lalonde$lr_ps, \n                          breaks = breaks5$breaks, \n                          include.lowest = TRUE, \n                          labels = breaks5$labels$strata)\ntable(lalonde$treat, lalonde$lr_strata5)\n#&gt;    \n#&gt;      A  B  C  D  E\n#&gt;   0 65 58 56 43 38\n#&gt;   1 25 30 33 46 51\n\n\n\nCodeggplot(lalonde, aes(x = lr_ps, color = as.logical(treat))) + \n    geom_density(aes(fill = as.logical(treat)), alpha = 0.2) +\n    geom_vline(xintercept = breaks5$breaks, alpha = 0.5) +\n    geom_text(data = breaks5$labels, \n              aes(x = xmid, y = 0, label = strata),\n              color = 'black', vjust = 1) +\n    xlab('Propensity Score') + ylab('Density') +\n    xlim(c(0, 1))\n\n\n\n\n\n\n\n\nCodeggplot() +\n    geom_vline(xintercept = breaks5$breaks) +\n    geom_point(data = lalonde, aes(x = lr_ps, y = log(re78 + 1), color = as.logical(treat)), alpha = 0.5) +\n    geom_text(data = breaks5$labels, aes(x = xmid, y = 0, label = strata), color = 'black', vjust = 1) +\n    xlab('Propensity Score')\n\n\n\n\n\n\n\n\n22.1.1.2 查看平衡混杂效应\n\nCodecovars &lt;- all.vars(lalonde_formu)\ncovars &lt;- lalonde[,covars[-1]]\nPSAgraphics::cv.bal.psa(covariates = covars, \n                        treatment = lalonde$treat,\n                        propensity = lalonde$lr_ps,\n                        strata = lalonde$lr_strata)\n\n\n\n\n\n\n\n数值变量的协变量平衡图\n\nCodePSAgraphics::box.psa(continuous = lalonde$age, \n                     treatment = lalonde$treat, \n                     strata = lalonde$lr_strata,\n                     xlab = \"Strata\", \n                     balance = FALSE,\n                     main = 'Covariate: age')\n\n\n\n\n\n\n\n分类变量的协变量平衡图\n\nCodePSAgraphics::cat.psa(categorical = lalonde$nodegr, \n                     treatment = lalonde$treat, \n                     strata = lalonde$lr_strata, \n                     xlab = 'Strata',\n                     balance = FALSE,\n                     main = 'Covariate: nodegr')\n\n\n\n\n\n\n#&gt; $`treatment:stratum.proportions`\n#&gt;   0:A 1:A 0:B 1:B   0:C  1:C   0:D  1:D   0:E   1:E\n#&gt; 0   0   0   0   0 0.036 0.03 0.302 0.37 0.737 0.706\n#&gt; 1   1   1   1   1 0.964 0.97 0.698 0.63 0.263 0.294\n\n\n22.1.2 估计因果效应\n个体处理效应：\n\\[\nITE=\\tau_i=y_i^1-y_i^0\n\\]\n因果推断的基本难题：Y=ZY1 +(1-Z)Y0 , Z=0 或 1，2个实际结果，2个反事实结果\n平均处理效应\n\\[\n\\widehat {ATE} =E(\\tau)=E(Y^1-Y^0)=E(Y^1)-E(Y^0)\n\\]\n实验组平均处理效应ATT\n对照组平均处理效应ATC\n\nCodePSAgraphics::loess.psa(response = log(lalonde$re78 + 1),\n                       treatment = lalonde$treat,\n                       propensity = lalonde$lr_ps)\n\n\n\n\n\n\n#&gt; $ATE\n#&gt; [1] 0.832516\n#&gt; \n#&gt; $se.wtd\n#&gt; [1] 0.3992742\n#&gt; \n#&gt; $CI95\n#&gt; [1] 0.03396767 1.63106435\n#&gt; \n#&gt; $summary.strata\n#&gt;    counts.0 counts.1  means.0  means.1  diff.means\n#&gt; 1        33       13 6.355024 6.090923 -0.26410149\n#&gt; 2        32       12 5.568504 5.490818 -0.07768589\n#&gt; 3        33       11 5.509654 5.537747  0.02809323\n#&gt; 4        25       19 5.449248 5.571249  0.12200105\n#&gt; 5        29       16 5.407022 5.912038  0.50501592\n#&gt; 6        27       17 5.280991 6.401716  1.12072425\n#&gt; 7        22       22 5.265440 6.791844  1.52640379\n#&gt; 8        21       24 5.241780 6.882596  1.64081539\n#&gt; 9        19       25 5.223695 7.051758  1.82806315\n#&gt; 10       19       26 5.660499 7.570755  1.91025558\n\npsa::loess_plot(ps = lalonde$lr_ps,\n                outcome = log(lalonde$re78 + 1),\n                treatment = lalonde$treat == 1,\n                responseTitle = 'log(re78)',\n                \n                plot.strata = 5,\n                points.treat.alpha = 0.5,\n                points.control.alpha = 0.5,\n                percentPoints.treat = 1,\n                percentPoints.control = 1,\n                se = FALSE, \n                method = 'loess')\n\n\n\n\n\n\n\n\nCodePSAgraphics::circ.psa(response = log(lalonde$re78 + 1), \n                      treatment = lalonde$treat == 1, \n                      strata = lalonde$lr_strata5)\n\n\n\n\n\n\n#&gt; $summary.strata\n#&gt;   n.FALSE n.TRUE means.FALSE means.TRUE\n#&gt; A      65     25    5.965231   5.813530\n#&gt; B      58     30    5.159507   5.017170\n#&gt; C      56     33    5.884181   7.170466\n#&gt; D      43     46    4.831869   6.300722\n#&gt; E      38     51    5.397140   7.479826\n#&gt; \n#&gt; $wtd.Mn.FALSE\n#&gt; [1] 5.449396\n#&gt; \n#&gt; $wtd.Mn.TRUE\n#&gt; [1] 6.358132\n#&gt; \n#&gt; $ATE\n#&gt; [1] 0.9087362\n#&gt; \n#&gt; $se.wtd\n#&gt; [1] 0.3965889\n#&gt; \n#&gt; $approx.t\n#&gt; [1] 2.291381\n#&gt; \n#&gt; $df\n#&gt; [1] 435\n#&gt; \n#&gt; $CI.95\n#&gt; [1] 0.1292676 1.6882048\n\n\n22.1.3 敏感性分析\n\n22.1.3.1 估计倾向得分（分类树）\n\nCodelibrary(tree)\ntree_out &lt;- tree::tree(lalonde_formu,\n                       data = lalonde)\nplot(tree_out); text(tree_out)\n\n\n\n\n\n\nCodelalonde$tree_ps &lt;- predict(tree_out)\ntable(lalonde$tree_ps, lalonde$treat, useNA = 'ifany')\n#&gt;                    \n#&gt;                       0   1\n#&gt;   0.332             167  83\n#&gt;   0.344827586206897  19  10\n#&gt;   0.351851851851852  35  19\n#&gt;   0.612903225806452  24  38\n#&gt;   0.659090909090909  15  29\n#&gt;   1                   0   6\nlalonde$tree_strata &lt;- predict(tree_out, type = 'where')\ntable(lalonde$tree_strata, lalonde$treat, useNA = 'ifany')\n#&gt;     \n#&gt;        0   1\n#&gt;   3  167  83\n#&gt;   5   15  29\n#&gt;   6   35  19\n#&gt;   9   24  38\n#&gt;   10  19  10\n#&gt;   11   0   6",
    "crumbs": [
      "倾向性评分",
      "<span class='chapter-number'>22</span>  <span class='chapter-title'>倾向性评分</span>"
    ]
  },
  {
    "objectID": "PropensityScore.html#匹配matching",
    "href": "PropensityScore.html#匹配matching",
    "title": "\n22  倾向性评分\n",
    "section": "\n22.2 匹配（Matching）",
    "text": "22.2 匹配（Matching）\n倾向评分匹配根据他们的倾向评分将治疗组中的每个人与对照组中的个体相匹配。对于每个人来说，倾向得分可以直观地视为从一系列协变量（和潜在混杂因素）计算出来的最近治疗的概率。两个人，一个来自治疗组，一个来自对照组，如果他们的倾向评分之间的差异很小，则被认为是匹配的。不匹配的参与者将被丢弃。\n\nCodelibrary(Matching)\n\n\n\nCodelalonde_match &lt;- Match(\n    Y = lalonde$re78,\n    Tr = lalonde$treat,\n    X = lalonde$lr_ps,\n    M = 1,\n    caliper = 0.1,\n    replace = TRUE,\n    estimand = 'ATE'\n)\n\nsummary(lalonde_match)\n#&gt; \n#&gt; Estimate...  2053.1 \n#&gt; AI SE......  803.05 \n#&gt; T-stat.....  2.5566 \n#&gt; p.val......  0.010569 \n#&gt; \n#&gt; Original number of observations..............  445 \n#&gt; Original number of treated obs...............  185 \n#&gt; Matched number of observations...............  433 \n#&gt; Matched number of observations  (unweighted).  744 \n#&gt; \n#&gt; Caliper (SDs)........................................   0.1 \n#&gt; Number of obs dropped by 'exact' or 'caliper'  12\n\nlalonde_match_df &lt;- data.frame(\n    treated.ps = lalonde[lalonde_match$index.treated, ]$lr_ps,\n    control.ps = lalonde[lalonde_match$index.control, ]$lr_ps,\n    treated.y = 1,\n    control.y = 0\n)\nlalonde_match_df &lt;- lalonde_match_df[order(lalonde_match_df$control.ps), ]\n\n\nrows &lt;- (1:nrow(lalonde_match_df) - 1) %% floor(nrow(lalonde_match_df) / 5) == 0\n\nggplot(lalonde, aes(x = lr_ps, y = treat)) +\n    geom_point(alpha = 0.5) +\n    geom_smooth(\n        method = glm,\n        formula = y ~ x,\n        method.args = list(family = binomial(link = 'logit')),\n        se = FALSE\n    ) +\n    xlim(c(0, 1)) +\n    xlab('Propensity Score') + ylab('Treatment') +\n    geom_segment(\n        data = lalonde_match_df,\n        aes(\n            x = treated.ps,\n            xend = control.ps,\n            y = treated.y,\n            yend = control.y\n        ),\n        color = 'purple',\n        alpha = 0.1\n    )\n\n\n\n\n\n\n\n匹配后，治疗组和对照组应具有非常相似的特征。可以使用简单的回归模型来估计治疗对结果的影响。\n\n22.2.1 一对一匹配ATT\n\nCoderr_att &lt;- Match(Y = lalonde$re78, \n                Tr = lalonde$treat, \n                X = lalonde$lr_ps,\n                M = 1,\n                estimand='ATT')\nsummary(rr_att) # The default estimate is ATT here\n#&gt; \n#&gt; Estimate...  2153.3 \n#&gt; AI SE......  825.4 \n#&gt; T-stat.....  2.6088 \n#&gt; p.val......  0.0090858 \n#&gt; \n#&gt; Original number of observations..............  445 \n#&gt; Original number of treated obs...............  185 \n#&gt; Matched number of observations...............  185 \n#&gt; Matched number of observations  (unweighted).  346\n\nrr_att_mb &lt;- psa::MatchBalance(\n    df = lalonde,\n    formu = lalonde_formu,\n    formu.Y = update.formula(lalonde_formu, re78 ~ .),\n    index.treated = rr_att$index.treated,\n    index.control = rr_att$index.control,\n    tolerance = 0.25,\n    M = 1,\n    estimand = 'ATT')\nplot(rr_att_mb)\n\n\n\n\n\n\nCodesummary(rr_att_mb)\n#&gt; Sample sizes and number of matches:\n#&gt;    Group   n n.matched n.percent.matched\n#&gt;  Treated 185       185         1.0000000\n#&gt;  Control 260       173         0.6653846\n#&gt;    Total 445       358         0.8044944\n#&gt; \n#&gt; Covariate importance and t-tests for matched pairs:\n#&gt;           Import.Treat Import.Y Import.Total std.estimate       t p.value\n#&gt; I(educ^2)        1.931   1.5228        3.453     -0.04903 -0.8916  0.3732\n#&gt; educ             2.099   1.2121        3.311     -0.05483 -0.9577  0.3389\n#&gt; black            0.705   1.8424        2.547     -0.02326 -0.5383  0.5907\n#&gt; I(re74^2)        0.353   1.6415        1.994      0.07581  2.0955  0.0369\n#&gt; u75              0.852   0.9435        1.796     -0.06655 -1.8144  0.0705\n#&gt; hisp             1.731   0.0404        1.771      0.02042  0.8161  0.4150\n#&gt; nodegr           1.090   0.5011        1.591      0.03496  1.0914  0.2759\n#&gt; re74             0.280   1.1019        1.382      0.07979  1.7483  0.0813\n#&gt; re75             0.642   0.5903        1.232      0.06147  1.3171  0.1887\n#&gt; age              0.237   0.6729        0.910      0.00896  0.1374  0.8908\n#&gt; married          0.646   0.1406        0.787      0.04627  1.0000  0.3180\n#&gt; I(re75^2)        0.390   0.3817        0.772      0.05125  1.0364  0.3007\n#&gt; I(age^2)         0.232   0.5096        0.742      0.00297  0.0438  0.9651\n#&gt; u74              0.184   0.0702        0.254      0.03913  0.7495  0.4541\n#&gt;             ci.min  ci.max PercentMatched\n#&gt; I(educ^2) -0.15719 0.05913           60.4\n#&gt; educ      -0.16744 0.05778           60.1\n#&gt; black     -0.10826 0.06173           91.0\n#&gt; I(re74^2)  0.00465 0.14696           86.7\n#&gt; u75       -0.13870 0.00559           89.3\n#&gt; hisp      -0.02879 0.06963           98.3\n#&gt; nodegr    -0.02804 0.09797           93.9\n#&gt; re74      -0.00998 0.16956           77.2\n#&gt; re75      -0.03032 0.15326           78.0\n#&gt; age       -0.11922 0.13713           44.8\n#&gt; married   -0.04474 0.13728           89.6\n#&gt; I(re75^2) -0.04602 0.14852           88.7\n#&gt; I(age^2)  -0.13062 0.13656           49.7\n#&gt; u74       -0.06356 0.14183           81.5\n\n\n\n22.2.2 一对一匹配ATE\n\nCoderr.ate &lt;- Match(Y = lalonde$re78, \n                Tr = lalonde$treat, \n                X = lalonde$lr_ps,\n                M = 1,\n                estimand = 'ATE')\nsummary(rr.ate)\n#&gt; \n#&gt; Estimate...  2013.3 \n#&gt; AI SE......  817.76 \n#&gt; T-stat.....  2.4619 \n#&gt; p.val......  0.013819 \n#&gt; \n#&gt; Original number of observations..............  445 \n#&gt; Original number of treated obs...............  185 \n#&gt; Matched number of observations...............  445 \n#&gt; Matched number of observations  (unweighted).  756\n\n\n\n22.2.3 一对多匹配 （ATT）\n\nCoderr2 &lt;- Match(Y = lalonde$re78,      \n             Tr = lalonde$treat, \n             X = lalonde$lr_ps,\n             M = 1, \n             ties = TRUE, \n             replace = TRUE,\n             estimand = 'ATT')\nsummary(rr2) # The default estimate is ATT here\n#&gt; \n#&gt; Estimate...  2153.3 \n#&gt; AI SE......  825.4 \n#&gt; T-stat.....  2.6088 \n#&gt; p.val......  0.0090858 \n#&gt; \n#&gt; Original number of observations..............  445 \n#&gt; Original number of treated obs...............  185 \n#&gt; Matched number of observations...............  185 \n#&gt; Matched number of observations  (unweighted).  346\n\n\n\n22.2.4 MachIt套件类型\n\nCodematchit.out &lt;- MatchIt::matchit(lalonde_formu, data = lalonde)\nsummary(matchit.out)\n#&gt; \n#&gt; Call:\n#&gt; MatchIt::matchit(formula = lalonde_formu, data = lalonde)\n#&gt; \n#&gt; Summary of Balance for All Data:\n#&gt;           Means Treated Means Control Std. Mean Diff. Var. Ratio eCDF Mean\n#&gt; distance         0.4468        0.3936          0.4533     1.2101    0.1340\n#&gt; age             25.8162       25.0538          0.1066     1.0278    0.0254\n#&gt; I(age^2)       717.3946      677.3154          0.0929     1.0115    0.0254\n#&gt; educ            10.3459       10.0885          0.1281     1.5513    0.0287\n#&gt; I(educ^2)      111.0595      104.3731          0.1701     1.6625    0.0287\n#&gt; black            0.8432        0.8269          0.0449          .    0.0163\n#&gt; hisp             0.0595        0.1077         -0.2040          .    0.0482\n#&gt; married          0.1892        0.1538          0.0902          .    0.0353\n#&gt; nodegr           0.7081        0.8346         -0.2783          .    0.1265\n#&gt; re74          2095.5740     2107.0268         -0.0023     0.7381    0.0192\n#&gt; I(re74^2) 28141433.9907 36667413.1577         -0.0747     0.5038    0.0192\n#&gt; re75          1532.0556     1266.9092          0.0824     1.0763    0.0508\n#&gt; I(re75^2) 12654752.6909 11196530.0057          0.0260     1.4609    0.0508\n#&gt; u74              0.7081        0.7500         -0.0921          .    0.0419\n#&gt; u75              0.6000        0.6846         -0.1727          .    0.0846\n#&gt;           eCDF Max\n#&gt; distance    0.2244\n#&gt; age         0.0652\n#&gt; I(age^2)    0.0652\n#&gt; educ        0.1265\n#&gt; I(educ^2)   0.1265\n#&gt; black       0.0163\n#&gt; hisp        0.0482\n#&gt; married     0.0353\n#&gt; nodegr      0.1265\n#&gt; re74        0.0471\n#&gt; I(re74^2)   0.0471\n#&gt; re75        0.1075\n#&gt; I(re75^2)   0.1075\n#&gt; u74         0.0419\n#&gt; u75         0.0846\n#&gt; \n#&gt; Summary of Balance for Matched Data:\n#&gt;           Means Treated Means Control Std. Mean Diff. Var. Ratio eCDF Mean\n#&gt; distance         0.4468        0.4284          0.1571     1.3077    0.0387\n#&gt; age             25.8162       25.1351          0.0952     1.1734    0.0243\n#&gt; I(age^2)       717.3946      675.1676          0.0979     1.1512    0.0243\n#&gt; educ            10.3459       10.2649          0.0403     1.2869    0.0174\n#&gt; I(educ^2)      111.0595      108.4919          0.0653     1.3938    0.0174\n#&gt; black            0.8432        0.8486         -0.0149          .    0.0054\n#&gt; hisp             0.0595        0.0703         -0.0457          .    0.0108\n#&gt; married          0.1892        0.1892          0.0000          .    0.0000\n#&gt; nodegr           0.7081        0.7676         -0.1308          .    0.0595\n#&gt; re74          2095.5740     1741.2109          0.0725     1.5797    0.0146\n#&gt; I(re74^2) 28141433.9907 18066538.6428          0.0883     3.5436    0.0146\n#&gt; re75          1532.0556     1314.8073          0.0675     1.3933    0.0264\n#&gt; I(re75^2) 12654752.6909  9126579.7979          0.0630     3.4873    0.0264\n#&gt; u74              0.7081        0.7243         -0.0357          .    0.0162\n#&gt; u75              0.6000        0.6108         -0.0221          .    0.0108\n#&gt;           eCDF Max Std. Pair Dist.\n#&gt; distance    0.1189          0.1585\n#&gt; age         0.0541          0.8159\n#&gt; I(age^2)    0.0541          0.7701\n#&gt; educ        0.0595          0.7662\n#&gt; I(educ^2)   0.0595          0.7604\n#&gt; black       0.0054          0.5798\n#&gt; hisp        0.0108          0.2286\n#&gt; married     0.0000          0.2378\n#&gt; nodegr      0.0595          0.5588\n#&gt; re74        0.0432          0.6080\n#&gt; I(re74^2)   0.0432          0.3620\n#&gt; re75        0.0649          0.7292\n#&gt; I(re75^2)   0.0649          0.3690\n#&gt; u74         0.0162          0.7728\n#&gt; u75         0.0108          0.7282\n#&gt; \n#&gt; Sample Sizes:\n#&gt;           Control Treated\n#&gt; All           260     185\n#&gt; Matched       185     185\n#&gt; Unmatched      75       0\n#&gt; Discarded       0       0\n\n\n\nCode# Same as above but calculate average treatment effect\nrr.ate &lt;- Match(Y = lalonde$re78, \n                Tr = lalonde$treat, \n                X = lalonde$lr_ps,\n                M = 1,\n                ties = FALSE, \n                replace = FALSE, \n                estimand='ATE')\nsummary(rr.ate) # Here the estimate is ATE\n#&gt; \n#&gt; Estimate...  2053.1 \n#&gt; SE.........  496.05 \n#&gt; T-stat.....  4.1389 \n#&gt; p.val......  3.4902e-05 \n#&gt; \n#&gt; Original number of observations..............  445 \n#&gt; Original number of treated obs...............  185 \n#&gt; Matched number of observations...............  370 \n#&gt; Matched number of observations  (unweighted).  370\n\n\n\nCode## Genetic Matching\nrr.gen &lt;- GenMatch(Tr = lalonde$treat, \n                   X = lalonde$lr_ps, \n                   BalanceMatrix = lalonde[,all.vars(lalonde_formu)[-1]],\n                   estimand = 'ATE', \n                   M = 1, \n                   pop.size = 16,\n                   print.level = 0)\nrr.gen.mout &lt;- Match(Y = lalonde$re78, \n                     Tr = lalonde$treat, \n                     X = lalonde$lr_ps,\n                     estimand = 'ATE',\n                     Weight.matrix = rr.gen)\nsummary(rr.gen.mout)\n#&gt; \n#&gt; Estimate...  2158.2 \n#&gt; AI SE......  814.93 \n#&gt; T-stat.....  2.6483 \n#&gt; p.val......  0.0080897 \n#&gt; \n#&gt; Original number of observations..............  445 \n#&gt; Original number of treated obs...............  185 \n#&gt; Matched number of observations...............  445 \n#&gt; Matched number of observations  (unweighted).  651\n\n\n\nCode## Partial exact matching\nrr2 &lt;- Matchby(Y = lalonde$re78, \n               Tr = lalonde$treat, \n               X = lalonde$lr_ps, \n               by = factor(lalonde$nodegr),\n               print.level = 0)\nsummary(rr2)\n#&gt; \n#&gt; Estimate...  2252.2 \n#&gt; SE.........  675.04 \n#&gt; T-stat.....  3.3363 \n#&gt; p.val......  0.00084896 \n#&gt; \n#&gt; Original number of observations..............  445 \n#&gt; Original number of treated obs...............  185 \n#&gt; Matched number of observations...............  185 \n#&gt; Matched number of observations  (unweighted).  185\n\n\n\nCode## Partial exact matching on two covariates\nrr3 &lt;- Matchby(Y = lalonde$re78, \n               Tr = lalonde$treat, \n               X = lalonde$lr_ps, \n               by = lalonde[,c('nodegr','married')],\n               print.level = 0)\nsummary(rr3)\n#&gt; \n#&gt; Estimate...  1668.8 \n#&gt; SE.........  715.87 \n#&gt; T-stat.....  2.3311 \n#&gt; p.val......  0.019747 \n#&gt; \n#&gt; Original number of observations..............  445 \n#&gt; Original number of treated obs...............  185 \n#&gt; Matched number of observations...............  185 \n#&gt; Matched number of observations  (unweighted).  185",
    "crumbs": [
      "倾向性评分",
      "<span class='chapter-number'>22</span>  <span class='chapter-title'>倾向性评分</span>"
    ]
  },
  {
    "objectID": "PropensityScore.html#倾向值匹配法的概述与应用-r实现",
    "href": "PropensityScore.html#倾向值匹配法的概述与应用-r实现",
    "title": "\n22  倾向性评分\n",
    "section": "\n22.3 倾向值匹配法的概述与应用 R实现",
    "text": "22.3 倾向值匹配法的概述与应用 R实现\n\nCodelibrary(Matching)\ndata(lalonde, package = 'Matching')\n\n\n\n\n变量名\n描述\n\n\n\nage\n年龄\n\n\neduc\n受教育年限\n\n\nblack\n分类变量，1为黑人\n\n\nhisp\n分类变量，1为西班牙裔\n\n\nmarried\n分类变量，1为已婚\n\n\nnodegr\n分类变量，1为有高中学历证书\n\n\nre74\n1974年的收入\n\n\nre75\n1975年的收入\n\n\nre78\n1978年的收入\n\n\nu74\n分类变量，1为1974年收入为零\n\n\nu75\n分类变量，1为1975年收入为零\n\n\ntreat\n分类变量，1为实验组\n\n\n\n\n22.3.1 估计倾向值分数\n\nCodeattach(lalonde)\nglm_ps &lt;- glm(\n    formula = treat ~ age + educ + black + hisp + married + nodegr + re74  + re75,\n    family = binomial(link = 'logit')\n)\n\npsm1 &lt;- Match(Y=re78,\n             Tr = treat,\n             X=glm_ps$fitted.values,\n             estimand = \"ATT\",\n             M=1,\n             replace = TRUE)\nsummary(psm1)\n#&gt; \n#&gt; Estimate...  2624.3 \n#&gt; AI SE......  802.19 \n#&gt; T-stat.....  3.2714 \n#&gt; p.val......  0.0010702 \n#&gt; \n#&gt; Original number of observations..............  445 \n#&gt; Original number of treated obs...............  185 \n#&gt; Matched number of observations...............  185 \n#&gt; Matched number of observations  (unweighted).  344\n\n\n如上所示，使用1对1样本可替代匹配法，实验组平均效应为2624.3，因果效应的标准误为803.19，t值为3.2714，p值为0.0010702&lt;0.05，表明估计的实验组平均处理效应有统计学差异。\n\nCodepsm2 &lt;- Match(Y=re78,\n             Tr = treat,\n             X=glm_ps$fitted.values,\n             estimand = \"ATT\",\n             M=1,\n             replace = FALSE)\nsummary(psm2)\n#&gt; \n#&gt; Estimate...  1912.9 \n#&gt; SE.........  644.47 \n#&gt; T-stat.....  2.9682 \n#&gt; p.val......  0.0029958 \n#&gt; \n#&gt; Original number of observations..............  445 \n#&gt; Original number of treated obs...............  185 \n#&gt; Matched number of observations...............  185 \n#&gt; Matched number of observations  (unweighted).  185\n\n\n\n22.3.2 检验\n受试者个体同质性，是否随机分配\n协变量分布是否平衡，是否重合：\n以age 为例，实验组匹配前25.816匹配后25.816，对照组匹配前25.054匹配后25.692 ，匹配后实验组与对照组更接近了；T-test p-value &gt; 0.05 ，表示匹配前后age 均值无统计学差异；KS Bootstrap p-value &gt; 0.05 ，表示匹配前后age 分布无统计学差异\n***** (V1) age *****                Before Matching          After Matching mean   treatment........          25.816             25.816  \nmean control..........     25.054            25.692 \nstd mean diff.........     10.655            1.7342 \n\nmean raw eQQ diff.....    0.94054           0.73837  \nmed  raw eQQ diff.....          1                 0  \nmax  raw eQQ diff.....          7                 9   \n\nmean eCDF diff........   0.025364          0.021893  \nmed  eCDF diff........   0.022193          0.020349  \nmax  eCDF diff........   0.065177          0.061047   \n\nvar ratio (Tr/Co).....     1.0278             1.083  \nT-test p-value........    0.26594           0.84975  \nKS Bootstrap p-value..      0.526             0.355  \nKS Naive p-value......     0.7481           0.54314  \nKS Statistic..........   0.065177          0.061047 \n\nCodecheck_balance &lt;- MatchBalance(\n    formul = treat ~ age + educ + black + hisp + married + nodegr + re74  + re75,\n    match.out = psm1,\n    nboots = 1000,data = lalonde\n)\n#&gt; \n#&gt; ***** (V1) age *****\n#&gt;                        Before Matching        After Matching\n#&gt; mean treatment........     25.816             25.816 \n#&gt; mean control..........     25.054             25.692 \n#&gt; std mean diff.........     10.655             1.7342 \n#&gt; \n#&gt; mean raw eQQ diff.....    0.94054            0.73837 \n#&gt; med  raw eQQ diff.....          1                  0 \n#&gt; max  raw eQQ diff.....          7                  9 \n#&gt; \n#&gt; mean eCDF diff........   0.025364           0.021893 \n#&gt; med  eCDF diff........   0.022193           0.020349 \n#&gt; max  eCDF diff........   0.065177           0.061047 \n#&gt; \n#&gt; var ratio (Tr/Co).....     1.0278              1.083 \n#&gt; T-test p-value........    0.26594            0.84975 \n#&gt; KS Bootstrap p-value..      0.528              0.354 \n#&gt; KS Naive p-value......     0.7481            0.54314 \n#&gt; KS Statistic..........   0.065177           0.061047 \n#&gt; \n#&gt; \n#&gt; ***** (V2) educ *****\n#&gt;                        Before Matching        After Matching\n#&gt; mean treatment........     10.346             10.346 \n#&gt; mean control..........     10.088             10.146 \n#&gt; std mean diff.........     12.806             9.9664 \n#&gt; \n#&gt; mean raw eQQ diff.....    0.40541            0.23256 \n#&gt; med  raw eQQ diff.....          0                  0 \n#&gt; max  raw eQQ diff.....          2                  2 \n#&gt; \n#&gt; mean eCDF diff........   0.028698           0.016611 \n#&gt; med  eCDF diff........   0.012682           0.010174 \n#&gt; max  eCDF diff........    0.12651           0.061047 \n#&gt; \n#&gt; var ratio (Tr/Co).....     1.5513             1.2344 \n#&gt; T-test p-value........    0.15017             0.1842 \n#&gt; KS Bootstrap p-value..      0.006              0.223 \n#&gt; KS Naive p-value......   0.062873            0.54314 \n#&gt; KS Statistic..........    0.12651           0.061047 \n#&gt; \n#&gt; \n#&gt; ***** (V3) black *****\n#&gt;                        Before Matching        After Matching\n#&gt; mean treatment........    0.84324            0.84324 \n#&gt; mean control..........    0.82692            0.86847 \n#&gt; std mean diff.........     4.4767            -6.9194 \n#&gt; \n#&gt; mean raw eQQ diff.....   0.016216           0.026163 \n#&gt; med  raw eQQ diff.....          0                  0 \n#&gt; max  raw eQQ diff.....          1                  1 \n#&gt; \n#&gt; mean eCDF diff........  0.0081601           0.013081 \n#&gt; med  eCDF diff........  0.0081601           0.013081 \n#&gt; max  eCDF diff........    0.01632           0.026163 \n#&gt; \n#&gt; var ratio (Tr/Co).....    0.92503             1.1572 \n#&gt; T-test p-value........    0.64736            0.40214 \n#&gt; \n#&gt; \n#&gt; ***** (V4) hisp *****\n#&gt;                        Before Matching        After Matching\n#&gt; mean treatment........   0.059459           0.059459 \n#&gt; mean control..........    0.10769            0.04955 \n#&gt; std mean diff.........    -20.341             4.1792 \n#&gt; \n#&gt; mean raw eQQ diff.....   0.048649           0.011628 \n#&gt; med  raw eQQ diff.....          0                  0 \n#&gt; max  raw eQQ diff.....          1                  1 \n#&gt; \n#&gt; mean eCDF diff........   0.024116           0.005814 \n#&gt; med  eCDF diff........   0.024116           0.005814 \n#&gt; max  eCDF diff........   0.048233           0.011628 \n#&gt; \n#&gt; var ratio (Tr/Co).....    0.58288             1.1875 \n#&gt; T-test p-value........   0.064043            0.46063 \n#&gt; \n#&gt; \n#&gt; ***** (V5) married *****\n#&gt;                        Before Matching        After Matching\n#&gt; mean treatment........    0.18919            0.18919 \n#&gt; mean control..........    0.15385            0.18423 \n#&gt; std mean diff.........     8.9995             1.2617 \n#&gt; \n#&gt; mean raw eQQ diff.....   0.037838           0.026163 \n#&gt; med  raw eQQ diff.....          0                  0 \n#&gt; max  raw eQQ diff.....          1                  1 \n#&gt; \n#&gt; mean eCDF diff........   0.017672           0.013081 \n#&gt; med  eCDF diff........   0.017672           0.013081 \n#&gt; max  eCDF diff........   0.035343           0.026163 \n#&gt; \n#&gt; var ratio (Tr/Co).....     1.1802             1.0207 \n#&gt; T-test p-value........    0.33425            0.89497 \n#&gt; \n#&gt; \n#&gt; ***** (V6) nodegr *****\n#&gt;                        Before Matching        After Matching\n#&gt; mean treatment........    0.70811            0.70811 \n#&gt; mean control..........    0.83462            0.76757 \n#&gt; std mean diff.........    -27.751            -13.043 \n#&gt; \n#&gt; mean raw eQQ diff.....    0.12432           0.043605 \n#&gt; med  raw eQQ diff.....          0                  0 \n#&gt; max  raw eQQ diff.....          1                  1 \n#&gt; \n#&gt; mean eCDF diff........   0.063254           0.021802 \n#&gt; med  eCDF diff........   0.063254           0.021802 \n#&gt; max  eCDF diff........    0.12651           0.043605 \n#&gt; \n#&gt; var ratio (Tr/Co).....     1.4998             1.1585 \n#&gt; T-test p-value........  0.0020368          0.0071385 \n#&gt; \n#&gt; \n#&gt; ***** (V7) re74 *****\n#&gt;                        Before Matching        After Matching\n#&gt; mean treatment........     2095.6             2095.6 \n#&gt; mean control..........       2107             2193.3 \n#&gt; std mean diff.........   -0.23437            -2.0004 \n#&gt; \n#&gt; mean raw eQQ diff.....     487.98             869.16 \n#&gt; med  raw eQQ diff.....          0                  0 \n#&gt; max  raw eQQ diff.....       8413              10305 \n#&gt; \n#&gt; mean eCDF diff........   0.019223           0.054701 \n#&gt; med  eCDF diff........     0.0158           0.050872 \n#&gt; max  eCDF diff........   0.047089            0.12209 \n#&gt; \n#&gt; var ratio (Tr/Co).....     0.7381            0.75054 \n#&gt; T-test p-value........    0.98186            0.84996 \n#&gt; KS Bootstrap p-value..      0.547              0.001 \n#&gt; KS Naive p-value......    0.97023           0.011858 \n#&gt; KS Statistic..........   0.047089            0.12209 \n#&gt; \n#&gt; \n#&gt; ***** (V8) re75 *****\n#&gt;                        Before Matching        After Matching\n#&gt; mean treatment........     1532.1             1532.1 \n#&gt; mean control..........     1266.9             2179.9 \n#&gt; std mean diff.........     8.2363            -20.125 \n#&gt; \n#&gt; mean raw eQQ diff.....     367.61             590.34 \n#&gt; med  raw eQQ diff.....          0                  0 \n#&gt; max  raw eQQ diff.....     2110.2             8092.9 \n#&gt; \n#&gt; mean eCDF diff........   0.050834           0.050338 \n#&gt; med  eCDF diff........   0.061954           0.049419 \n#&gt; max  eCDF diff........    0.10748           0.098837 \n#&gt; \n#&gt; var ratio (Tr/Co).....     1.0763            0.56563 \n#&gt; T-test p-value........    0.38527           0.079002 \n#&gt; KS Bootstrap p-value..      0.031              0.012 \n#&gt; KS Naive p-value......    0.16449           0.069435 \n#&gt; KS Statistic..........    0.10748           0.098837 \n#&gt; \n#&gt; \n#&gt; Before Matching Minimum p.value: 0.0020368 \n#&gt; Variable Name(s): nodegr  Number(s): 6 \n#&gt; \n#&gt; After Matching Minimum p.value: 0.001 \n#&gt; Variable Name(s): re74  Number(s): 7\n\n\n\nCode# age 变平衡了\nqqplot(lalonde$age[psm1$index.control],lalonde$age[psm1$index.treated])\nabline(a=0,b=1)\n\n\n\n\n\n\nCode\n# re74 更不平衡了\nqqplot(lalonde$re74[psm1$index.control],lalonde$re74[psm1$index.treated])\nabline(a=0,b=1)\n\n\n\n\n\n\n\n\nCode# # The covariates we want to match on\nx &lt;- cbind(age , educ , black , hisp , married , nodegr , re74  , re75)\n\n# The covariates we want to obtain balance on\nBalanceMatrix = x\nset.seed(100)\n\n\n\n# Genetic Matching 自动适配平衡\ngen_match &lt;- GenMatch(Tr=treat,\n                      X=glm_ps$fitted.values,\n                      BalanceMatrix = x,\n                      estimand = \"ATT\")\n#&gt; \n#&gt; \n#&gt; Thu Jul  4 18:04:49 2024\n#&gt; Domains:\n#&gt;  0.000000e+00   &lt;=  X1   &lt;=    1.000000e+03 \n#&gt; \n#&gt; Data Type: Floating Point\n#&gt; Operators (code number, name, population) \n#&gt;  (1) Cloning...........................  15\n#&gt;  (2) Uniform Mutation..................  12\n#&gt;  (3) Boundary Mutation.................  12\n#&gt;  (4) Non-Uniform Mutation..............  12\n#&gt;  (5) Polytope Crossover................  12\n#&gt;  (6) Simple Crossover..................  12\n#&gt;  (7) Whole Non-Uniform Mutation........  12\n#&gt;  (8) Heuristic Crossover...............  12\n#&gt;  (9) Local-Minimum Crossover...........  0\n#&gt; \n#&gt; SOFT Maximum Number of Generations: 100\n#&gt; Maximum Nonchanging Generations: 4\n#&gt; Population size       : 100\n#&gt; Convergence Tolerance: 1.000000e-03\n#&gt; \n#&gt; Not Using the BFGS Derivative Based Optimizer on the Best Individual Each Generation.\n#&gt; Not Checking Gradients before Stopping.\n#&gt; Using Out of Bounds Individuals.\n#&gt; \n#&gt; Maximization Problem.\n#&gt; GENERATION: 0 (initializing the population)\n#&gt; Lexical Fit..... 1.180299e-02  1.180299e-02  1.155612e-01  1.186261e-01  1.822343e-01  3.842491e-01  3.842491e-01  4.144313e-01  4.144313e-01  4.610718e-01  5.977650e-01  7.731052e-01  7.731052e-01  8.523060e-01  9.184104e-01  9.749549e-01  \n#&gt; #unique......... 100, #Total UniqueCount: 100\n#&gt; var 1:\n#&gt; best............ 3.729259e+01\n#&gt; mean............ 4.810920e+02\n#&gt; variance........ 7.636997e+04\n#&gt; \n#&gt; GENERATION: 1\n#&gt; Lexical Fit..... 1.180299e-02  1.180299e-02  1.155612e-01  1.186261e-01  1.822343e-01  3.842491e-01  3.842491e-01  4.144313e-01  4.144313e-01  4.610718e-01  5.977650e-01  7.731052e-01  7.731052e-01  8.523060e-01  9.184104e-01  9.749549e-01  \n#&gt; #unique......... 61, #Total UniqueCount: 161\n#&gt; var 1:\n#&gt; best............ 3.729259e+01\n#&gt; mean............ 2.015230e+02\n#&gt; variance........ 6.039634e+04\n#&gt; \n#&gt; GENERATION: 2\n#&gt; Lexical Fit..... 1.180299e-02  1.180299e-02  1.155612e-01  1.186261e-01  1.822343e-01  3.842491e-01  3.842491e-01  4.144313e-01  4.144313e-01  4.610718e-01  5.977650e-01  7.731052e-01  7.731052e-01  8.523060e-01  9.184104e-01  9.749549e-01  \n#&gt; #unique......... 56, #Total UniqueCount: 217\n#&gt; var 1:\n#&gt; best............ 3.729259e+01\n#&gt; mean............ 9.873041e+01\n#&gt; variance........ 3.291501e+04\n#&gt; \n#&gt; GENERATION: 3\n#&gt; Lexical Fit..... 1.180299e-02  1.180299e-02  1.155612e-01  1.186261e-01  1.822343e-01  3.842491e-01  3.842491e-01  4.144313e-01  4.144313e-01  4.610718e-01  5.977650e-01  7.731052e-01  7.731052e-01  8.523060e-01  9.184104e-01  9.749549e-01  \n#&gt; #unique......... 56, #Total UniqueCount: 273\n#&gt; var 1:\n#&gt; best............ 3.729259e+01\n#&gt; mean............ 1.042351e+02\n#&gt; variance........ 2.899583e+04\n#&gt; \n#&gt; GENERATION: 4\n#&gt; Lexical Fit..... 1.180299e-02  1.180299e-02  1.155612e-01  1.186261e-01  1.822343e-01  3.842491e-01  3.842491e-01  4.144313e-01  4.144313e-01  4.610718e-01  5.977650e-01  7.731052e-01  7.731052e-01  8.523060e-01  9.184104e-01  9.749549e-01  \n#&gt; #unique......... 58, #Total UniqueCount: 331\n#&gt; var 1:\n#&gt; best............ 3.729259e+01\n#&gt; mean............ 1.050645e+02\n#&gt; variance........ 2.721152e+04\n#&gt; \n#&gt; GENERATION: 5\n#&gt; Lexical Fit..... 1.541148e-02  2.397991e-02  2.418950e-02  2.418950e-02  1.729273e-01  1.956942e-01  3.942807e-01  3.942807e-01  6.059370e-01  6.059370e-01  6.074259e-01  6.137460e-01  8.414918e-01  8.538318e-01  9.621995e-01  9.621995e-01  \n#&gt; #unique......... 58, #Total UniqueCount: 389\n#&gt; var 1:\n#&gt; best............ 2.941808e-01\n#&gt; mean............ 8.418536e+01\n#&gt; variance........ 1.578216e+04\n#&gt; \n#&gt; GENERATION: 6\n#&gt; Lexical Fit..... 4.145421e-02  4.145421e-02  4.499068e-02  4.499068e-02  1.608408e-01  1.806532e-01  2.764640e-01  4.729068e-01  4.729068e-01  6.940013e-01  6.940013e-01  7.762162e-01  8.635587e-01  8.667712e-01  8.667712e-01  9.507460e-01  \n#&gt; #unique......... 62, #Total UniqueCount: 451\n#&gt; var 1:\n#&gt; best............ 7.310932e-02\n#&gt; mean............ 9.403781e+01\n#&gt; variance........ 2.447312e+04\n#&gt; \n#&gt; GENERATION: 7\n#&gt; Lexical Fit..... 4.177047e-02  4.177047e-02  4.419097e-02  6.248288e-02  1.198352e-01  2.880778e-01  3.513309e-01  4.150287e-01  4.150287e-01  8.316757e-01  8.316757e-01  8.667712e-01  8.667712e-01  8.836843e-01  8.920699e-01  8.920699e-01  \n#&gt; #unique......... 61, #Total UniqueCount: 512\n#&gt; var 1:\n#&gt; best............ 8.760968e-02\n#&gt; mean............ 1.016562e+02\n#&gt; variance........ 4.437002e+04\n#&gt; \n#&gt; GENERATION: 8\n#&gt; Lexical Fit..... 4.177047e-02  4.177047e-02  4.559074e-02  6.427954e-02  1.215371e-01  2.846955e-01  3.519026e-01  4.150287e-01  4.150287e-01  8.316757e-01  8.316757e-01  8.667712e-01  8.667712e-01  8.794500e-01  8.948772e-01  8.948772e-01  \n#&gt; #unique......... 60, #Total UniqueCount: 572\n#&gt; var 1:\n#&gt; best............ 8.627748e-02\n#&gt; mean............ 7.473970e+01\n#&gt; variance........ 2.676016e+04\n#&gt; \n#&gt; GENERATION: 9\n#&gt; Lexical Fit..... 4.177047e-02  4.177047e-02  4.559074e-02  6.427954e-02  1.215371e-01  2.846955e-01  3.519026e-01  4.150287e-01  4.150287e-01  8.316757e-01  8.316757e-01  8.667712e-01  8.667712e-01  8.794500e-01  8.948772e-01  8.948772e-01  \n#&gt; #unique......... 55, #Total UniqueCount: 627\n#&gt; var 1:\n#&gt; best............ 8.627748e-02\n#&gt; mean............ 4.192386e+01\n#&gt; variance........ 1.737331e+04\n#&gt; \n#&gt; GENERATION: 10\n#&gt; Lexical Fit..... 4.177047e-02  4.177047e-02  4.559074e-02  6.427954e-02  1.215371e-01  2.846955e-01  3.519026e-01  4.150287e-01  4.150287e-01  8.316757e-01  8.316757e-01  8.667712e-01  8.667712e-01  8.794500e-01  8.948772e-01  8.948772e-01  \n#&gt; #unique......... 51, #Total UniqueCount: 678\n#&gt; var 1:\n#&gt; best............ 8.627748e-02\n#&gt; mean............ 6.242257e+01\n#&gt; variance........ 2.722981e+04\n#&gt; \n#&gt; GENERATION: 11\n#&gt; Lexical Fit..... 4.177047e-02  4.177047e-02  4.559074e-02  6.427954e-02  1.215371e-01  2.846955e-01  3.519026e-01  4.150287e-01  4.150287e-01  8.316757e-01  8.316757e-01  8.667712e-01  8.667712e-01  8.794500e-01  8.948772e-01  8.948772e-01  \n#&gt; #unique......... 49, #Total UniqueCount: 727\n#&gt; var 1:\n#&gt; best............ 8.627748e-02\n#&gt; mean............ 5.280735e+01\n#&gt; variance........ 1.784927e+04\n#&gt; \n#&gt; GENERATION: 12\n#&gt; Lexical Fit..... 4.177047e-02  4.177047e-02  4.559074e-02  6.427954e-02  1.215371e-01  2.846955e-01  3.519026e-01  4.150287e-01  4.150287e-01  8.316757e-01  8.316757e-01  8.667712e-01  8.667712e-01  8.794500e-01  8.948772e-01  8.948772e-01  \n#&gt; #unique......... 50, #Total UniqueCount: 777\n#&gt; var 1:\n#&gt; best............ 8.627748e-02\n#&gt; mean............ 5.682777e+01\n#&gt; variance........ 2.131922e+04\n#&gt; \n#&gt; GENERATION: 13\n#&gt; Lexical Fit..... 4.177047e-02  4.177047e-02  4.559074e-02  6.427954e-02  1.215371e-01  2.846955e-01  3.519026e-01  4.150287e-01  4.150287e-01  8.316757e-01  8.316757e-01  8.667712e-01  8.667712e-01  8.794500e-01  8.948772e-01  8.948772e-01  \n#&gt; #unique......... 53, #Total UniqueCount: 830\n#&gt; var 1:\n#&gt; best............ 8.627748e-02\n#&gt; mean............ 3.877940e+01\n#&gt; variance........ 1.599211e+04\n#&gt; \n#&gt; 'wait.generations' limit reached.\n#&gt; No significant improvement in 4 generations.\n#&gt; \n#&gt; Solution Lexical Fitness Value:\n#&gt; 4.177047e-02  4.177047e-02  4.559074e-02  6.427954e-02  1.215371e-01  2.846955e-01  3.519026e-01  4.150287e-01  4.150287e-01  8.316757e-01  8.316757e-01  8.667712e-01  8.667712e-01  8.794500e-01  8.948772e-01  8.948772e-01  \n#&gt; \n#&gt; Parameters at the Solution:\n#&gt; \n#&gt;  X[ 1] : 8.627748e-02\n#&gt; \n#&gt; Solution Found Generation 8\n#&gt; Number of Generations Run 13\n#&gt; \n#&gt; Thu Jul  4 18:04:55 2024\n#&gt; Total run time : 0 hours 0 minutes and 6 seconds\n\nPSM &lt;-  Match(Y=re78,\n             Tr = treat,\n             X=glm_ps$fitted.values,\n             estimand = \"ATT\",\n             Weight.matrix = gen_match,\n             replace = TRUE,)\nsummary(PSM)\n#&gt; \n#&gt; Estimate...  2439.3 \n#&gt; AI SE......  813.4 \n#&gt; T-stat.....  2.9989 \n#&gt; p.val......  0.0027099 \n#&gt; \n#&gt; Original number of observations..............  445 \n#&gt; Original number of treated obs...............  185 \n#&gt; Matched number of observations...............  185 \n#&gt; Matched number of observations  (unweighted).  489\n\ncheck_balance2 &lt;- MatchBalance(\n    formul = treat ~ age + educ + black + hisp + married + nodegr + re74  + re75,\n    match.out = PSM,\n    nboots = 1000,data = lalonde\n)\n#&gt; \n#&gt; ***** (V1) age *****\n#&gt;                        Before Matching        After Matching\n#&gt; mean treatment........     25.816             25.816 \n#&gt; mean control..........     25.054             25.217 \n#&gt; std mean diff.........     10.655             8.3769 \n#&gt; \n#&gt; mean raw eQQ diff.....    0.94054            0.46217 \n#&gt; med  raw eQQ diff.....          1                  0 \n#&gt; max  raw eQQ diff.....          7                  9 \n#&gt; \n#&gt; mean eCDF diff........   0.025364           0.012952 \n#&gt; med  eCDF diff........   0.022193           0.010225 \n#&gt; max  eCDF diff........   0.065177            0.03681 \n#&gt; \n#&gt; var ratio (Tr/Co).....     1.0278             1.2224 \n#&gt; T-test p-value........    0.26594             0.3519 \n#&gt; KS Bootstrap p-value..      0.503              0.734 \n#&gt; KS Naive p-value......     0.7481            0.89488 \n#&gt; KS Statistic..........   0.065177            0.03681 \n#&gt; \n#&gt; \n#&gt; ***** (V2) educ *****\n#&gt;                        Before Matching        After Matching\n#&gt; mean treatment........     10.346             10.346 \n#&gt; mean control..........     10.088             10.188 \n#&gt; std mean diff.........     12.806             7.8605 \n#&gt; \n#&gt; mean raw eQQ diff.....    0.40541            0.17587 \n#&gt; med  raw eQQ diff.....          0                  0 \n#&gt; max  raw eQQ diff.....          2                  2 \n#&gt; \n#&gt; mean eCDF diff........   0.028698           0.012562 \n#&gt; med  eCDF diff........   0.012682           0.010225 \n#&gt; max  eCDF diff........    0.12651            0.03681 \n#&gt; \n#&gt; var ratio (Tr/Co).....     1.5513             1.2791 \n#&gt; T-test p-value........    0.15017             0.2847 \n#&gt; KS Bootstrap p-value..      0.011              0.456 \n#&gt; KS Naive p-value......   0.062873            0.89488 \n#&gt; KS Statistic..........    0.12651            0.03681 \n#&gt; \n#&gt; \n#&gt; ***** (V3) black *****\n#&gt;                        Before Matching        After Matching\n#&gt; mean treatment........    0.84324            0.84324 \n#&gt; mean control..........    0.82692              0.868 \n#&gt; std mean diff.........     4.4767            -6.7917 \n#&gt; \n#&gt; mean raw eQQ diff.....   0.016216           0.034765 \n#&gt; med  raw eQQ diff.....          0                  0 \n#&gt; max  raw eQQ diff.....          1                  1 \n#&gt; \n#&gt; mean eCDF diff........  0.0081601           0.017382 \n#&gt; med  eCDF diff........  0.0081601           0.017382 \n#&gt; max  eCDF diff........    0.01632           0.034765 \n#&gt; \n#&gt; var ratio (Tr/Co).....    0.92503             1.1537 \n#&gt; T-test p-value........    0.64736            0.41503 \n#&gt; \n#&gt; \n#&gt; ***** (V4) hisp *****\n#&gt;                        Before Matching        After Matching\n#&gt; mean treatment........   0.059459           0.059459 \n#&gt; mean control..........    0.10769           0.057132 \n#&gt; std mean diff.........    -20.341            0.98148 \n#&gt; \n#&gt; mean raw eQQ diff.....   0.048649            0.00818 \n#&gt; med  raw eQQ diff.....          0                  0 \n#&gt; max  raw eQQ diff.....          1                  1 \n#&gt; \n#&gt; mean eCDF diff........   0.024116            0.00409 \n#&gt; med  eCDF diff........   0.024116            0.00409 \n#&gt; max  eCDF diff........   0.048233            0.00818 \n#&gt; \n#&gt; var ratio (Tr/Co).....    0.58288             1.0382 \n#&gt; T-test p-value........   0.064043            0.86677 \n#&gt; \n#&gt; \n#&gt; ***** (V5) married *****\n#&gt;                        Before Matching        After Matching\n#&gt; mean treatment........    0.18919            0.18919 \n#&gt; mean control..........    0.15385            0.18101 \n#&gt; std mean diff.........     8.9995             2.0837 \n#&gt; \n#&gt; mean raw eQQ diff.....   0.037838           0.018405 \n#&gt; med  raw eQQ diff.....          0                  0 \n#&gt; max  raw eQQ diff.....          1                  1 \n#&gt; \n#&gt; mean eCDF diff........   0.017672          0.0092025 \n#&gt; med  eCDF diff........   0.017672          0.0092025 \n#&gt; max  eCDF diff........   0.035343           0.018405 \n#&gt; \n#&gt; var ratio (Tr/Co).....     1.1802             1.0348 \n#&gt; T-test p-value........    0.33425            0.83168 \n#&gt; \n#&gt; \n#&gt; ***** (V6) nodegr *****\n#&gt;                        Before Matching        After Matching\n#&gt; mean treatment........    0.70811            0.70811 \n#&gt; mean control..........    0.83462            0.75333 \n#&gt; std mean diff.........    -27.751            -9.9207 \n#&gt; \n#&gt; mean raw eQQ diff.....    0.12432           0.034765 \n#&gt; med  raw eQQ diff.....          0                  0 \n#&gt; max  raw eQQ diff.....          1                  1 \n#&gt; \n#&gt; mean eCDF diff........   0.063254           0.017382 \n#&gt; med  eCDF diff........   0.063254           0.017382 \n#&gt; max  eCDF diff........    0.12651           0.034765 \n#&gt; \n#&gt; var ratio (Tr/Co).....     1.4998             1.1123 \n#&gt; T-test p-value........  0.0020368            0.04177 \n#&gt; \n#&gt; \n#&gt; ***** (V7) re74 *****\n#&gt;                        Before Matching        After Matching\n#&gt; mean treatment........     2095.6             2095.6 \n#&gt; mean control..........       2107             2018.1 \n#&gt; std mean diff.........   -0.23437             1.5857 \n#&gt; \n#&gt; mean raw eQQ diff.....     487.98             648.91 \n#&gt; med  raw eQQ diff.....          0                  0 \n#&gt; max  raw eQQ diff.....       8413              10305 \n#&gt; \n#&gt; mean eCDF diff........   0.019223           0.037077 \n#&gt; med  eCDF diff........     0.0158           0.033742 \n#&gt; max  eCDF diff........   0.047089           0.087935 \n#&gt; \n#&gt; var ratio (Tr/Co).....     0.7381            0.86668 \n#&gt; T-test p-value........    0.98186            0.87945 \n#&gt; KS Bootstrap p-value..      0.555              0.002 \n#&gt; KS Naive p-value......    0.97023           0.045591 \n#&gt; KS Statistic..........   0.047089           0.087935 \n#&gt; \n#&gt; \n#&gt; ***** (V8) re75 *****\n#&gt;                        Before Matching        After Matching\n#&gt; mean treatment........     1532.1             1532.1 \n#&gt; mean control..........     1266.9             2079.5 \n#&gt; std mean diff.........     8.2363            -17.005 \n#&gt; \n#&gt; mean raw eQQ diff.....     367.61             532.46 \n#&gt; med  raw eQQ diff.....          0                  0 \n#&gt; max  raw eQQ diff.....     2110.2             8092.9 \n#&gt; \n#&gt; mean eCDF diff........   0.050834           0.040137 \n#&gt; med  eCDF diff........   0.061954             0.0409 \n#&gt; max  eCDF diff........    0.10748           0.083845 \n#&gt; \n#&gt; var ratio (Tr/Co).....     1.0763            0.64518 \n#&gt; T-test p-value........    0.38527            0.12154 \n#&gt; KS Bootstrap p-value..      0.038               0.02 \n#&gt; KS Naive p-value......    0.16449            0.06428 \n#&gt; KS Statistic..........    0.10748           0.083845 \n#&gt; \n#&gt; \n#&gt; Before Matching Minimum p.value: 0.0020368 \n#&gt; Variable Name(s): nodegr  Number(s): 6 \n#&gt; \n#&gt; After Matching Minimum p.value: 0.002 \n#&gt; Variable Name(s): re74  Number(s): 7\n\n# age 变平衡了\nqqplot(lalonde$age[PSM$index.control],lalonde$age[PSM$index.treated])\nabline(a=0,b=1)\n\n\n\n\n\n\nCode\n# re74 也变平衡了\nqqplot(lalonde$re74[PSM$index.control],lalonde$re74[PSM$index.treated])\nabline(a=0,b=1)\n\n\n\n\n\n\n\n敏感性分析\n\nCodelibrary(rbounds)\npsens(x =lalonde[PSM$index.treated,\"re78\"],\n      y =lalonde[PSM$index.control,\"re78\"] ,Gamma = 2,GammaInc = 0.1)\n#&gt; \n#&gt;  Rosenbaum Sensitivity Test for Wilcoxon Signed Rank P-Value \n#&gt;  \n#&gt; Unconfounded estimate ....  1e-04 \n#&gt; \n#&gt;  Gamma Lower bound Upper bound\n#&gt;    1.0       1e-04      0.0001\n#&gt;    1.1       0e+00      0.0015\n#&gt;    1.2       0e+00      0.0142\n#&gt;    1.3       0e+00      0.0693\n#&gt;    1.4       0e+00      0.2048\n#&gt;    1.5       0e+00      0.4152\n#&gt;    1.6       0e+00      0.6393\n#&gt;    1.7       0e+00      0.8140\n#&gt;    1.8       0e+00      0.9191\n#&gt;    1.9       0e+00      0.9699\n#&gt;    2.0       0e+00      0.9903\n#&gt; \n#&gt;  Note: Gamma is Odds of Differential Assignment To\n#&gt;  Treatment Due to Unobserved Factors \n#&gt; \npsens\n#&gt; function (x, y, Gamma = 6, GammaInc = 1) \n#&gt; {\n#&gt;     trt &lt;- x\n#&gt;     ctrl &lt;- y\n#&gt;     gamma &lt;- seq(1, Gamma, by = GammaInc)\n#&gt;     m &lt;- length(gamma)\n#&gt;     pvals &lt;- matrix(NA, m, 2)\n#&gt;     diff &lt;- trt - ctrl\n#&gt;     S &lt;- length(diff)\n#&gt;     diff &lt;- diff[diff != 0]\n#&gt;     ranks &lt;- rank(abs(diff), ties.method = \"average\")\n#&gt;     psi &lt;- as.numeric(diff &gt; 0)\n#&gt;     T &lt;- sum(psi * ranks)\n#&gt;     for (i in 1:m) {\n#&gt;         p.plus &lt;- gamma[i]/(1 + gamma[i])\n#&gt;         p.minus &lt;- 1/(1 + gamma[i])\n#&gt;         E.T.plus &lt;- sum(ranks * p.plus)\n#&gt;         V.T &lt;- sum(ranks^2 * p.plus * (1 - p.plus))\n#&gt;         E.T.minus &lt;- sum(ranks * p.minus)\n#&gt;         z.plus &lt;- (T - E.T.plus)/sqrt(V.T)\n#&gt;         z.minus &lt;- (T - E.T.minus)/sqrt(V.T)\n#&gt;         p.val.up &lt;- 1 - pnorm(z.plus)\n#&gt;         p.val.low &lt;- 1 - pnorm(z.minus)\n#&gt;         pvals[i, 1] &lt;- round(p.val.low, digits = 4)\n#&gt;         pvals[i, 2] &lt;- round(p.val.up, digits = 4)\n#&gt;     }\n#&gt;     pval &lt;- pvals[1, 1]\n#&gt;     bounds &lt;- data.frame(gamma, pvals)\n#&gt;     names(bounds) &lt;- c(\"Gamma\", \"Lower bound\", \"Upper bound\")\n#&gt;     msg &lt;- \"Rosenbaum Sensitivity Test for Wilcoxon Signed Rank P-Value \\n\"\n#&gt;     note &lt;- \"Note: Gamma is Odds of Differential Assignment To\\n Treatment Due to Unobserved Factors \\n\"\n#&gt;     Obj &lt;- list(Gamma = Gamma, GammaInc = GammaInc, pval = pval, \n#&gt;         msg = msg, bounds = bounds, note = note)\n#&gt;     class(Obj) &lt;- c(\"rbounds\", class(Obj))\n#&gt;     Obj\n#&gt; }\n#&gt; &lt;bytecode: 0x0000021cdb998080&gt;\n#&gt; &lt;environment: namespace:rbounds&gt;\n\n\n对PSM（Y=re78）使用psens()进行Wilcoxon 符合秩检验，当τ=1.3，p值就大于0.05了，说明处理发生比为1.3时，就可以改变原先对于处理效应的结论，也就是说，这个隐藏性偏差不必太大就可以改变原来的结论，因此分析结果对隐藏性排除的影响非常敏感，结论不可靠。\n对 PSM（Y=re78）使用Hodges-Lehmann点估计检验法 hlsens() ，当τ=1.5，其95%置信区间包含零，说明此时处理效应是无效的。说明处理发生比为1.5时，隐藏性偏差就可以改变原来的结论，因此匹配后的结论不可靠。\n\nCodex = lalonde[PSM$index.treated, \"re78\"]\ny = lalonde[PSM$index.control, \"re78\"]\nhlsens(x, y,Gamma = 2,GammaInc = 0.1)\n#&gt; \n#&gt;  Rosenbaum Sensitivity Test for Hodges-Lehmann Point Estimate \n#&gt;  \n#&gt; Unconfounded estimate ....  1527.95 \n#&gt; \n#&gt;  Gamma Lower bound Upper bound\n#&gt;    1.0 1527.900000      1527.9\n#&gt;    1.1  917.250000      1580.2\n#&gt;    1.2  608.050000      1918.7\n#&gt;    1.3  338.450000      2141.0\n#&gt;    1.4  114.850000      2407.3\n#&gt;    1.5   -0.050046      2631.4\n#&gt;    1.6 -154.050000      2850.3\n#&gt;    1.7 -378.150000      3072.7\n#&gt;    1.8 -545.350000      3258.1\n#&gt;    1.9 -706.350000      3474.2\n#&gt;    2.0 -867.650000      3678.9\n#&gt; \n#&gt;  Note: Gamma is Odds of Differential Assignment To\n#&gt;  Treatment Due to Unobserved Factors \n#&gt; \n\n\n共同支持域的查验\n\nCodesum(glm_ps$fitted.values[lalonde$treat==1]&gt; \n        max(glm_ps$fitted.values[lalonde$treat==0]))\n#&gt; [1] 4\n\nsum(glm_ps$fitted.values[lalonde$treat==1]&lt; \n        min(glm_ps$fitted.values[lalonde$treat==0]))\n#&gt; [1] 0\n\n\n丢弃的实验组样本共有4个。185-181\n\nCodeattach(lalonde)\nsummary(PSM)\n#&gt; \n#&gt; Estimate...  2439.3 \n#&gt; AI SE......  813.4 \n#&gt; T-stat.....  2.9989 \n#&gt; p.val......  0.0027099 \n#&gt; \n#&gt; Original number of observations..............  445 \n#&gt; Original number of treated obs...............  185 \n#&gt; Matched number of observations...............  185 \n#&gt; Matched number of observations  (unweighted).  489\nPSM_CS &lt;-  Match(Y=re78,\n             Tr = treat,\n             X=glm_ps$fitted.values,\n             estimand = \"ATT\",\n             Weight.matrix = gen_match,\n             replace = TRUE,\n             CommonSupport = TRUE)\nsummary(PSM_CS)\n#&gt; \n#&gt; Estimate...  2330 \n#&gt; AI SE......  821.6 \n#&gt; T-stat.....  2.836 \n#&gt; p.val......  0.0045684 \n#&gt; \n#&gt; Original number of observations..............  430 \n#&gt; Original number of treated obs...............  181 \n#&gt; Matched number of observations...............  181 \n#&gt; Matched number of observations  (unweighted).  468\ndetach(lalonde)\n\n\n有查验共同支持域的ATT（2330），与无查验共同支持域（2439.3）存在差异，因此必须重新改进倾向值分析。\n\n22.3.3 MatchIt\n\n22.3.3.1 匹配数据\n\nCodelibrary(MatchIt)\nNM &lt;- MatchIt::matchit(\n    formula = treat ~ age + educ + black + hisp + married + nodegr + re74  + re75,\n    data = lalonde,\n    method = \"nearest\", # 最近邻匹配\n    ratio = 1, # 1:1\n    replace = FALSE\n)\nsummary(NM)\n#&gt; \n#&gt; Call:\n#&gt; MatchIt::matchit(formula = treat ~ age + educ + black + hisp + \n#&gt;     married + nodegr + re74 + re75, data = lalonde, method = \"nearest\", \n#&gt;     replace = FALSE, ratio = 1)\n#&gt; \n#&gt; Summary of Balance for All Data:\n#&gt;          Means Treated Means Control Std. Mean Diff. Var. Ratio eCDF Mean\n#&gt; distance        0.4377        0.4001          0.3935     1.0471    0.1117\n#&gt; age            25.8162       25.0538          0.1066     1.0278    0.0254\n#&gt; educ           10.3459       10.0885          0.1281     1.5513    0.0287\n#&gt; black           0.8432        0.8269          0.0449          .    0.0163\n#&gt; hisp            0.0595        0.1077         -0.2040          .    0.0482\n#&gt; married         0.1892        0.1538          0.0902          .    0.0353\n#&gt; nodegr          0.7081        0.8346         -0.2783          .    0.1265\n#&gt; re74         2095.5740     2107.0268         -0.0023     0.7381    0.0192\n#&gt; re75         1532.0556     1266.9092          0.0824     1.0763    0.0508\n#&gt;          eCDF Max\n#&gt; distance   0.2140\n#&gt; age        0.0652\n#&gt; educ       0.1265\n#&gt; black      0.0163\n#&gt; hisp       0.0482\n#&gt; married    0.0353\n#&gt; nodegr     0.1265\n#&gt; re74       0.0471\n#&gt; re75       0.1075\n#&gt; \n#&gt; Summary of Balance for Matched Data:\n#&gt;          Means Treated Means Control Std. Mean Diff. Var. Ratio eCDF Mean\n#&gt; distance        0.4377        0.4267          0.1152     1.0987    0.0298\n#&gt; age            25.8162       25.8757         -0.0083     0.9551    0.0121\n#&gt; educ           10.3459       10.1459          0.0995     1.3748    0.0220\n#&gt; black           0.8432        0.8486         -0.0149          .    0.0054\n#&gt; hisp            0.0595        0.0649         -0.0229          .    0.0054\n#&gt; married         0.1892        0.2000         -0.0276          .    0.0108\n#&gt; nodegr          0.7081        0.7730         -0.1427          .    0.0649\n#&gt; re74         2095.5740     1659.5326          0.0892     1.1752    0.0351\n#&gt; re75         1532.0556     1359.6980          0.0535     0.9270    0.0502\n#&gt;          eCDF Max Std. Pair Dist.\n#&gt; distance   0.1027          0.1302\n#&gt; age        0.0432          0.8711\n#&gt; educ       0.0757          0.6533\n#&gt; black      0.0054          0.4906\n#&gt; hisp       0.0054          0.2057\n#&gt; married    0.0108          0.7177\n#&gt; nodegr     0.0649          0.2378\n#&gt; re74       0.0865          0.6297\n#&gt; re75       0.1081          0.7019\n#&gt; \n#&gt; Sample Sizes:\n#&gt;           Control Treated\n#&gt; All           260     185\n#&gt; Matched       185     185\n#&gt; Unmatched      75       0\n#&gt; Discarded       0       0\n\n\n\n22.3.3.2 评估质量\n\nCode# 散点图展示了匹配后实验组和对照组样本倾向值的分布，凸显了分布平衡与不平衡，分布缺乏重合\nplot(NM,type = \"jitter\")\n\n\n\n\n\n\n#&gt; To identify the units, use first mouse button; to stop, use second.\n\n\nCode# QQ图 展示了 匹配前（All）匹配后（Matched）的平衡情况\nplot(NM,type = \"QQ\")\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCode\n# 直方图展示了匹配前后倾向值的分布\nplot(NM,type = \"hist\")\n\n\n\n\n\n\n\n\nCode# 标准化平衡统计值，Std. Mean Diff.\nsummary(NM,standardize = TRUE)\n#&gt; \n#&gt; Call:\n#&gt; MatchIt::matchit(formula = treat ~ age + educ + black + hisp + \n#&gt;     married + nodegr + re74 + re75, data = lalonde, method = \"nearest\", \n#&gt;     replace = FALSE, ratio = 1)\n#&gt; \n#&gt; Summary of Balance for All Data:\n#&gt;          Means Treated Means Control Std. Mean Diff. Var. Ratio eCDF Mean\n#&gt; distance        0.4377        0.4001          0.3935     1.0471    0.1117\n#&gt; age            25.8162       25.0538          0.1066     1.0278    0.0254\n#&gt; educ           10.3459       10.0885          0.1281     1.5513    0.0287\n#&gt; black           0.8432        0.8269          0.0449          .    0.0163\n#&gt; hisp            0.0595        0.1077         -0.2040          .    0.0482\n#&gt; married         0.1892        0.1538          0.0902          .    0.0353\n#&gt; nodegr          0.7081        0.8346         -0.2783          .    0.1265\n#&gt; re74         2095.5740     2107.0268         -0.0023     0.7381    0.0192\n#&gt; re75         1532.0556     1266.9092          0.0824     1.0763    0.0508\n#&gt;          eCDF Max\n#&gt; distance   0.2140\n#&gt; age        0.0652\n#&gt; educ       0.1265\n#&gt; black      0.0163\n#&gt; hisp       0.0482\n#&gt; married    0.0353\n#&gt; nodegr     0.1265\n#&gt; re74       0.0471\n#&gt; re75       0.1075\n#&gt; \n#&gt; Summary of Balance for Matched Data:\n#&gt;          Means Treated Means Control Std. Mean Diff. Var. Ratio eCDF Mean\n#&gt; distance        0.4377        0.4267          0.1152     1.0987    0.0298\n#&gt; age            25.8162       25.8757         -0.0083     0.9551    0.0121\n#&gt; educ           10.3459       10.1459          0.0995     1.3748    0.0220\n#&gt; black           0.8432        0.8486         -0.0149          .    0.0054\n#&gt; hisp            0.0595        0.0649         -0.0229          .    0.0054\n#&gt; married         0.1892        0.2000         -0.0276          .    0.0108\n#&gt; nodegr          0.7081        0.7730         -0.1427          .    0.0649\n#&gt; re74         2095.5740     1659.5326          0.0892     1.1752    0.0351\n#&gt; re75         1532.0556     1359.6980          0.0535     0.9270    0.0502\n#&gt;          eCDF Max Std. Pair Dist.\n#&gt; distance   0.1027          0.1302\n#&gt; age        0.0432          0.8711\n#&gt; educ       0.0757          0.6533\n#&gt; black      0.0054          0.4906\n#&gt; hisp       0.0054          0.2057\n#&gt; married    0.0108          0.7177\n#&gt; nodegr     0.0649          0.2378\n#&gt; re74       0.0865          0.6297\n#&gt; re75       0.1081          0.7019\n#&gt; \n#&gt; Sample Sizes:\n#&gt;           Control Treated\n#&gt; All           260     185\n#&gt; Matched       185     185\n#&gt; Unmatched      75       0\n#&gt; Discarded       0       0\n\n\n继续改进，调整模型和协变量\n\n22.3.3.3 计算平均处理效应\n为了简化步骤，以当前的结果进行匹配后分析。\n\nCode\n# 提取匹配后的样本\nmData &lt;- match.data(NM,group = \"all\")\nmData_trt &lt;- match.data(NM,group = \"treat\")\nmData_ctrl &lt;- match.data(NM,group = \"control\")\n \n# 包从CRAN剔除了\n\n\n\nCodelibrary(rbounds)\npsens(x =mData_trt$re78,\n      y =mData_ctrl$re78 ,Gamma = 2,GammaInc = 0.1)\n#&gt; \n#&gt;  Rosenbaum Sensitivity Test for Wilcoxon Signed Rank P-Value \n#&gt;  \n#&gt; Unconfounded estimate ....  0.0199 \n#&gt; \n#&gt;  Gamma Lower bound Upper bound\n#&gt;    1.0      0.0199      0.0199\n#&gt;    1.1      0.0048      0.0639\n#&gt;    1.2      0.0010      0.1491\n#&gt;    1.3      0.0002      0.2749\n#&gt;    1.4      0.0000      0.4248\n#&gt;    1.5      0.0000      0.5755\n#&gt;    1.6      0.0000      0.7076\n#&gt;    1.7      0.0000      0.8108\n#&gt;    1.8      0.0000      0.8844\n#&gt;    1.9      0.0000      0.9328\n#&gt;    2.0      0.0000      0.9627\n#&gt; \n#&gt;  Note: Gamma is Odds of Differential Assignment To\n#&gt;  Treatment Due to Unobserved Factors \n#&gt; \n\nhlsens(x =mData_trt$re78,\n      y =mData_ctrl$re78 ,Gamma = 2,GammaInc = 0.1)\n#&gt; \n#&gt;  Rosenbaum Sensitivity Test for Hodges-Lehmann Point Estimate \n#&gt;  \n#&gt; Unconfounded estimate ....  1435.08 \n#&gt; \n#&gt;  Gamma Lower bound Upper bound\n#&gt;    1.0  1.4351e+03      1435.1\n#&gt;    1.1  8.0828e+02      1515.9\n#&gt;    1.2  4.6298e+02      1809.0\n#&gt;    1.3  1.8238e+02      2178.1\n#&gt;    1.4 -2.0266e-02      2439.4\n#&gt;    1.5 -2.4892e+02      2678.5\n#&gt;    1.6 -4.5162e+02      2937.5\n#&gt;    1.7 -6.7212e+02      3184.0\n#&gt;    1.8 -8.9732e+02      3462.6\n#&gt;    1.9 -1.1328e+03      3651.1\n#&gt;    2.0 -1.3022e+03      3848.9\n#&gt; \n#&gt;  Note: Gamma is Odds of Differential Assignment To\n#&gt;  Treatment Due to Unobserved Factors \n#&gt;",
    "crumbs": [
      "倾向性评分",
      "<span class='chapter-number'>22</span>  <span class='chapter-title'>倾向性评分</span>"
    ]
  },
  {
    "objectID": "PropensityScore.html#加权weighting",
    "href": "PropensityScore.html#加权weighting",
    "title": "\n22  倾向性评分\n",
    "section": "\n22.4 加权（Weighting）",
    "text": "22.4 加权（Weighting）\n……",
    "crumbs": [
      "倾向性评分",
      "<span class='chapter-number'>22</span>  <span class='chapter-title'>倾向性评分</span>"
    ]
  },
  {
    "objectID": "PropensityScore.html#回归",
    "href": "PropensityScore.html#回归",
    "title": "\n22  倾向性评分\n",
    "section": "\n22.5 回归",
    "text": "22.5 回归\n……",
    "crumbs": [
      "倾向性评分",
      "<span class='chapter-number'>22</span>  <span class='chapter-title'>倾向性评分</span>"
    ]
  },
  {
    "objectID": "PropensityScore.html#psapsa_shiny",
    "href": "PropensityScore.html#psapsa_shiny",
    "title": "\n22  倾向性评分\n",
    "section": "\n22.6 psa::psa_shiny()",
    "text": "22.6 psa::psa_shiny()\n\nCodepsa::psa_shiny()",
    "crumbs": [
      "倾向性评分",
      "<span class='chapter-number'>22</span>  <span class='chapter-title'>倾向性评分</span>"
    ]
  },
  {
    "objectID": "diagnostic_test.html",
    "href": "diagnostic_test.html",
    "title": "\n23  诊断性测试\n",
    "section": "",
    "text": "23.1 基本特征",
    "crumbs": [
      "研究设计",
      "<span class='chapter-number'>23</span>  <span class='chapter-title'>诊断性测试</span>"
    ]
  },
  {
    "objectID": "diagnostic_test.html#基本特征",
    "href": "diagnostic_test.html#基本特征",
    "title": "\n23  诊断性测试\n",
    "section": "",
    "text": "23.1.1 灵敏度（Sensitivity）\n真阳性率：指在所有真实状况为阳性的样本中，被正确识别出阳性的比例。\n\\[\nSe=\\frac{TP}{TP+FN}\n\\]\n其中TP 是真阳性的数量，FN 是假阴性的数量。\n假阴性率(FNR) /漏诊率\n\\[\nFNR=1-Se\n\\]\n\n23.1.2 特异度（Specificity）\n真阴性率：指在所有真实状况为阴性的样本中，被正确识别出阴性的比例。\n\\[\nSp=\\frac{TN}{TN+FP}\n\\]\n其中 TN 是真阴性的数量，FP 是假阳性的数量。\n假阳性率(FPR) /误诊率\n\\[ FPR=1-Sp \\]\n\n23.1.3 Youden’s Index\n\\[\nJ=Se-FPR =Se+Sp-1,J[1,-1]\n\\]\n\nJ 越大诊断有效性越高\nJ=1 表示完美的诊断性能，因为Se，Sp都是1。\nJ≤0 表示没有诊断价值\n\n23.1.4 Likelihood Ratio\n正似然比\n\\[\nLR+=\\frac{Se}{FPR}=\\frac{Se}{1-Sp}\n\\]\n\nLR+越大表示患病测出阳性结果的优势越大\nLR+=1表示诊断无效\n\n负似然比\n\\[\nLR-=\\frac{FNR}{Sp}=\\frac{1-Sp}{Sp}\n\\]\n\nLR-越小表示患病测出阴性结果的优势越小\nLR-=1表示诊断无效\n\n23.1.5 预测值\n\nCodem\n#&gt;        truth\n#&gt; predict +    -   \n#&gt;       + \"TP\" \"FP\"\n#&gt;       - \"FN\" \"TN\"\n\n\n阳性预测值（Positive Predictive Value, PPV）：在所有被测试为阳性的样本中，真正的阳性比例。\n\\[\nPPV=\\frac{TP}{TP+NP}\n\\]\n阴性预测值（Negative Predictive Value, NPV）：在所有被测试为阴性的样本中，真正的阴性比例。\n\\[\nPPV=\\frac{TN}{TN+FN}\n\\]\n配对样本设计\n\\(\\chi^2\\)配对检验\n完全随机设计\n\\(\\chi^2\\)检验",
    "crumbs": [
      "研究设计",
      "<span class='chapter-number'>23</span>  <span class='chapter-title'>诊断性测试</span>"
    ]
  },
  {
    "objectID": "diagnostic_test.html#一致性agreement",
    "href": "diagnostic_test.html#一致性agreement",
    "title": "\n23  诊断性测试\n",
    "section": "\n23.2 一致性agreement",
    "text": "23.2 一致性agreement\n准确度（Accuracy）：指测试正确地分类（阳性或阴性）的样本占总样本的比例。\n\\[\nAccuracy=\\frac{TP+TN}{N}\n\\]\nkappa 系数\n\\[\n\\kappa =\\frac{Accuracy-[(a+b)(a+c)+(c+d)(b+d)]/N^2}{1-[(a+b)(a+c)+(c+d)(b+d)]/N^2}\n\\]\n\nκ=1表示完全一致\nκ=-1表示完全不一致\nκ=0表示一致性与偶然一致性Pe相同\n\n通常κ＞0.7即可以认为两种诊断方法有较好的一致性",
    "crumbs": [
      "研究设计",
      "<span class='chapter-number'>23</span>  <span class='chapter-title'>诊断性测试</span>"
    ]
  },
  {
    "objectID": "diagnostic_test.html#roc曲线receiver-operating-characteristic-curve",
    "href": "diagnostic_test.html#roc曲线receiver-operating-characteristic-curve",
    "title": "\n23  诊断性测试\n",
    "section": "\n23.3 ROC曲线（Receiver Operating Characteristic Curve）",
    "text": "23.3 ROC曲线（Receiver Operating Characteristic Curve）\nROC曲线（Receiver Operating Characteristic Curve）：是一个图形工具，用于展示不同阈值下灵敏度和特异度之间的关系。曲线下面积（AUC）越接近1，表示测试的性能越好。\n\nCodelibrary(pROC)\n\nroc_data &lt;- aSAH %&gt;%\n    dplyr::filter(gender == \"Female\") %&gt;%\n    roc(outcome, s100b)\n\n\n\n# 绘制ROC曲线\nplot(roc_data, print.thres = \"best\", print.thres.pattern = \"Best cutoff: %.2f\", main = \"ROC Curve\")\n\n\n\n\n\n\nCode\n\n# 计算AUC\nauc_value &lt;- auc(roc_data)\nprint(paste(\"AUC:\", auc_value))\n#&gt; [1] \"AUC: 0.72\"\n\n\n\n23.3.1 AUC\n$ A=P(X&gt;Y) $\n\\[\nS(X,Y)=\n\\begin{cases}\n1,\\ \\ \\ \\  X&gt;Y\\\\\n1/2,X=Y\\\\\n0,\\ \\ \\ \\ X&lt;Y\\\\\n\\end{cases}\n\\]\n$ A=_1^{n_1}_1^{n_0}S(X,Y) $\n\n23.3.2 分组AUC的比较\n完全随机设计\n\\[\nZ=\\frac{\\hat A_1-\\hat A_2}{\\sqrt{Var(\\hat A_1)+Var(\\hat A_2)}}\n\\]\n配对样本设计\n\\[\nZ=\\frac{\\hat A_1-\\hat A_2}{\\sqrt{Var(\\hat A_1)+Var(\\hat A_2)-2Cov(\\hat A_1,\\hat A_2)}}\n\\]",
    "crumbs": [
      "研究设计",
      "<span class='chapter-number'>23</span>  <span class='chapter-title'>诊断性测试</span>"
    ]
  }
]