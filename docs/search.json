[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "医学与生物统计学",
    "section": "",
    "text": "推荐阅读\n\nR语言教程 Ⅶ 统计模型 ——李东风\n统计学习 ISLR\nR语言实战医学统计\nhttps://www.tidymodels.org/\n医学研究中的生存数据建模（4e）\nApplied Propensity Score Analysis with R\nModern Statistics for Modern Biology",
    "crumbs": [
      "推荐阅读"
    ]
  },
  {
    "objectID": "descriptive_statistics.html",
    "href": "descriptive_statistics.html",
    "title": "描述性统计",
    "section": "",
    "text": "基本概念",
    "crumbs": [
      "描述性统计"
    ]
  },
  {
    "objectID": "descriptive_statistics.html#基本概念",
    "href": "descriptive_statistics.html#基本概念",
    "title": "描述性统计",
    "section": "",
    "text": "同质 (Homogeneity)：指数据样本的同质性，即样本中各个个体之间的相似性或一致性。\n变异 (Variation)：指数据样本中各个个体之间的差异性或变化程度。\n总体 (Population)：研究对象的全部个体的集合。描述总体特征的统计学指标称为参数 (Parameter)。\n样本 (Sample)：从总体中抽取的一部分个体。由样本计算出的特征指标称为统计量 (Statistic)。\n变量 (Variable)：随机变量的简称，是研究对象的属性或特征，可以在不同个体之间或同一个体在不同时间上取不同值。\n数据 (Data)：变量的观测值",
    "crumbs": [
      "描述性统计"
    ]
  },
  {
    "objectID": "descriptive_statistics.html#数据类型及其分布",
    "href": "descriptive_statistics.html#数据类型及其分布",
    "title": "描述性统计",
    "section": "数据类型及其分布",
    "text": "数据类型及其分布\n定量数据（quantitative data）\n连续型\n\n正态分布：t 检验，方差分析，相关性检验\n\n\\[\nf(x)= \\frac{1}{\\sqrt{2πσ^2}} e^{\\frac {−(x−μ) ^2 }{2σ^2 }}\n\\]\n其中，，\\(\\mu\\)是均值， \\(\\sigma\\)是标准差\n\nCodelibrary(ggplot2)\nlibrary(tibble)\n# 标准正态分布\nnormal_data &lt;- tibble(x = seq(-5, 5, length.out = 500),\n                      y = dnorm(x, mean = 0, sd = 1))\n\n\nggplot(normal_data, aes(x = x, y = y)) +\n    geom_line() +\n    ggtitle(\"Normal Distribution\")\n\n\n\n\n\n\n\n\n对数正态分布：非参数检验\n指数分布：广义线性模型，对数秩（log-rank ）检验\n\n\\[\nf(x)=λe^{−λx}，x\\ge 0\n\\]\n其中，默认(rate)：\\(\\lambda = 1\\)。\n\nCode# 指数分布\nexponential_data &lt;- tibble(x = seq(0, 3, length.out = 100),\n                           y = dexp(x, rate = 1))\n\n\nggplot(exponential_data, aes(x = x, y = y)) +\n    geom_line() +\n    ggtitle(\"Exponential Distribution\")\n\n\n\n\n\n\n\n\n均匀分布\n离散型\n\n二项分布\n\n\\[\n    P(x)=\\binom{n}{x}p^x(1-p)^{n-x}\n\\]\n\nCode# 二项分布\nbinomial_data &lt;- tibble(x = 0:100, y = dbinom(x, size = 100, prob = 0.5))\n\nggplot(binomial_data, aes(x = x, y = y, color = y)) +\n    geom_bar(stat = \"identity\") +\n    ggtitle(\"Binomial Distribution\")\n\n\n\n\n\n\n\n\n负二项分布：DESeq2 差异分析\n\n\\[\n    P(x)=\\frac{\\Gamma(x+n)}{\\Gamma(n)\\ x!}p^n(1-p)^x\n\\]\n其中，均值 \\(\\mu = \\frac{n(1-p)}{p}\\)，方差 \\(\\frac{(1-p)}{p^2}\\)。\n\nCode# 负二项分布\nnegative_binomial_data &lt;- tibble(x = 0:20, y =  dnbinom(x, size = 1, prob = 0.5))\n\nggplot(negative_binomial_data, aes(x = x, y = y)) +\n    geom_bar(stat = \"identity\") +\n    ggtitle(\"Negative Binomial Distribution\")\n\n\n\n\n\n\n\n\n泊松分布\n\n\\[\nP(x)=\\frac{\\lambda^x e^{-\\lambda}}{x!}，E(X)=Var(X)=λ\n\\]\n\nCode# 泊松分布\npoisson_data &lt;- tibble(x = 0:20,\n                       y = dpois(x, lambda = 5))\n\nggplot(poisson_data, aes(x = x, y = y)) +\n    geom_bar(stat = \"identity\") +\n    ggtitle(\"Poisson Distribution\")\n\n\n\n\n\n\n\n\n超几何分布\n\nHypergeometric Distribution，不放回抽样\n\\[\nP(x)=\\frac{\\binom {m}{x}\\binom{n}{k-x}}{\\binom{m+n}{k}}；x=0，...，k；p=m/(m+n) ；N=m+n\n\\]\n其中，\\(p = \\frac{m}{m+n}\\)，\\(N = m+n\\)，均值 \\(E[X] = \\mu = kp\\)，方差 \\(Var(X) = kp(1-p) \\frac{(m+n-1)}{(m+n-k)}\\)。\n\nCode# 超几何分布\nhypergeometric_data &lt;- tibble(x = 0:9, y = dhyper(x, m = 10,n = 7,k = 8))\n\nggplot(hypergeometric_data, aes(x = x, y = y)) +\n    geom_bar(stat = \"identity\") +\n    ggtitle(\"Hypergeometric Distribution\")\n\n\n\n\n\n\n\n定性数据（qualitative data）\n\n名义型（nominal）\n有序型（ordered）",
    "crumbs": [
      "描述性统计"
    ]
  },
  {
    "objectID": "descriptive_statistics.html#数据可视化",
    "href": "descriptive_statistics.html#数据可视化",
    "title": "描述性统计",
    "section": "数据可视化",
    "text": "数据可视化",
    "crumbs": [
      "描述性统计"
    ]
  },
  {
    "objectID": "quantitative_data.html",
    "href": "quantitative_data.html",
    "title": "\n1  定量数据的描述\n",
    "section": "",
    "text": "1.1 频数分布\nCodelibrary(ggplot2)\nlibrary(tibble)\nggplot(data = mtcars, aes(x = mpg)) +\n    geom_histogram(color = \"black\", bins = 10)\n\n\n\n\n\n\nCode\nggplot(data = mtcars, aes(x = mpg)) +\n    geom_histogram(color = \"black\", binwidth = diff(range(mtcars$mpg)) / 9)\nCodeas_tibble(mtcars$mpg)\n\n\n\n\nvalue\n\n\n\n21.0\n\n\n21.0\n\n\n22.8\n\n\n21.4\n\n\n18.7\n\n\n18.1\n\n\n14.3\n\n\n24.4\n\n\n22.8\n\n\n19.2\n\n\n17.8\n\n\n16.4\n\n\n17.3\n\n\n15.2\n\n\n10.4\n\n\n10.4\n\n\n14.7\n\n\n32.4\n\n\n30.4\n\n\n33.9\n\n\n21.5\n\n\n15.5\n\n\n15.2\n\n\n13.3\n\n\n19.2\n\n\n27.3\n\n\n26.0\n\n\n30.4\n\n\n15.8\n\n\n19.7\n\n\n15.0\n\n\n21.4",
    "crumbs": [
      "描述性统计",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>定量数据的描述</span>"
    ]
  },
  {
    "objectID": "quantitative_data.html#频数分布",
    "href": "quantitative_data.html#频数分布",
    "title": "\n1  定量数据的描述\n",
    "section": "",
    "text": "极差(Range) : \\(R=X_{max}-X_{min}\\)\n组数 (Number of Bins) \\(k\\) : 通常选择 \\(8\\) 到 \\(15\\) 之间的值。\n组距 (Bin Width) : \\(interval=\\frac{R}{k}\\)\n频数 (Frequency) : \\(Frequency = count\\)\n频率 (Relative Frequency)： \\(Relative\\ Frequency = \\frac{count}{n} \\times 100\\%\\)",
    "crumbs": [
      "描述性统计",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>定量数据的描述</span>"
    ]
  },
  {
    "objectID": "quantitative_data.html#集中趋势central-tendency",
    "href": "quantitative_data.html#集中趋势central-tendency",
    "title": "\n1  定量数据的描述\n",
    "section": "\n1.2 集中趋势（central tendency）",
    "text": "1.2 集中趋势（central tendency）\n\nCode#算术均数\nmean(mtcars$mpg)     \n#&gt; [1] 20.09062\n\n# 截尾均数\nx &lt;- c(1,2:9,11)\nmean(x)\n#&gt; [1] 5.6\n\nmean(x,trim = 0.1)\n#&gt; [1] 5.5\n#中位数\nmedian(mtcars$mpg)   \n#&gt; [1] 19.2\n\n#众数 mode \nrstatix::get_mode(mtcars$mpg)\n#&gt; [1] 10.4 15.2 19.2 21.0 21.4 22.8 30.4\n\n\n注意：函数rstatix::get_mode() 可能返回多个众数，如果存在多个众数，请检查其处理方式。",
    "crumbs": [
      "描述性统计",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>定量数据的描述</span>"
    ]
  },
  {
    "objectID": "quantitative_data.html#离散趋势dispersion-tendency",
    "href": "quantitative_data.html#离散趋势dispersion-tendency",
    "title": "\n1  定量数据的描述\n",
    "section": "\n1.3 离散趋势（dispersion tendency）",
    "text": "1.3 离散趋势（dispersion tendency）\n\nCode# 值域\nrange(mtcars$mpg)  \n#&gt; [1] 10.4 33.9\n# 极差 or 全距\ndiff(range(mtcars$mpg) )  \n#&gt; [1] 23.5\n\n# 分位数\nquantile(mtcars$mpg,probs = c(0,0.1,0.25,0.5,0.75,1))    \n#&gt;     0%    10%    25%    50%    75%   100% \n#&gt; 10.400 14.340 15.425 19.200 22.800 33.900\n# 四分位数间距\nIQR(mtcars$mpg)     \n#&gt; [1] 7.375\n\n# 方差 variance\nvar(mtcars$mpg)       \n#&gt; [1] 36.3241\n\n# 标准差 standard deviation\nsd(mtcars$mpg)       \n#&gt; [1] 6.026948\n\n\n# 变异系数 Coefficient of Variation\nCV &lt;- function(x, na.rm = TRUE) {  \n    if (na.rm) x &lt;- x[!is.na(x)]\n    CV = sd(x) / mean(x) * 100\n    sprintf(\"%.6f%%\", CV)\n}\nCV(mtcars$mpg)\n#&gt; [1] \"29.998808%\"\n\n\n# 绝对中位差 median absolute deviation\nmad(mtcars$mpg,constant = 1.4826)\n#&gt; [1] 5.41149\nmedian(abs(mtcars$mpg-median(mtcars$mpg)))\n#&gt; [1] 3.65\nmedian(abs(mtcars$mpg-median(mtcars$mpg)))*1.4826\n#&gt; [1] 5.41149\n\n\n说明：mad() 计算时乘以比例因子 constant = 1.4826 以实现渐进正态一致性。",
    "crumbs": [
      "描述性统计",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>定量数据的描述</span>"
    ]
  },
  {
    "objectID": "quantitative_data.html#分布形态",
    "href": "quantitative_data.html#分布形态",
    "title": "\n1  定量数据的描述\n",
    "section": "\n1.4 分布形态",
    "text": "1.4 分布形态\n\n1.4.1 偏度系数\n\n1.4.1.1 总体偏度（Population Skewness）\n表示随机变量概率分布的不对称性。\nhttps://www.macroption.com/skewness-formula/\n三阶中心矩。二阶中心矩即方差。\n\\[\nPopulation\\ Skewness (X) =  \\frac{E(X_i-E(X))^3}{Var(X)^{\\frac{3}{2}}} =E  [(\\frac{X_i-\\mu}{\\sigma})^3]= \\frac{1}{n} \\sum_{i=1}^{n}  (\\frac{X_i-\\mu}{\\sigma} )^3\n\\]\n偏度的取值范围： \\((-\\infty,+\\infty)\\)\n\nSkew＞0，正偏态分布，右偏 = 尾部向右延伸。Mode &lt; Median &lt; Mean；\nSkew=0，数据相对均匀的分布在均值两侧；\nSkew＜0，负偏态分布，左偏 = 尾部向左延伸；Mode &gt; Median &gt; Mean。\n\n\nCodex &lt;- c(1,2,3,5)\ns &lt;- psych::describeBy(x=x,group = NULL)\ns$skew\n#&gt; [1] 0.2823139\n\nskewness &lt;- function(x,na.rm=TRUE){\n    if(na.rm) x &lt;- x[!is.na(x)]\n    n=length(x)\n    μ=mean(x)\n    SD=sd(x)\n    sknewness = mean(((x-μ)/SD)^3)\n    return(sknewness=sknewness)\n}\nskewness(x)\n#&gt; [1] 0.2823139\n\ne1071::skewness(x)\n#&gt; [1] 0.2823139\n\n\n\n1.4.1.2 样本偏度（Sample Skewness）\n\\[\nSample\\ Skewness(X) =  \\frac{n}{(n-1)(n-2)} \\sum_{i=1}^{n}  \\left [\\frac{X_i-\\bar X}{S} \\right ]^3\n\\]\n\n\n\n\n\n1.4.2 峰度系数\n\n1.4.2.1 总体峰度（Population Kurtosis）\n表示随机变量概率分布的尖峭程度。四阶中心矩与方差平方的比值。\nhttps://www.macroption.com/kurtosis-formula/\n超额峰度 excess kurtosis ：四阶中心矩与方差平方的比值减3。\nhttps://www.macroption.com/excess-kurtosis/\n\\[\nPopulation\\ Kurtosis(X) =  \\frac{E(X_i-E(X))^4}{Var(X)^{2}}-3= E  [(\\frac{X_i-\\mu}{\\sigma})^4] - 3= \\frac{1}{n} \\sum_{i=1}^{n}  (\\frac{X_i-\\mu}{\\sigma} )^4-3\n\\]\n超额峰度的取值范围：\\([-2,+\\infty)\\)\n\n超额峰度＜0，数据分布与正态分布相比较为扁平；\n超额峰度=0，正态分布；\n超额峰度＞0，数据分布与正态分布相比较为高尖。\n\n\nCodes$kurtosis\n#&gt; [1] -1.961786\n\nkurtosis&lt;-function(x,na.rm=TRUE){\n    if(na.rm) x&lt;-x[!is.na(x)]\n    n=length(x)\n    μ=mean(x)\n    SD=sd(x)\n    kurtosis= mean(((x-μ)/SD)^4)-3\n    return(kurtosis=kurtosis)\n}\nkurtosis(x)\n#&gt; [1] -1.961786\ne1071::kurtosis(x)\n#&gt; [1] -1.961786\n\n\n\n1.4.2.2 样本峰度（Sample Kurtosis）\n\\[\nSample \\ Kurtosis(X) =   \\frac{n(n+1)}{(n-1)(n-2)(n-3)} \\sum_{i=1}^{n} \\left [\\frac{X_i-\\bar X}{S} \\right]^4-\\frac{3(n-1)^2}{(n-2)(n-3)}\n\\]",
    "crumbs": [
      "描述性统计",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>定量数据的描述</span>"
    ]
  },
  {
    "objectID": "quantitative_data.html#标准化变换",
    "href": "quantitative_data.html#标准化变换",
    "title": "\n1  定量数据的描述\n",
    "section": "\n1.5 标准化变换",
    "text": "1.5 标准化变换\n\nCodescale(mtcars$mpg,center = T,scale = T) |&gt; tibble()\n\n\n\n\nscale(mtcars$mpg, center = T, scale = T)\n\n\n\n0.15088482\n\n\n0.15088482\n\n\n0.44954345\n\n\n0.21725341\n\n\n-0.23073453\n\n\n-0.33028740\n\n\n-0.96078893\n\n\n0.71501778\n\n\n0.44954345\n\n\n-0.14777380\n\n\n-0.38006384\n\n\n-0.61235388\n\n\n-0.46302456\n\n\n-0.81145962\n\n\n-1.60788262\n\n\n-1.60788262\n\n\n-0.89442035\n\n\n2.04238943\n\n\n1.71054652\n\n\n2.29127162\n\n\n0.23384555\n\n\n-0.76168319\n\n\n-0.81145962\n\n\n-1.12671039\n\n\n-0.14777380\n\n\n1.19619000\n\n\n0.98049211\n\n\n1.71054652\n\n\n-0.71190675\n\n\n-0.06481307\n\n\n-0.84464392\n\n\n0.21725341",
    "crumbs": [
      "描述性统计",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>定量数据的描述</span>"
    ]
  },
  {
    "objectID": "quantitative_data.html#统计摘要",
    "href": "quantitative_data.html#统计摘要",
    "title": "\n1  定量数据的描述\n",
    "section": "\n1.6 统计摘要",
    "text": "1.6 统计摘要\n\nCodesummary(mtcars$mpg)\n#&gt;    Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n#&gt;   10.40   15.43   19.20   20.09   22.80   33.90\nrstatix::get_summary_stats(mtcars,mpg,type = \"full\")\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nvariable\nn\nmin\nmax\nmedian\nq1\nq3\niqr\nmad\nmean\nsd\nse\nci\n\n\nmpg\n32\n10.4\n33.9\n19.2\n15.425\n22.8\n7.375\n5.411\n20.091\n6.027\n1.065\n2.173\n\n\n\n\nCode\n\npsych::describeBy(mtcars$mpg,group =NULL)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nvars\nn\nmean\nsd\nmedian\ntrimmed\nmad\nmin\nmax\nrange\nskew\nkurtosis\nse\n\n\nX1\n1\n32\n20.09062\n6.026948\n19.2\n19.69615\n5.41149\n10.4\n33.9\n23.5\n0.610655\n-0.372766\n1.065424",
    "crumbs": [
      "描述性统计",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>定量数据的描述</span>"
    ]
  },
  {
    "objectID": "qualitative_data.html",
    "href": "qualitative_data.html",
    "title": "\n2  定性数据的统计描述\n",
    "section": "",
    "text": "2.0.1 率\n率（rate）表示在一定空间或时间范围内某现象的发生数与可能发生的总数之比，说明某现象出现的频率。\n标准化率（standardized rate）\n\n2.0.2 构成比\n构成比（proportion）\n\n2.0.3 相对比\n相对比（relative ratio）是A和B两个有关联指标值之比。\n\n相对危险度 （Relative Risk，RR），是指暴露组人群的发病率与非暴露组人群的发病率之比。RR 用于反映暴露因素与结局事件的关联程度， 其 取值范围为 0 到无穷大。数值为 1 时，表明暴露因素与结局事件无关联；小于 1 时，表 明暴露因素导致结局事件的发生率降低；大于 1 时，表明暴露因素导致结局事件的发生率增加。相对风险适用于前瞻性队列研究。\n优势比（Odds Ratio，OR），是指暴露组中病例与非病例人数的比值除以非暴露组中病例与非病例人数的比值。　　OR 的取值范围也为 0 到无穷大。如果 OR 值大于 1 ，说明该暴露因素更 容易导致结果事件发生，或者说该因素是一个危险因素；小于 1 ，则说明该暴露因素更不 容易导致结果事件发生，或者说该因素是一个保护因素。比值比适用于队列研究和病例对照研究。\n\nUsing R for Biomedical Statistics\n\nCodex &lt;- matrix(c(156,9421,1531,14797),nrow=2,byrow=TRUE,\n             dimnames = list(c(\"Exposed\",\"Unexposed\"),c(\"Disease\",\"Control\")))\n\nx\n#&gt;           Disease Control\n#&gt; Exposed       156    9421\n#&gt; Unexposed    1531   14797\n# RR\n156/(156+9421)*(1531+14797)/1531\n#&gt; [1] 0.1737212\nsource(\"function/calcRelativeRisk.R\")\ncalcRelativeRisk(x,alpha=0.05)\n#&gt; [1] \"category = Exposed , relative risk =  0.173721236521721\"\n#&gt; [1] \"category = Exposed ,  95 % confidence interval = [ 0.147624440337197 , 0.204431379720742 ]\"\n\n# OR\n156/9421/(1531/14797)\n#&gt; [1] 0.1600391\nsource(\"function/calcOddsRatio.R\")\ncalcOddsRatio(x,alpha = 0.05)\n#&gt; [1] \"category = Exposed , odds ratio =  0.160039091621751\"\n#&gt; [1] \"category = Exposed ,  95 % confidence interval = [ 0.135460641900536 , 0.189077140693912 ]\"\n\n\n\nCodey &lt;- matrix(c(30,24,76,241,82,509),nrow=3,byrow=TRUE,\n            dimnames = list(c(\"Exposure1\",\"Exposure2\",\"Unexposed\"),\n                            c(\"Disease\",\"Control\")))\ny\n#&gt;           Disease Control\n#&gt; Exposure1      30      24\n#&gt; Exposure2      76     241\n#&gt; Unexposed      82     509\ncalcOddsRatio(y, referencerow=3)\n#&gt; [1] \"category = Exposure1 , odds ratio =  7.75914634146342\"\n#&gt; [1] \"category = Exposure1 ,  95 % confidence interval = [ 4.32163714854064 , 13.9309131884372 ]\"\n#&gt; [1] \"category = Exposure2 , odds ratio =  1.95749418075094\"\n#&gt; [1] \"category = Exposure2 ,  95 % confidence interval = [ 1.38263094540732 , 2.77137111707344 ]\"\ncalcRelativeRisk(y, referencerow=3)\n#&gt; [1] \"category = Exposure1 , relative risk =  4.00406504065041\"\n#&gt; [1] \"category = Exposure1 ,  95 % confidence interval = [ 2.93130744422409 , 5.46941498113737 ]\"\n#&gt; [1] \"category = Exposure2 , relative risk =  1.72793721628068\"\n#&gt; [1] \"category = Exposure2 ,  95 % confidence interval = [ 1.30507489771431 , 2.2878127750653 ]\"",
    "crumbs": [
      "描述性统计",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>定性数据的统计描述</span>"
    ]
  },
  {
    "objectID": "probability_theory.html",
    "href": "probability_theory.html",
    "title": "\n3  概率论基础\n",
    "section": "",
    "text": "3.1 古典概率\n样本点（sample point）是每一次随机试验的结果，用 \\(\\omega\\) 表示。\nCode# 假设随机试验是抛掷硬币\nw1 &lt;- \"正面\"\nw2 &lt;- \"反面\"\n样本空间（sample space）是所有样本点的集合，用\\(\\Omega=\\{\\omega_{i};i=0,1,2,... \\}\\)表示。\nCodespace&lt;- c(w1=w1,w2=w2)\nspace\n#&gt;     w1     w2 \n#&gt; \"正面\" \"反面\"\n随机事件（random event）是样本空间中满足一定条件的子集（\\(\\Omega\\)的子集），用大写字母 \\(A,B,C,...\\)表示。\n一个样本点的集合称为简单事件（simple event），用 \\(\\Omega=\\{\\omega\\}\\) 表示。\n若干个简单事件的集合称为混合事件（composite event）。\n全集 \\(\\Omega\\) 称为必然事件（deterministic event）。\n空集（null set） \\(\\emptyset\\) 称为不可能事件（impossible event）。",
    "crumbs": [
      "概率论与数理统计",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>概率论基础</span>"
    ]
  },
  {
    "objectID": "probability_theory.html#古典概率",
    "href": "probability_theory.html#古典概率",
    "title": "\n3  概率论基础\n",
    "section": "",
    "text": "3.1.1 事件的运算\n\n\n包含关系（containment） ：Venn diagram\n\n\\(A\\subseteq B\\)\n\\(A\\supseteq B\\)\n\n\n并集（\\(A\\cup B\\)）\n交集（\\(A\\cap B\\)，\\(AB\\) ）\n补集（\\(\\bar A\\)）\n互斥事件 \\(A\\cap B=\\emptyset\\)\n对立（互补）事件 \\(A\\cap B=\\emptyset\\) 且 \\(A\\cup B=\\Omega\\)\n\n3.1.2 排列组合\n组合（combination）：\\(C_n^k =\\binom{n}{k} =\\frac {n!}{k!(n-k)!}\\)\n\nCodechoose(5,3)\n#&gt; [1] 10\n\n\n排列（permutation）：\\(P_n^k =k!\\binom{n}{k} =\\frac {n!}{(n-k)!}\\)\n\n3.1.3 概率的运算法则\n加法定理\n\\[\nP(A\\cup B)=P(A)+P(B)-P(A\\cap B)\n\\]\n条件概率 conditional probability\n\\[\nP(B|A)=\\frac{P(AB)}{P(A)}\n\\]\n推出乘法定理 \\(P(A B)=P(A)\\times P(B|A)\\)\n独立性（积的概率等于各自概率的积）\n\\[\nP(B|A)=P(B) \\ 或者\\  P(A)=0\\\\\nP(AB)=P(A) \\times P(B)\n\\]\n\n3.1.4 全概率公式\n（给定Ai发生，B的加权平均条件概率）\n\\[P(B)=\\sum_{i=1}^{n}P(A_i)P(B|A_i)\\]\n\n3.1.5 贝叶斯公式\n条件概率定义与全概率公式的推论\n逆概率公式（后验概率）\n\\[P(A_k |B)=\\frac{P(A_k)P(B|A_k)}{\\sum_{i=1}^{n}P(A_i)P(B|A_i)}\\]\n\n3.1.6 混淆矩阵",
    "crumbs": [
      "概率论与数理统计",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>概率论基础</span>"
    ]
  },
  {
    "objectID": "probability_theory.html#离散型随机变量",
    "href": "probability_theory.html#离散型随机变量",
    "title": "\n3  概率论基础\n",
    "section": "\n3.2 离散型随机变量",
    "text": "3.2 离散型随机变量\n离散型随机变量的全部可能取值只有有限多个或可列无穷多个。\n离散型随机变量的概率分布列：\n\\[P(X=x_k)=p_k \\ ,\\ \\  (k=1,2,…)\\]\n累计分布函数：\n\\[F(x) =P(X≤x)= \\sum_{x_k≤x}p_k\\]\n随机变量的数学期望或均值：\n\\[E(X)=\\sum_{k}x_k p_k\\ ,\\ \\ (k=1,2,...)\\]\n方差：\n\\[Var(X)=\\sum_{k}(x_k-\\mu)^2 p_k\\]\n\n3.2.1 二项分布\n二项试验\n\\[\nX\\sim B(n,\\pi)\n\\]\n概率质量函数（pmf）：\n\\[P(X=k)=p_k=C_n^k\\pi^k(1-\\pi)^{n-k} \\ ，\\ \\ (k=0,1,...,n)\\]\n其中n表示独立试验的次数，\\(\\pi\\) 表示成功概率。\n累计概率：至多k0次成功的概率\n\\[F(X)=P(X≤k_0)=\\sum_{k=0}^{k_0} p_k\\]\n至少k0次成功的概率\n\\[P(X≥k_0)=\\sum_{k=k_0}^{n} p_k\\]\n期望：\\(E(X)=n\\pi\\)\n方差：\\(Var(X)=n\\pi(1-\\pi)\\)\n\nCodebinom &lt;- function(n,p){\n    ggplot() +\n        geom_line(data.frame(x = 0:n, \n                      y = dbinom(0:n, size = n, prob = p)), \n           mapping=aes(x = x, y = y),\n           color=\"red\")+\n        geom_line(data.frame(x = 0:n, \n                      y = pbinom(0:n, size = n, prob = p)), \n           mapping=aes(x = x, y = y),\n           color=\"blue\")\n}\n\nbinom(30,0.5)\n\n\n\n\n\n\n\n\n3.2.2 超几何分布\n概率分布律：\n\\[P(X=k)=p_k=\\frac {\\binom{r}{k}\\binom{N-r}{n-k}}{\\binom{N}{n}} \\ ，\\ \\ (k=0,1,...,r)\\]\nr为N中表示合格的元素个数，N-r表示不合格的元素个数，超几何分布考虑在n次无放回的试验中，k个合格n-k个不合格的概率。\n期望：\\(E(X)=\\frac{nr}{N}\\)\n\n3.2.3 多项式分布\n概率：\\(P(X_1=n_1,...,X_i=n_i,...,X_k=n_k)=\\frac {n!}{n_1!...n_i!...n_k!}\\pi_1^{n_1}...\\pi_i^{n_i}...\\pi_k^{n_k}\\)\n\\[\nX \\sim M(n,\\pi_1,\\pi_2,...,\\pi_k)\n\\]\n其中\\(n=n_1+n_2+...+n_k\\) 表示独立试验的次数，\\(\\pi_k\\) 表示\\(k\\) 个互斥结果的成功概率。\n期望(\\(A_i 与 -A_i\\))：\\(\\mu_{A_i}=n\\pi_{A_i}\\)\n方差(\\(A_i 与 -A_i\\))：\\(\\sigma_{A_i}^2=n\\pi_{A_i}(1-\\pi_{A_i})\\)\n\n3.2.4 泊松分布\n特定时间段或某空间段内事件发生的次数\n\\[\nX\\sim P(\\lambda)\n\\] 概率分布列：\n\\[P(X=k)=p_k=\\frac {\\lambda ^k}{k!}e^{-\\lambda} \\ ,\\ \\ (\\lambda &gt; 0;k=0,1,…)\\]\n其中\\(\\lambda\\) 表示单位时间/空间罕见事件发生的期望值。\n期望：\\(\\mu=\\lambda\\)\n方差：\\(Var(X)=\\lambda\\)\n\n3.2.4.1 二项分布近似泊松分布\n当\\(n(n≥100)\\)足够大，\\(\\pi(\\pi ≤0.01)\\) 足够小，二项分布的均值 \\(n\\pi\\) 与方差\\(n\\pi(1-\\pi)\\approx n\\pi\\) 近似相等，此时的二项分布近似\\(\\lambda=n\\pi\\) 的泊松分布。\n\\[\nP(X=k)=C_n^k \\pi^k(1-\\pi)^{n-k} \\approx \\frac{\\lambda ^k}{k!}e^{-\\lambda}\n\\]",
    "crumbs": [
      "概率论与数理统计",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>概率论基础</span>"
    ]
  },
  {
    "objectID": "probability_theory.html#连续型随机变量",
    "href": "probability_theory.html#连续型随机变量",
    "title": "\n3  概率论基础\n",
    "section": "\n3.3 连续型随机变量",
    "text": "3.3 连续型随机变量\n对于随机变量X，如果存在一个定义在（-∞，+∞）上的非负函数f(x)，使得对于任意实数x，总有：累计分布函数（cdf）：\n\\[F(x)=P(X≤x)=\\int_{-\\infty}^{x}f(t)dt\\]\n概率：\\(P(a≤X≤b)=\\int_{a}^{b}f(x)dx\\)\n概率密度函数（pdf）：\\(f(x)\\)\n期望：\\(E(X)\\equiv\\mu =\\int_{-\\infty}^{+\\infty}xf(x)dx\\)\n方差：\\(Var(X)\\equiv \\int_{-\\infty}^{+\\infty}(x-\\mu)^2f(x)dx\\)\n\n3.3.1 正态分布\n概率密度函数（pdf）：\\(f(x)=\\frac {1}{\\sigma\\sqrt{2\\pi}}e^{-\\frac{(x-\\mu)^2}{2\\sigma^2}}（-\\infty ＜x ＜+\\infty）\\)\n累计分布函数（cdf）:\\(F(x)=P(X≤x)=\\int_{-\\infty}^{x}f(t)dt=\\frac{1}{\\sqrt{2\\pi}\\sigma}\\int_{-\\infty}^{x}e^{-\\frac{(t-\\mu)^2}{2\\sigma^2}}dt\\ (-\\infty＜x＜+\\infty)\\)\n\\[\nX \\sim N(\\mu,\\sigma^2)\n\\]\n\n3.3.2 标准正态分布\n\\[\nZ=\\frac {X-\\mu}{\\sigma} \\sim \\ N(0,1)\n\\]\npdf：\\(\\varphi (z)=\\frac{1}{\\sqrt{2\\pi}}e^{-\\frac{z^2}{2}} (-\\infty＜z＜+\\infty)\\)\ncdf：\\(\\Phi(z)=P(Z≤z)=\\int_{-\\infty}^{z}\\varphi (\\nu )d\\nu =\\frac{1}{\\sqrt{2\\pi}}\\int_{-\\infty}^{z}e^{-\\frac{\\nu^2}{2}}dt\\ (-\\infty＜z＜+\\infty)\\)\n\nCode# 标准正态分布\nnorm &lt;- function(mu=0,sigma=1,...){\n  ggplot() + xlim(c(mu-4*sigma,mu+4*sigma)) +\n    geom_function(fun = dnorm, args = list(mean = mu, sd = sigma), color=\"red\")+\n        scale_y_continuous(limits = c(0,1))+\n    geom_function(fun = pnorm,color=\"blue\")\n}\nnorm()        # Area Under the Curve (AUC) = 1\n\n\n\n\n\n\n\n\n3.3.3 正态性的检验\n\n3.3.3.1 直方图/茎叶图\n直方图：钟形分布（bell-shaped distribution）\n\nCodemtcars$mpg\n#&gt;  [1] 21.0 21.0 22.8 21.4 18.7 18.1 14.3 24.4 22.8 19.2 17.8 16.4 17.3 15.2 10.4\n#&gt; [16] 10.4 14.7 32.4 30.4 33.9 21.5 15.5 15.2 13.3 19.2 27.3 26.0 30.4 15.8 19.7\n#&gt; [31] 15.0 21.4\nh&lt;-hist(mtcars$mpg,breaks = 12)\nx&lt;-seq(min(mtcars$mpg),max(mtcars$mpg),by=0.001)\ny&lt;-dnorm(x,mean=mean(mtcars$mpg),sd=sd(mtcars$mpg)) #密度曲线  f(x)=(F(i)/n)/ΔXi\ny&lt;-y*diff(h$mids[1:2])*length(mtcars$mpg)  # f(x)*ΔXi*n  正态分布\nlines(x,y,col=\"blue\")\n\n\n\n\n\n\n\n茎叶图（Stem-and-Leaf Plot）\n\nCodestem(mtcars$mpg,scale = 1)\n#&gt; \n#&gt;   The decimal point is at the |\n#&gt; \n#&gt;   10 | 44\n#&gt;   12 | 3\n#&gt;   14 | 3702258\n#&gt;   16 | 438\n#&gt;   18 | 17227\n#&gt;   20 | 00445\n#&gt;   22 | 88\n#&gt;   24 | 4\n#&gt;   26 | 03\n#&gt;   28 | \n#&gt;   30 | 44\n#&gt;   32 | 49\nlength(mtcars$mpg)\n#&gt; [1] 32\n\n\n\n3.3.3.2 P-P图/Q-Q图\nP-P图是累计相对频率的观测值（x轴）与理论值（y轴）的散点图；\nQ-Q图是分位数的观测值（x轴）与理论值（y轴）的散点图。\n\nCodelibrary(ggpubr)\nggqqplot(mtcars$mpg)  #  直线 \n\n\n\n\n\n\n\n\n3.3.3.3 矩量法（Moment Method）\n偏度=0 且 超值峰度=0\n\\[\nH_0:总体偏度系数\\gamma_1=0 或者总体峰度系数\\gamma_2=0\n\\]\n\\[\nz_i=\\frac{g_i-0}{\\sigma_{g_i}}  \\ \\ \\ \\ 临界值z_{1-\\alpha/2}\n\\]\n\n3.3.3.4 Shapiro-Wilk检验（小样本）\n\nCodeshapiro.test(mtcars$mpg)  \n#&gt; \n#&gt;  Shapiro-Wilk normality test\n#&gt; \n#&gt; data:  mtcars$mpg\n#&gt; W = 0.94756, p-value = 0.1229\n\n\n\n3.3.3.5 Kolmogorov-Smirnov检验（Lilliefors correction 大样本）\n\nCodeks.test(rnorm(1000),\"pnorm\")\n#&gt; \n#&gt;  Asymptotic one-sample Kolmogorov-Smirnov test\n#&gt; \n#&gt; data:  rnorm(1000)\n#&gt; D = 0.016935, p-value = 0.9366\n#&gt; alternative hypothesis: two-sided\n\n\n\nCodex &lt;- rnorm(50) \ny &lt;- runif(50) \nks.test(x, y)  # perform ks test\n#&gt; \n#&gt;  Exact two-sample Kolmogorov-Smirnov test\n#&gt; \n#&gt; data:  x and y\n#&gt; D = 0.42, p-value = 0.000246\n#&gt; alternative hypothesis: two-sided\n\nx &lt;- rnorm(50)\ny &lt;- rnorm(50)\nks.test(x, y) \n#&gt; \n#&gt;  Exact two-sample Kolmogorov-Smirnov test\n#&gt; \n#&gt; data:  x and y\n#&gt; D = 0.18, p-value = 0.3959\n#&gt; alternative hypothesis: two-sided\n\n\n\n3.3.4 二项分布近似正态分布\n当\\(n\\pi(1-\\pi)≥5 且X\\sim B(n,\\pi)\\)时，\\(P(a≤X≤b)近似等于X\\sim N(n\\pi,n\\pi(1-\\pi))在区间(a-0.5,b+0.5)上的曲线下面积\\)。\n\\[\nZ=\\frac{x-\\mu}{\\sigma}=\\frac{x-n\\pi}{\\sqrt{n\\pi(1-\\pi)}}\n\\]\n\nCodelibrary(patchwork)\nbinom(30,0.5)|norm(mu=15,sigma = 7.5)\n\n\n\n\n\n\n\n\n3.3.5 泊松分布近似正态分布\n当\\(\\lambda≥10 且X\\sim P(\\lambda)\\)时，\\(P(a≤X≤b)近似等于X\\sim N(\\lambda,\\lambda)在区间(a-0.5,b+0.5)上的曲线下面积\\)。\n\\[\nZ=\\frac{x-\\mu}{\\sigma}=\\frac{x-\\lambda}{\\sqrt{\\lambda}}\n\\]\n\n3.3.6 医学参考区间",
    "crumbs": [
      "概率论与数理统计",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>概率论基础</span>"
    ]
  },
  {
    "objectID": "SamplingDistribution.html",
    "href": "SamplingDistribution.html",
    "title": "\n4  抽样分布\n",
    "section": "",
    "text": "4.1 均值（mean）的抽样分布\n假设 \\(X_1,X_2,...,X_n\\)是来自均值为\\(μ\\)，有限方差为\\(σ^2\\)的总体为 \\(X\\)的一组样本量为n的随机样本。\n\\(\\bar X\\) 的抽样分布是指从总体 \\(X\\)中选择的样本量为\\(n\\)的所有可能样本的 \\(\\bar x\\)值（\\(\\bar x=\\frac{1}{n}\\sum_{i}x_i\\)）的分布。\nCode# 标准正态分布\nnorm &lt;- function(mu = 0, sigma = 1, ...) {\n    ggplot() +\n        geom_function(\n            aes(color = \"pdf\"),\n            fun = dnorm,\n            args = list(mean = mu, sd = sigma),\n            linewidth = 1\n        ) +\n        geom_function(\n            aes(color = \"cdf\"),\n            fun = pnorm,\n            linewidth = 1,\n            linetype = \"dashed\"\n        ) +\n        scale_color_manual(values = c(\"pdf\" = \"red\", \"cdf\" = \"blue\")) +\n        scale_x_continuous(name = \"x\",\n                           limits = c(mu - 4 * sigma, mu + 4 * sigma)) +\n        scale_y_continuous(name = \"Density/Probability\", limits = c(0, 1)) +\n        labs(title = paste(\"normal distribution N( \", mu, \", \", sigma, \")\", sep = \"\")) +\n        theme(plot.title = element_text(hjust = 0.5)) +\n        guides(color = guide_legend(title = \"Type\"))\n}\nnorm()",
    "crumbs": [
      "概率论与数理统计",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>抽样分布</span>"
    ]
  },
  {
    "objectID": "SamplingDistribution.html#均值mean的抽样分布",
    "href": "SamplingDistribution.html#均值mean的抽样分布",
    "title": "\n4  抽样分布\n",
    "section": "",
    "text": "4.1.1 \\(N( 0, 1)\\)——σ2 已知的正态总体\n\\[\n\\bar X \\sim N(μ,\\frac{σ^2}{n})\n\\]\n标准化\\(\\bar X\\)\n\\[\nZ=\\frac{\\bar X-\\mu}{\\sigma_{\\bar X}}=\\frac{\\bar X-\\mu}{\\sigma /\\sqrt n} \\sim N(0,1)\n\\]\n均值的标准差即标准误 \\(\\sigma _{\\bar X} =\\frac {\\sigma}{\\sqrt n}\\) 可以用 \\(S _{\\bar X} =\\frac {S}{\\sqrt n}\\) 估计。\n\n4.1.2 \\(N(μ,\\frac{σ^2}{n})\\)——大样本量的非正态总体\n\n中心极限定理（central limit theorem）\n\n当样本量n足够大（n≥30）时，即使随机样本并非来自正态分布总体，样本均值\\(\\bar X\\) 的抽样分布也会近似服从均值为\\(\\mu\\) ，方差为\\(\\sigma^2/n\\) 的正态分布，即\n\\[ \\bar X \\dot{\\sim}  N(μ,\\frac{σ^2}{n}) \\]\n\n\n4.1.3 t分布——σ2 未知的正态分布\n\\(Z\\sim N(0,1)\\)，\\(X\\sim \\chi^2(n)\\) 且X与Z相互独立，则称\n\\[ T=\\frac{Z}{\\sqrt{X/n}} \\]\n为自由度为n 的\\(t\\)分布，记为\\(T\\sim t(n)\\)\n如果\\(Z\\sim N(\\delta,1)\\) ，则称T为非中心化的t分布。记为\\(T\\sim t(n,\\delta)\\) ，称δ为非中心化参数。\nt分布的数学期望和方差：\n\\[\\begin{aligned} E(X)=&0,\\ \\ \\ n\\ge2 \\\\ Var(X)=&\\frac{n}{n-2},\\ \\ \\ n\\ge3 \\end{aligned} \\]\n统计量的分布：\n\\[ t=\\frac{\\bar X-\\mu}{S_{\\bar X}}=\\frac{\\bar X-\\mu}{S /\\sqrt n} \\sim t(\\nu) \\]\n其中自由度（degrees of freedom）\\(\\nu=n-1\\) 。当 \\(\\nu \\to +\\infty 时,t\\sim N(0,1)\\) 。\n\nCodet_distribution &lt;- function(df = 1, ...) {\n  # Generate sequence of x values\n  x &lt;- seq(-10, 10, length.out = 1000)\n  \n  # Calculate the probability density function (PDF) and cumulative distribution function (CDF)  values\n  pdf_values &lt;- dt(x, df) \n  cdf_values &lt;- pt(x, df)\n  \n  # Create the ggplot\n  ggplot(data.frame(x, pdf_values, cdf_values), aes(x = x)) +\n    geom_line(aes(y = pdf_values, color = \"PDF\"), linewidth = 1) +\n    geom_line(aes(y = cdf_values, color = \"CDF\"), linewidth = 1, linetype = \"dashed\") +\n    scale_color_manual(values = c(\"PDF\" = \"red\", \"CDF\" = \"blue\")) +\n    scale_y_continuous(name = \"Density/Probability\") +\n    scale_x_continuous(name = \"x\") +\n    labs(title = paste(\"Student's t-distribution (df =\", df, \")\", sep = \"\")) +\n    guides(color = guide_legend(title = \"Type\"))\n}\nlibrary(patchwork)\nt_distribution(df=10)|norm()",
    "crumbs": [
      "概率论与数理统计",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>抽样分布</span>"
    ]
  },
  {
    "objectID": "SamplingDistribution.html#方差variance的抽样分布",
    "href": "SamplingDistribution.html#方差variance的抽样分布",
    "title": "\n4  抽样分布\n",
    "section": "\n4.2 方差（variance）的抽样分布",
    "text": "4.2 方差（variance）的抽样分布\n\n4.2.1 \\(\\chi^2\\)分布\n\\(Z_i\\sim N(0,1)\\),且\\(Z_i\\)相互独立，则称\n\\[\nX=Z_1^2+Z_2^2+...+Z_n^2\n\\]\n为自由度为n的\\(\\chi^2\\)分布，记为\\(X\\sim \\chi^2(n)\\)\n如果\\(Z_i\\sim N(\\delta,1)\\) ，则称X为非中心化的卡方分布。记为\\(X\\sim \\chi^2(n,\\delta)\\) ，称δ为非中心化参数。\n卡方分布的数学期望和方差：\n\\[\n\\begin{aligned}\nE(X)=&n\\\\\nVar(X)=&2n\n\\end{aligned}\n\\]\n假设 \\(X_1,X_2,...,X_n\\)是独立同分布于均值为\\(μ\\)，有限方差为\\(σ^2\\)的一组样本量为n的随机样本。统计量的分布：\n\\[\n\\frac {(n-1)S^2}{\\sigma^2}\\sim \\chi^2(\\nu)\n\\]\n其中自由度（degrees of freedom）\\(\\nu=n-1\\) 。\n\nCodechisq_distribution &lt;- function(df = 1, ...) {\n  # Generate sequence of x values\n  x &lt;- seq(0, 20, length.out = 1000)\n  \n  # Calculate the probability density function (PDF) and cumulative distribution function (CDF)  values\n  pdf_values &lt;- dchisq(x, df) \n  cdf_values &lt;- pchisq(x, df)\n  \n  # Create the ggplot\n  ggplot(data.frame(x, pdf_values, cdf_values), aes(x = x)) +\n    geom_line(aes(y = pdf_values, color = \"PDF\"), size = 1) +\n    geom_line(aes(y = cdf_values, color = \"CDF\"), size = 1, linetype = \"dashed\") +\n    scale_color_manual(values = c(\"PDF\" = \"red\", \"CDF\" = \"blue\")) +\n    scale_y_continuous(name = \"Density/Probability\") +\n    scale_x_continuous(name = \"x\") +\n    labs(title = paste(\"Chi square distribution (df =\", df, \")\", sep = \"\")) +\n    guides(color = guide_legend(title = \"Type\"))\n}\n(chisq_distribution(df=1)+chisq_distribution(df=2))/\n(chisq_distribution(df=4)+chisq_distribution(df=10))+plot_layout(guides = \"collect\")\n\n\n\n\n\n\n\n\n4.2.2 F分布\n\\(X\\sim \\chi^2(n_1)\\) ，\\(Y\\sim \\chi^2(n_2)\\)且相互独立，则称\n\\[ F=\\frac{X/n1}{Y/n2}\\]\n为第一个自由度为n1和第二个自由度为n2的\\(F\\)分布，记为\\(F\\sim F(n_1,n_2)\\)\n如果\\(X\\sim \\chi^2(n_1,\\delta)\\) ，则称F为非中心化的F分布。记为\\(F\\sim F(n_1,n_2;\\delta)\\) ，称δ为非中心化参数。\n卡方分布的数学期望和方差：\n\\[\\begin{aligned} E(X)=&n\\\\ Var(X)=&2n \\end{aligned} \\]\n\nCodeF_distribution &lt;- function(df1 = 1,df2 = 1, ...) {\n  # Generate sequence of x values\n  x &lt;- seq(0, 10, length.out = 1000)\n  \n  # Calculate the probability density function (PDF) and cumulative distribution function (CDF)  values\n  pdf_values &lt;- df(x, df1,df2) \n  cdf_values &lt;- pchisq(x, df1,df2)\n  \n  # Create the ggplot\n  ggplot(data.frame(x, pdf_values, cdf_values), aes(x = x)) +\n    geom_line(aes(y = pdf_values, color = \"PDF\"), size = 1) +\n    geom_line(aes(y = cdf_values, color = \"CDF\"), size = 1, linetype = \"dashed\") +\n    scale_color_manual(values = c(\"PDF\" = \"red\", \"CDF\" = \"blue\")) +\n    scale_y_continuous(name = \"Density/Probability\") +\n    scale_x_continuous(name = \"x\") +\n    labs(title = paste(\"F distribution (df1 =\", df1,\", \",\"df2 = \",df2, \")\", sep = \"\")) +\n    guides(color = guide_legend(title = \"Type\"))\n}\n(F_distribution(1,1)+F_distribution(3,1))/\n    (F_distribution(3,15)+F_distribution(7,15))+plot_layout(guides = \"collect\")\n\n\n\n\n\n\n\n\n4.2.3 比率（rate）抽样分布——分类数据\n假设 \\(X\\sim B(n,\\pi)\\) ，一组样本量为n的随机样本。列出样本量为\\(n\\)的所有可能随机样本。\n样本比率\\(p=X/n\\) ，则 \\[\nE(p)=E(X/n)=\\frac{1}{n}E(X)=\\pi\n\\]\n\\[\nVar(p)=Var(X/n)=\\frac{1}{n^2}Var(X)=\\frac{\\pi(1-\\pi)}{n}\n\\]\n比率的标准误 \\(\\sigma_p =\\sqrt{\\frac{\\pi(1-\\pi)}{n}}\\) 可以用 \\(S _p =\\sqrt{\\frac{p(1-p)}{n}}\\) 估计。\n当\\(n\\pi(1-\\pi)≥5 且X\\sim B(n,\\pi)\\)时，率的抽样分布\n\\[\np\\dot\\sim N(\\pi,\\frac{\\pi(1-\\pi)}{n})\n\\]",
    "crumbs": [
      "概率论与数理统计",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>抽样分布</span>"
    ]
  },
  {
    "objectID": "ParameterEstimation.html",
    "href": "ParameterEstimation.html",
    "title": "5  参数估计",
    "section": "",
    "text": "5.1 一个总体的参数估计",
    "crumbs": [
      "概率论与数理统计",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>参数估计</span>"
    ]
  },
  {
    "objectID": "ParameterEstimation.html#一个总体的参数估计",
    "href": "ParameterEstimation.html#一个总体的参数估计",
    "title": "5  参数估计",
    "section": "",
    "text": "5.1.0.1 点估计\n假设 \\(\\theta\\)是总体\\(X\\)的一个参数，\\(\\hat\\theta=\\hat\\theta(X_1,X_2,...,X_n)\\)是代表\\(\\theta\\)的数值估计的一个统计量。任何可能的\\(\\hat\\theta\\)称为\\(\\theta\\)的点估计。\n\n无偏性（unbiasedness）\n如果\\(E(\\hat\\theta)=\\theta\\),就说参数\\(\\theta\\)的一个估计\\(\\hat\\theta\\)是无偏的。\n\\[\n\\bar X=\\sum_{i=1}^{n}X_i/n\n\\]\n\\[\nE(\\bar X)=\\frac{1}{n}E(\\sum_{i=1}^{n}X_i)=\\frac{n\\mu}{\\mu}=\\mu\n\\]\n所以样本均值\\(\\bar X\\)是总体均值\\(\\mu\\)的一个无偏估计。\n\\[\nS^2=\\frac{1}{n-1}\\sum_{i=1}^{n}(X_i-\\bar X)^2\n\\]\n\\[\nE(S^2)=E(\\frac{n}{n-1}S_n^2)=\\frac{n}{n-1}E(S_n^2)=\\frac{n}{n-1}E(\\frac {1}{n}\\sum_{i=1}^{n}(X_i-\\bar X)^2\\\\=\\frac{n}{n-1}\\times\\frac{n-1}{n}\\sigma^2=\\sigma^2\n\\] 所以样本方差\\(S^2\\)是总体方差\\(\\sigma^2\\)的一个无偏估计。\n\n\n最小方差无偏估计（MVUE）\n\\(\\hat\\theta\\)无偏且最小方差\n\n\n一致性（consistency）\n对于任意一个\\(\\epsilon＞0\\) ，如果 \\[\\lim_{n\\to \\infty}P(|\\hat\\theta_n-\\theta|＜\\epsilon)=1\\] 那么\\(\\hat\\theta_n\\)是总体参数\\(\\theta\\)的一个一致估计。\n\n\n\n5.1.1 区间估计\n\n5.1.1.1 均值的区间估计\n\n\\(\\sigma^2\\)已知的正态分布\n\\(X_1,X_2,...,X_n\\)是来自\\(N(\\mu,\\sigma^2)\\)的随机样本,则\\(\\bar X\\sim N(\\mu,\\frac{\\sigma^2}{n})\\),变换\\(Z=\\frac{\\bar X-\\mu}{\\sigma/\\sqrt n}\\sim N(0,1)\\)。\n对于给定的\\(\\alpha\\)，称\\(z_{\\alpha/2}\\)和\\(z_{1-\\alpha/2}\\)为临界值（critical value）。当\\(Z\\)分布是对称的，\\(z_{\\alpha/2}=-z_{1-\\alpha/2}\\)。\n区间估计的置信水平（confidence level）：\\(1-\\alpha\\)\n总体均值的置信区间（confidence interval）：\\(\\bar X \\pm z_{1-\\alpha/2}\\frac{\\sigma}{\\sqrt n}\\)\n\n\n大样本量的非正态分布\n\\(X_1,X_2,...,X_n\\)是来自非正态分布的随机样本,当样本量足够大时，\\(\\bar X \\dot{\\sim} N(μ,\\frac{σ^2}{n})\\), 变换\\(Z=\\frac{\\bar X-\\mu}{S/\\sqrt n}\\dot\\sim N(0,1)\\)。\n总体均值的置信区间（confidence interval）：\\(\\bar X \\pm z_{1-\\alpha/2}\\frac{S}{\\sqrt n}\\)\n\n\n\\(\\sigma^2\\)未知的正态分布\n\\(X_1,X_2,...,X_n\\)是来自\\(N(\\mu,\\sigma^2)\\)的随机样本,则\\(t=\\frac{\\bar X-\\mu}{S /\\sqrt n} \\sim t(\\nu),\\nu=n-1\\)。\n对于给定的\\(\\alpha\\)，称\\(t_{\\nu,\\alpha/2}\\)和\\(t_{\\nu,1-\\alpha/2}\\)为临界值（critical value）。\\(t_{\\alpha/2}=-t_{1-\\alpha/2}\\)。\n总体均值的置信区间（confidence interval）：\\([\\bar X- t_{\\nu,1-\\alpha/2}\\frac{S}{\\sqrt n},\\bar X+ t_{\\nu,1-\\alpha/2}\\frac{S}{\\sqrt n}]\\)\n\n\n\n5.1.1.2 方差的区间估计\n\\(X_1,X_2,...,X_n\\)是来自\\(N(\\mu,\\sigma^2)\\)的随机样本,则\\(\\frac {(n-1)S^2}{\\sigma^2}\\sim \\chi^2(\\nu),\\nu=n-1\\)\n对于给定的\\(\\alpha\\)，称\\(\\chi^2_{\\nu,\\alpha/2}\\)和\\(\\chi^2_{\\nu,1-\\alpha/2}\\)为临界值（critical value）。\n区间估计的置信水平（confidence level）：\\(1-\\alpha\\)\n总体方差的置信区间（confidence interval）：\\([\\frac {(n-1)S^2}{\\chi^2_{\\nu,1-\\alpha/2}},\\frac {(n-1)S^2}{\\chi^2_{\\nu,\\alpha/2}}]\\)\n\n\n5.1.1.3 比率的区间估计\n\\(X_1,X_2,...,X_n\\)是来自\\(B(n,\\pi)\\)的随机样本, 当\\(n\\pi(1-\\pi)≥5\\)时，比率的抽样分布 \\(p\\dot\\sim N(\\pi,\\frac{\\pi(1-\\pi)}{n})\\)，则变换\\(Z=\\frac{p-\\pi}{\\sqrt{p(1-p)/n}}\\dot\\sim N(0,1)\\)。\n总体率的置信区间（confidence interval）：\\(\\bar p \\pm z_{1-\\alpha/2}\\sqrt{\\frac{p(1-p)}{n}}\\)",
    "crumbs": [
      "概率论与数理统计",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>参数估计</span>"
    ]
  },
  {
    "objectID": "ParameterEstimation.html#两个总体的参数估计",
    "href": "ParameterEstimation.html#两个总体的参数估计",
    "title": "5  参数估计",
    "section": "5.2 两个总体的参数估计",
    "text": "5.2 两个总体的参数估计\n\n5.2.1 均值差值的估计\n\n5.2.1.1 点估计\n\\[E(\\bar X_1-\\bar X_2)=\\mu_1-\\mu_2\\]\n\\[Var(\\bar X_1-\\bar X_2)=\\frac{\\sigma^2_1}{n_1}+\\frac{\\sigma^2_2}{n_2}\\]\n统计量\\(\\bar X_1-\\bar X_2\\)是\\(\\mu_1-\\mu_2\\)的MVUE。\n\n\n5.2.1.2 区间估计\n\n正态分布或中心极限定理成立\n当\\(n_1＞30\\ \\&\\ n_2＞30\\)时，\n\\[\n(\\bar X_1-\\bar X_2) \\dot\\sim N(\\mu_1-\\mu_2,\\frac{\\sigma^2_1}{n_1}+\\frac{\\sigma^2_2}{n_2})\n\\] 标准化变换 \\[\nZ=\\frac{(\\bar X_1-\\bar X_2)-(\\mu_1-\\mu_2)}{\\sqrt{\\frac{\\sigma^2_1}{n_1}+\\frac{\\sigma^2_2}{n_2}}}\\dot\\sim N(0,1)\n\\] 用样本方差代替总体方差，总体均值的置信区间（confidence interval）：\\(\\bar X_1-\\bar X_2 \\pm z_{1-\\alpha/2}\\sqrt{\\frac{S^2_1}{n_1}+\\frac{S^2_2}{n_2}}\\)\n\n\n方差相等的未知正态分布\n\\[\nt=\\frac{(\\bar X_1-\\bar X_2)-(\\mu_1-\\mu_2)}{S_{\\bar X_1-\\bar X_2}}\\sim t(\\nu)\n\\]\n其中\\(v=n_1+n_2-2\\) 和 \\[\nS_{\\bar X_1-\\bar X_2}=\\sqrt{S_C^2(\\frac{1}{n_1}+\\frac{1}{n_2})}\n\\]\n其中\\(S_C^2=\\frac {(n_1-1)S_1^2+(n_2-1)S_2^2}{n_1+n_2-2}\\)是\\(S_1^2\\)和\\(S_2^2\\)的加权平均，也称为合并样本方差（pooled sample variance）\n总体均值的置信区间（confidence interval）：\\(\\bar X_1-\\bar X_2 \\pm t_{\\nu,1-\\alpha/2} S_{\\bar X_1-\\bar X_2}\\)\n\n\n方差不等的未知正态分布\n\\[\nt'=\\frac{(\\bar X_1-\\bar X_2)-(\\mu_1-\\mu_2)}{\\sqrt{\\frac{S_1^2}{n_1}+\\frac{S_2^2}{n_2}}}\\sim t(\\nu ')\n\\]\n其中 \\[\nv'=\\frac{(\\frac{S_1^2}{n_1}+\\frac{S_2^2}{n_2})^2}{\\frac{(\\frac{S_1^2}{n_1})^2}{n_1-1}+\\frac{(\\frac{S_2^2}{n_2})^2}{n_2-1}}(舍入到最近整数)\n\\]\n总体均值的置信区间（confidence interval）：\\(\\bar X_1-\\bar X_2 \\pm t_{\\nu ',1-\\alpha/2} \\sqrt{\\frac{S_1^2}{n_1}+\\frac{S_2^2}{n_2}}\\)\n\n\n\n\n5.2.2 方差比的估计\n\n5.2.2.1 点估计\n\\[X_1\\sim N(\\mu_1,\\sigma_1^2)\\]\n\\[X_2\\sim N(\\mu_2,\\sigma_2^2)\\]\n统计量\\(S_1^2/S_2^2\\)是\\(\\sigma_1^2/\\sigma_2^2\\)的MVUE。\n\n\n5.2.2.2 区间估计\n\\[\nF=\\frac{\\frac {(n_1-1)S_1^2}{\\sigma_1^2}/(n_1-1)}{\\frac {(n_2-1)S_2^2}{\\sigma_2^2}/(n_2-1)}=(\\frac{S_1^2}{S_2^2})(\\frac{\\sigma_2^2}{\\sigma_1^2})\\sim F(\\nu_1,\\nu_2),\\nu_1=n_1-1,\\nu_2=n_2-1\n\\] 对于给定的\\(\\alpha\\)，称\\(F_{(\\nu_1,\\nu_2),\\alpha/2}\\)和\\(F_{(\\nu_1,\\nu_2),1-\\alpha/2}\\)为临界值（critical value）。\\(F_{(\\nu_1,\\nu_2),\\alpha/2}=\\frac{1}{F_{(\\nu_1,\\nu_2),1-\\alpha/2}}\\)\n总体方差的置信区间（confidence interval）：\\([\\frac{S_1^2}{S_2^2}\\times \\frac{1}{F_{(\\nu_1,\\nu_2),1-\\alpha/2}},\\frac{S_1^2}{S_2^2}\\times \\frac{1}{F_{(\\nu_1,\\nu_2),\\alpha/2}}]\\)\n\n\n\n5.2.3 比率差异的估计\n\n5.2.3.1 点估计\n当\\(n_ip_i(1-p_i)≥5,(i=1,2)\\)时，\\(p_i\\dot\\sim N(\\pi_i,\\frac{\\pi_i(1-\\pi_i)}{n_i})\\)\n\\(E(p_1-p_2)=\\pi_1-\\pi_2\\)\n\\(Var(p_1-p_2)=\\frac{\\pi_1(1-\\pi_1)}{n_1}+\\frac{\\pi_2(1-\\pi_2)}{n_2}\\)\n统计量\\(p_1-p_2\\)是\\(\\pi_1-\\pi_2\\)的MVUE。\n\n\n5.2.3.2 区间估计\n\\[\n(p_1-p_2)\\dot\\sim N(\\pi_1-\\pi_2,\\frac{\\pi_1(1-\\pi_1)}{n_1}+\\frac{\\pi_2(1-\\pi_2)}{n_2})\n\\] 标准化变换 \\[\nZ=\\frac{(p_1-p_2)-(\\pi_1-\\pi_2)}{S_{p_1-p_2}}\\dot\\sim N(0,1)\n\\] 其中\\(S_{p_1-p_2}=\\sqrt{\\frac{p_1(1-p_1)}{n_1}+\\frac{p_2(1-p_2)}{n_2}}\\)",
    "crumbs": [
      "概率论与数理统计",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>参数估计</span>"
    ]
  },
  {
    "objectID": "hypothesis_test.html",
    "href": "hypothesis_test.html",
    "title": "6  假设检验",
    "section": "",
    "text": "6.1 标准流程",
    "crumbs": [
      "概率论与数理统计",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>假设检验</span>"
    ]
  },
  {
    "objectID": "hypothesis_test.html#标准流程",
    "href": "hypothesis_test.html#标准流程",
    "title": "6  假设检验",
    "section": "",
    "text": "建立假设和确定显著性水平\n\nnull hypothesis：\\(H_0\\)\nalternative hypothesis：\\(H_1\\)\n显著性水平/犯第\\(Ⅰ\\)类错误（拒绝真\\(H_0\\)）的概率/拒绝域的概率：\\(α\\)\n\n选择检验方法和计算检验统计量\n\n\\(t\\)检验，\\(z\\)检验，\\(\\chi^2\\)检验，\\(F\\)检验，非参数检验等\n\n根据P值做出统计推断\n\np≤α，拒绝\\(H_0\\)，接受\\(H_1\\)\np＞α，不拒绝\\(H_0\\)",
    "crumbs": [
      "概率论与数理统计",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>假设检验</span>"
    ]
  },
  {
    "objectID": "hypothesis_test.html#功效分析",
    "href": "hypothesis_test.html#功效分析",
    "title": "6  假设检验",
    "section": "6.2 功效分析",
    "text": "6.2 功效分析\nhttps://www.statmethods.net/stats/power.html\n\n第\\(Ⅰ\\)类错误：拒绝真\\(H_0\\)，犯第Ⅰ类错误的概率\\(\\alpha=P(reject\\  H_0|H_0\\ is\\ True)\\)\n第\\(Ⅱ\\)类错误：不拒绝假\\(H_0\\)，犯第Ⅱ类错误的概率\\(\\beta=(not\\ reject\\  H_0|H_1\\ is\\ True)\\)\n功效 \\(power=1-β=P(reject\\  H0|H1 \\ is\\  True)\\)\n效应值 effect size 备择假设下的效应值\n样本量 sample size",
    "crumbs": [
      "概率论与数理统计",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>假设检验</span>"
    ]
  },
  {
    "objectID": "hypothesis_test.html#假设检验与区间估计",
    "href": "hypothesis_test.html#假设检验与区间估计",
    "title": "6  假设检验",
    "section": "6.3 假设检验与区间估计",
    "text": "6.3 假设检验与区间估计\n如果参数\\(θ\\)的\\((1-α)×100\\%\\)置信区间CI包含参数\\(\\theta_0\\)所有的估计值，那么不拒绝\\(H_0\\);\n如果参数\\(θ\\)的\\((1-α)×100\\%\\)置信区间CI不包含参数\\(\\theta_0\\)任意一个估计值，那么拒绝\\(H_0\\);\np value 和 CI 对于统计推断同等重要，尤其是大样本量。",
    "crumbs": [
      "概率论与数理统计",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>假设检验</span>"
    ]
  },
  {
    "objectID": "normality_test.html",
    "href": "normality_test.html",
    "title": "\n7  正态性检验\n",
    "section": "",
    "text": "7.1 描述性统计方法",
    "crumbs": [
      "概率论与数理统计",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>正态性检验</span>"
    ]
  },
  {
    "objectID": "normality_test.html#描述性统计方法",
    "href": "normality_test.html#描述性统计方法",
    "title": "\n7  正态性检验\n",
    "section": "",
    "text": "7.1.1 密度图\n密度图提供了关于分布是否为钟形的视觉判断\n\nCodeggdensity(df$ctrl, fill = \"lightgray\") +\n   #  stat_overlay_normal_density(color = \"red\", linetype = \"dashed\")+\n    xlim(c(mean(df$ctrl) - 3 * sd(df$ctrl), \n           mean(df$ctrl) + 3 * sd(df$ctrl)))\n\n\n\n\n\n\n\n\n7.1.2 Q-Q图\nQ-Q图（或分位数-分位数图）绘制给定样本与正态分布之间的相关性。还绘制了一条 45 度参考线。在 QQ 图中，每个观测值都绘制为一个点。如果数据是正常的，则点应形成一条直线。\n\nCodeggqqplot(df$ctrl)\n\n\n\n\n\n\n\n\nCodenorm &lt;- rnorm(1000,10,3)\nggqqplot(norm)\n\n\n\n\n\n\nCodeunif &lt;- runif(1000,5,15)\nggqqplot(unif)\n\n\n\n\n\n\nCode\nexp &lt;- rexp(1000,1)\nggqqplot(exp)",
    "crumbs": [
      "概率论与数理统计",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>正态性检验</span>"
    ]
  },
  {
    "objectID": "normality_test.html#基于卡方分布",
    "href": "normality_test.html#基于卡方分布",
    "title": "\n7  正态性检验\n",
    "section": "\n7.2 基于卡方分布",
    "text": "7.2 基于卡方分布\n\n7.2.1 D’Agostino-Pearson Omnibus Test\nD’Agostino-Pearson test\nD’Agostino-Pearson 综合检验 是基于数据的偏度和峰度来评估数据是否接近正态分布的。\n\n首先计算偏斜度和峰度，以量化分布在不对称性和形状方面与高斯分布的差距。然后，其计算这些值中的每一个与高斯分布的预期值之间的差异，并基于这些差异的总和，计算各P值。这是一种通用和强大的正态性检验，通常推荐使用。但值得注意的是，该建议也有例外。具体而言，当该分布的偏度和峰度非常接近正态分布的偏度和峰度，但肯定是非正态分布时，该检验将无法将该分布确定为非正态分布。\n\n\n\n\n在R语言中，可以使用 moments 包中的 agostino.test() 函数来执行此检验。此检验的原假设是数据来自正态分布，如果检验的p值小于显著性水平（通常是0.05），则可以拒绝原假设，认为数据不服从正态分布。\n\nCodemoments::agostino.test(df$ctrl)\n#&gt; \n#&gt;  D'Agostino skewness test\n#&gt; \n#&gt; data:  df$ctrl\n#&gt; skew = -0.20140, z = -0.41707, p-value = 0.6766\n#&gt; alternative hypothesis: data have a skewness\nmoments::agostino.test(df$trt)\n#&gt; \n#&gt;  D'Agostino skewness test\n#&gt; \n#&gt; data:  df$trt\n#&gt; skew = 0.15146, z = 0.31410, p-value = 0.7534\n#&gt; alternative hypothesis: data have a skewness\n\n# 样本偏度和峰度\nskewness &lt;- moments::skewness(df$ctrl,na.rm = T)\nkurtosis &lt;- moments::kurtosis(df$ctrl,na.rm = T)\n# D'Agostino's K² 检验\nK2 &lt;- length(df$ctrl) * (skewness^2 / 6 + (kurtosis - 3)^2 / 24)\np_value &lt;- 1 - pchisq(K2, df = 2)\n\nK2\n#&gt; [1] 0.8247351\np_value\n#&gt; [1] 0.6620809\n\n\n\n7.2.2 Jarque-Bera 正态性检验\nJarque-Bera检验也是一种基于样本偏度和峰度的正态性检验方法。\n\n\n\n\n\nCodeif(!require(tseries)){install.packages('tseries')}\ntseries::jarque.bera.test(df$ctrl)\n#&gt; \n#&gt;  Jarque Bera Test\n#&gt; \n#&gt; data:  df$ctrl\n#&gt; X-squared = 0.82474, df = 2, p-value = 0.6621\ntseries::jarque.bera.test(df$trt)\n#&gt; \n#&gt;  Jarque Bera Test\n#&gt; \n#&gt; data:  df$trt\n#&gt; X-squared = 0.69681, df = 2, p-value = 0.7058\n\n\n\n7.2.3 Pearson’s X2 test\n\nCode\n\nnortest::pearson.test(df$ctrl)\n#&gt; \n#&gt;  Pearson chi-square normality test\n#&gt; \n#&gt; data:  df$ctrl\n#&gt; P = 2.375, p-value = 0.6671\nnortest::pearson.test(df$trt)\n#&gt; \n#&gt;  Pearson chi-square normality test\n#&gt; \n#&gt; data:  df$trt\n#&gt; P = 3.25, p-value = 0.5169",
    "crumbs": [
      "概率论与数理统计",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>正态性检验</span>"
    ]
  },
  {
    "objectID": "normality_test.html#基于回归和相关",
    "href": "normality_test.html#基于回归和相关",
    "title": "\n7  正态性检验\n",
    "section": "\n7.3 基于回归和相关",
    "text": "7.3 基于回归和相关\n\n7.3.1 Shapiro-Wilk’s test\nShapiro-Wilk检验而是将数据的实际SD与根据数据的QQ图斜率计算的SD进行比较，并计算其比率。如果数据从高斯分布中采样，则两个值将相似，因此比率将接近1.0，而比率与1相差很大则表明为非正态分布。如果每个值均唯一，则Shapiro-Wilk检验非常有效，但如果几个值均相同，则不那么有效。推荐样本量 7~2000。\n这些检验的原假设是“样本分布是正态的”。如果检验显著，则分布为非正态分布。Shapiro-Wilk 方法被广泛推荐用于正态性检验，它提供了比 K-S 更好的功率。 它基于数据与相应的正常分数之间的相关性。\n\n\n\n\n\n\nNote\n\n\n\n正态性检验对样本量很敏感。小样本通常通过正态性检验。因此，为了做出正确的决定，将图示法和显著性检验结合起来是很重要的。如果样本数量大于 50，则首选正态 QQ 图，因为在较大的样本量下，Shapiro-Wilk 检验变得非常敏感，即使与正态的微小偏差也是如此。\n\n\n\nCodemap_df(df,~ shapiro.test(.x)[c(\"statistic\",\"p.value\")])\n\n\n\n\nstatistic\np.value\n\n\n\n0.9607632\n0.6756693\n\n\n0.9655983\n0.7632600\n\n\n\n\n\nCodedf %&gt;% shapiro_test(ctrl,trt)\n\n\n\n\nvariable\nstatistic\np\n\n\n\nctrl\n0.9607632\n0.6756693\n\n\ntrt\n0.9655983\n0.7632600\n\n\n\n\n\n\n\nCodeToothGrowth %&gt;%\n  group_by(dose) %&gt;%\n  shapiro_test(len)\n\n\n\n\ndose\nvariable\nstatistic\np\n\n\n\n0.5\nlen\n0.9406451\n0.2466015\n\n\n1.0\nlen\n0.9313431\n0.1638821\n\n\n2.0\nlen\n0.9777535\n0.9019115\n\n\n\n\n\n\n\nCode# Shapiro Wilk normality test for two variables\niris %&gt;% shapiro_test(Sepal.Length, Petal.Width)\n\n\n\n\nvariable\nstatistic\np\n\n\n\nPetal.Width\n0.9018349\n0.0000000\n\n\nSepal.Length\n0.9760903\n0.0101812\n\n\n\n\n\n\n\nCode# Multivariate normality test\nmshapiro_test(iris[, 1:3])\n\n\n\n\nstatistic\np.value\n\n\n0.9908412\n0.4426676",
    "crumbs": [
      "概率论与数理统计",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>正态性检验</span>"
    ]
  },
  {
    "objectID": "normality_test.html#基于经验分布函数empirical-distribution-function",
    "href": "normality_test.html#基于经验分布函数empirical-distribution-function",
    "title": "\n7  正态性检验\n",
    "section": "\n7.4 基于经验分布函数（empirical distribution function）",
    "text": "7.4 基于经验分布函数（empirical distribution function）\n\n7.4.1 Kolmogorov-Smirnov (K-S) test\nKolmogorov-Smirnov检验（K-S检验），这是一种非参数检验方法，用于比较一个样本的累积分布函数（CDF）与某个理论CDF的差异。需要指定总体的均值和方差\n不建议使用Kolmogorov-Smirnov检验。但在大样本（&gt;2000）实用\n\nCodeks.test(df$ctrl,\"pnorm\",mean=mean(df$ctrl),sd=sd(df$ctrl))\n#&gt; Warning in ks.test.default(df$ctrl, \"pnorm\", mean = mean(df$ctrl), sd =\n#&gt; sd(df$ctrl)): ties should not be present for the one-sample Kolmogorov-Smirnov\n#&gt; test\n#&gt; \n#&gt;  Asymptotic one-sample Kolmogorov-Smirnov test\n#&gt; \n#&gt; data:  df$ctrl\n#&gt; D = 0.13004, p-value = 0.9496\n#&gt; alternative hypothesis: two-sided\n\n\n在执行单样本Kolmogorov-Smirnov检验时，数据中不应该存在“ties”，即不应该有重复的数值。如果存在重复的数值，它会影响检验的有效性，因为K-S检验对数据中的“ties”敏感。此时，可以考虑使用其他对“ties”不敏感的检验方法，例如Shapiro-Wilk检验或Lilliefors检验。\n\n7.4.2 Lilliefors test\nLilliefors test 是一个修改版的K-S检验，它使用样本均值和标准差来标准化数据，然后与标准正态分布进行比较\n\nCodenortest::lillie.test(df$ctrl)\n#&gt; \n#&gt;  Lilliefors (Kolmogorov-Smirnov) normality test\n#&gt; \n#&gt; data:  df$ctrl\n#&gt; D = 0.13004, p-value = 0.6656\nnortest::lillie.test(df$trt)\n#&gt; \n#&gt;  Lilliefors (Kolmogorov-Smirnov) normality test\n#&gt; \n#&gt; data:  df$trt\n#&gt; D = 0.11011, p-value = 0.87\n\n\n\n7.4.3 Anderson-Darling test\nAnderson-Darling test 是基于累积分布函数（CDF）的比较，通过计算观测值与理论分布之间的差异程度来评估数据的拟合程度。在R语言中，可以使用 nortest 包中的 ad.test() 函数来执行此检验291011。此检验的原假设同样是数据服从正态分布，如果p值小于显著性水平，则拒绝原假设，认为数据不服从正态分布。对尾部敏感，适用于中等样本量的数据\n\nCodenortest::ad.test(df$ctrl)\n#&gt; \n#&gt;  Anderson-Darling normality test\n#&gt; \n#&gt; data:  df$ctrl\n#&gt; A = 0.24254, p-value = 0.7247\nnortest::ad.test(df$trt)\n#&gt; \n#&gt;  Anderson-Darling normality test\n#&gt; \n#&gt; data:  df$trt\n#&gt; A = 0.24294, p-value = 0.7233",
    "crumbs": [
      "概率论与数理统计",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>正态性检验</span>"
    ]
  },
  {
    "objectID": "normality_test.html#数据变换",
    "href": "normality_test.html#数据变换",
    "title": "\n7  正态性检验\n",
    "section": "\n7.5 数据变换",
    "text": "7.5 数据变换\n\n7.5.1 中度偏度-平方根变换\n\nCodelibrary(moments)\nskewness(iris$Sepal.Length, na.rm = TRUE)\n#&gt; [1] 0.3117531\ne1071::skewness(iris$Sepal.Length, na.rm = TRUE)\n#&gt; [1] 0.3086407\n\n\n\nsqrt(x)对于正偏态数据，\nsqrt(max(x+1) - x)对于负偏态数据\n\n7.5.2 更偏态-对数变换\n\nlog10(x)对于正偏态数据，\nlog10(max(x+1) - x)对于负偏态数据\n\n7.5.3 非常偏态-倒数\n\n1/x对于正偏态数据\n1/(max(x+1) - x)对于负偏态数据\n\n7.5.4 线性度和异方差性\nLinearity and heteroscedasticity\n\n首先，在因变量随着自变量值的增加而开始更快地增加的情况下尝试log 变换\n如果数据与此相反（因变量值随着自变量值的增加而减少得更快）可以考虑square变换\n\n\nCodelibrary(ggpubr)\nlibrary(moments)\ndata(\"USJudgeRatings\")\ndf &lt;- USJudgeRatings\nhead(df)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCONT\nINTG\nDMNR\nDILG\nCFMG\nDECI\nPREP\nFAMI\nORAL\nWRIT\nPHYS\nRTEN\n\n\n\nAARONSON,L.H.\n5.7\n7.9\n7.7\n7.3\n7.1\n7.4\n7.1\n7.1\n7.1\n7.0\n8.3\n7.8\n\n\nALEXANDER,J.M.\n6.8\n8.9\n8.8\n8.5\n7.8\n8.1\n8.0\n8.0\n7.8\n7.9\n8.5\n8.7\n\n\nARMENTANO,A.J.\n7.2\n8.1\n7.8\n7.8\n7.5\n7.6\n7.5\n7.5\n7.3\n7.4\n7.9\n7.8\n\n\nBERDON,R.I.\n6.8\n8.8\n8.5\n8.8\n8.3\n8.5\n8.7\n8.7\n8.4\n8.5\n8.8\n8.7\n\n\nBRACKEN,J.J.\n7.3\n6.4\n4.3\n6.5\n6.0\n6.2\n5.7\n5.7\n5.1\n5.3\n5.5\n4.8\n\n\nBURNS,E.B.\n6.2\n8.8\n8.7\n8.5\n7.9\n8.0\n8.1\n8.0\n8.0\n8.0\n8.6\n8.6\n\n\n\n\n\n\n\nCode# Distribution of CONT variable\nggdensity(df, x = \"CONT\", fill = \"lightgray\", title = \"CONT\") +\n  scale_x_continuous(limits = c(3, 12)) +\n  stat_overlay_normal_density(color = \"red\", linetype = \"dashed\")\n\n\n\n\n\n\nCode\n# Distribution of PHYS variable\nggdensity(df, x = \"PHYS\", fill = \"lightgray\", title = \"PHYS\") +\n  scale_x_continuous(limits = c(3, 12)) +\n  stat_overlay_normal_density(color = \"red\", linetype = \"dashed\")\n\n\n\n\n\n\n\n\nCodeskewness(df$CONT, na.rm = TRUE)\n#&gt; [1] 1.085972\nskewness(df$PHYS, na.rm = TRUE)\n#&gt; [1] -1.558215\n\n\n\n7.5.5 Box-Cox 幂次变换\n\nCodebc &lt;- car::powerTransform(df)\n\nbc\n#&gt; Estimated transformation parameters \n#&gt;       CONT       INTG       DMNR       DILG       CFMG       DECI       PREP \n#&gt; -0.9819079  3.8646573  3.1866054  3.0071768  3.2197291  2.8949756  2.2797376 \n#&gt;       FAMI       ORAL       WRIT       PHYS       RTEN \n#&gt;  2.0508085  2.4118066  2.2521739  4.9918792  3.3428550\nsummary(bc)\n#&gt; bcPower Transformations to Multinormality \n#&gt;      Est Power Rounded Pwr Wald Lwr Bnd Wald Upr Bnd\n#&gt; CONT   -0.9819        0.00      -2.7096       0.7458\n#&gt; INTG    3.8647        3.86       2.3656       5.3637\n#&gt; DMNR    3.1866        3.19       2.1669       4.2063\n#&gt; DILG    3.0072        2.00       1.9536       4.0607\n#&gt; CFMG    3.2197        3.22       2.1068       4.3326\n#&gt; DECI    2.8950        2.00       1.6568       4.1332\n#&gt; PREP    2.2797        2.00       1.5568       3.0026\n#&gt; FAMI    2.0508        2.00       1.1463       2.9553\n#&gt; ORAL    2.4118        2.00       1.8057       3.0180\n#&gt; WRIT    2.2522        2.00       1.5698       2.9346\n#&gt; PHYS    4.9919        4.99       3.1346       6.8491\n#&gt; RTEN    3.3429        3.34       2.5902       4.0955\n#&gt; \n#&gt; Likelihood ratio test that transformation parameters are equal to 0\n#&gt;  (all log transformations)\n#&gt;                                                  LRT df       pval\n#&gt; LR test, lambda = (0 0 0 0 0 0 0 0 0 0 0 0) 121.8881 12 &lt; 2.22e-16\n#&gt; \n#&gt; Likelihood ratio test that no transformations are needed\n#&gt;                                                  LRT df       pval\n#&gt; LR test, lambda = (1 1 1 1 1 1 1 1 1 1 1 1) 61.75316 12 1.0794e-08",
    "crumbs": [
      "概率论与数理统计",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>正态性检验</span>"
    ]
  },
  {
    "objectID": "variance_homogeneity_test.html",
    "href": "variance_homogeneity_test.html",
    "title": "\n8  方差齐性检验\n",
    "section": "",
    "text": "8.1 两组",
    "crumbs": [
      "概率论与数理统计",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>方差齐性检验</span>"
    ]
  },
  {
    "objectID": "variance_homogeneity_test.html#两组",
    "href": "variance_homogeneity_test.html#两组",
    "title": "\n8  方差齐性检验\n",
    "section": "",
    "text": "8.1.1 F 检验\nF 检验：比较两组的方差。数据必须呈正态分布。\n步骤：\n\n检查数据是否呈正态分布（例如使用 Shapiro-Wilk 检验）。\n进行 F 检验以比较两组的方差。\n\n\nCodedf &lt;- tibble(\n    ctrl=c(2,6,13,5,8,9,12,11,8,10,12,14,13,6,7,4),\n    trt=c(8,6,8,9,12,12,14,15,16,17,14,12,11,8,10,10)\n)\ndf\n\n\n\n\nctrl\ntrt\n\n\n\n2\n8\n\n\n6\n6\n\n\n13\n8\n\n\n5\n9\n\n\n8\n12\n\n\n9\n12\n\n\n12\n14\n\n\n11\n15\n\n\n8\n16\n\n\n10\n17\n\n\n12\n14\n\n\n14\n12\n\n\n13\n11\n\n\n6\n8\n\n\n7\n10\n\n\n4\n10\n\n\n\n\n\nCodevar.test(df$ctrl,df$trt)\n#&gt; \n#&gt;  F test to compare two variances\n#&gt; \n#&gt; data:  df$ctrl and df$trt\n#&gt; F = 1.2553, num df = 15, denom df = 15, p-value = 0.6653\n#&gt; alternative hypothesis: true ratio of variances is not equal to 1\n#&gt; 95 percent confidence interval:\n#&gt;  0.4385898 3.5927405\n#&gt; sample estimates:\n#&gt; ratio of variances \n#&gt;           1.255285\n\nres &lt;- var.test(len ~ supp, data = ToothGrowth)\nres\n#&gt; \n#&gt;  F test to compare two variances\n#&gt; \n#&gt; data:  len by supp\n#&gt; F = 0.6386, num df = 29, denom df = 29, p-value = 0.2331\n#&gt; alternative hypothesis: true ratio of variances is not equal to 1\n#&gt; 95 percent confidence interval:\n#&gt;  0.3039488 1.3416857\n#&gt; sample estimates:\n#&gt; ratio of variances \n#&gt;          0.6385951\n\n\np 值为 p = 0.2，大于显著性水平 0.05，可以认为两个方差之间没有显著差异。",
    "crumbs": [
      "概率论与数理统计",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>方差齐性检验</span>"
    ]
  },
  {
    "objectID": "variance_homogeneity_test.html#多组",
    "href": "variance_homogeneity_test.html#多组",
    "title": "\n8  方差齐性检验\n",
    "section": "\n8.2 多组",
    "text": "8.2 多组\n\n8.2.1 Bartlett 检验\nBartlett 检验：比较两组或多组的方差。数据必须呈正态分布。\n具有一个自变量的 Bartlett 检验\n\nCoderes &lt;- bartlett.test(weight ~ group, data = PlantGrowth)\nres\n#&gt; \n#&gt;  Bartlett test of homogeneity of variances\n#&gt; \n#&gt; data:  weight by group\n#&gt; Bartlett's K-squared = 2.8786, df = 2, p-value = 0.2371\n\n\n具有多个自变量的 Bartlett 检验：必须使用interaction（） 函数将多个因子折叠成一个包含因子所有组合的变量\n\nCode\nwith(ToothGrowth,interaction(supp,dose)) |&gt; levels()\n#&gt; [1] \"OJ.0.5\" \"VC.0.5\" \"OJ.1\"   \"VC.1\"   \"OJ.2\"   \"VC.2\"\n\n\n\nbartlett.test(len ~ interaction(supp,dose), data=ToothGrowth)\n#&gt; \n#&gt;  Bartlett test of homogeneity of variances\n#&gt; \n#&gt; data:  len by interaction(supp, dose)\n#&gt; Bartlett's K-squared = 6.9273, df = 5, p-value = 0.2261\n\n\n\n8.2.2 Levene’s 检验\nLevene’s 检验：Bartlett 检验的可靠替代方案，对偏离正态不太敏感。\n\n\nLevene 检验有三个版本：\n\n使用平均值（原始）\n使用中位数（Brown-Forsythe扩展）\n10% trimmed mean（Brown-Forsythe扩展）\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nLevene 检验是文献中最常用的检验。\n\n\n\nCodelibrary(car)\n# Levene's test with one independent variable\nleveneTest(weight ~ group, data = PlantGrowth,center=mean)\n\n\n\n\n\nDf\nF value\nPr(&gt;F)\n\n\n\ngroup\n2\n1.236963\n0.3061949\n\n\n\n27\nNA\nNA\n\n\n\n\n\nCodeleveneTest(weight ~ group, data = PlantGrowth,center=mean,trim=0.1)\n\n\n\n\n\nDf\nF value\nPr(&gt;F)\n\n\n\ngroup\n2\n1.277734\n0.2949851\n\n\n\n27\nNA\nNA\n\n\n\n\n\nCodeleveneTest(weight ~ group, data = PlantGrowth,center=median)\n\n\n\n\n\nDf\nF value\nPr(&gt;F)\n\n\n\ngroup\n2\n1.119186\n0.3412266\n\n\n\n27\nNA\nNA\n\n\n\n\n\nCode\nrstatix::levene_test(PlantGrowth,weight ~ group,center = mean)\n\n\n\n\ndf1\ndf2\nstatistic\np\n\n\n2\n27\n1.236963\n0.3061949\n\n\n\n\n\n\nCode# Levene's test with multiple independent variables\nToothGrowth$dose &lt;- factor(ToothGrowth$dose)\nleveneTest(len ~ supp*dose, data = ToothGrowth)\n\n\n\n\n\nDf\nF value\nPr(&gt;F)\n\n\n\ngroup\n5\n1.708578\n0.1483606\n\n\n\n54\nNA\nNA\n\n\n\n\n\n\n\nBrown-Forsythe 检验 作为 Levene 检验的扩展，特别适用于处理非正态数据。\n\n\nCodeleveneTest(weight ~ group, data = PlantGrowth,center=median)\n\n\n\n\n\nDf\nF value\nPr(&gt;F)\n\n\n\ngroup\n2\n1.119186\n0.3412266\n\n\n\n27\nNA\nNA\n\n\n\n\n\nCodeHH::hov(weight ~ group, data = PlantGrowth)\n#&gt; \n#&gt;  hov: Brown-Forsyth\n#&gt; \n#&gt; data:  weight\n#&gt; F = 1.1192, df:group = 2, df:Residuals = 27, p-value = 0.3412\n#&gt; alternative hypothesis: variances are not identical\n\n\n\n8.2.3 Fligner-Killeen 检验\nFligner-Killeen 检验：一种非参数检验，对偏离正态非常稳健。\n\nCodefligner.test(weight ~ group, data = PlantGrowth)\n#&gt; \n#&gt;  Fligner-Killeen test of homogeneity of variances\n#&gt; \n#&gt; data:  weight by group\n#&gt; Fligner-Killeen:med chi-squared = 2.3499, df = 2, p-value = 0.3088",
    "crumbs": [
      "概率论与数理统计",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>方差齐性检验</span>"
    ]
  },
  {
    "objectID": "t_test.html",
    "href": "t_test.html",
    "title": "\n9  t 检验\n",
    "section": "",
    "text": "9.1 假设",
    "crumbs": [
      "概率论与数理统计",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>t 检验</span>"
    ]
  },
  {
    "objectID": "t_test.html#假设",
    "href": "t_test.html#假设",
    "title": "\n9  t 检验\n",
    "section": "",
    "text": "正态性假设 (Normality)：\n\n两组数据应来自正态分布的总体。对于大样本（通常 n &gt; 30），由于中心极限定理，即使数据不完全符合正态分布，t 检验通常仍然稳健。\n\n\n\n方差齐性假设 (Homoscedasticity)：\n\n两组数据的方差应该相等。如果方差不相等，需使用 Welch’s t-test，它不假设方差齐性。\n\n\n\n独立性假设 (Independence)：\n\n样本中的观测应相互独立，一个观测的值不应影响另一个观测的值。",
    "crumbs": [
      "概率论与数理统计",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>t 检验</span>"
    ]
  },
  {
    "objectID": "t_test.html#t检验类型",
    "href": "t_test.html#t检验类型",
    "title": "\n9  t 检验\n",
    "section": "\n9.2 t检验类型",
    "text": "9.2 t检验类型\n\n单样本t检验 (One-sample t-test): 用于比较单个样本的均值与已知的总体均值之间的差异。\n独立样本t检验 (Independent samples t-test): 用于比较两个独立样本的均值差异。\n配对样本t检验 (Paired samples t-test): 用于比较同一组受试者在两个不同条件下的均值差异。\n\n\nCodeggplot() + xlim(-10,10) +\n    geom_function(mapping = aes(color=\"normal Distribution\"),\n                  fun = dnorm, args = list(mean = 0, sd = 1),\n                   )+\n    geom_function(mapping = aes(color=\"t Distribution\"),\n                  fun = dt, args = list(df = 1 ,ncp=0), \n                 )+\n    scale_color_manual(values = c(\"normal Distribution\" = \"red\",\n                                  \"t Distribution\" = \"blue\"))+\n    labs(color = \"Distribution\")\n\n\n\n\n\n\n\nt 检验（Student‘s t test），主要用于小样本（n&lt;30），标准差未知的正态分布总体。在进行t检验之前，可以先通过正态性检验 shapiro.test()",
    "crumbs": [
      "概率论与数理统计",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>t 检验</span>"
    ]
  },
  {
    "objectID": "t_test.html#单样本-t-检验",
    "href": "t_test.html#单样本-t-检验",
    "title": "\n9  t 检验\n",
    "section": "\n9.3 单样本 t 检验",
    "text": "9.3 单样本 t 检验\n在数据符合正态分布的前提下使用单样本t-test来比较一组样本的均值和已知(理论/总体)均值，所谓的已知均值能来自于之前的实验数据或者理论值。根据研究问题(原假设)的不同又分为双尾(不等)和单尾检验(大于或者小于)\n\\[t=\\frac{\\bar X-\\mu_0}{S /\\sqrt n} \\sim t(\\nu=n-1) \\]\n它是一种参数检验，用于检验样本均值是否可以合理地为总体均值或特定值。\n\nCodex&lt;- dplyr::filter(PlantGrowth,group==\"ctrl\")\nsummary(x$weight)\n#&gt;    Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n#&gt;   4.170   4.550   5.155   5.032   5.293   6.110\n\nshapiro.test(x$weight)\n#&gt; \n#&gt;  Shapiro-Wilk normality test\n#&gt; \n#&gt; data:  x$weight\n#&gt; W = 0.95668, p-value = 0.7475\nt.test(x$weight, mu=5)\n#&gt; \n#&gt;  One Sample t-test\n#&gt; \n#&gt; data:  x$weight\n#&gt; t = 0.17355, df = 9, p-value = 0.8661\n#&gt; alternative hypothesis: true mean is not equal to 5\n#&gt; 95 percent confidence interval:\n#&gt;  4.614882 5.449118\n#&gt; sample estimates:\n#&gt; mean of x \n#&gt;     5.032\n\n\n\nCodet_test_two_sided &lt;- function(data,mu,level=0.95,...){\n    \n    bar_X &lt;- mean(data,na.rm = T)\n    sd &lt;- sd(data, na.rm = T)\n    n=length(data)\n    se=sd/sqrt(n)\n    t_statistic &lt;- (bar_X-mu)/se\n    p_value &lt;- 2*(1-pt(abs(t_statistic),df=n-1))\n    t_critical &lt;- qt((1-(1-level)/2),df = n-1)\n    CI_lower &lt;- bar_X - t_critical * se\n    CI_upper &lt;- bar_X+ t_critical * se\n    CI &lt;- paste0(level*100,\"%置信区间: \",\"[\",CI_lower,\",\",CI_upper,\"]\",sep = \"\")\n    \n    output &lt;- list(\n        均值=bar_X,\n        标准差=sd,\n        标准误=se,\n        t=t_statistic,\n        df=n-1,\n        p_value=p_value,\n        CI=CI\n\n    )\n    return(output)\n    \n}\n\n\nt_test_two_sided(x$weight,mu = 5)\n#&gt; $均值\n#&gt; [1] 5.032\n#&gt; \n#&gt; $标准差\n#&gt; [1] 0.5830914\n#&gt; \n#&gt; $标准误\n#&gt; [1] 0.1843897\n#&gt; \n#&gt; $t\n#&gt; [1] 0.1735455\n#&gt; \n#&gt; $df\n#&gt; [1] 9\n#&gt; \n#&gt; $p_value\n#&gt; [1] 0.8660633\n#&gt; \n#&gt; $CI\n#&gt; [1] \"95%置信区间: [4.61488155565504,5.44911844434496]\"",
    "crumbs": [
      "概率论与数理统计",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>t 检验</span>"
    ]
  },
  {
    "objectID": "t_test.html#配对样本t检验",
    "href": "t_test.html#配对样本t检验",
    "title": "\n9  t 检验\n",
    "section": "\n9.4 配对样本t检验",
    "text": "9.4 配对样本t检验\n\\[\nH_0:\\mu_{\\bar d}=0\n\\] \\[\nt=\\frac{\\bar d- \\mu_{\\bar d}}{S_d /\\sqrt n} \\sim t(\\nu)\n\\] 其中\\(d= X_2-X_1,\\mu_{\\bar d}=0\\)。\n\nCodedf &lt;- tribble(\n    ~id,~baseline,~ten_days_later,~d,\n    1,58.27,120.61,62.34,\n    2,59.51,126.33,66.82,\n    3,53.84,108.35,54.51,\n    4,54.70,139.99,85.29,\n    5,54.03,115.29,61.26,\n    6,61.29,146.96,85.67,\n    7,54.72,115.64,60.92,\n    8,70.43,124.62,54.19,\n    9,66.45,121.40,54.95,\n    10,59.31,134.81,75.50,\n    11,63.48,130.73,67.25,\n    12,67.19,118.37,51.18,\n    13,52.92,129.28,76.36,\n    14,71.99,117.40,45.41\n)\nd_mean &lt;- mean(df$d)\nd_sd &lt;- sd(df$d)\nd_se &lt;- d_sd/sqrt(length(df$d))\nt_statistic &lt;- d_mean/d_se\nn &lt;- 14\n\n# p值\np_value &lt;- 2 * (1 - pt(abs(t_statistic),df = n-1 ))\n\n# 查找95%置信水平下的t分布的临界值\nt_critical &lt;- qt(0.975, df=n-1)\n\n# 计算95%置信区间\nCI_lower &lt;- d_mean - t_critical * d_se\nCI_upper &lt;- d_mean + t_critical * d_se\n\n# 输出结果\ncat(\"95% Confidence Interval:\", CI_lower, \"to\", CI_upper)\n#&gt; 95% Confidence Interval: 57.20275 to 71.6044\n\n\n\nCode\nshapiro.test(df$baseline)\n#&gt; \n#&gt;  Shapiro-Wilk normality test\n#&gt; \n#&gt; data:  df$baseline\n#&gt; W = 0.91419, p-value = 0.1813\nshapiro.test(df$ten_days_later)\n#&gt; \n#&gt;  Shapiro-Wilk normality test\n#&gt; \n#&gt; data:  df$ten_days_later\n#&gt; W = 0.96676, p-value = 0.8306\nshapiro.test(df$d)\n#&gt; \n#&gt;  Shapiro-Wilk normality test\n#&gt; \n#&gt; data:  df$d\n#&gt; W = 0.94337, p-value = 0.4632\nt.test(df$ten_days_later,df$baseline,paired = TRUE)\n#&gt; \n#&gt;  Paired t-test\n#&gt; \n#&gt; data:  df$ten_days_later and df$baseline\n#&gt; t = 19.322, df = 13, p-value = 5.866e-11\n#&gt; alternative hypothesis: true mean difference is not equal to 0\n#&gt; 95 percent confidence interval:\n#&gt;  57.20275 71.60440\n#&gt; sample estimates:\n#&gt; mean difference \n#&gt;        64.40357\n#t.test(Pair(df$ten_days_later,df$baseline)~1,data=df)",
    "crumbs": [
      "概率论与数理统计",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>t 检验</span>"
    ]
  },
  {
    "objectID": "t_test.html#两独立样本的均值差异",
    "href": "t_test.html#两独立样本的均值差异",
    "title": "\n9  t 检验\n",
    "section": "\n9.5 两独立样本的均值差异",
    "text": "9.5 两独立样本的均值差异\n\n9.5.1 方差相等——t检验\n\\[H_0:\\mu_1-\\mu_2=0\\]\n\\[\nt=\\frac{(\\bar X_1-\\bar X_2)-(\\mu_1-\\mu_2)}{S_{\\bar X_1-\\bar X_2}}=\\frac{\\bar X_1-\\bar X_2}{S_C\\sqrt{(\\frac{1}{n_1}+\\frac{1}{n_2})}}\n\\]\n其中，\\(S_c^2=\\frac{(n_1-1)S_1^2+(n_2-1)S_2^2}{n_1+n_2-2}\\)\n\nCodedf2 &lt;- tibble(\n    experimental=c(120.61 ,126.33 ,108.35 ,139.99 ,115.29 ,146.96 ,115.64,\n                   124.62 ,121.40 ,134.81 ,130.73 ,118.37 ,129.28 ,117.45),\n    control=c(58.23 ,54.50 ,59.47 ,59.64 ,53.77 ,43.48 ,\n              54.63 ,71.91 ,53.97 ,49.72 ,61.26 ,78.17,NA,NA)\n)\n\ne_mean &lt;- mean(df2$experimental)\ne_sd &lt;- sd(df2$experimental)\nn1 &lt;- length(df2$experimental)\n\nctrl_mean &lt;- mean(df2$control,na.rm = TRUE)\nctrl_sd &lt;- sd(df2$control,na.rm = TRUE)\nn2 &lt;- length(df2$control)-sum(is.na(df2$control))\n\nSc_2 &lt;- ((n1-1)*e_sd^2+(n2-1)*ctrl_sd^2)/(n1+n2-2)\n\nt2 &lt;- (e_mean-ctrl_mean)/sqrt(Sc_2*(1/14+1/12))\n\nt.test(df2$experimental,df2$control,var.equal = TRUE)\n#&gt; \n#&gt;  Two Sample t-test\n#&gt; \n#&gt; data:  df2$experimental and df2$control\n#&gt; t = 16.967, df = 24, p-value = 7.215e-15\n#&gt; alternative hypothesis: true difference in means is not equal to 0\n#&gt; 95 percent confidence interval:\n#&gt;  58.63784 74.87954\n#&gt; sample estimates:\n#&gt; mean of x mean of y \n#&gt; 124.98786  58.22917\n\n\n\n9.5.2 方差是否相等——F检验\n\\[H_0:\\frac{\\sigma_1^2}{\\sigma_2^2}=1\\]\n\\[\nF=\\frac{\\frac {(n_1-1)S_1^2}{\\sigma_1^2}/(n_1-1)}{\\frac {(n_2-1)S_2^2}{\\sigma_2^2}/(n_2-1)}=(\\frac{S_1^2}{S_2^2})(\\frac{\\sigma_2^2}{\\sigma_1^2})=\\frac{S_1^2}{S_2^2}\\sim F(\\nu_1,\\nu_2),\\nu_1=n_1-1,\\nu_2=n_2-1\n\\]\n\nCode# 检验两个样本的方差是否相等\nvar.test(df2$experimental,df2$control)\n#&gt; \n#&gt;  F test to compare two variances\n#&gt; \n#&gt; data:  df2$experimental and df2$control\n#&gt; F = 1.287, num df = 13, denom df = 11, p-value = 0.6831\n#&gt; alternative hypothesis: true ratio of variances is not equal to 1\n#&gt; 95 percent confidence interval:\n#&gt;  0.3794599 4.1152566\n#&gt; sample estimates:\n#&gt; ratio of variances \n#&gt;           1.287025\n\n\n\nCodeF_stats &lt;- (e_sd^2)/(ctrl_sd^2)\nF_stats\n#&gt; [1] 1.287025\n\n# 计算p值\np_value &lt;- 1 - pf(F_stats, df1=13, df2=11, lower.tail =F)\n# p_value &lt;- pf(F_stats, df1=13, df2=11)\n\n\n\nalpha &lt;- 0.05\nconfidence_level &lt;- 1 - alpha\n\n# 计算F分布的临界值\nf_critical_lower &lt;- qf((1 - confidence_level) / 2, df1 = 13, df2 = 11)\nf_critical_upper &lt;- qf(confidence_level, df1 = 13, df2 = 11)\n\n# 计算方差比率的置信区间\nci_lower &lt;- sqrt(f_critical_lower * (ctrl_sd^2 / e_sd^2))\nci_upper &lt;- sqrt(f_critical_upper * (ctrl_sd^2 / e_sd^2))\n\n# 输出结果\ncat(\"95% CI for variances ratio:\", ci_lower, \"to\", ci_upper)\n#&gt; 95% CI for variances ratio: 0.4929485 to 1.464781\n\n\n\n9.5.3 方差不等—— Approximation t 检验\n\\[H_0:\\mu_1-\\mu_2=0\\]\n\\[\nt'=\\frac{(\\bar X_1-\\bar X_2)-(\\mu_1-\\mu_2)}{\\sqrt{\\frac{S_1^2}{n_1}+\\frac{S_2^2}{n_2}}}=\\frac{\\bar X_1-\\bar X_2}{\\sqrt{\\frac{S_1^2}{n_1}+\\frac{S_2^2}{n_2}}}\\sim t(\\nu ')\n\\]\n\n9.5.3.1 Cochran & Cox Approximation t-test\n强调方差的变异\n因为\\(t'\\)既不遵循t分布，也不遵循正态分布，因此t’的临界值需要特定的计算方法。\n\\[\nt'_{\\alpha/2}=\\frac{S^2_{\\bar X_1}t_{\\nu_1,\\alpha/2}+S^2_{\\bar X_2}t_{\\nu_2,\\alpha/2}}{S^2_{\\bar X_1}+S^2_{\\bar X_2}}\n\\]\n\\[\nt'_{1-\\alpha/2}=\\frac{S^2_{\\bar X_1}t_{\\nu_1,1-\\alpha/2}+S^2_{\\bar X_2}t_{\\nu_2,1-\\alpha/2}}{S^2_{\\bar X_1}+S^2_{\\bar X_2}}\n\\] 其中\\(\\nu_1=n_1-1,\\nu_2=n_2-1,t_{\\nu_1,1-\\alpha/2}和t_{\\nu_2,1-\\alpha/2}\\)分别是\\(t_{\\nu_1}和t_{\\nu_2}\\)的临界值。\n因为t分布是对称的，\\(t_{\\nu,\\alpha/2}=-t_{\\nu,1-\\alpha/2}\\)，所以\\(t'_{\\alpha/2}=t'_{1-\\alpha/2}\\)。\n\n9.5.3.2 Satterthwaite Approximation t-test\n强调自由度\n\\[\nv'=\\frac{(\\frac{S_1^2}{n_1}+\\frac{S_2^2}{n_2})^2}{\\frac{(\\frac{S_1^2}{n_1})^2}{n_1-1}+\\frac{(\\frac{S_2^2}{n_2})^2}{n_2-1}}(舍入到最近整数)\n\\]\n\n9.5.4 中心极限定理 大样本量—— Z检验\n当\\(n_1＞30\\ \\&\\ n_2＞30\\)时，\n\\[\n\\bar X_1\\dot\\sim N(\\mu_1,\\frac{\\sigma^2_1}{n_1})\n\\]\n\\[\n\\bar X_2\\dot\\sim N(\\mu_2,\\frac{\\sigma^2_2}{n_2})\n\\]\n\\[H_0:\\mu_1-\\mu_2=0\\]\n\\[\nZ=\\frac{(\\bar X_1-\\bar X_2)-(\\mu_1-\\mu_2)}{\\sqrt{\\frac{\\sigma^2_1}{n_1}+\\frac{\\sigma^2_2}{n_2}}}=\\frac{\\bar X_1-\\bar X_2}{\\sqrt{\\frac{\\sigma^2_1}{n_1}+\\frac{\\sigma^2_2}{n_2}}}\\dot\\sim N(0,1)\n\\]\n实际应用中，总体方差未知，使用t 检验，提供了对总体方差不确定性的自然估计。",
    "crumbs": [
      "概率论与数理统计",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>t 检验</span>"
    ]
  },
  {
    "objectID": "t_test.html#批量t检验",
    "href": "t_test.html#批量t检验",
    "title": "\n9  t 检验\n",
    "section": "\n9.6 批量t检验",
    "text": "9.6 批量t检验",
    "crumbs": [
      "概率论与数理统计",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>t 检验</span>"
    ]
  },
  {
    "objectID": "t_test.html#功效分析",
    "href": "t_test.html#功效分析",
    "title": "\n9  t 检验\n",
    "section": "\n9.7 功效分析",
    "text": "9.7 功效分析\n功效(power) \\(1-β\\approx\\Phi(-z_{1-\\alpha/2}+\\frac{|\\mu_1-\\mu_2|}{\\sqrt {\\sigma_1^2/n_1+\\sigma_2^2/n_2}})\\)\n样本量\n\n两组样本量相等 \\[\nn=\\frac{(\\sigma_1^2+\\sigma_1^2)(z_{1-\\alpha/2}+z_{1-\\beta})^2}{(\\mu_1-\\mu_2)^2}\n\\]\n\n两组样本量不等（\\(n_2=kn_1\\)） \\[\nn_1=\\frac{(\\sigma_1^2+\\sigma_1^2/k)(z_{1-\\alpha/2}+z_{1-\\beta})^2}{(\\mu_1-\\mu_2)^2}\n\\]\n\\[\nn_2=\\frac{(k\\sigma_1^2+\\sigma_1^2)(z_{1-\\alpha/2}+z_{1-\\beta})^2}{(\\mu_1-\\mu_2)^2}\n\\]",
    "crumbs": [
      "概率论与数理统计",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>t 检验</span>"
    ]
  },
  {
    "objectID": "rate_proportion_test.html",
    "href": "rate_proportion_test.html",
    "title": "\n10  比例检验\n",
    "section": "",
    "text": "10.1 单总体\n如果样本比较小，则使用二项分布进行统计. 在R中，对于小样本，采用 binom.test()，对于大样本使用正态分布近似二项分布，利用 prop.test()进行分析。 在单样本比例检验中，我们关心的是具有同种特性的两个群体，在该特性总体中所占有的比例情况。\n\\[\nZ=\\frac{p-\\pi_0}{\\sqrt{\\pi_0(1-\\pi_0)/n}}\\sim N(0,1)\n\\]\nCI：\\(\\bar p \\pm z_{1-\\alpha/2}\\sqrt{\\frac{p(1-p)}{n}}\\)\n对于小样本，可以连续校正\n\\[\nZ_{corr}=\\frac{|p-\\pi_0|-1/(2n)}{\\sqrt{\\pi_0(1-\\pi_0)/n}}\\sim N(0,1)\n\\]\n例如，小鼠中公鼠母鼠各有一半，有100只患有某种疾病，其中有公鼠60只，母鼠40只。想知道是否公鼠患病率比母鼠高。在该问题中成功次数为公鼠患病数60，总次数为100，预期比例为50% ( 公母鼠数量相等)\nCodep &lt;- 0.6\npi_0 &lt;- 0.5\nn &lt;- 100\nZ &lt;- (p-pi_0)/sqrt(pi_0*(1-pi_0)/n)\nZ_corr &lt;- (p-pi_0-1/(2*n))/sqrt(pi_0*(1-pi_0)/n)\nCode# 示例数据\nsuccesses &lt;- 60\ntotal &lt;- 100\np0 &lt;- 0.5\n\n# 使用 prop.test() 函数进行比例检验\nprop.test(\n    x = successes,\n    n = total,\n    p = p0,\n    alternative = \"greater\",\n    correct = F\n)\n#&gt; \n#&gt;  1-sample proportions test without continuity correction\n#&gt; \n#&gt; data:  successes out of total, null probability p0\n#&gt; X-squared = 4, df = 1, p-value = 0.02275\n#&gt; alternative hypothesis: true p is greater than 0.5\n#&gt; 95 percent confidence interval:\n#&gt;  0.5178095 1.0000000\n#&gt; sample estimates:\n#&gt;   p \n#&gt; 0.6\nCodeprop.test(\n    x = successes,\n    n = total,\n    p = p0,\n    alternative = \"greater\",\n    correct = T\n)\n#&gt; \n#&gt;  1-sample proportions test with continuity correction\n#&gt; \n#&gt; data:  successes out of total, null probability p0\n#&gt; X-squared = 3.61, df = 1, p-value = 0.02872\n#&gt; alternative hypothesis: true p is greater than 0.5\n#&gt; 95 percent confidence interval:\n#&gt;  0.5127842 1.0000000\n#&gt; sample estimates:\n#&gt;   p \n#&gt; 0.6",
    "crumbs": [
      "概率论与数理统计",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>比例检验</span>"
    ]
  },
  {
    "objectID": "rate_proportion_test.html#两总体",
    "href": "rate_proportion_test.html#两总体",
    "title": "\n10  比例检验\n",
    "section": "\n10.2 两总体",
    "text": "10.2 两总体\n当样本量较小时(所有np和n(1-p)都小于5)，通常采用非参数检验 Fisher Exact probability test 进行分析。当样本量较大时，使用近似正态分布z检验来进行预测。\n当\\(n_ip_i(1-p_i)≥5,(i=1,2)\\)时，\\(p_i\\dot\\sim N(\\pi_i,\\frac{\\pi_i(1-\\pi_i)}{n_i})\\)\n\\[\n(p_1-p_2)\\dot\\sim N(\\pi_1-\\pi_2,\\frac{\\pi_1(1-\\pi_1)}{n_1}+\\frac{\\pi_2(1-\\pi_2)}{n_2})\n\\]\n\\(H_0:\\pi_1=\\pi_2\\)\n\\[\nZ=\\frac{(p_1-p_2)-(\\pi_1-\\pi_2)}{S_{p_1-p_2}}=\\frac{p_1-p_2}{\\sqrt{p_C(1-p_C)(\\frac{1}{n_1}+\\frac{1}{n_2})}}\\dot\\sim N(0,1)\n\\]\n其中,合并比例\\(p_C=\\frac{n_1p_1+n_2p_2}{n_1+n_2}\\) 。\n如果我们已知两组具有不同特性(A和B)样本的样本量和这两样本中具有某种共同特性(C)的个体数量(也就是知道了C特性各自群体比例和总体比例)，想要计算具有C特性的个体在A特性群体和B特性群体中的比例是否一样，就需要用到双比例检验。\n例如，男生500人，女生500人，其中喜欢阅读的男生有400人，喜欢阅读的女生有460人。男生喜欢阅读的比例是否比女生高。我们假设男生喜欢阅读的比例比女生高，则备择假设是男生喜欢阅读的比例比女生低。\n\nCode# 示例数据\nsuccesses1 &lt;- 400\ntotal1 &lt;- 500\nsuccesses2 &lt;- 460\ntotal2 &lt;- 500\n\n# 使用 prop.test() 函数进行两总体比例检验\nprop.test(x = c(successes1, successes2), n = c(total1, total2), alternative = \"less\")\n#&gt; \n#&gt;  2-sample test for equality of proportions with continuity correction\n#&gt; \n#&gt; data:  c(successes1, successes2) out of c(total1, total2)\n#&gt; X-squared = 28.912, df = 1, p-value = 3.787e-08\n#&gt; alternative hypothesis: less\n#&gt; 95 percent confidence interval:\n#&gt;  -1.0000000 -0.0824468\n#&gt; sample estimates:\n#&gt; prop 1 prop 2 \n#&gt;   0.80   0.92\n\n\n功效分析\n\n\\(1-\\beta\\)\n\\(n1,n_2=kn_1\\)",
    "crumbs": [
      "概率论与数理统计",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>比例检验</span>"
    ]
  },
  {
    "objectID": "ANOVA.html",
    "href": "ANOVA.html",
    "title": "\n11  方差分析\n",
    "section": "",
    "text": "11.1 单因素组间方差分析",
    "crumbs": [
      "概率论与数理统计",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>方差分析</span>"
    ]
  },
  {
    "objectID": "ANOVA.html#单因素组间方差分析",
    "href": "ANOVA.html#单因素组间方差分析",
    "title": "\n11  方差分析\n",
    "section": "",
    "text": "11.1.1 计算公式\n\n\n\n\n因子A有\\(A_1,A_2,...,A_k\\)共k个水平\ntotal sum of squares\n\\[\nSS_T=\\sum_{j=1}^{k}\\sum_{i=1}^{n_j}X_{ij}^2-\\frac{(\\sum_{j=1}^{k}\\sum_{i=1}^{n_j}X_{ij})^2}{n}=SS_{组间}+SS_{组内}\n\\]\nbetween groups sum of squares \\[\nSS_{组间}=\\sum_{j=1}^{k}\\frac{(\\sum_{i=1}^{n_j}X_{ij})^2}{n_j}-\\frac{(\\sum_{j=1}^{k}\\sum_{i=1}^{n_j}X_{ij})^2}{n}\n\\]\n自由度\\(\\nu=n-1,\\nu_{组间}=k-1,\\nu_{组内}=\\sum_{j=1}^{k}(n_j-1)=n-k\\)\nBetween groups mean square \\(MS_{组间}=\\frac{SS_{组间}}{k-1}\\)\nWithin groups mean square \\(MS_{组内}=\\frac{SS_{组内}}{n-k}\\)\n\\[H_0:\\mu_1=\\mu_2=...=\\mu_k\\]\n\\[\n\\frac{SS_T}{\\sigma^2}\\sim \\chi^2(\\nu),\\nu=n-1\n\\] \\[\n\\frac{SS_{组内}}{\\sigma^2}\\sim \\chi^2(\\nu),\\nu=n-k\n\\] 因此，\n\\[\n\\frac{SS_{组间}}{\\sigma^2}=\\frac{SS_T}{\\sigma^2}-\\frac{SS_{组内}}{\\sigma^2}\\ \\ \\ \\sim \\chi^2(\\nu),\\nu=k-1\n\\]\n检验统计量\n\\[\nF=\\frac{\\frac{SS_{组间}}{(k-1)\\sigma^2}}{\\frac{SS_{组内}}{(n-k)\\sigma^2}}=\\frac{\\frac{SS_{组间}}{k-1}}{\\frac{SS_{组内}}{n-k}}=\\frac{MS_{组间}}{MS_{组内}}\\ \\ \\ \\sim \\chi^2(\\nu),\\nu=k-1\n\\]\n\n\n\n\n\nCodedf &lt;- tibble(\n    low=c(53.5,43.7,46.5,50.3,56.1),\n    medium=c(33.2,30.6,23.9,26.4,35.9),\n    high=c(11.5,21.9,18.6,13.6,9.5)\n)\n\n\n\n11.1.2 手算\n\nCodek &lt;- 3\ndf_sum &lt;- sum(df)\ndf_sum_square &lt;- sum(df^2)\nn &lt;- 15\nC &lt;- df_sum^2/n\n\nSS_T &lt;- df_sum_square-C\nSS_between &lt;- apply(df, 2, function(x) sum(sum(x)^2/length(x))) |&gt; sum()-C\n\nSS_within &lt;- SS_T-SS_between\n\nMS_between &lt;- SS_between/(k-1)\nMS_within &lt;- SS_within/(n-k)\nF_stat &lt;-MS_between/MS_within \n\np_value &lt;- pf(F_stat,2,12,lower.tail = F)\n\n\n\n11.1.3 stats::aov()\n\n\nCodedf_long &lt;- df |&gt; pivot_longer(cols = everything(),\n                              names_to = \"level\",\n                              values_to = \"value\")\ndf_long$level &lt;- factor(df_long$level)\ndf_aov &lt;- aov(value~level,data = df_long)\n\nanova(df_aov)\n\n\n\n\n\nDf\nSum Sq\nMean Sq\nF value\nPr(&gt;F)\n\n\n\nlevel\n2\n3083.668\n1541.83400\n61.24546\n5e-07\n\n\nResiduals\n12\n302.096\n25.17467\nNA\nNA\n\n\n\n\n\n\n\n11.1.4 ez::ezANOVA()\n\n\nCodedf_long &lt;- df_long |&gt; rowid_to_column(var = \"id\") |&gt; \n    relocate(id,.before = 1) |&gt; mutate(id=factor(id))\n\nez::ezANOVA(data = df_long,\n            dv = value,\n            wid = id,\n            between = level,\n            type = 3,\n            detailed = T)\n#&gt; $ANOVA\n#&gt;        Effect DFn DFd       SSn     SSd         F            p p&lt;.05       ges\n#&gt; 1 (Intercept)   1  12 15054.336 302.096 597.99545 1.318663e-11     * 0.9803277\n#&gt; 2       level   2  12  3083.668 302.096  61.24546 5.045797e-07     * 0.9107746\n#&gt; \n#&gt; $`Levene's Test for Homogeneity of Variance`\n#&gt;   DFn DFd        SSn   SSd           F         p p&lt;.05\n#&gt; 1   2  12 0.05733333 92.36 0.003724556 0.9962835\n\n\n\n11.1.5 stats::lm()\n\n\nCodelm_aov &lt;- lm(formula = value ~  level, data = df_long)\nlm_aov\n#&gt; \n#&gt; Call:\n#&gt; lm(formula = value ~ level, data = df_long)\n#&gt; \n#&gt; Coefficients:\n#&gt; (Intercept)     levellow  levelmedium  \n#&gt;       15.02        35.00        14.98\n\nanova(lm_aov)\n\n\n\n\n\nDf\nSum Sq\nMean Sq\nF value\nPr(&gt;F)\n\n\n\nlevel\n2\n3083.668\n1541.83400\n61.24546\n5e-07\n\n\nResiduals\n12\n302.096\n25.17467\nNA\nNA\n\n\n\n\n\nCode\nmodel.matrix(~ level, data = df_long)\n#&gt;    (Intercept) levellow levelmedium\n#&gt; 1            1        1           0\n#&gt; 2            1        0           1\n#&gt; 3            1        0           0\n#&gt; 4            1        1           0\n#&gt; 5            1        0           1\n#&gt; 6            1        0           0\n#&gt; 7            1        1           0\n#&gt; 8            1        0           1\n#&gt; 9            1        0           0\n#&gt; 10           1        1           0\n#&gt; 11           1        0           1\n#&gt; 12           1        0           0\n#&gt; 13           1        1           0\n#&gt; 14           1        0           1\n#&gt; 15           1        0           0\n#&gt; attr(,\"assign\")\n#&gt; [1] 0 1 1\n#&gt; attr(,\"contrasts\")\n#&gt; attr(,\"contrasts\")$level\n#&gt; [1] \"contr.treatment\"\nlm(formula = value ~ 0 + level, data = df_long)\n#&gt; \n#&gt; Call:\n#&gt; lm(formula = value ~ 0 + level, data = df_long)\n#&gt; \n#&gt; Coefficients:\n#&gt;   levelhigh     levellow  levelmedium  \n#&gt;       15.02        50.02        30.00\nmodel.matrix(~ 0 + level, data = df_long)\n#&gt;    levelhigh levellow levelmedium\n#&gt; 1          0        1           0\n#&gt; 2          0        0           1\n#&gt; 3          1        0           0\n#&gt; 4          0        1           0\n#&gt; 5          0        0           1\n#&gt; 6          1        0           0\n#&gt; 7          0        1           0\n#&gt; 8          0        0           1\n#&gt; 9          1        0           0\n#&gt; 10         0        1           0\n#&gt; 11         0        0           1\n#&gt; 12         1        0           0\n#&gt; 13         0        1           0\n#&gt; 14         0        0           1\n#&gt; 15         1        0           0\n#&gt; attr(,\"assign\")\n#&gt; [1] 1 1 1\n#&gt; attr(,\"contrasts\")\n#&gt; attr(,\"contrasts\")$level\n#&gt; [1] \"contr.treatment\"\n\n\n\n11.1.6 事后检验\n成对比较的数量 \\(N=\\frac{k!}{2!(k-2)!},k≥3\\)，导致犯第Ⅰ类错误的概率迅速增加，\\([1-(1-\\alpha)^N]\\)。\n\n11.1.6.1 Tukey’s test\nTukey’s test 也被称为Tukey’s honestly significant difference (Tukey’s HSD) test。\n\nk个均值从大到小排列；\n均值最大的组依次与均值最小，第二小，……，第二大比较；\n均值第二大的组以同样的方式比较；\n以此类推\n在各组样本量相等的情况下，如果在两个均值之间未发现显著差异，则推断这两个均值所包含的任何均值之间不存在显著差异，并且不再检验所包含均值之间的差异。\n\nstudentized range statistic \\(q=\\frac{\\bar X_{max}-\\bar X_{min}}{S_{\\bar X_{max}-\\bar X_{min}}}\\)，其中\\(S_{\\bar X_{max}-\\bar X_{min}}=\\sqrt{\\frac{MS_{组内}}{n}}\\)，\\(n\\)是每一个治疗组的样本量。\n如果各组样本量不等,则\\(S_{\\bar X_{max}-\\bar X_{min}}=\\sqrt{\\frac{MS_{组内}}{2}(\\frac{1}{n_i}+\\frac{1}{n_j})}\\)\n检验统计量\n\\[\nHSD=q_{(k,\\nu_{组内}),1-\\alpha} \\times S_{\\bar X_{max}-\\bar X_{min}},\\nu_{组内}=k(n_j-1)\n\\]\n对于任意i,j且\\(\\bar X_i＞\\bar X_j\\)，如果\\(\\bar X_i-\\bar X_j＞HSD\\)，那么拒绝\\(H_0\\)，说明这两组存在显著差异。\n\\[\nH_0:\\mu_i=\\mu_j(i≠j)\n\\]\n\nCodek_means &lt;- apply(df,2,mean) |&gt; sort(,decreasing = TRUE)\nk_means\n#&gt;    low medium   high \n#&gt;  50.02  30.00  15.02\n\n# 附录q  q(3,12),1-0.05  3(5-1)=12\nq_critical_value &lt;- 3.77\nnj &lt;- 5\nHSD &lt;- q_critical_value*sqrt(MS_within/nj)\n\nk_means\n#&gt;    low medium   high \n#&gt;  50.02  30.00  15.02\ndiff_means &lt;- c()\nnames_diff_means &lt;- c()\n\nfor(i in 1:(length(k_means)-1)){\n    for(j in length(k_means):(i+1)){\n        diff_value &lt;- k_means[i] - k_means[j]\n        diff_means &lt;- c(diff_means, diff_value)\n        names_diff_means &lt;- c(names_diff_means, paste(names(k_means)[i], \"vs.\", names(k_means)[j],sep = \"_\"))\n    }\n}\nnames(diff_means) &lt;- names_diff_means\ndiff_means\n#&gt;    low_vs._high  low_vs._medium medium_vs._high \n#&gt;           35.00           20.02           14.98\n#全为真，3组成对比较都存在显著差异\ndiff_means &gt; HSD \n#&gt;    low_vs._high  low_vs._medium medium_vs._high \n#&gt;            TRUE            TRUE            TRUE\n\n\n\nCodepairwise &lt;- TukeyHSD(df_aov)\npairwise\n#&gt;   Tukey multiple comparisons of means\n#&gt;     95% family-wise confidence level\n#&gt; \n#&gt; Fit: aov(formula = value ~ level, data = df_long)\n#&gt; \n#&gt; $level\n#&gt;               diff        lwr       upr     p adj\n#&gt; low-high     35.00  26.534054  43.46595 0.0000003\n#&gt; medium-high  14.98   6.514054  23.44595 0.0013315\n#&gt; medium-low  -20.02 -28.485946 -11.55405 0.0001069\n\n\n\n11.1.6.2 Dunnett’s test\nDunnett’s test也称为q’-test,是两独立样本t-test的一种修正。Dunnett’s test 假设数据符合正态分布，并且各组的方差相等。 控制对照组（C）与其他每个实验组（T）比较。\n\\(H_0:\\mu_C=\\mu_T\\)\n\\[\nq'=\\frac{\\bar X_T-\\bar X_C}{\\sqrt{MS_{组内}(\\frac{1}{n_T}+\\frac{1}{n_C})}} \\sim q'(\\nu,a) \\ \\ \\nu=\\nu_{组内},a=k\n\\]\n临界值 \\(q'_{(a,\\nu_E),1-\\alpha/2}\\)\n\nCodenT &lt;- nC &lt;- 5 \n\nSE_mean_diff &lt;- sqrt(MS_within*(1/nT+1/nC))\n\nk_means\n#&gt;    low medium   high \n#&gt;  50.02  30.00  15.02\ndiff_means &lt;- c()\nnames_diff_means &lt;- c()\n\n# 以 low 作控制组\nfor(i in 2:length(k_means)){\n        diff_value &lt;- k_means[i] - k_means[1]\n        diff_means &lt;- c(diff_means, diff_value)\n        names_diff_means &lt;- c(names_diff_means, paste(names(k_means)[1], \"vs.\", names(k_means)[i],sep = \"_\"))\n}\nnames(diff_means) &lt;- names_diff_means\ndiff_means\n#&gt; low_vs._medium   low_vs._high \n#&gt;         -20.02         -35.00\n\nq撇_stat &lt;- diff_means/SE_mean_diff\n\n# 附录q'  q'(3,12),1-0.05/2  \nabs(q撇_stat)&gt;2.50  \n#&gt; low_vs._medium   low_vs._high \n#&gt;           TRUE           TRUE\n#全为真，各实验组与控制组均存在显著差异\n\n\n\nCodelibrary(multcomp)\ndunnett_result &lt;- glht(df_aov, linfct =mcp(level =c(\"medium - low = 0\", \"high - low = 0\")))\n\n# 查看 Dunnett's test 结果\nsummary(dunnett_result)\n#&gt; \n#&gt;   Simultaneous Tests for General Linear Hypotheses\n#&gt; \n#&gt; Multiple Comparisons of Means: User-defined Contrasts\n#&gt; \n#&gt; \n#&gt; Fit: aov(formula = value ~ level, data = df_long)\n#&gt; \n#&gt; Linear Hypotheses:\n#&gt;                   Estimate Std. Error t value Pr(&gt;|t|)    \n#&gt; medium - low == 0  -20.020      3.173  -6.309 7.46e-05 ***\n#&gt; high - low == 0    -35.000      3.173 -11.030 2.38e-07 ***\n#&gt; ---\n#&gt; Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n#&gt; (Adjusted p values reported -- single-step method)\n\n\n\n11.1.6.3 LSD-t test\nleast significant difference t-test\n挑选任意感兴趣的两组进行比较\n\\[\nH_0:\\mu_i=\\mu_j(i≠j)\n\\]\n\\[\nLSD-t=\\frac{\\bar X_i-\\bar X_j}{\\sqrt{MS_{组内}(\\frac{1}{n_i}+\\frac{1}{n_j})}} \\sim t(\\nu) \\ ,\\ \\nu=\\nu_{组内}=n-k,a=k\n\\]\n\nCode# medium high\nLSD &lt;- (k_means[2]-k_means[3])/sqrt(MS_within*(1/5+1/5))\n\n# 附录 t(12,1-0.05/2)=2.719",
    "crumbs": [
      "概率论与数理统计",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>方差分析</span>"
    ]
  },
  {
    "objectID": "ANOVA.html#方差分析假设",
    "href": "ANOVA.html#方差分析假设",
    "title": "\n11  方差分析\n",
    "section": "\n11.2 方差分析假设",
    "text": "11.2 方差分析假设\nhttps://www.statmethods.net/stats/rdiagnostics.html\n\n11.2.1 独立性\n\n11.2.2 正态性\n\nCode# 异常观测点\n\ncar::outlierTest(df_aov) \n#&gt; No Studentized residuals with Bonferroni p &lt; 0.05\n#&gt; Largest |rstudent|:\n#&gt;   rstudent unadjusted p-value Bonferroni p\n#&gt; 6  1.63682            0.12993           NA\n\n\n\n11.2.2.1 直方图/茎叶图\n\n11.2.2.2 P-P图/Q-Q图\n\n11.2.2.3 偏度和峰度\n\\[\nH_0:总体偏度系数\\gamma_1=0 或者总体峰度系数\\gamma_2=0\n\\]\n\\[\nz_i=\\frac{g_i-0}{\\sigma_{g_i}}  \\ \\ \\ \\ 临界值z_{1-\\alpha/2}\n\\]\n\n11.2.2.4 Shapiro-Wilk检验（小样本）\n\nCodeshapiro.test(df$low)  \n#&gt; \n#&gt;  Shapiro-Wilk normality test\n#&gt; \n#&gt; data:  df$low\n#&gt; W = 0.9718, p-value = 0.8867\nshapiro.test(df$medium)  \n#&gt; \n#&gt;  Shapiro-Wilk normality test\n#&gt; \n#&gt; data:  df$medium\n#&gt; W = 0.96762, p-value = 0.8598\nshapiro.test(df$high)  \n#&gt; \n#&gt;  Shapiro-Wilk normality test\n#&gt; \n#&gt; data:  df$high\n#&gt; W = 0.94361, p-value = 0.6916\n\n# 因为观测太少，也可以同时检验\nshapiro.test(c(df$low,df$medium,df$high))  \n#&gt; \n#&gt;  Shapiro-Wilk normality test\n#&gt; \n#&gt; data:  c(df$low, df$medium, df$high)\n#&gt; W = 0.94559, p-value = 0.4578\n\n\n\n11.2.2.5 Kolmogorov-Smirnov检验（Lilliefors correction 大样本）\n\nCodeks.test(c(df$low,df$medium,df$high),\"pnorm\")\n#&gt; \n#&gt;  Exact one-sample Kolmogorov-Smirnov test\n#&gt; \n#&gt; data:  c(df$low, df$medium, df$high)\n#&gt; D = 1, p-value &lt; 2.2e-16\n#&gt; alternative hypothesis: two-sided\nks.test(rnorm(1000),\"pnorm\")\n#&gt; \n#&gt;  Asymptotic one-sample Kolmogorov-Smirnov test\n#&gt; \n#&gt; data:  rnorm(1000)\n#&gt; D = 0.031901, p-value = 0.2607\n#&gt; alternative hypothesis: two-sided\n\n\n\nCodex &lt;- rnorm(50) \ny &lt;- runif(50) \nks.test(x, y)  # perform ks test\n#&gt; \n#&gt;  Exact two-sample Kolmogorov-Smirnov test\n#&gt; \n#&gt; data:  x and y\n#&gt; D = 0.56, p-value = 1.453e-07\n#&gt; alternative hypothesis: two-sided\n\nx &lt;- rnorm(50)\ny &lt;- rnorm(50)\nks.test(x, y) \n#&gt; \n#&gt;  Exact two-sample Kolmogorov-Smirnov test\n#&gt; \n#&gt; data:  x and y\n#&gt; D = 0.2, p-value = 0.2719\n#&gt; alternative hypothesis: two-sided\n\n\n\n11.2.3 方差齐性\nhttp://www.cookbook-r.com/Statistical_analysis/Homogeneity_of_variance/\n\n11.2.3.1 Bartlett’s test\n数据满足正态性\n比较每一组方差的加权算术均值和几何均值。\n\\[\nH_0:\\sigma_1^2=\\sigma_2^2=...=\\sigma_k^2\n\\] 当样本量\\(n_j\\)≥5时，检验统计量(各组样本量相等)\n\\[\nB=\\frac{(n-1)[kln\\bar S^2-\\sum_{j=1}^{k}lnS_j^2]}{1+\\frac{k+1}{3k(n-1)}} \\sim\\ \\chi^2(\\nu)\\ ,\\nu=k-1\n\\] 其中n是每一组的样本量，\\(S_j^2\\)是某一组的样本方差，\\(\\bar S^2\\)是所有k个组样本方差的平均值。\n当各组样本量不等时，\n\\[\nB=\\frac{\\sum_{j=1}^{k}(n_j-1)ln\\frac{\\bar S^2}{S_j^2}}{1+\\frac{1}{3(k-1)}(\\sum_{j=1}^{k}\\frac {1}{n_j-1}-\\frac{1}{\\sum_{j=1}^{k}(n_j-1)})} \\sim\\ \\chi^2(\\nu)\\ ,\\nu=k-1\n\\] 其中\\(h_j\\)是某一组的样本量，\\(\\bar S^2=(\\sum_{j=1}^{k}(n_j-1)S_j^2)/(\\sum_{j=1}^{k}(n_j-1))\\)是所有k个组样本方差的加权平均值。\n\nCoden1=n2=n3=5\nk=3\nS2 &lt;- apply(df,2,var)\nS2\n#&gt;    low medium   high \n#&gt; 25.372 23.895 26.257\n\nlnS2 &lt;- log(S2)\nlnS2\n#&gt;      low   medium     high \n#&gt; 3.233646 3.173669 3.267933\n\nS2_mean &lt;- (5-1)*(sum(S2))/(3*(5-1))\nS2_mean\n#&gt; [1] 25.17467\n\n\n\nB &lt;- ((5-1)*(3*log(S2_mean)-sum(lnS2)))/(1+(3+1)/(3*3*(5-1)))\nB\n#&gt; [1] 0.008159536\n\n\n\nCodebartlett.test(df)\n#&gt; \n#&gt;  Bartlett test of homogeneity of variances\n#&gt; \n#&gt; data:  df\n#&gt; Bartlett's K-squared = 0.0081595, df = 2, p-value = 0.9959\n\n\n\n11.2.3.2 Levene’s test\n数据不满足正态性\n\nk个随机样本是独立的\n随机变量X是连续的\n\nLevene 变换：\n\\[\nZ_{ij}=|X_{ij}-\\bar X_{.\\ j}|(i=1,2...,n_j;\\ j=1,2,...,k)\n\\]\n\nCodeoptions(digits = 2)\nz_df &lt;- bind_cols(\n    low=df[1]-k_means[1],\n    medium=df[2]-k_means[2],\n    high=df[3]-k_means[3]\n) |&gt; abs()\n    \n\nz_df\n\n\n\n\nlow\nmedium\nhigh\n\n\n\n3.48\n3.2\n3.5\n\n\n6.32\n0.6\n6.9\n\n\n3.52\n6.1\n3.6\n\n\n0.28\n3.6\n1.4\n\n\n6.08\n5.9\n5.5\n\n\n\n\n\n\n检验统计量（基于变换后的F检验）\n\\[\nW=\\frac{MS_{组间}}{MS_{组内}}=\\frac{\\sum_jn_j(\\bar Z_{.j}-\\bar Z_{..})^2/(k-1)}{\\sum_j\\sum_i(Z_{ij}-\\bar Z_{.j})^2/(n-k)}  \\sim F(\\nu_1,\\nu_2)   \\ \\ \\ \\ \\nu_1=k-1,\\nu_2=n-k\n\\]\n\nCodev1=3-1\nv2=15-3\n\n\nz.j_mean &lt;- apply(z_df, 2, mean)\nz.j_mean\n#&gt;    low medium   high \n#&gt;    3.9    3.9    4.2\n\nz_mean &lt;- mean(z.j_mean)\nz_mean \n#&gt; [1] 4\n\noptions(digits = 4)\nW &lt;- 12*sum(5*(z.j_mean-z_mean)^2)/(2*(sum((z_df$low-z.j_mean[1])^2)+sum((z_df$medium-z.j_mean[2])^2)+sum((z_df$high-z.j_mean[3])^2)))\n\nW\n#&gt; [1] 0.0254",
    "crumbs": [
      "概率论与数理统计",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>方差分析</span>"
    ]
  },
  {
    "objectID": "ANOVA.html#welchs-anova-test",
    "href": "ANOVA.html#welchs-anova-test",
    "title": "\n11  方差分析\n",
    "section": "\n11.3 Welch’s ANOVA Test",
    "text": "11.3 Welch’s ANOVA Test",
    "crumbs": [
      "概率论与数理统计",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>方差分析</span>"
    ]
  },
  {
    "objectID": "ANOVA.html#数据变换",
    "href": "ANOVA.html#数据变换",
    "title": "\n11  方差分析\n",
    "section": "\n11.4 数据变换",
    "text": "11.4 数据变换\n当方差分析的正态性假设或方差齐性假设不为真时，通常使用(1)数据变换方法；(2)非参数检验方法 比较均值差异\n\n11.4.1 平方根变换\n当每个水平组的方差与均值成比例，尤其是样本来自泊松分布\n\\[\nY=\\sqrt{X}\n\\]\n当数据中有零或非常小的值时，\n\\[\nY=\\sqrt{X+a} \\ \\ \\ \\ a=0.5或0.1\n\\]\n\n11.4.2 对数变换\n当数据方差不齐且每个水平组标准差与均值成比例时\n\\[\nY=\\log{X} \\ \\ \\ \\ base=e或10\n\\]\n当数据中有零或负值时，\n\\[\nY=\\log{(X+a)} \\ \\ \\ \\ a为实数，使得X+a&gt;0\n\\]\n\n11.4.3 反正弦平方根变换\n率，服从二项分布\\(B(n,\\pi)\\)\n\\[\nY=\\arcsin {\\sqrt{\\pi}} \\ \\ \\ \\\n\\]",
    "crumbs": [
      "概率论与数理统计",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>方差分析</span>"
    ]
  },
  {
    "objectID": "repeated_measures_ANOVA.html",
    "href": "repeated_measures_ANOVA.html",
    "title": "\n12  重复测量方差分析\n",
    "section": "",
    "text": "12.1 单因素重复测量\n假设\n\\[\nSS_T=\\sum_{j=1}^{t}\\sum_{i=1}^{n}X_{ij}^2-\\frac{(\\sum_{j=1}^{t}\\sum_{i=1}^{n}X_{ij})^2}{nt}=SS_{受试者间}+SS_{不同时间点}+SS_{E\\ \\ 随机误差}，\\nu_T=nt-1\n\\]\n\\[\nSS_{受试者间}=\\frac{\\sum_{i}(\\sum_{j}X_{ij})^2}{t}-C，\\nu_{受试者}=n-1\n\\]反映了在受试者间的变异。\n\\[\nSS_{不同时间点}=\\frac{\\sum_{j}(\\sum_{i}X_{ij})^2}{n}-C ，\\nu_{时间点}=t-1\n\\]反映了在每个受试者内不同时间点的重复测量变异。\n\\[\nSS_E=SS_T-SS_{受试者间}-SS_{不同时间点}，\\nu_E=(n-1)(t-1)\n\\]\n\\(H_0:\\mu_1=\\mu_2=...=\\mu_t\\)，检验统计量\n\\[\nF=\\frac{MS_{不同时间点}}{MS_E}=\\frac{SS_{不同时间点}/(t-1)}{SS_E/((n-1)(t-1))}\n\\]\nCodedf &lt;- tribble(\n    ~id,~zero,~ten,~twenty,~thirty,\n    1,186,122,134,110,\n    2,345,312,268,176,\n    3,98,84,52,61,\n    4,288,98,91,85,\n    5,176,86,130,99,\n    6,210,188,143,120,\n    7,271,322,86,65,\n    8,415,332,265,186,\n    9,171,126,130,135,\n    10,243,330,95,64,\n)\ndf_long &lt;-\n    df |&gt; pivot_longer(cols = -1,\n                       names_to = \"week\",\n                       values_to = \"ALT\") |&gt; mutate(week = factor(week))\n\n\n# 假设检验\nshapiro.test(df$zero)\n#&gt; \n#&gt;  Shapiro-Wilk normality test\n#&gt; \n#&gt; data:  df$zero\n#&gt; W = 0.97166, p-value = 0.9058\nshapiro.test(df$ten)\n#&gt; \n#&gt;  Shapiro-Wilk normality test\n#&gt; \n#&gt; data:  df$ten\n#&gt; W = 0.7963, p-value = 0.01307\nshapiro.test(df$twenty)\n#&gt; \n#&gt;  Shapiro-Wilk normality test\n#&gt; \n#&gt; data:  df$twenty\n#&gt; W = 0.83443, p-value = 0.03783\nshapiro.test(df$thirty)\n#&gt; \n#&gt;  Shapiro-Wilk normality test\n#&gt; \n#&gt; data:  df$thirty\n#&gt; W = 0.90722, p-value = 0.2624\nbartlett.test(df[-1])\n#&gt; \n#&gt;  Bartlett test of homogeneity of variances\n#&gt; \n#&gt; data:  df[-1]\n#&gt; Bartlett's K-squared = 6.7482, df = 3, p-value = 0.08037\n\n    \n# 总变异\nxij_sum &lt;- sum(df_long$ALT)\nxij_square_sum &lt;- sum(df_long$ALT^2)\nC &lt;- xij_sum^2/40\nSS_T &lt;- xij_square_sum-C\n\n# 受试者间  \nxi._sum &lt;- rowSums(df[,-1])\nxi._sum\n#&gt;  [1]  552 1101  295  562  491  661  744 1198  562  732\nSS_B &lt;- sum(xi._sum^2)/4-C #行和平方和\nMS_B &lt;- SS_B/9\n\n# 不同时间点\nx.j_sum &lt;- colSums(df[,-1])\nx.j_sum\n#&gt;   zero    ten twenty thirty \n#&gt;   2403   2000   1394   1101\nSS_W &lt;- sum(x.j_sum^2)/10-C #列和平方和\nMS_W &lt;- SS_W/3\n\n\n\nSS_E &lt;- SS_T-SS_B-SS_W\nMS_E &lt;- SS_E/(9*3)\n\nF_stat &lt;- MS_W/MS_E\nCodelibrary(nlme)\nmodel &lt;- lme(fixed=ALT ~ week, random = ~1| id/week, data = df_long)\nsummary(model)\n#&gt; Linear mixed-effects model fit by REML\n#&gt;   Data: df_long \n#&gt;        AIC      BIC    logLik\n#&gt;   431.0046 442.0892 -208.5023\n#&gt; \n#&gt; Random effects:\n#&gt;  Formula: ~1 | id\n#&gt;         (Intercept)\n#&gt; StdDev:    62.83357\n#&gt; \n#&gt;  Formula: ~1 | week %in% id\n#&gt;         (Intercept) Residual\n#&gt; StdDev:     50.6942 22.91705\n#&gt; \n#&gt; Fixed effects:  ALT ~ week \n#&gt;             Value Std.Error DF   t-value p-value\n#&gt; (Intercept) 200.0  26.53893 27  7.536098  0.0000\n#&gt; weekthirty  -89.9  24.88008 27 -3.613332  0.0012\n#&gt; weektwenty  -60.6  24.88008 27 -2.435683  0.0217\n#&gt; weekzero     40.3  24.88008 27  1.619770  0.1169\n#&gt;  Correlation: \n#&gt;            (Intr) wkthrt wktwnt\n#&gt; weekthirty -0.469              \n#&gt; weektwenty -0.469  0.500       \n#&gt; weekzero   -0.469  0.500  0.500\n#&gt; \n#&gt; Standardized Within-Group Residuals:\n#&gt;         Min          Q1         Med          Q3         Max \n#&gt; -0.55743919 -0.26471921 -0.01206831  0.19777410  0.89724666 \n#&gt; \n#&gt; Number of Observations: 40\n#&gt; Number of Groups: \n#&gt;           id week %in% id \n#&gt;           10           40\nanova_results &lt;- anova(model)\nanova_results\n\n\n\n\n\nnumDF\ndenDF\nF-value\np-value\n\n\n\n(Intercept)\n1\n27\n62.98194\n0.00e+00\n\n\nweek\n3\n27\n11.13855\n6.17e-05",
    "crumbs": [
      "概率论与数理统计",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>重复测量方差分析</span>"
    ]
  },
  {
    "objectID": "repeated_measures_ANOVA.html#单因素重复测量",
    "href": "repeated_measures_ANOVA.html#单因素重复测量",
    "title": "\n12  重复测量方差分析\n",
    "section": "",
    "text": "正态性\n方差齐性\n协方差矩阵的球形检验（W=1）\n\n\n\n\n\n\n\n\n\n\n12.1.1 事后检验\n\nCodelibrary(multcomp)\nglht_result &lt;-glht(model, linfct = mcp(week =c(\"ten - zero = 0 \",\n                                               \"twenty - zero == 0\",\n                                               \"thirty - zero = 0 \")))\nsummary(glht_result)\n#&gt; \n#&gt;   Simultaneous Tests for General Linear Hypotheses\n#&gt; \n#&gt; Multiple Comparisons of Means: User-defined Contrasts\n#&gt; \n#&gt; \n#&gt; Fit: lme.formula(fixed = ALT ~ week, data = df_long, random = ~1 | \n#&gt;     id/week)\n#&gt; \n#&gt; Linear Hypotheses:\n#&gt;                    Estimate Std. Error z value Pr(&gt;|z|)    \n#&gt; ten - zero == 0      -40.30      24.88  -1.620    0.248    \n#&gt; twenty - zero == 0  -100.90      24.88  -4.055   &lt;0.001 ***\n#&gt; thirty - zero == 0  -130.20      24.88  -5.233   &lt;0.001 ***\n#&gt; ---\n#&gt; Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n#&gt; (Adjusted p values reported -- single-step method)\nglht_result\n#&gt; \n#&gt;   General Linear Hypotheses\n#&gt; \n#&gt; Multiple Comparisons of Means: User-defined Contrasts\n#&gt; \n#&gt; \n#&gt; Linear Hypotheses:\n#&gt;                    Estimate\n#&gt; ten - zero == 0       -40.3\n#&gt; twenty - zero == 0   -100.9\n#&gt; thirty - zero == 0   -130.2\n\n\n\n12.1.2 计算示例\n\nCodedf2 &lt;- tribble(\n    ~Participant,~A1,~A2,~A3,\n    \"P1\",5  ,6  ,7,\n    \"P2\",7  ,13 ,13,\n    \"P3\",2  ,4  ,6,\n    \"P4\",6  ,9  ,12\n)\ndf2\n\n\n\n\nParticipant\nA1\nA2\nA3\n\n\n\nP1\n5\n6\n7\n\n\nP2\n7\n13\n13\n\n\nP3\n2\n4\n6\n\n\nP4\n6\n9\n12\n\n\n\n\n\n\n自由度\n\nCodedf_A &lt;- 3-1\n\ndf_P &lt;- 4-1\n\ndf_error &lt;- df_A * df_P\n\n\ndf_total &lt;- df_A + df_P + df_error\n# 或者\ndf_total &lt;- 3*4-1 \n\n\n均方和\nSStotal ，SSA，SSP",
    "crumbs": [
      "概率论与数理统计",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>重复测量方差分析</span>"
    ]
  },
  {
    "objectID": "repeated_measures_ANOVA.html#含组间因子的重复测量",
    "href": "repeated_measures_ANOVA.html#含组间因子的重复测量",
    "title": "\n12  重复测量方差分析\n",
    "section": "\n12.2 含组间因子的重复测量",
    "text": "12.2 含组间因子的重复测量\n\\[\n\\begin{aligned}\nSS_总&= SS_{受试对象间}+SS_{受试对象内}  \\\\\n&=（SS_{处理方法}+SS_{个体间差异}）+（SS_{时间}+SS_{处理与时间交互}+SS_{个体内差异}）\n\\end{aligned}\n\\]\nhttps://personality-project.org/r/r.guide/r.anova.html#oneway\n\n12.2.1 第一个案例\n\nCodedf &lt;- read_rds(\"data/repeated_measures_design_ANOVA.rds\")\n\ndf\n\n\n\n\nid\nDays\nmethod\nvolume\n\n\n\n1\n-1\nPBS\n19.162112\n\n\n2\n-1\nPBS\n27.011250\n\n\n3\n-1\nPBS\n23.372456\n\n\n4\n-1\nPBS\n27.909632\n\n\n5\n-1\nPBS\n29.730456\n\n\n6\n-1\nSLAMF6+ PD-1+ CD8+ cells\n31.905280\n\n\n7\n-1\nSLAMF6+ PD-1+ CD8+ cells\n34.464572\n\n\n8\n-1\nSLAMF6+ PD-1+ CD8+ cells\n44.381076\n\n\n9\n-1\nSLAMF6+ PD-1+ CD8+ cells\n29.128390\n\n\n10\n-1\nSLAMF6+ PD-1+ CD8+ cells\n41.406258\n\n\n11\n-1\nSLAMF6- PD-1+ CD8+ cells\n20.566502\n\n\n12\n-1\nSLAMF6- PD-1+ CD8+ cells\n35.290912\n\n\n13\n-1\nSLAMF6- PD-1+ CD8+ cells\n27.498006\n\n\n14\n-1\nSLAMF6- PD-1+ CD8+ cells\n29.082921\n\n\n15\n-1\nSLAMF6- PD-1+ CD8+ cells\n37.914624\n\n\n1\n7\nPBS\n37.671413\n\n\n2\n7\nPBS\n45.329217\n\n\n3\n7\nPBS\n51.874884\n\n\n4\n7\nPBS\n22.612576\n\n\n5\n7\nPBS\n17.473050\n\n\n6\n7\nSLAMF6+ PD-1+ CD8+ cells\n6.741792\n\n\n7\n7\nSLAMF6+ PD-1+ CD8+ cells\n13.051836\n\n\n8\n7\nSLAMF6+ PD-1+ CD8+ cells\n7.226306\n\n\n9\n7\nSLAMF6+ PD-1+ CD8+ cells\n4.274888\n\n\n10\n7\nSLAMF6+ PD-1+ CD8+ cells\n9.863168\n\n\n11\n7\nSLAMF6- PD-1+ CD8+ cells\n27.119307\n\n\n12\n7\nSLAMF6- PD-1+ CD8+ cells\n44.669691\n\n\n13\n7\nSLAMF6- PD-1+ CD8+ cells\n28.546986\n\n\n14\n7\nSLAMF6- PD-1+ CD8+ cells\n22.613338\n\n\n15\n7\nSLAMF6- PD-1+ CD8+ cells\n30.652641\n\n\n1\n14\nPBS\n61.520364\n\n\n2\n14\nPBS\n46.968863\n\n\n3\n14\nPBS\n72.014040\n\n\n4\n14\nPBS\n31.844456\n\n\n5\n14\nPBS\n26.931400\n\n\n6\n14\nSLAMF6+ PD-1+ CD8+ cells\n6.353438\n\n\n7\n14\nSLAMF6+ PD-1+ CD8+ cells\n2.328942\n\n\n8\n14\nSLAMF6+ PD-1+ CD8+ cells\n3.315222\n\n\n9\n14\nSLAMF6+ PD-1+ CD8+ cells\n2.356608\n\n\n10\n14\nSLAMF6+ PD-1+ CD8+ cells\n0.030056\n\n\n11\n14\nSLAMF6- PD-1+ CD8+ cells\n53.475862\n\n\n12\n14\nSLAMF6- PD-1+ CD8+ cells\n41.727860\n\n\n13\n14\nSLAMF6- PD-1+ CD8+ cells\n34.477317\n\n\n14\n14\nSLAMF6- PD-1+ CD8+ cells\n25.084087\n\n\n15\n14\nSLAMF6- PD-1+ CD8+ cells\n34.260048\n\n\n\n\n\n\n\nCode# 2x2 mixed: 独立变量（被试间） : age\n# 独立变量（被试内） : time 依赖变量: value\n# aov_age_time &lt;- aov(value ~ age * time + Error(subject/time),\n#   data = data_long)\n# summary(aov_age_time)\n\n# 两个被试内变量 \n#aov.ww &lt;- aov(y ~ w1*w2 +Error(subject/(w1*w2)), data=data_long) \n\n# 1个被试间变量，两个被试内变量 \n#aov.bww &lt;- aov(y ~b1*w1*w2 + Error(subject/(w1*w2)) + b1,data=data_long) \n\n# 两个被试间变量，一个被试内变量\n# aov.bww &lt;- aov(y ~ b1*b2*w1 + Error(subject/(w1)) + b1*b2, data=data_long)\n\n\n\nCode# 第一种  有混合效应无法事后检验\naov_1 &lt;- aov(volume ~ method*Days+Error(id/Days),data = df)\nsummary(aov_1)\n#&gt; \n#&gt; Error: id\n#&gt;           Df Sum Sq Mean Sq F value   Pr(&gt;F)    \n#&gt; method     2   3572  1786.0   13.13 0.000953 ***\n#&gt; Residuals 12   1633   136.1                     \n#&gt; ---\n#&gt; Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n#&gt; \n#&gt; Error: id:Days\n#&gt;             Df Sum Sq Mean Sq F value   Pr(&gt;F)    \n#&gt; Days         2    301   150.3   1.893    0.172    \n#&gt; method:Days  4   4363  1090.8  13.742 5.81e-06 ***\n#&gt; Residuals   24   1905    79.4                     \n#&gt; ---\n#&gt; Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\n\nCode# 第二种 最好\nlibrary(nlme)\nmodel &lt;- lme(volume ~ method*Days, random = ~1|id/Days, data = df)\nsummary(model)\n#&gt; Linear mixed-effects model fit by REML\n#&gt;   Data: df \n#&gt;        AIC      BIC    logLik\n#&gt;   304.5845 323.5868 -140.2923\n#&gt; \n#&gt; Random effects:\n#&gt;  Formula: ~1 | id\n#&gt;         (Intercept)\n#&gt; StdDev:    4.346709\n#&gt; \n#&gt;  Formula: ~1 | Days %in% id\n#&gt;         (Intercept) Residual\n#&gt; StdDev:    8.366812 3.060766\n#&gt; \n#&gt; Fixed effects:  volume ~ method * Days \n#&gt;                                           Value Std.Error DF   t-value p-value\n#&gt; (Intercept)                            25.43718  4.433186 24  5.737900  0.0000\n#&gt; methodSLAMF6+ PD-1+ CD8+ cells         10.81993  6.269472 12  1.725813  0.1100\n#&gt; methodSLAMF6- PD-1+ CD8+ cells          4.63341  6.269472 12  0.739043  0.4741\n#&gt; Days7                                   9.55505  5.634601 24  1.695781  0.1029\n#&gt; Days14                                 22.41864  5.634601 24  3.978745  0.0006\n#&gt; methodSLAMF6+ PD-1+ CD8+ cells:Days7  -37.58056  7.968529 24 -4.716123  0.0001\n#&gt; methodSLAMF6- PD-1+ CD8+ cells:Days7   -8.90525  7.968529 24 -1.117552  0.2748\n#&gt; methodSLAMF6+ PD-1+ CD8+ cells:Days14 -55.79891  7.968529 24 -7.002410  0.0000\n#&gt; methodSLAMF6- PD-1+ CD8+ cells:Days14 -14.68420  7.968529 24 -1.842774  0.0777\n#&gt;  Correlation: \n#&gt;                                       (Intr) mtSLAMF6+PD-1+CD8+c\n#&gt; methodSLAMF6+ PD-1+ CD8+ cells        -0.707                    \n#&gt; methodSLAMF6- PD-1+ CD8+ cells        -0.707  0.500             \n#&gt; Days7                                 -0.636  0.449             \n#&gt; Days14                                -0.636  0.449             \n#&gt; methodSLAMF6+ PD-1+ CD8+ cells:Days7   0.449 -0.636             \n#&gt; methodSLAMF6- PD-1+ CD8+ cells:Days7   0.449 -0.318             \n#&gt; methodSLAMF6+ PD-1+ CD8+ cells:Days14  0.449 -0.636             \n#&gt; methodSLAMF6- PD-1+ CD8+ cells:Days14  0.449 -0.318             \n#&gt;                                       mtSLAMF6-PD-1+CD8+c Days7  Days14\n#&gt; methodSLAMF6+ PD-1+ CD8+ cells                                         \n#&gt; methodSLAMF6- PD-1+ CD8+ cells                                         \n#&gt; Days7                                  0.449                           \n#&gt; Days14                                 0.449               0.500       \n#&gt; methodSLAMF6+ PD-1+ CD8+ cells:Days7  -0.318              -0.707 -0.354\n#&gt; methodSLAMF6- PD-1+ CD8+ cells:Days7  -0.636              -0.707 -0.354\n#&gt; methodSLAMF6+ PD-1+ CD8+ cells:Days14 -0.318              -0.354 -0.707\n#&gt; methodSLAMF6- PD-1+ CD8+ cells:Days14 -0.636              -0.354 -0.707\n#&gt;                                       mSLAMF6+PD-1+CD8+c:D7\n#&gt; methodSLAMF6+ PD-1+ CD8+ cells                             \n#&gt; methodSLAMF6- PD-1+ CD8+ cells                             \n#&gt; Days7                                                      \n#&gt; Days14                                                     \n#&gt; methodSLAMF6+ PD-1+ CD8+ cells:Days7                       \n#&gt; methodSLAMF6- PD-1+ CD8+ cells:Days7   0.500               \n#&gt; methodSLAMF6+ PD-1+ CD8+ cells:Days14  0.500               \n#&gt; methodSLAMF6- PD-1+ CD8+ cells:Days14  0.250               \n#&gt;                                       mSLAMF6-PD-1+CD8+c:D7\n#&gt; methodSLAMF6+ PD-1+ CD8+ cells                             \n#&gt; methodSLAMF6- PD-1+ CD8+ cells                             \n#&gt; Days7                                                      \n#&gt; Days14                                                     \n#&gt; methodSLAMF6+ PD-1+ CD8+ cells:Days7                       \n#&gt; methodSLAMF6- PD-1+ CD8+ cells:Days7                       \n#&gt; methodSLAMF6+ PD-1+ CD8+ cells:Days14  0.250               \n#&gt; methodSLAMF6- PD-1+ CD8+ cells:Days14  0.500               \n#&gt;                                       mSLAMF6+PD-1+CD8+c:D1\n#&gt; methodSLAMF6+ PD-1+ CD8+ cells                             \n#&gt; methodSLAMF6- PD-1+ CD8+ cells                             \n#&gt; Days7                                                      \n#&gt; Days14                                                     \n#&gt; methodSLAMF6+ PD-1+ CD8+ cells:Days7                       \n#&gt; methodSLAMF6- PD-1+ CD8+ cells:Days7                       \n#&gt; methodSLAMF6+ PD-1+ CD8+ cells:Days14                      \n#&gt; methodSLAMF6- PD-1+ CD8+ cells:Days14  0.500               \n#&gt; \n#&gt; Standardized Within-Group Residuals:\n#&gt;         Min          Q1         Med          Q3         Max \n#&gt; -0.62401382 -0.15515176 -0.03440848  0.17260010  0.72287328 \n#&gt; \n#&gt; Number of Observations: 45\n#&gt; Number of Groups: \n#&gt;           id Days %in% id \n#&gt;           15           45\ndf_aov &lt;- anova(model)\ndf_aov\n\n\n\n\n\nnumDF\ndenDF\nF-value\np-value\n\n\n\n(Intercept)\n1\n24\n263.954417\n0.0000000\n\n\nmethod\n2\n12\n13.127286\n0.0009528\n\n\nDays\n2\n24\n1.893203\n0.1724036\n\n\nmethod:Days\n4\n24\n13.742424\n0.0000058\n\n\n\n\n\nCode\n#成对比较\nlibrary(emmeans)\nmethod_means &lt;- emmeans(model, ~method)  \nprint(method_means)  \n#&gt;  method                   emmean   SE df lower.CL upper.CL\n#&gt;  PBS                        36.1 3.01 14    29.64     42.6\n#&gt;  SLAMF6+ PD-1+ CD8+ cells   15.8 3.01 12     9.23     22.4\n#&gt;  SLAMF6- PD-1+ CD8+ cells   32.9 3.01 12    26.30     39.4\n#&gt; \n#&gt; Results are averaged over the levels of: Days \n#&gt; Degrees-of-freedom method: containment \n#&gt; Confidence level used: 0.95\nmethod_comparisons &lt;- pairs(method_means)  \nprint(method_comparisons)\n#&gt;  contrast                                                estimate   SE df\n#&gt;  PBS - (SLAMF6+ PD-1+ CD8+ cells)                           20.31 4.26 12\n#&gt;  PBS - (SLAMF6- PD-1+ CD8+ cells)                            3.23 4.26 12\n#&gt;  (SLAMF6+ PD-1+ CD8+ cells) - (SLAMF6- PD-1+ CD8+ cells)   -17.08 4.26 12\n#&gt;  t.ratio p.value\n#&gt;    4.768  0.0012\n#&gt;    0.758  0.7345\n#&gt;   -4.009  0.0046\n#&gt; \n#&gt; Results are averaged over the levels of: Days \n#&gt; Degrees-of-freedom method: containment \n#&gt; P value adjustment: tukey method for comparing a family of 3 estimates\n\n\n\nCodelibrary(\"afex\")     # needed for ANOVA functions.\nlibrary(\"emmeans\")  # emmeans must now be loaded explicitly for follow-up tests.\nlibrary(\"multcomp\") # for advanced control for multiple testing/Type 1 errors.\nlibrary(\"ggplot2\")  # for customizing plots.\n\n\na1 &lt;- aov_ez(id = \"id\",dv = \"volume\", df, between =\"method\" , within = c(\"Days\"))\na1\n#&gt; Anova Table (Type 3 tests)\n#&gt; \n#&gt; Response: volume\n#&gt;        Effect          df    MSE         F  ges p.value\n#&gt; 1      method       2, 12 136.05 13.13 *** .502   &lt;.001\n#&gt; 2        Days 1.33, 15.94 119.49      1.89 .078    .188\n#&gt; 3 method:Days 2.66, 15.94 119.49 13.74 *** .552   &lt;.001\n#&gt; ---\n#&gt; Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '+' 0.1 ' ' 1\n#&gt; \n#&gt; Sphericity correction method: GG\n\naov_car(volume ~ method + Error(id/Days), data = df)\n#&gt; Anova Table (Type 3 tests)\n#&gt; \n#&gt; Response: volume\n#&gt;        Effect          df    MSE         F  ges p.value\n#&gt; 1      method       2, 12 136.05 13.13 *** .502   &lt;.001\n#&gt; 2        Days 1.33, 15.94 119.49      1.89 .078    .188\n#&gt; 3 method:Days 2.66, 15.94 119.49 13.74 *** .552   &lt;.001\n#&gt; ---\n#&gt; Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '+' 0.1 ' ' 1\n#&gt; \n#&gt; Sphericity correction method: GG\naov_4(volume ~ method + (Days|id), data = df)\n#&gt; Anova Table (Type 3 tests)\n#&gt; \n#&gt; Response: volume\n#&gt;        Effect          df    MSE         F  ges p.value\n#&gt; 1      method       2, 12 136.05 13.13 *** .502   &lt;.001\n#&gt; 2        Days 1.33, 15.94 119.49      1.89 .078    .188\n#&gt; 3 method:Days 2.66, 15.94 119.49 13.74 *** .552   &lt;.001\n#&gt; ---\n#&gt; Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '+' 0.1 ' ' 1\n#&gt; \n#&gt; Sphericity correction method: GG\n\n\n\n# 事后检验\nm1 &lt;- emmeans(a1, ~ method)\nm1\n#&gt;  method                   emmean   SE df lower.CL upper.CL\n#&gt;  PBS                        36.1 3.01 12    29.53     42.7\n#&gt;  SLAMF6+ PD-1+ CD8+ cells   15.8 3.01 12     9.23     22.4\n#&gt;  SLAMF6- PD-1+ CD8+ cells   32.9 3.01 12    26.30     39.4\n#&gt; \n#&gt; Results are averaged over the levels of: Days \n#&gt; Confidence level used: 0.95\npairs(m1)\n#&gt;  contrast                                                estimate   SE df\n#&gt;  PBS - (SLAMF6+ PD-1+ CD8+ cells)                           20.31 4.26 12\n#&gt;  PBS - (SLAMF6- PD-1+ CD8+ cells)                            3.23 4.26 12\n#&gt;  (SLAMF6+ PD-1+ CD8+ cells) - (SLAMF6- PD-1+ CD8+ cells)   -17.08 4.26 12\n#&gt;  t.ratio p.value\n#&gt;    4.768  0.0012\n#&gt;    0.758  0.7345\n#&gt;   -4.009  0.0046\n#&gt; \n#&gt; Results are averaged over the levels of: Days \n#&gt; P value adjustment: tukey method for comparing a family of 3 estimates\n\n\n\n12.2.2 第二个案例\n\nCode# 医学统计学 人卫版 第7版\ndf &lt;- read_delim(\"data/麻醉诱导时相.txt\")\ndf\n\n\n\n\nid\ngroup\nt0\nt1\nt2\nt3\nt4\n\n\n\n1\nA\n120\n108\n112\n120\n117\n\n\n2\nA\n118\n109\n115\n126\n123\n\n\n3\nA\n119\n112\n119\n124\n118\n\n\n4\nA\n121\n112\n119\n126\n120\n\n\n5\nA\n127\n121\n127\n133\n126\n\n\n6\nB\n121\n120\n118\n131\n137\n\n\n7\nB\n122\n121\n119\n129\n133\n\n\n8\nB\n128\n129\n126\n135\n142\n\n\n9\nB\n117\n115\n111\n123\n131\n\n\n10\nB\n118\n114\n116\n123\n133\n\n\n11\nC\n131\n119\n118\n135\n129\n\n\n12\nC\n129\n128\n121\n148\n132\n\n\n13\nC\n123\n123\n120\n143\n136\n\n\n14\nC\n123\n121\n116\n145\n126\n\n\n15\nC\n125\n124\n118\n142\n130\n\n\n\n\n\nCodedf_long &lt;- df |&gt; pivot_longer(cols = starts_with(\"t\"),\n                              names_to = \"time\",\n                              values_to = \"BP\") |&gt; \n    mutate(\n        id=factor(id),\n        group=factor(group),\n        time=factor(time)\n    )\ndf_long\n\n\n\n\nid\ngroup\ntime\nBP\n\n\n\n1\nA\nt0\n120\n\n\n1\nA\nt1\n108\n\n\n1\nA\nt2\n112\n\n\n1\nA\nt3\n120\n\n\n1\nA\nt4\n117\n\n\n2\nA\nt0\n118\n\n\n2\nA\nt1\n109\n\n\n2\nA\nt2\n115\n\n\n2\nA\nt3\n126\n\n\n2\nA\nt4\n123\n\n\n3\nA\nt0\n119\n\n\n3\nA\nt1\n112\n\n\n3\nA\nt2\n119\n\n\n3\nA\nt3\n124\n\n\n3\nA\nt4\n118\n\n\n4\nA\nt0\n121\n\n\n4\nA\nt1\n112\n\n\n4\nA\nt2\n119\n\n\n4\nA\nt3\n126\n\n\n4\nA\nt4\n120\n\n\n5\nA\nt0\n127\n\n\n5\nA\nt1\n121\n\n\n5\nA\nt2\n127\n\n\n5\nA\nt3\n133\n\n\n5\nA\nt4\n126\n\n\n6\nB\nt0\n121\n\n\n6\nB\nt1\n120\n\n\n6\nB\nt2\n118\n\n\n6\nB\nt3\n131\n\n\n6\nB\nt4\n137\n\n\n7\nB\nt0\n122\n\n\n7\nB\nt1\n121\n\n\n7\nB\nt2\n119\n\n\n7\nB\nt3\n129\n\n\n7\nB\nt4\n133\n\n\n8\nB\nt0\n128\n\n\n8\nB\nt1\n129\n\n\n8\nB\nt2\n126\n\n\n8\nB\nt3\n135\n\n\n8\nB\nt4\n142\n\n\n9\nB\nt0\n117\n\n\n9\nB\nt1\n115\n\n\n9\nB\nt2\n111\n\n\n9\nB\nt3\n123\n\n\n9\nB\nt4\n131\n\n\n10\nB\nt0\n118\n\n\n10\nB\nt1\n114\n\n\n10\nB\nt2\n116\n\n\n10\nB\nt3\n123\n\n\n10\nB\nt4\n133\n\n\n11\nC\nt0\n131\n\n\n11\nC\nt1\n119\n\n\n11\nC\nt2\n118\n\n\n11\nC\nt3\n135\n\n\n11\nC\nt4\n129\n\n\n12\nC\nt0\n129\n\n\n12\nC\nt1\n128\n\n\n12\nC\nt2\n121\n\n\n12\nC\nt3\n148\n\n\n12\nC\nt4\n132\n\n\n13\nC\nt0\n123\n\n\n13\nC\nt1\n123\n\n\n13\nC\nt2\n120\n\n\n13\nC\nt3\n143\n\n\n13\nC\nt4\n136\n\n\n14\nC\nt0\n123\n\n\n14\nC\nt1\n121\n\n\n14\nC\nt2\n116\n\n\n14\nC\nt3\n145\n\n\n14\nC\nt4\n126\n\n\n15\nC\nt0\n125\n\n\n15\nC\nt1\n124\n\n\n15\nC\nt2\n118\n\n\n15\nC\nt3\n142\n\n\n15\nC\nt4\n130\n\n\n\n\n\n\n\nCode# 第一种方法\nlibrary(nlme)\nmodel &lt;- lme(BP ~ group*time, random = ~1 |id/time, data = df_long)\nsummary(model)\n#&gt; Linear mixed-effects model fit by REML\n#&gt;   Data: df_long \n#&gt;       AIC      BIC   logLik\n#&gt;   364.496 402.1942 -164.248\n#&gt; \n#&gt; Random effects:\n#&gt;  Formula: ~1 | id\n#&gt;         (Intercept)\n#&gt; StdDev:    3.831231\n#&gt; \n#&gt;  Formula: ~1 | time %in% id\n#&gt;         (Intercept) Residual\n#&gt; StdDev:    2.100669 1.033856\n#&gt; \n#&gt; Fixed effects:  BP ~ group * time \n#&gt;               Value Std.Error DF  t-value p-value\n#&gt; (Intercept)   121.0  2.007984 48 60.25944  0.0000\n#&gt; groupB          0.2  2.839718 12  0.07043  0.9450\n#&gt; groupC          5.2  2.839718 12  1.83117  0.0920\n#&gt; timet1         -8.6  1.480766 48 -5.80781  0.0000\n#&gt; timet2         -2.6  1.480766 48 -1.75585  0.0855\n#&gt; timet3          4.8  1.480766 48  3.24157  0.0022\n#&gt; timet4         -0.2  1.480766 48 -0.13507  0.8931\n#&gt; groupB:timet1   7.2  2.094119 48  3.43820  0.0012\n#&gt; groupC:timet1   5.4  2.094119 48  2.57865  0.0130\n#&gt; groupB:timet2  -0.6  2.094119 48 -0.28652  0.7757\n#&gt; groupC:timet2  -5.0  2.094119 48 -2.38764  0.0209\n#&gt; groupB:timet3   2.2  2.094119 48  1.05056  0.2987\n#&gt; groupC:timet3  11.6  2.094119 48  5.53932  0.0000\n#&gt; groupB:timet4  14.2  2.094119 48  6.78090  0.0000\n#&gt; groupC:timet4   4.6  2.094119 48  2.19663  0.0329\n#&gt;  Correlation: \n#&gt;               (Intr) groupB groupC timet1 timet2 timet3 timet4 grpB:1 grpC:1\n#&gt; groupB        -0.707                                                        \n#&gt; groupC        -0.707  0.500                                                 \n#&gt; timet1        -0.369  0.261  0.261                                          \n#&gt; timet2        -0.369  0.261  0.261  0.500                                   \n#&gt; timet3        -0.369  0.261  0.261  0.500  0.500                            \n#&gt; timet4        -0.369  0.261  0.261  0.500  0.500  0.500                     \n#&gt; groupB:timet1  0.261 -0.369 -0.184 -0.707 -0.354 -0.354 -0.354              \n#&gt; groupC:timet1  0.261 -0.184 -0.369 -0.707 -0.354 -0.354 -0.354  0.500       \n#&gt; groupB:timet2  0.261 -0.369 -0.184 -0.354 -0.707 -0.354 -0.354  0.500  0.250\n#&gt; groupC:timet2  0.261 -0.184 -0.369 -0.354 -0.707 -0.354 -0.354  0.250  0.500\n#&gt; groupB:timet3  0.261 -0.369 -0.184 -0.354 -0.354 -0.707 -0.354  0.500  0.250\n#&gt; groupC:timet3  0.261 -0.184 -0.369 -0.354 -0.354 -0.707 -0.354  0.250  0.500\n#&gt; groupB:timet4  0.261 -0.369 -0.184 -0.354 -0.354 -0.354 -0.707  0.500  0.250\n#&gt; groupC:timet4  0.261 -0.184 -0.369 -0.354 -0.354 -0.354 -0.707  0.250  0.500\n#&gt;               grpB:2 grpC:2 grpB:3 grpC:3 grpB:4\n#&gt; groupB                                          \n#&gt; groupC                                          \n#&gt; timet1                                          \n#&gt; timet2                                          \n#&gt; timet3                                          \n#&gt; timet4                                          \n#&gt; groupB:timet1                                   \n#&gt; groupC:timet1                                   \n#&gt; groupB:timet2                                   \n#&gt; groupC:timet2  0.500                            \n#&gt; groupB:timet3  0.500  0.250                     \n#&gt; groupC:timet3  0.250  0.500  0.500              \n#&gt; groupB:timet4  0.500  0.250  0.500  0.250       \n#&gt; groupC:timet4  0.250  0.500  0.250  0.500  0.500\n#&gt; \n#&gt; Standardized Within-Group Residuals:\n#&gt;         Min          Q1         Med          Q3         Max \n#&gt; -1.11748859 -0.15879013 -0.03722313  0.17409704  1.22118250 \n#&gt; \n#&gt; Number of Observations: 75\n#&gt; Number of Groups: \n#&gt;           id time %in% id \n#&gt;           15           75\ndf_aov &lt;- anova(model)\ndf_aov\n\n\n\n\n\nnumDF\ndenDF\nF-value\np-value\n\n\n\n(Intercept)\n1\n48\n14649.223399\n0.0000000\n\n\ngroup\n2\n12\n5.782943\n0.0174335\n\n\ntime\n4\n48\n106.557616\n0.0000000\n\n\ngroup:time\n8\n48\n19.100638\n0.0000000\n\n\n\n\n\nCode\n#成对比较\nlibrary(emmeans)\nmethod_means &lt;- emmeans(model, ~group)  \nprint(method_means)  \n#&gt;  group emmean   SE df lower.CL upper.CL\n#&gt;  A        120 1.78 14      116      123\n#&gt;  B        124 1.78 12      121      128\n#&gt;  C        128 1.78 12      124      132\n#&gt; \n#&gt; Results are averaged over the levels of: time \n#&gt; Degrees-of-freedom method: containment \n#&gt; Confidence level used: 0.95\nmethod_comparisons &lt;- pairs(method_means)  \nprint(method_comparisons)\n#&gt;  contrast estimate   SE df t.ratio p.value\n#&gt;  A - B       -4.80 2.51 12  -1.911  0.1780\n#&gt;  A - C       -8.52 2.51 12  -3.392  0.0137\n#&gt;  B - C       -3.72 2.51 12  -1.481  0.3338\n#&gt; \n#&gt; Results are averaged over the levels of: time \n#&gt; Degrees-of-freedom method: containment \n#&gt; P value adjustment: tukey method for comparing a family of 3 estimates\n\n\n\nCodelibrary(rstatix)\na2 &lt;- anova_test(data = df_long,\n           dv = BP,\n           wid = id,\n           within = time,\n           between = group\n           )\n\na2\n#&gt; ANOVA Table (type II tests)\n#&gt; \n#&gt; $ANOVA\n#&gt;       Effect DFn DFd       F        p p&lt;.05   ges\n#&gt; 1      group   2  12   5.783 1.70e-02     * 0.430\n#&gt; 2       time   4  48 106.558 3.02e-23     * 0.659\n#&gt; 3 group:time   8  48  19.101 1.62e-12     * 0.409\n#&gt; \n#&gt; $`Mauchly's Test for Sphericity`\n#&gt;       Effect     W     p p&lt;.05\n#&gt; 1       time 0.293 0.178      \n#&gt; 2 group:time 0.293 0.178      \n#&gt; \n#&gt; $`Sphericity Corrections`\n#&gt;       Effect   GGe      DF[GG]    p[GG] p[GG]&lt;.05   HFe      DF[HF]    p[HF]\n#&gt; 1       time 0.679 2.71, 32.58 1.87e-16         * 0.896 3.59, 43.03 4.65e-21\n#&gt; 2 group:time 0.679 5.43, 32.58 4.26e-09         * 0.896 7.17, 43.03 2.04e-11\n#&gt;   p[HF]&lt;.05\n#&gt; 1         *\n#&gt; 2         *\n\n\nhttps://cran.r-project.org/web/packages/afex/vignettes/afex_anova_example.html\n\nCodelibrary(\"afex\")     # needed for ANOVA functions.\nlibrary(\"emmeans\")  # emmeans must now be loaded explicitly for follow-up tests.\nlibrary(\"multcomp\") # for advanced control for multiple testing/Type 1 errors.\nlibrary(\"ggplot2\")  # for customizing plots.\n\n\n\na1 &lt;- aov_ez(\"id\", \"BP\", df_long, between =\"group\" , \n       within = c(\"time\"))\na1\n#&gt; Anova Table (Type 3 tests)\n#&gt; \n#&gt; Response: BP\n#&gt;       Effect          df   MSE          F  ges p.value\n#&gt; 1      group       2, 12 78.87     5.78 * .430    .017\n#&gt; 2       time 2.71, 32.58  8.08 106.56 *** .659   &lt;.001\n#&gt; 3 group:time 5.43, 32.58  8.08  19.10 *** .409   &lt;.001\n#&gt; ---\n#&gt; Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '+' 0.1 ' ' 1\n#&gt; \n#&gt; Sphericity correction method: GG\n\naov_car(BP ~ group + Error(id/time), data = df_long)\n#&gt; Anova Table (Type 3 tests)\n#&gt; \n#&gt; Response: BP\n#&gt;       Effect          df   MSE          F  ges p.value\n#&gt; 1      group       2, 12 78.87     5.78 * .430    .017\n#&gt; 2       time 2.71, 32.58  8.08 106.56 *** .659   &lt;.001\n#&gt; 3 group:time 5.43, 32.58  8.08  19.10 *** .409   &lt;.001\n#&gt; ---\n#&gt; Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '+' 0.1 ' ' 1\n#&gt; \n#&gt; Sphericity correction method: GG\naov_4(BP ~ group + (time|id), data = df_long)\n#&gt; Anova Table (Type 3 tests)\n#&gt; \n#&gt; Response: BP\n#&gt;       Effect          df   MSE          F  ges p.value\n#&gt; 1      group       2, 12 78.87     5.78 * .430    .017\n#&gt; 2       time 2.71, 32.58  8.08 106.56 *** .659   &lt;.001\n#&gt; 3 group:time 5.43, 32.58  8.08  19.10 *** .409   &lt;.001\n#&gt; ---\n#&gt; Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '+' 0.1 ' ' 1\n#&gt; \n#&gt; Sphericity correction method: GG\n\nprint(xtable::xtable(anova(a1), digits = c(rep(2, 5), 3, 4)), type = \"html\")\n#&gt; &lt;!-- html table generated in R 4.4.0 by xtable 1.8-4 package --&gt;\n#&gt; &lt;!-- Sun Jun 30 23:30:42 2024 --&gt;\n#&gt; &lt;table border=1&gt;\n#&gt; &lt;tr&gt; &lt;th&gt;  &lt;/th&gt; &lt;th&gt; num Df &lt;/th&gt; &lt;th&gt; den Df &lt;/th&gt; &lt;th&gt; MSE &lt;/th&gt; &lt;th&gt; F &lt;/th&gt; &lt;th&gt; ges &lt;/th&gt; &lt;th&gt; Pr(&gt;F) &lt;/th&gt;  &lt;/tr&gt;\n#&gt;   &lt;tr&gt; &lt;td&gt; group &lt;/td&gt; &lt;td align=\"right\"&gt; 2.00 &lt;/td&gt; &lt;td align=\"right\"&gt; 12.00 &lt;/td&gt; &lt;td align=\"right\"&gt; 78.87 &lt;/td&gt; &lt;td align=\"right\"&gt; 5.78 &lt;/td&gt; &lt;td align=\"right\"&gt; 0.430 &lt;/td&gt; &lt;td align=\"right\"&gt; 0.0174 &lt;/td&gt; &lt;/tr&gt;\n#&gt;   &lt;tr&gt; &lt;td&gt; time &lt;/td&gt; &lt;td align=\"right\"&gt; 2.71 &lt;/td&gt; &lt;td align=\"right\"&gt; 32.58 &lt;/td&gt; &lt;td align=\"right\"&gt; 8.08 &lt;/td&gt; &lt;td align=\"right\"&gt; 106.56 &lt;/td&gt; &lt;td align=\"right\"&gt; 0.659 &lt;/td&gt; &lt;td align=\"right\"&gt; 0.0000 &lt;/td&gt; &lt;/tr&gt;\n#&gt;   &lt;tr&gt; &lt;td&gt; group:time &lt;/td&gt; &lt;td align=\"right\"&gt; 5.43 &lt;/td&gt; &lt;td align=\"right\"&gt; 32.58 &lt;/td&gt; &lt;td align=\"right\"&gt; 8.08 &lt;/td&gt; &lt;td align=\"right\"&gt; 19.10 &lt;/td&gt; &lt;td align=\"right\"&gt; 0.409 &lt;/td&gt; &lt;td align=\"right\"&gt; 0.0000 &lt;/td&gt; &lt;/tr&gt;\n#&gt;    &lt;/table&gt;\n\n\n# 事后检验\nm1 &lt;- emmeans(a1, ~ group)\nm1\n#&gt;  group emmean   SE df lower.CL upper.CL\n#&gt;  A        120 1.78 12      116      124\n#&gt;  B        124 1.78 12      121      128\n#&gt;  C        128 1.78 12      124      132\n#&gt; \n#&gt; Results are averaged over the levels of: time \n#&gt; Confidence level used: 0.95\npairs(m1)\n#&gt;  contrast estimate   SE df t.ratio p.value\n#&gt;  A - B       -4.80 2.51 12  -1.911  0.1780\n#&gt;  A - C       -8.52 2.51 12  -3.392  0.0137\n#&gt;  B - C       -3.72 2.51 12  -1.481  0.3338\n#&gt; \n#&gt; Results are averaged over the levels of: time \n#&gt; P value adjustment: tukey method for comparing a family of 3 estimates\n# summary(as.glht(pairs(m1)), test=adjusted(\"fdr\"))\n# p1 &lt;- afex_plot(a1, x = \"time\", #trace = \"BP\", \n#                 panel = \"group\", error = \"none\", \n#                 mapping = c(\"color\", \"fill\"), \n#                 data_geom = geom_boxplot, data_arg = list(width = 0.4), \n#                 point_arg = list(size = 1.5), line_arg = list(size = 1))\n# p1\n\n\n\\[\n\\begin{aligned}\nSS_总&= SS_{受试对象间}+SS_{受试对象内}  \\\\\n&=（SS_{处理方法}+SS_{个体间差异}）+（SS_{时间}+SS_{处理与时间交互}+SS_{个体内差异}）\n\\end{aligned}\n\\]\n\\[\n\\begin{aligned}\n\\nu_总&= \\nu_{受试对象间}+\\nu_{受试对象内}  \\\\\n&=（\\nu_{处理方法}+\\nu_{个体差异}）+（\\nu_{时间}+\\nu_{处理与时间交互}+\\nu_{个体差异}）\n\\end{aligned}\n\\]\n\n\n\n\n\n\n\n\n\n\n\nPage 86-87\n变异\nSS\nv\nMS\nF\nCP\n\n\n\n受试对象间\n处理\n912.24\n2\n456.12\n5.78\n0.0174\n\n\n\n个体差异\n946.48\n12\n78.87\n\n\n\n\n\n\n1858.72\n\n\n\n\n\n\n受试对象内\n时间\n2336.45\n4\n584.11\n106.56\n&lt;0.0001\n\n\n\n处理与时间交互\n837.63\n8\n104.70\n19.10\n&lt;0.0001\n\n\n\n个体差异\n263.12\n48\n5.48\n\n\n\n\n\n\n3437.2\n\n\n\n\n\n\n总\n\n5295.92\n3×15-1=74\n\n\n\n\n\n\n\n12.2.2.1 SS总\n\n\\[\nSS_总=\\sum_i^n{（X_i-\\bar X）^2}\n\\]\n其中，n是观测值的总数，Xi 为每个观测值，\\(\\bar X\\) 是所有观测值的均值。\n\nCodeoptions(digits = 4)\nBP &lt;- c(df$t0,df$t1,df$t2,df$t3,df$t4)\nBP_mean &lt;- mean(BP) \nSS_total &lt;- sum((BP-BP_mean)^2)\n\nSS_total    \n#&gt; [1] 5296\n\n\n\n12.2.2.2 SS受试对象间\n\n\\[\nSS_{受试对象间}=\\sum_{j=1}^m n_{.j}(\\bar X_{.j}-\\bar X)^2\n\\]\n其中，m是受试者数量（15），n.j 是第j 个受试对象的观测值数量，\\bar X.j 是第j 个受试对象的观测值的均值，\\bar X 是所有观测值的均值。\n\nCodeid_mean &lt;- df |&gt; dplyr::select(c(-1,-2)) |&gt; rowMeans()\n\nSS_between &lt;- 0\nfor (i in 1:nrow(df)) {\n    SS_between &lt;- SS_between + 5*(id_mean[i]-BP_mean)^2\n}\nSS_between\n#&gt; [1] 1859\n\n\n\nCodegroup__summary &lt;- df_long |&gt; group_by(group) |&gt; \n    summarise(n=n(),mean=mean(BP),sum=sum(BP))\ngroup__summary \n\n\n\n\ngroup\nn\nmean\nsum\n\n\n\nA\n25\n119.7\n2992\n\n\nB\n25\n124.5\n3112\n\n\nC\n25\n128.2\n3205\n\n\n\n\n\n\n\\[\nSS_{处理}= \\sum_i^k n_k (\\bar X_k - \\bar X)^2\n\\]\n其中，k为不同处理组的组数，nk 为第 k 处理组观测值的总数，\\(\\bar  X_k\\) 为第k 处理组观测值的均数，\\(\\bar X\\) 是所有观测值的均值。\n\nCodeSS_处理 &lt;- 25*( (group__summary$mean[1] - BP_mean )^2 + \n                       (group__summary$mean[2] - BP_mean )^2 +\n                       (group__summary$mean[3] - BP_mean )^2) \nSS_处理\n#&gt; [1] 912.2\n\n\n\nCodeSS_between_error &lt;- SS_between-SS_处理\n\nSS_between_error\n#&gt; [1] 946.5\n\n\n\n12.2.2.3 SS受试对象内\n\n\\[\nSS_{受试对象内}=SS_总-SS_{受试对象间}\n\\]\n\nCodeSS_within &lt;- SS_total-SS_between\nSS_within\n#&gt; [1] 3437\n\n\n\n\\[\nSS_{时间}=\\sum _{t=1}^T n_t （\\bar X_{.t}-\\bar X）^2\n\\]\n其中，T是时间点的数量，nt 是在时间点t的观测值数量，\\bar X.t 是在时间点 t 的均值。\n\nCodet_mean &lt;- df |&gt; dplyr::select(c(-1,-2)) |&gt; colMeans()\n\nSS_time &lt;- 0\nfor (i in seq_along(t_mean)) {\n    \n    SS_time &lt;- SS_time + 15*(t_mean[i]-BP_mean)^2\n    \n}\nnames(SS_time) &lt;- \"SS_time\"\nSS_time\n#&gt; SS_time \n#&gt;    2336\n\n\n\\[\nSS_{处理与时间交互}=\\sum_{i=1}^{k}\\sum_{j=1}^{T}n_{ij}\\left (\\bar X_{ij.} -\\bar X_{i..}-\\bar X_{.j.} + \\bar X_{...} \\right )^2\n\\]\n其中，\n\nk 是处理方法的数量，3\nT 是时间点的数量，5\nnij 是第 i 个处理方法和第 j 个时间点的观测次数，25/5=5\nXij . 是第 i 个处理方法、第 j 个时间点的观测值的平均值\nXi . . 是第 i 个处理方法观测值的平均值，不考虑时间点\nX. j . 是第 j 个时间点观测值的平均值，不考虑处理方法\nX. . . 是所有观测值的平均值，不考虑处理方法和时间点\n\n\nCodeinteraction_effect_summary &lt;- df_long |&gt;\n    summarise(\n        #n = n(),\n        mean = mean(BP),\n       # sum = sum(BP),\n        .by = c(group , time)\n    )\ninteraction_effect_mean &lt;- interaction_effect_summary |&gt; pivot_wider(names_from = c(\"time\"),values_from = \"mean\")\n\n\n\nSS_interaction_effect &lt;- 0\nfor (i in 1:3) {\n    for (j in 1:5) {\n        SS_interaction_effect &lt;- SS_interaction_effect + 5 * (interaction_effect_mean[i, j + 1] -group__summary$mean[i] - t_mean[j] + BP_mean) ^ 2\n    }\n    \n}\nnames(SS_interaction_effect) &lt;- \"SS_interaction_effect\"\nSS_interaction_effect\n\n\n\n\nSS_interaction_effect\n\n\n837.6\n\n\n\n\n\n\nCodeSS_within_error &lt;- SS_within-SS_time-SS_interaction_effect\n\nnames(SS_within_error) &lt;- \"SS_within_error\"\nSS_within_error \n\n\n\n\nSS_within_error\n\n\n263.1",
    "crumbs": [
      "概率论与数理统计",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>重复测量方差分析</span>"
    ]
  },
  {
    "objectID": "repeated_measures_ANOVA.html#球形度检验-sphericity",
    "href": "repeated_measures_ANOVA.html#球形度检验-sphericity",
    "title": "\n12  重复测量方差分析\n",
    "section": "\n12.3 球形度检验 sphericity",
    "text": "12.3 球形度检验 sphericity\n重复测量方差分析假设相关条件（或组水平）的所有组合之间的差异方差相等。这被称为球形度假设。\nR中球形度检验\n球度仅针对具有两个以上水平的变量进行评估，因为球形度必然适用于只有两个水平的条件。\n违反球形度假设可能会扭曲方差计算，从而导致更宽松的重复测量方差分析检验（即 I 类错误率增加）。在这种情况下，必须根据违反球形度的程度适当校正重复测量方差分析。文献中使用了两种常见的校正：Greenhouse-Geisser epsilon （GGe） 和 Huynh-Feldt epsilon （HFe）。\n球形度的 Mauchly 检验用于评估是否满足球形度的假设。使用rstatix::anova_test() 时，会自动报告此问题。尽管该方法受到严厉批评，通常无法检测到小样本中的球形偏离，而在大样本中则过度检测到它们，但它仍然是一种常用的方法。\n\nCodelibrary(tidyverse)\nlibrary(ggpubr)\nlibrary(rstatix)\n\n\n\nCodedf &lt;- read_delim(\"data/麻醉诱导时相.txt\")\ndf\n\n\n\n\nid\ngroup\nt0\nt1\nt2\nt3\nt4\n\n\n\n1\nA\n120\n108\n112\n120\n117\n\n\n2\nA\n118\n109\n115\n126\n123\n\n\n3\nA\n119\n112\n119\n124\n118\n\n\n4\nA\n121\n112\n119\n126\n120\n\n\n5\nA\n127\n121\n127\n133\n126\n\n\n6\nB\n121\n120\n118\n131\n137\n\n\n7\nB\n122\n121\n119\n129\n133\n\n\n8\nB\n128\n129\n126\n135\n142\n\n\n9\nB\n117\n115\n111\n123\n131\n\n\n10\nB\n118\n114\n116\n123\n133\n\n\n11\nC\n131\n119\n118\n135\n129\n\n\n12\nC\n129\n128\n121\n148\n132\n\n\n13\nC\n123\n123\n120\n143\n136\n\n\n14\nC\n123\n121\n116\n145\n126\n\n\n15\nC\n125\n124\n118\n142\n130\n\n\n\n\n\nCodedf_long &lt;- df |&gt; pivot_longer(cols = starts_with(\"t\"),\n                              names_to = \"time\",\n                              values_to = \"BP\") |&gt; \n    mutate(\n        id=factor(id),\n        group=factor(group),\n        time=factor(time)\n    )\ndf_long\n\n\n\n\nid\ngroup\ntime\nBP\n\n\n\n1\nA\nt0\n120\n\n\n1\nA\nt1\n108\n\n\n1\nA\nt2\n112\n\n\n1\nA\nt3\n120\n\n\n1\nA\nt4\n117\n\n\n2\nA\nt0\n118\n\n\n2\nA\nt1\n109\n\n\n2\nA\nt2\n115\n\n\n2\nA\nt3\n126\n\n\n2\nA\nt4\n123\n\n\n3\nA\nt0\n119\n\n\n3\nA\nt1\n112\n\n\n3\nA\nt2\n119\n\n\n3\nA\nt3\n124\n\n\n3\nA\nt4\n118\n\n\n4\nA\nt0\n121\n\n\n4\nA\nt1\n112\n\n\n4\nA\nt2\n119\n\n\n4\nA\nt3\n126\n\n\n4\nA\nt4\n120\n\n\n5\nA\nt0\n127\n\n\n5\nA\nt1\n121\n\n\n5\nA\nt2\n127\n\n\n5\nA\nt3\n133\n\n\n5\nA\nt4\n126\n\n\n6\nB\nt0\n121\n\n\n6\nB\nt1\n120\n\n\n6\nB\nt2\n118\n\n\n6\nB\nt3\n131\n\n\n6\nB\nt4\n137\n\n\n7\nB\nt0\n122\n\n\n7\nB\nt1\n121\n\n\n7\nB\nt2\n119\n\n\n7\nB\nt3\n129\n\n\n7\nB\nt4\n133\n\n\n8\nB\nt0\n128\n\n\n8\nB\nt1\n129\n\n\n8\nB\nt2\n126\n\n\n8\nB\nt3\n135\n\n\n8\nB\nt4\n142\n\n\n9\nB\nt0\n117\n\n\n9\nB\nt1\n115\n\n\n9\nB\nt2\n111\n\n\n9\nB\nt3\n123\n\n\n9\nB\nt4\n131\n\n\n10\nB\nt0\n118\n\n\n10\nB\nt1\n114\n\n\n10\nB\nt2\n116\n\n\n10\nB\nt3\n123\n\n\n10\nB\nt4\n133\n\n\n11\nC\nt0\n131\n\n\n11\nC\nt1\n119\n\n\n11\nC\nt2\n118\n\n\n11\nC\nt3\n135\n\n\n11\nC\nt4\n129\n\n\n12\nC\nt0\n129\n\n\n12\nC\nt1\n128\n\n\n12\nC\nt2\n121\n\n\n12\nC\nt3\n148\n\n\n12\nC\nt4\n132\n\n\n13\nC\nt0\n123\n\n\n13\nC\nt1\n123\n\n\n13\nC\nt2\n120\n\n\n13\nC\nt3\n143\n\n\n13\nC\nt4\n136\n\n\n14\nC\nt0\n123\n\n\n14\nC\nt1\n121\n\n\n14\nC\nt2\n116\n\n\n14\nC\nt3\n145\n\n\n14\nC\nt4\n126\n\n\n15\nC\nt0\n125\n\n\n15\nC\nt1\n124\n\n\n15\nC\nt2\n118\n\n\n15\nC\nt3\n142\n\n\n15\nC\nt4\n130\n\n\n\n\n\n\n\n12.3.1 计算 sphericity 和 Mauchly 检验\n具体操作步骤如下：\n\n计算相关组的每个组合之间的差异\n计算每个组差的方差\n\n\n\nCoded &lt;- df |&gt; mutate(\n    `t0-t1`=t0-t1,\n    `t0-t2`=t0-t2,\n    `t0-t3`=t0-t3,\n    `t0-t4`=t0-t4,\n    `t1-t2`=t1-t2,\n    `t1-t3`=t1-t3,\n    `t1-t4`=t1-t4,\n    `t2-t3`=t2-t3,\n    `t2-t4`=t2-t4,\n    `t3-t4`=t3-t4,\n) |&gt; select(8:17)\nd\n\n\n\n\nt0-t1\nt0-t2\nt0-t3\nt0-t4\nt1-t2\nt1-t3\nt1-t4\nt2-t3\nt2-t4\nt3-t4\n\n\n\n12\n8\n0\n3\n-4\n-12\n-9\n-8\n-5\n3\n\n\n9\n3\n-8\n-5\n-6\n-17\n-14\n-11\n-8\n3\n\n\n7\n0\n-5\n1\n-7\n-12\n-6\n-5\n1\n6\n\n\n9\n2\n-5\n1\n-7\n-14\n-8\n-7\n-1\n6\n\n\n6\n0\n-6\n1\n-6\n-12\n-5\n-6\n1\n7\n\n\n1\n3\n-10\n-16\n2\n-11\n-17\n-13\n-19\n-6\n\n\n1\n3\n-7\n-11\n2\n-8\n-12\n-10\n-14\n-4\n\n\n-1\n2\n-7\n-14\n3\n-6\n-13\n-9\n-16\n-7\n\n\n2\n6\n-6\n-14\n4\n-8\n-16\n-12\n-20\n-8\n\n\n4\n2\n-5\n-15\n-2\n-9\n-19\n-7\n-17\n-10\n\n\n12\n13\n-4\n2\n1\n-16\n-10\n-17\n-11\n6\n\n\n1\n8\n-19\n-3\n7\n-20\n-4\n-27\n-11\n16\n\n\n0\n3\n-20\n-13\n3\n-20\n-13\n-23\n-16\n7\n\n\n2\n7\n-22\n-3\n5\n-24\n-5\n-29\n-10\n19\n\n\n1\n7\n-17\n-5\n6\n-18\n-6\n-24\n-12\n12\n\n\n\n\n\nCode\nd|&gt; map(var)\n#&gt; $`t0-t1`\n#&gt; [1] 19.54\n#&gt; \n#&gt; $`t0-t2`\n#&gt; [1] 12.84\n#&gt; \n#&gt; $`t0-t3`\n#&gt; [1] 45.26\n#&gt; \n#&gt; $`t0-t4`\n#&gt; [1] 49.64\n#&gt; \n#&gt; $`t1-t2`\n#&gt; [1] 24.5\n#&gt; \n#&gt; $`t1-t3`\n#&gt; [1] 27.31\n#&gt; \n#&gt; $`t1-t4`\n#&gt; [1] 23.12\n#&gt; \n#&gt; $`t2-t3`\n#&gt; [1] 65.55\n#&gt; \n#&gt; $`t2-t4`\n#&gt; [1] 47.98\n#&gt; \n#&gt; $`t3-t4`\n#&gt; [1] 77.38\n \n### 单因素\nt &lt;- df |&gt; select(3:7) |&gt; as.matrix()\nt\n#&gt;        t0  t1  t2  t3  t4\n#&gt;  [1,] 120 108 112 120 117\n#&gt;  [2,] 118 109 115 126 123\n#&gt;  [3,] 119 112 119 124 118\n#&gt;  [4,] 121 112 119 126 120\n#&gt;  [5,] 127 121 127 133 126\n#&gt;  [6,] 121 120 118 131 137\n#&gt;  [7,] 122 121 119 129 133\n#&gt;  [8,] 128 129 126 135 142\n#&gt;  [9,] 117 115 111 123 131\n#&gt; [10,] 118 114 116 123 133\n#&gt; [11,] 131 119 118 135 129\n#&gt; [12,] 129 128 121 148 132\n#&gt; [13,] 123 123 120 143 136\n#&gt; [14,] 123 121 116 145 126\n#&gt; [15,] 125 124 118 142 130\n\nmauchly.test(lm(t~1),X = ~1)\n#&gt; \n#&gt;  Mauchly's test of sphericity\n#&gt;  Contrasts orthogonal to\n#&gt;  ~1\n#&gt; \n#&gt; \n#&gt; data:  SSD matrix from lm(formula = t ~ 1)\n#&gt; W = 0.11, p-value = 0.001\n\n\n### 双因素\n\ndf_split &lt;- df |&gt; group_split(group)\n\ndf[1:5,3:7]\n\n\n\n\nt0\nt1\nt2\nt3\nt4\n\n\n\n120\n108\n112\n120\n117\n\n\n118\n109\n115\n126\n123\n\n\n119\n112\n119\n124\n118\n\n\n121\n112\n119\n126\n120\n\n\n127\n121\n127\n133\n126\n\n\n\n\n\nCode\ndf2 &lt;- as.matrix(cbind(df_split[[1]][3:7],df_split[[2]][3:7],df_split[[3]][3:7]))\ntimes &lt;- ordered(rep(1:5,3))\ngroup &lt;- factor(rep(c(\"A\",\"B\",\"C\"),each=5))\n\n\n\n\n\nmauchly.test(lm(df2~1),M=~group+times,X=~ times)\n#&gt; \n#&gt;  Mauchly's test of sphericity\n#&gt;  Contrasts orthogonal to\n#&gt;  ~times\n#&gt; \n#&gt;  Contrasts spanned by\n#&gt;  ~group + times\n#&gt; \n#&gt; \n#&gt; data:  SSD matrix from lm(formula = df2 ~ 1)\n#&gt; W = 0.43, p-value = 0.3\n\n\n\n12.3.2 方差分析\n\nCode\n\n\na2 &lt;- anova_test(data = df_long,\n           dv = BP,\n           wid = id,\n           within = time,\n           between = group\n           )\n\na2\n#&gt; ANOVA Table (type II tests)\n#&gt; \n#&gt; $ANOVA\n#&gt;       Effect DFn DFd       F        p p&lt;.05   ges\n#&gt; 1      group   2  12   5.783 1.70e-02     * 0.430\n#&gt; 2       time   4  48 106.558 3.02e-23     * 0.659\n#&gt; 3 group:time   8  48  19.101 1.62e-12     * 0.409\n#&gt; \n#&gt; $`Mauchly's Test for Sphericity`\n#&gt;       Effect     W     p p&lt;.05\n#&gt; 1       time 0.293 0.178      \n#&gt; 2 group:time 0.293 0.178      \n#&gt; \n#&gt; $`Sphericity Corrections`\n#&gt;       Effect   GGe      DF[GG]    p[GG] p[GG]&lt;.05   HFe      DF[HF]    p[HF]\n#&gt; 1       time 0.679 2.71, 32.58 1.87e-16         * 0.896 3.59, 43.03 4.65e-21\n#&gt; 2 group:time 0.679 5.43, 32.58 4.26e-09         * 0.896 7.17, 43.03 2.04e-11\n#&gt;   p[HF]&lt;.05\n#&gt; 1         *\n#&gt; 2         *\n\n\n输出是一个包含三个表的列表：\n\n方差分析结果显示标有（generalized eta squared，ges）的列上的 p 值和效应大小;效应大小本质上是由于受试者内因素而忽略受试者效应而导致的变异量。\nMauchly Sphericity检验。仅报告具有 &gt;2 水平的变量或效应，因为球形度必然适用于只有 2 个水平的效应。原假设是组差的方差相等。因此，显著的 p 值 （p &lt;= 0.05） 表示组差的方差不相等。\n球度校正结果，以防我们无法维持球形度假设。提供了文献中使用的两种常见校正：Greenhouse-Geisser epsilon （GGe） 和 Huynh-Feldt epsilon （HFe） 及其相应的 p 值\n\n\nCodelibrary(ez)\n\n# 进行重复测量方差分析\nresults &lt;- ezANOVA(data = df_long,\n                   dv = BP,\n                   wid = id,\n                   within = time,\n                   between = group,\n                   detailed = TRUE)\n\n# 查看球形检验结果\nprint(results)\n#&gt; $ANOVA\n#&gt;        Effect DFn DFd          SSn    SSd            F            p p&lt;.05\n#&gt; 1 (Intercept)   1  12 1155433.0800 946.48 14649.223396 6.784700e-20     *\n#&gt; 2       group   2  12     912.2400 946.48     5.782943 1.743351e-02     *\n#&gt; 3        time   4  48    2336.4533 263.12   106.557616 3.017101e-23     *\n#&gt; 4  group:time   8  48     837.6267 263.12    19.100638 1.621310e-12     *\n#&gt;         ges\n#&gt; 1 0.9989542\n#&gt; 2 0.4299287\n#&gt; 3 0.6588884\n#&gt; 4 0.4091519\n#&gt; \n#&gt; $`Mauchly's Test for Sphericity`\n#&gt;       Effect         W         p p&lt;.05\n#&gt; 3       time 0.2930746 0.1776608      \n#&gt; 4 group:time 0.2930746 0.1776608      \n#&gt; \n#&gt; $`Sphericity Corrections`\n#&gt;       Effect      GGe        p[GG] p[GG]&lt;.05      HFe        p[HF] p[HF]&lt;.05\n#&gt; 3       time 0.678693 1.867336e-16         * 0.896371 4.649080e-21         *\n#&gt; 4 group:time 0.678693 4.262529e-09         * 0.896371 2.041727e-11         *\n\n\n\n12.3.3 当满足球形度假设时\n\n球形度的 Mauchly 检验不显著 （p &gt; 0.05）;这表明，受试者内因素水平之间的差异方差是相等的。因此，我们可以假设协方差矩阵的球形度，并解释方差分析表中可用的标准输出。\n\nCode# Display ANOVA table\na2$ANOVA\n\n\n\n\nEffect\nDFn\nDFd\nF\np\np&lt;.05\nges\n\n\n\ngroup\n2\n12\n5.783\n0.017\n*\n0.430\n\n\ntime\n4\n48\n106.558\n0.000\n*\n0.659\n\n\ngroup:time\n8\n48\n19.101\n0.000\n*\n0.409\n\n\n\n\n\n\n\nF表示我们正在与 F 分布（F 检验）进行比较; 分别表示 time 和 Error（time） 的自由度; 表示得到的 F 统计量值(2, 18)81.8\np指定 p 值\nges（广义 eta 平方，eta2[g]）是效应大小（由于受试者内因素引起的变异量）\n\n12.3.4 当违反球形度假设时\n\n如果数据违反了球形度假设（即 Mauchly 检验，p &lt;= 0.05），则应解释表sphericity corrections中的结果，其中对自由度进行了调整，这会影响检验的统计显著性（即 p 值）。校正通过乘法和校正估计值（Greenhouse-Geisser （GG） 和 Huynh-Feldt （HF） ε 值）来应用。\n\n\n\n\n\n\nNote\n\n\n\nepsilon 提供了球形度被侵犯的程度的度量。值为 1 表示不偏离球形度（组差的所有方差均相等）。违反球形度会导致 epsilon 值低于 1。epsilon 离 1 越远，违规越严重。\n\n\n\nCodea2$`Sphericity Corrections`\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nEffect\nGGe\nDF[GG]\np[GG]\np[GG]&lt;.05\nHFe\nDF[HF]\np[HF]\np[HF]&lt;.05\n\n\n\ntime\n0.679\n2.71, 32.58\n0\n*\n0.896\n3.59, 43.03\n0\n*\n\n\ngroup:time\n0.679\n5.43, 32.58\n0\n*\n0.896\n7.17, 43.03\n0\n*\n\n\n\n\n\n\n可以看出，即使在球形度校正（p[GG] &lt; 0.001，p[HF] &lt; 0.001）之后，平均自尊得分在不同时间点仍存在统计学差异。\n在两种球形度校正方法中，Huynh-Feldt 校正被认为是最不保守的（高估了 epsilon），而 Greenhouse-Geisser 被认为是更保守的（当 epsilon 接近 1 时低估了 epsilon）。\n一般建议使用 Greenhouse-Geisser 校正，特别是当 epsilon &lt; 0.75 时。在 epsilon 大于 0.75 的情况下，一些统计学家建议使用 Huynh-Feldt 校正 （Girden 1992）。\n\nCode# correction = \"auto\"\nget_anova_table(a2)\n\n\n\n\nEffect\nDFn\nDFd\nF\np\np&lt;.05\nges\n\n\n\ngroup\n2\n12\n5.783\n0.017\n*\n0.430\n\n\ntime\n4\n48\n106.558\n0.000\n*\n0.659\n\n\ngroup:time\n8\n48\n19.101\n0.000\n*\n0.409\n\n\n\n\n\n\n\nCode# correction = \"GG\"\nget_anova_table(a2, correction = \"GG\")\n\n\n\n\nEffect\nDFn\nDFd\nF\np\np&lt;.05\nges\n\n\n\ngroup\n2.00\n12.00\n5.783\n0.017\n*\n0.430\n\n\ntime\n2.71\n32.58\n106.558\n0.000\n*\n0.659\n\n\ngroup:time\n5.43\n32.58\n19.101\n0.000\n*\n0.409\n\n\n\n\n\n\n\n12.3.5 post-hoc test\n\nCodedf_long |&gt; pairwise_t_test(BP~time,paired = T,p.adjust.method = \"bonferroni\")\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n.y.\ngroup1\ngroup2\nn1\nn2\nstatistic\ndf\np\np.adj\np.adj.signif\n\n\n\nBP\nt0\nt1\n15\n15\n3.8548215\n14\n2.00e-03\n1.80e-02\n*\n\n\nBP\nt0\nt2\n15\n15\n4.8281291\n14\n2.68e-04\n3.00e-03\n**\n\n\nBP\nt0\nt3\n15\n15\n-5.4116527\n14\n9.17e-05\n9.17e-04\n***\n\n\nBP\nt0\nt4\n15\n15\n-3.3349414\n14\n5.00e-03\n4.90e-02\n*\n\n\nBP\nt1\nt2\n15\n15\n0.0521691\n14\n9.59e-01\n1.00e+00\nns\n\n\nBP\nt1\nt3\n15\n15\n-10.2265652\n14\n1.00e-07\n7.00e-07\n****\n\n\nBP\nt1\nt4\n15\n15\n-8.4299370\n14\n7.00e-07\n7.40e-06\n****\n\n\nBP\nt2\nt3\n15\n15\n-6.6332058\n14\n1.13e-05\n1.13e-04\n***\n\n\nBP\nt2\nt4\n15\n15\n-5.8894810\n14\n3.94e-05\n3.94e-04\n***\n\n\nBP\nt3\nt4\n15\n15\n1.4675988\n14\n1.64e-01\n1.00e+00\nns",
    "crumbs": [
      "概率论与数理统计",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>重复测量方差分析</span>"
    ]
  },
  {
    "objectID": "chi-square_test.html",
    "href": "chi-square_test.html",
    "title": "\n13  \\(\\chi^2\\) 检验\n",
    "section": "",
    "text": "13.1 卡方分布\n卡方分布可以通过原假设，得到一个统计量来表示期望结果和实际结果之间的偏离程度，进而根据分布，自由度和假设成立的情况，得出观察频率极值的发生概率（比当前统计结果更加极端的概率）。计算方法是对概率分布中的每个频率，用期望频数和实际频数差的平方除以期望频数，最后把所有结果相加。\n\\[ \\chi^2=\\sum \\frac {(O-E)^2} {E} \\]\n得到的统计量结果越大，说明差别越显著，数值越小说明观察和期望的差别越小，当观察频数和期望频数一致是卡方为0。其实就是在比较观测到的比例和期望的比例的关系。\nCodeggplot() + xlim(-10,10) +\n    geom_function(mapping = aes(color=\"normal Distribution\"),\n                  fun = dnorm, args = list(mean = 0, sd = 1),\n                   )+\n    geom_function(mapping = aes(color=\"chi-square Distribution\"),\n                  fun = dchisq, args = list(df = 1 ,ncp=0), \n                 )+\n    scale_color_manual(values = c(\"normal Distribution\" = \"red\",\n                                  \"chi-square Distribution\" = \"blue\"))+\n    labs(color = \"Distribution\")\n卡方分布就可以用来检验某个分类变量各类的出现概率是否等于指定概率，可以检验数据的拟合优度（指定的一组数据与指定分布的吻合度），也可以用来检验两个变量的独立性（两个变量之间是否存在某种关联）。\n在使用卡方检验时，需要的一个参数被称为自由度，指的是独立变量的个数（组数减去限制数）。通常，二项分布已知 \\(\\pi\\) ，泊松分布已知 \\(\\lambda\\) ，正态分布已知 \\(\\mu\\) 和 \\(\\sigma^2\\) 时的自由度是n-1。进行独立性检验时，n行m列联列表的自由度是(n-1) x (m-1)。\nPearson’s \\(\\chi^2\\) 检验 用于检验涉及双向无序多分类变量的概率或比例。",
    "crumbs": [
      "概率论与数理统计",
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>$\\chi^2$ 检验</span>"
    ]
  },
  {
    "objectID": "chi-square_test.html#独立22列联表",
    "href": "chi-square_test.html#独立22列联表",
    "title": "\n13  \\(\\chi^2\\) 检验\n",
    "section": "\n13.2 独立2×2列联表",
    "text": "13.2 独立2×2列联表\n\nCodex &lt;- matrix(c(97,73,7,30),2,dimnames = list(c(\"experiment\",\"control\"),c(\"+\",\"-\")))\nx\n#&gt;             +  -\n#&gt; experiment 97  7\n#&gt; control    73 30\n\n(k1 &lt;- chisq.test(x,correct = F))\n#&gt; \n#&gt;  Pearson's Chi-squared test\n#&gt; \n#&gt; data:  x\n#&gt; X-squared = 17.681, df = 1, p-value = 2.612e-05\n\n# 期望频数列联表\nk1$expected\n#&gt;                   +        -\n#&gt; experiment 85.41063 18.58937\n#&gt; control    84.58937 18.41063\n\n\n\n13.2.1 Yate’s 校正\n\nCode(k2 &lt;- chisq.test(x,correct = T))\n#&gt; \n#&gt;  Pearson's Chi-squared test with Yates' continuity correction\n#&gt; \n#&gt; data:  x\n#&gt; X-squared = 16.188, df = 1, p-value = 5.734e-05\n\n\n\n13.2.2 Fisher’s Exact 检验\nT &lt; 5 且 n &lt; 40\n超几何分布\n\nCodeggplot() + xlim(-10,10) +\n    geom_function(mapping = aes(color=\"normal Distribution\"),\n                  fun = dnorm, args = list(mean = 0, sd = 1),\n                   )+\n    geom_function(mapping = aes(color=\"hypergeometric Distribution\"),\n                  fun = dhyper, args = list(m = 5,n=10,k=2 ), \n                 )+\n    scale_color_manual(values = c(\"normal Distribution\" = \"red\",\n                                  \"hypergeometric Distribution\" = \"blue\"))+\n    labs(color = \"Distribution\")\n\n\n\n\n\n\n\n\nCodex &lt;- matrix(c(7,2,7,17),2,dimnames = list(c(\"A\",\"B\"),c(\"Yes\",\"No\")))\nx\n#&gt;   Yes No\n#&gt; A   7  7\n#&gt; B   2 17\n\n(k5 &lt;- fisher.test(x))\n#&gt; \n#&gt;  Fisher's Exact Test for Count Data\n#&gt; \n#&gt; data:  x\n#&gt; p-value = 0.01914\n#&gt; alternative hypothesis: true odds ratio is not equal to 1\n#&gt; 95 percent confidence interval:\n#&gt;   1.134346 96.442876\n#&gt; sample estimates:\n#&gt; odds ratio \n#&gt;   7.892809\n chisq.test(x)\n#&gt; \n#&gt;  Pearson's Chi-squared test with Yates' continuity correction\n#&gt; \n#&gt; data:  x\n#&gt; X-squared = 4.4985, df = 1, p-value = 0.03393\n\nE &lt;- chisq.test(x)$expected\n\nchisq &lt;- sum((x-E)^2/E)\nchisq \n#&gt; [1] 6.332237\n\np_value_asymptotic &lt;- 1 - pchisq(chisq, df = 1)",
    "crumbs": [
      "概率论与数理统计",
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>$\\chi^2$ 检验</span>"
    ]
  },
  {
    "objectID": "chi-square_test.html#配对四格表",
    "href": "chi-square_test.html#配对四格表",
    "title": "\n13  \\(\\chi^2\\) 检验\n",
    "section": "\n13.3 配对四格表",
    "text": "13.3 配对四格表\n二项分布\n\nCodeggplot() + xlim(-10,10) +\n    geom_function(mapping = aes(color=\"normal Distribution\"),\n                  fun = dnorm, args = list(mean = 5, sd = 1),\n                   )+\n    geom_function(mapping = aes(color=\"chi-square Distribution\"),\n                  fun = dbinom, args = list(size=10 ,prob=0.5), \n                 )+\n    scale_color_manual(values = c(\"normal Distribution\" = \"red\",\n                                  \"chi-square Distribution\" = \"blue\"))+\n    labs(color = \"Distribution\")\n\n\n\n\n\n\n\n\n13.3.1 McNemar’s 检验\nb+c =5 + 34 &gt; 20\n\nCodex &lt;- matrix(c(36,34,5,135),2,dimnames = list(c(\"A+\",\"A-\"),c(\"B+\",\"B-\")))\nx\n#&gt;    B+  B-\n#&gt; A+ 36   5\n#&gt; A- 34 135\n\n(k3 &lt;- mcnemar.test(x,correct = F))\n#&gt; \n#&gt;  McNemar's Chi-squared test\n#&gt; \n#&gt; data:  x\n#&gt; McNemar's chi-squared = 21.564, df = 1, p-value = 3.422e-06\n\n\n# 校正\n(k4 &lt;- mcnemar.test(x,correct = T))\n#&gt; \n#&gt;  McNemar's Chi-squared test with continuity correction\n#&gt; \n#&gt; data:  x\n#&gt; McNemar's chi-squared = 20.103, df = 1, p-value = 7.34e-06\n\n\n\n13.3.2 精确 McNemar’s 检验\nb+c = 7 + 1 &lt;20\n二项分布B（b+c，0.5），k=min（b，c）\n\\[\nP=\\sum_{i≤k} p_i\n\\]\n\nCodex &lt;- matrix(c(3,1,7,9),2,dimnames = list(c(\"A+\",\"A-\"),c(\"B+\",\"B-\")))\nx\n#&gt;    B+ B-\n#&gt; A+  3  7\n#&gt; A-  1  9\n\n\n\nP_two_sided &lt;- 2*sum(dbinom(x=0:1,size = 8,prob = 0.5))\nP_two_sided\n#&gt; [1] 0.0703125",
    "crumbs": [
      "概率论与数理统计",
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>$\\chi^2$ 检验</span>"
    ]
  },
  {
    "objectID": "chi-square_test.html#rc列联表",
    "href": "chi-square_test.html#rc列联表",
    "title": "\n13  \\(\\chi^2\\) 检验\n",
    "section": "\n13.4 R×C列联表",
    "text": "13.4 R×C列联表\n\nCodex &lt;- matrix(c(150,184,198,50,16,2),3,dimnames = list(c(\"A\",\"B\",\"C\"),c(\"Yes\",\"No\")))\nx\n#&gt;   Yes No\n#&gt; A 150 50\n#&gt; B 184 16\n#&gt; C 198  2\n\n(k &lt;- chisq.test(x,correct = F))\n#&gt; \n#&gt;  Pearson's Chi-squared test\n#&gt; \n#&gt; data:  x\n#&gt; X-squared = 60.637, df = 2, p-value = 6.806e-14\n\n\n\nT &lt; 5 的格子不超过1/5\n没有 T &lt;1 的格子\n\n\nCode(k &lt;- chisq.test(x,correct = T))\n#&gt; \n#&gt;  Pearson's Chi-squared test\n#&gt; \n#&gt; data:  x\n#&gt; X-squared = 60.637, df = 2, p-value = 6.806e-14\nk$expected\n#&gt;        Yes       No\n#&gt; A 177.3333 22.66667\n#&gt; B 177.3333 22.66667\n#&gt; C 177.3333 22.66667\n\n\n\n13.4.1 多重比较\n\\[\n\\alpha'=\\frac {\\alpha}{比较的次数=\\frac{k(k-1)}{2}}\n\\]\n\n13.4.1.1 卡方分割法\n卡方分割法与Bonferroni方法调整p值是两种不同的统计分析方法，主要用于处理多重比较问题。它们的区别如下： 1. 卡方分割法 - 定义：卡方分割法通常用于对卡方检验结果进行后续分析，以确定哪些具体的类别或组之间存在显著差异。该方法基于检验统计量在每对比较中的分布进行分析。 - 应用：常用于发现哪些特定组（行或列）之间存在差异，通常需要进行后续的成对比较。 - 目的：帮助识别在显著性结果中，具体是哪些组之间存在显著差异。\n\n13.4.1.2 Bonferroni方法\n\n定义：Bonferroni方法是一种用于控制多重比较的显著性水平的校正方法。在进行多次假设检验时，原始的显著性水平（例如0.05）会被除以比较次数，从而得出新的显著性水平。\n应用：适用于多个独立检验结果的显著性水平调整，以减少因多重比较导致的假阳性率。\n目的：降低第一类错误的概率（即假阳性），确保在多次检验中保持整体的显著性水平。\n卡方分割法更侧重于分析具体的类别差异，而Bonferroni方法则专注于调整p值以控制错误率。\n如果你已经通过卡方检验发现某些组之间有显著差异，卡方分割法可以帮助你进一步了解哪些组之间有差异。而Bonferroni方法在初步检验前就帮助控制多重比较的问题，确保分析结果的可靠性。 ’\n\n\nCode\n# 创建频率矩阵\ndata &lt;- matrix(c(251, 225,\n                 368, 347,\n                 132, 16,\n                 54, 22,\n                 9, 18,\n                 21, 110,\n                 4, 30,\n                 46, 93), \n               nrow = 8, \n               byrow = TRUE)\n\n# 为矩阵添加行和列名称\nrownames(data) &lt;- c(\"团队\", \"球员\", \"教练\", \"品牌\", \"管理\", \"历史\", \"文化\", \"其他\")\ncolnames(data) &lt;- c(\"Period 1\", \"Period 2\")\n\n# 执行卡方检验\nchi_square_result &lt;- chisq.test(data, correct=T)\n\n# 显示结果\nprint(chi_square_result)\n#&gt; \n#&gt;  Pearson's Chi-squared test\n#&gt; \n#&gt; data:  data\n#&gt; X-squared = 205.38, df = 7, p-value &lt; 2.2e-16\n\n# 提取卡方值，自由度和p值\nchi_square_value &lt;- chi_square_result$statistic\ndegrees_of_freedom &lt;- chi_square_result$parameter\np_value &lt;- chi_square_result$p.value\n\n# 打印结果\ncat(\"卡方值:\", chi_square_value, \"\\n\")\n#&gt; 卡方值: 205.3786\ncat(\"自由度:\", degrees_of_freedom, \"\\n\")\n#&gt; 自由度: 7\ncat(\"显著性水平 (p值):\", p_value, \"\\n\")\n#&gt; 显著性水平 (p值): 8.326236e-41\n\n\n# 进行多重卡方检验\nchi_square_results &lt;- apply(data, 1, function(x) chisq.test(matrix(x, nrow=2)))\n\n# 提取卡方，自由度，p值\n\nX2 &lt;-  sapply(chi_square_results, function(x) x$statistic)\n\np_values &lt;- sapply(chi_square_results, function(x) x$p.value)\n\ndf &lt;- sapply(chi_square_results, function(x) x$parameter)\n\n# 多重比较调整\nadjusted_p_values &lt;- p.adjust(p_values, method = \"bonferroni\")\n\nsignifcance &lt;- case_when(\n    \n    adjusted_p_values&lt;0.001 ~ \"***\",\n    adjusted_p_values&lt;0.01 ~ \"**\",\n    adjusted_p_values&lt;0.05 ~ \"*\",\n    .default = \"ns\"\n    \n)\n    \n    \n    \nresults &lt;- tibble(\n    Dimension = rownames(data),\n    X2 = X2,\n    P_Value = p_values,\n    Adjusted_P_Value = adjusted_p_values,\n    signifcance = signifcance\n)\n\nprint(results)\n#&gt; # A tibble: 8 × 5\n#&gt;   Dimension     X2  P_Value Adjusted_P_Value signifcance\n#&gt;   &lt;chr&gt;      &lt;dbl&gt;    &lt;dbl&gt;            &lt;dbl&gt; &lt;chr&gt;      \n#&gt; 1 团队       1.42  2.33e- 1         1   e+ 0 ns         \n#&gt; 2 球员       0.617 4.32e- 1         1   e+ 0 ns         \n#&gt; 3 教练      90.9   1.50e-21         1.20e-20 ***        \n#&gt; 4 品牌      13.5   2.42e- 4         1.94e- 3 **         \n#&gt; 5 管理       3     8.33e- 2         6.66e- 1 ns         \n#&gt; 6 历史      60.5   7.49e-15         5.99e-14 ***        \n#&gt; 7 文化      19.9   8.24e- 6         6.59e- 5 ***        \n#&gt; 8 其他      15.9   6.71e- 5         5.36e- 4 ***",
    "crumbs": [
      "概率论与数理统计",
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>$\\chi^2$ 检验</span>"
    ]
  },
  {
    "objectID": "chi-square_test.html#拟合优度检验",
    "href": "chi-square_test.html#拟合优度检验",
    "title": "\n13  \\(\\chi^2\\) 检验\n",
    "section": "\n13.5 拟合优度检验",
    "text": "13.5 拟合优度检验\nPearson’s \\(\\chi^2\\) goodness-of-fit test",
    "crumbs": [
      "概率论与数理统计",
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>$\\chi^2$ 检验</span>"
    ]
  },
  {
    "objectID": "chi-square_test.html#独立性检验",
    "href": "chi-square_test.html#独立性检验",
    "title": "\n13  \\(\\chi^2\\) 检验\n",
    "section": "\n13.6 独立性检验",
    "text": "13.6 独立性检验\n\n13.6.1 列联表\n\nCodeeg &lt;- matrix(c(156,9421,1531,14797),nrow=2,byrow=TRUE)\ncolnames(eg) &lt;- c(\"Disease\",\"Control\")\nrownames(eg) &lt;- c(\"Exposed\",\"Unexposed\")\nprint(eg)\n#&gt;           Disease Control\n#&gt; Exposed       156    9421\n#&gt; Unexposed    1531   14797\nprop.table(eg)          #各单元格比例\n#&gt;               Disease   Control\n#&gt; Exposed   0.006022003 0.3636750\n#&gt; Unexposed 0.059100560 0.5712025\nprop.table(eg,margin = 1)        #行比例 \n#&gt;              Disease   Control\n#&gt; Exposed   0.01628903 0.9837110\n#&gt; Unexposed 0.09376531 0.9062347\n\n\n\n13.6.2 边际列联表\n\nCode# 边际\nmargin.table(x=eg,margin = 2)      #列和\n#&gt; Disease Control \n#&gt;    1687   24218\naddmargins(eg)          #添加行和、列和\n#&gt;           Disease Control   Sum\n#&gt; Exposed       156    9421  9577\n#&gt; Unexposed    1531   14797 16328\n#&gt; Sum          1687   24218 25905\naddmargins(eg,1)        #添加列和\n#&gt;           Disease Control\n#&gt; Exposed       156    9421\n#&gt; Unexposed    1531   14797\n#&gt; Sum          1687   24218\naddmargins(eg,2)        #添加行和\n#&gt;           Disease Control   Sum\n#&gt; Exposed       156    9421  9577\n#&gt; Unexposed    1531   14797 16328\naddmargins(prop.table(eg,1))\n#&gt;              Disease   Control Sum\n#&gt; Exposed   0.01628903 0.9837110   1\n#&gt; Unexposed 0.09376531 0.9062347   1\n#&gt; Sum       0.11005434 1.8899457   2\n\nftable(eg)   # \"平铺式\"列联表\n#&gt;            Disease Control\n#&gt;                           \n#&gt; Exposed        156    9421\n#&gt; Unexposed     1531   14797\n\n\n\n13.6.3 独立性检验\n独立性：判断两个或多个分类变量之间是否存在关联或取值互不影响，分析联合概率分布是否可以分解为各自概率分布的乘积。\n\n13.6.3.1 \\(\\chi^2\\) 独立性检验\n\nCodeM &lt;- as.table(rbind(c(86, 29), c(44, 30)))\ndimnames(M) &lt;- list(gender = c(\"F\", \"M\"),\n                    smoking = c(\"Yes\",\"No\"))\nM\n#&gt;       smoking\n#&gt; gender Yes No\n#&gt;      F  86 29\n#&gt;      M  44 30\n\nchisq &lt;- chisq.test(M)\nchisq\n#&gt; \n#&gt;  Pearson's Chi-squared test with Yates' continuity correction\n#&gt; \n#&gt; data:  M\n#&gt; X-squared = 4.2359, df = 1, p-value = 0.03958\nchisq$expected  # 期望频数\n#&gt;       smoking\n#&gt; gender      Yes       No\n#&gt;      F 79.10053 35.89947\n#&gt;      M 50.89947 23.10053\nchisq$parameter # degrees of freedom\n#&gt; df \n#&gt;  1\n\n#对于频数表中每个单元格的期望频数都比较大（大于 5）的大样本，correct设为 FALSE,不进行连续校正\nchisq2 &lt;- chisq.test(M,correct = FALSE) \nchisq2\n#&gt; \n#&gt;  Pearson's Chi-squared test\n#&gt; \n#&gt; data:  M\n#&gt; X-squared = 4.9237, df = 1, p-value = 0.02649\n\n\n\n13.6.3.2 Fisher精确检验\n　　如果观察总记录数 n 小于 40，或者频数表里的某个期望频数很小（小于 1） ，则需要使 用 Fisher 精确概率检验。\n\nCode# Fisher's exact test to test independence of rows and columns in contingency table\nfisher.test(M)\n#&gt; \n#&gt;  Fisher's Exact Test for Count Data\n#&gt; \n#&gt; data:  M\n#&gt; p-value = 0.03618\n#&gt; alternative hypothesis: true odds ratio is not equal to 1\n#&gt; 95 percent confidence interval:\n#&gt;  1.028780 3.964904\n#&gt; sample estimates:\n#&gt; odds ratio \n#&gt;   2.014137\n\n\n\n13.6.3.3 Cochran-Mantel-Haenszel \\(\\chi^2\\) 检验\n又叫行均分检验，常用于按照某个变量进行分层后的检验，这个方法课本上说用于检验两个有序分类变量是否存在线性相关，但实际上用途很广泛，比如因变量是有序变量的单向有序列联表，也可以用。　　\n两个变量的关联有可能受到第三个变量的影响，因此我们有必要检验两个分类变量在 调整（控制）第三个变量的情况下是否独立。 Cochran-Mantel-Haenszel χ 2 检验常用于探索 变量间的混杂因素。其零假设是：两个分类变量在第三个变量的每一层都是条件独立的。函数 mantelhaen.test( ) 可以用来进行该检验。\n\nCodeRabbits &lt;-\narray(c(0, 0, 6, 5,\n        3, 0, 3, 6,\n        6, 2, 0, 4,\n        5, 6, 1, 0,\n        2, 5, 0, 0),\n      dim = c(2, 2, 5),\n      dimnames = list(\n          Delay = c(\"None\", \"1.5h\"),\n          Response = c(\"Cured\", \"Died\"),\n          Penicillin.Level = c(\"1/8\", \"1/4\", \"1/2\", \"1\", \"4\")))\nRabbits\n#&gt; , , Penicillin.Level = 1/8\n#&gt; \n#&gt;       Response\n#&gt; Delay  Cured Died\n#&gt;   None     0    6\n#&gt;   1.5h     0    5\n#&gt; \n#&gt; , , Penicillin.Level = 1/4\n#&gt; \n#&gt;       Response\n#&gt; Delay  Cured Died\n#&gt;   None     3    3\n#&gt;   1.5h     0    6\n#&gt; \n#&gt; , , Penicillin.Level = 1/2\n#&gt; \n#&gt;       Response\n#&gt; Delay  Cured Died\n#&gt;   None     6    0\n#&gt;   1.5h     2    4\n#&gt; \n#&gt; , , Penicillin.Level = 1\n#&gt; \n#&gt;       Response\n#&gt; Delay  Cured Died\n#&gt;   None     5    1\n#&gt;   1.5h     6    0\n#&gt; \n#&gt; , , Penicillin.Level = 4\n#&gt; \n#&gt;       Response\n#&gt; Delay  Cured Died\n#&gt;   None     2    0\n#&gt;   1.5h     5    0\n\nmantelhaen.test(Rabbits)\n#&gt; \n#&gt;  Mantel-Haenszel chi-squared test with continuity correction\n#&gt; \n#&gt; data:  Rabbits\n#&gt; Mantel-Haenszel X-squared = 3.9286, df = 1, p-value = 0.04747\n#&gt; alternative hypothesis: true common odds ratio is not equal to 1\n#&gt; 95 percent confidence interval:\n#&gt;   1.026713 47.725133\n#&gt; sample estimates:\n#&gt; common odds ratio \n#&gt;                 7\n\n\n\n13.6.3.4 配对列联表的 χ 2 检验\n　　医学科研实践中经常遇到配对设计的计数资料，例如两种检验方法、诊断方法结果的 比较。其特点是对每个研究对象分别用两种方法处理，然后观察两种处理方法的某两分类 变量的计数结果。对于这种数据，我们也可以整理成列联表的形式，但是不能用前述的 χ 2独立性检验，需进行 Mcnemar 检验。\n\nCode#　　某实验室分别用免疫荧光法和乳胶凝集法对 58 名疑似系统性红斑狼疮患者血清中抗 核抗体进行测定\nresult&lt;- matrix(c(11, 2, 12, 33), nrow = 2,dimnames = list(c(\"+\",\"-\"),c(\"+\",\"-\")))\nresult\n#&gt;    +  -\n#&gt; + 11 12\n#&gt; -  2 33\n\n#　　对于配对四格表，如果样本量较小（不一致的结果的总数小于 40 ） ，则需要进行连续性校正。\nmcnemar.test(result,correct = TRUE)\n#&gt; \n#&gt;  McNemar's Chi-squared test with continuity correction\n#&gt; \n#&gt; data:  result\n#&gt; McNemar's chi-squared = 5.7857, df = 1, p-value = 0.01616",
    "crumbs": [
      "概率论与数理统计",
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>$\\chi^2$ 检验</span>"
    ]
  },
  {
    "objectID": "nonparametric_test.html",
    "href": "nonparametric_test.html",
    "title": "\n14  非参数秩检验\n",
    "section": "",
    "text": "14.1 单样本Wilcoxon Signed-Rank 检验\n如果样本数据没有通过正态分布检验就要采用单样本wilcoxon符号秩检验进行计算。使用该检验需要满足的条件是样本值均匀地分布在均值两侧。\nCodex&lt;- dplyr::filter(PlantGrowth,group==\"ctrl\")\nshapiro.test(x$weight)\n#&gt; \n#&gt;  Shapiro-Wilk normality test\n#&gt; \n#&gt; data:  x$weight\n#&gt; W = 0.95668, p-value = 0.7475\nsummary(x$weight)\n#&gt;    Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n#&gt;   4.170   4.550   5.155   5.032   5.293   6.110\nwilcox.test(x$weight, mu=7) \n#&gt; \n#&gt;  Wilcoxon signed rank exact test\n#&gt; \n#&gt; data:  x$weight\n#&gt; V = 0, p-value = 0.001953\n#&gt; alternative hypothesis: true location is not equal to 7",
    "crumbs": [
      "概率论与数理统计",
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>非参数秩检验</span>"
    ]
  },
  {
    "objectID": "nonparametric_test.html#配对-wilcoxons-signed-rank-检验",
    "href": "nonparametric_test.html#配对-wilcoxons-signed-rank-检验",
    "title": "\n14  非参数秩检验\n",
    "section": "\n14.2 配对 Wilcoxon’s signed-rank 检验",
    "text": "14.2 配对 Wilcoxon’s signed-rank 检验\n\\[\nT_++T_-=\\frac{n(n+1)}{2},n为非零配对差值的数量\n\\]\n\\[\nT=min{(T_+,T_-)}\n\\]\n5 ≤ n ≤30，附表T0\nn＞16，正态近似法\n\nCode\ndf &lt;- tibble(\n    low=c(958.5,838.4,612.2,812.9,739.0,899.4,758.5,695.0,749.7,815.5),\n    high=c(958.5,866.5,788.9,815.2,783.2,910.9,760.8,870.8,862.3,799.9),\n)\n\nshapiro.test(df$high-df$low)\n#&gt; \n#&gt;  Shapiro-Wilk normality test\n#&gt; \n#&gt; data:  df$high - df$low\n#&gt; W = 0.79689, p-value = 0.01329\n\n# 忽略 差值为0\nwilcox.test(df$low[-1],df$high[-1],exact = T,paired = T)\n#&gt; \n#&gt;  Wilcoxon signed rank exact test\n#&gt; \n#&gt; data:  df$low[-1] and df$high[-1]\n#&gt; V = 4, p-value = 0.02734\n#&gt; alternative hypothesis: true location shift is not equal to 0",
    "crumbs": [
      "概率论与数理统计",
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>非参数秩检验</span>"
    ]
  },
  {
    "objectID": "nonparametric_test.html#独立双样本wilcoxons-rank-sum-检验",
    "href": "nonparametric_test.html#独立双样本wilcoxons-rank-sum-检验",
    "title": "\n14  非参数秩检验\n",
    "section": "\n14.3 独立双样本Wilcoxon’s Rank-Sum 检验",
    "text": "14.3 独立双样本Wilcoxon’s Rank-Sum 检验\n当两个样本不满足正态分布时，使用Wilcoxon秩和检验进行非参数检验\n\\[\nT=T_{min(n1,n2)}=T_1\n\\]\n\nCodeMVR = c(38, 29, 35, 33, 38, 41, 31)\nMVP = c(32, 43, 44, 81, 35, 46, 37, 45, 44)\nshapiro.test(c(MVR,MVP))\n#&gt; \n#&gt;  Shapiro-Wilk normality test\n#&gt; \n#&gt; data:  c(MVR, MVP)\n#&gt; W = 0.70443, p-value = 0.0001889\n\ncombined_data &lt;- c(MVR, MVP)\nranked_data &lt;- rank(combined_data)\nranked_data \n#&gt;  [1]  8.5  1.0  5.5  4.0  8.5 10.0  2.0  3.0 11.0 12.5 16.0  5.5 15.0  7.0 14.0\n#&gt; [16] 12.5\n\nMVR_ranks &lt;- ranked_data[1:length(MVR)]\nMVP_ranks &lt;- ranked_data[(length(MVR)+1):length(combined_data)]\n\nT1 &lt;- sum(MVR_ranks)\nT2 &lt;- sum(MVP_ranks)\n\nW &lt;- T1-length(MVR)*(length(MVR)+1)/2\n\n\n曼-惠特尼 U 统计量\n\\[\n曼-惠特尼U统计量\\ \\ W= 威尔科克森W秩和\\  \\ \\  T_1-\\frac{n_1(n_1+1)}{2}\n\\]\nn1&lt;10,n2-n1&lt;10，附录\nn1&gt;10,n2&gt;10，正态近似法\n\nCodewilcox.test(MVR,MVP,exact = F,correct = F)\n#&gt; \n#&gt;  Wilcoxon rank sum test\n#&gt; \n#&gt; data:  MVR and MVP\n#&gt; W = 11.5, p-value = 0.03386\n#&gt; alternative hypothesis: true location shift is not equal to 0\n\n\n\nCode\n\nggplot() + xlim(0,50) +\n    geom_function(mapping = aes(color=\"Wilcox Distribution\"),\n                  fun = dwilcox, args = list(m=7 ,n=9), \n                 )+\n    scale_color_manual(values = c(\"Wilcox Distribution\" = \"blue\"))+\n    labs(color = \"Distribution\")",
    "crumbs": [
      "概率论与数理统计",
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>非参数秩检验</span>"
    ]
  },
  {
    "objectID": "nonparametric_test.html#独立多样本kruskal-wallis-检验",
    "href": "nonparametric_test.html#独立多样本kruskal-wallis-检验",
    "title": "\n14  非参数秩检验\n",
    "section": "\n14.4 独立多样本Kruskal-Wallis 检验",
    "text": "14.4 独立多样本Kruskal-Wallis 检验\n假设：\n\n随机，独立\n每个样本至少5个观测\n能够计算秩次\n\n\nCodekruskal.test(weight~group,data = PlantGrowth)\n#&gt; \n#&gt;  Kruskal-Wallis rank sum test\n#&gt; \n#&gt; data:  weight by group\n#&gt; Kruskal-Wallis chi-squared = 7.9882, df = 2, p-value = 0.01842\n\n\n\n14.4.1 多重比较\n\nCodepairwise.wilcox.test(PlantGrowth$weight,PlantGrowth$group,p.adjust.method = \"fdr\",exact=F)\n#&gt; \n#&gt;  Pairwise comparisons using Wilcoxon rank sum test with continuity correction \n#&gt; \n#&gt; data:  PlantGrowth$weight and PlantGrowth$group \n#&gt; \n#&gt;      ctrl  trt1 \n#&gt; trt1 0.199 -    \n#&gt; trt2 0.096 0.034\n#&gt; \n#&gt; P value adjustment method: fdr",
    "crumbs": [
      "概率论与数理统计",
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>非参数秩检验</span>"
    ]
  },
  {
    "objectID": "nonparametric_test.html#单因素重复测量方差分析的非参数替代",
    "href": "nonparametric_test.html#单因素重复测量方差分析的非参数替代",
    "title": "\n14  非参数秩检验\n",
    "section": "\n14.5 单因素重复测量方差分析的非参数替代",
    "text": "14.5 单因素重复测量方差分析的非参数替代\n\nCodefriedman.test()",
    "crumbs": [
      "概率论与数理统计",
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>非参数秩检验</span>"
    ]
  },
  {
    "objectID": "correlation.html",
    "href": "correlation.html",
    "title": "\n15  相关性\n",
    "section": "",
    "text": "15.1 分类变量\n如果独立性检验的结果表明两个变量之间不独立，那么如何量化它们之间相关性的强弱?",
    "crumbs": [
      "概率论与数理统计",
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>相关性</span>"
    ]
  },
  {
    "objectID": "correlation.html#分类变量",
    "href": "correlation.html#分类变量",
    "title": "\n15  相关性\n",
    "section": "",
    "text": "15.1.1 Phi 系数、列联系数和 Cramer’s V 系数\n\nvcd 包里的函数 assocstats( )可以用来计算列联表的 Phi 系数、列联系数和 Cramer’s V 系数。其中， Phi 系数只适用于四格表。 　　\n\nCodelibrary(vcd)\nmytable &lt;- table(Arthritis$Sex, Arthritis$Treatment)\nassocstats(mytable)\n#&gt;                      X^2 df P(&gt; X^2)\n#&gt; Likelihood Ratio 0.73748  1  0.39047\n#&gt; Pearson          0.73653  1  0.39078\n#&gt; \n#&gt; Phi-Coefficient   : 0.094 \n#&gt; Contingency Coeff.: 0.093 \n#&gt; Cramer's V        : 0.094\n\n\n\n15.1.2 Kappa 统计量\n对于配对列联表，可以计算一致性指标 Kappa 统计量。 epiDisplay 包里的函数 kap( )可以用于计算一致性的比例以及 Kappa 统计量的值 　　 　　\n\nCodemy.matrix &lt;- matrix(c(11, 2, 12, 33), nrow = 2)\nsum(my.matrix)\n#&gt; [1] 58\nvcd::Kappa(my.matrix)\n#&gt;            value    ASE     z Pr(&gt;|z|)\n#&gt; Unweighted 0.455 0.1153 3.945 7.97e-05\n#&gt; Weighted   0.455 0.1153 3.945 7.97e-05\nepiDisplay::kap(my.matrix)\n#&gt; \n#&gt;  Table for calculation of kappa\n#&gt;    A  B\n#&gt; A 11 12\n#&gt; B  2 33\n#&gt; \n#&gt; Observed agreement = 75.86 % \n#&gt; Expected agreement = 55.71 % \n#&gt; Kappa = 0.455 \n#&gt; Standard error = 0.121 , Z = 3.762 , P value = &lt; 0.001 \n#&gt; \n\n\n　　共 58 个对象，每一对象用两种检测方法检测，其中11 个对象的两种检测结果都为阳性， 33 个对象的两种检测结果都是阴性，所以总一致性为 (11 + 33)/58 ≈ 75.86% 。\n\nCodechisq.test(my.matrix)$expected\n#&gt;          [,1]     [,2]\n#&gt; [1,] 5.155172 17.84483\n#&gt; [2,] 7.844828 27.15517\n\n\n　为了解释期望一致性和 Kappa 值的含义，先计算各个单元格的期望频数。 对角线上的这两个单元格对应的期望频数分别约为5.155172 和27.15517 ，因此期望一致性为 (5.155172+27.15517)/58≈ 55.71% 。期望一致性是假定两种方法的检测结果都是完全随机的情况下的 一致性。也就是说，即使两种检测方法都毫无作用，平均也能达到 55.71% 的一致性。 Kappa 统计量是超出随机的一致性的部分占最大可能超出随机的一致性的比例。在本例中，前者为 75.86% − 55.71% ， 后者为 100% − 55.71% 。 因此， Kappa 值为 (75.86 - 55.71)/(100 - 55.71) ≈ 0.455\n\n15.1.3 马赛克图\n　　马赛克图中的矩形面积正比于多维列联表中单元格的频率 　　\n\nCodemosaicplot(mytable,xlab =\"Sex\",ylab =  \"Treatment\",las = 1)\n\n\n\n\n\n\nCodemosaicplot(my.matrix)",
    "crumbs": [
      "概率论与数理统计",
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>相关性</span>"
    ]
  },
  {
    "objectID": "correlation.html#连续变量",
    "href": "correlation.html#连续变量",
    "title": "\n15  相关性\n",
    "section": "\n15.2 连续变量",
    "text": "15.2 连续变量\n如果两个连续变量不相互独立时，使用协方差（covariance）来描述两个变量的关系。\n协方差（或相关系数）为零，不相关，不存在线性关系，但可能存在非线性关系。\n\nCodedf &lt;- mpg[,c(3,8,9)]\ncov(df)    # 协方差矩阵\n#&gt;           displ      cty       hwy\n#&gt; displ  1.669158 -4.39069 -5.893111\n#&gt; cty   -4.390690 18.11307 24.225432\n#&gt; hwy   -5.893111 24.22543 35.457779\n\n\n\n15.2.0.1 相关系数\n相关系数的取值范围： \\([-1,1]\\)\n\\[\nr(X,Y)=\\frac {\\sum_{i=1}^n (x_i-\\bar x)(y_i-\\bar y)}{\\sqrt{\\sum_{i=1}^n (x_i-\\bar x)^2 \\sum_{i=1}^n (y_i-\\bar y)^2}}\n\\]\n\nCode# Pearson's 积差相关系数 　　一般要求两个连续变量都服从正态分布\ncor(df,use = \"everything\",method=\"pearson\") # default\n#&gt;           displ        cty        hwy\n#&gt; displ  1.000000 -0.7985240 -0.7660200\n#&gt; cty   -0.798524  1.0000000  0.9559159\n#&gt; hwy   -0.766020  0.9559159  1.0000000\n\ncorrelation::correlation(df,method = \"pearson\",p_adjust = \"holm\")\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nParameter1\nParameter2\nr\nCI\nCI_low\nCI_high\nt\ndf_error\np\nMethod\nn_Obs\n\n\n\ndispl\ncty\n-0.7985240\n0.95\n-0.8406782\n-0.7467508\n-20.20515\n232\n0\nPearson correlation\n234\n\n\ndispl\nhwy\n-0.7660200\n0.95\n-0.8142727\n-0.7072539\n-18.15085\n232\n0\nPearson correlation\n234\n\n\ncty\nhwy\n0.9559159\n0.95\n0.9433129\n0.9657663\n49.58470\n232\n0\nPearson correlation\n234\n\n\n\n\n\nCode\n# Spearman's rank相关系数  　　非参数\ncor(df,method = \"spearman\")\n#&gt;            displ        cty        hwy\n#&gt; displ  1.0000000 -0.8809049 -0.8266576\n#&gt; cty   -0.8809049  1.0000000  0.9542104\n#&gt; hwy   -0.8266576  0.9542104  1.0000000\n\ncorrelation::correlation(df,method = \"spearman\",p_adjust = \"holm\")\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nParameter1\nParameter2\nrho\nCI\nCI_low\nCI_high\nS\np\nMethod\nn_Obs\n\n\n\ndispl\ncty\n-0.8809049\n0.95\n-0.9073926\n-0.8474471\n4016568.96\n0\nSpearman correlation\n234\n\n\ndispl\nhwy\n-0.8266576\n0.95\n-0.8643401\n-0.7797446\n3900726.77\n0\nSpearman correlation\n234\n\n\ncty\nhwy\n0.9542104\n0.95\n0.9406973\n0.9647003\n97781.21\n0\nSpearman correlation\n234\n\n\n\n\n\nCode\n# Kendall's tau相关系数  　　非参数\ncor(df,method = \"kendall\")\n#&gt;            displ        cty        hwy\n#&gt; displ  1.0000000 -0.7210828 -0.6536974\n#&gt; cty   -0.7210828  1.0000000  0.8628045\n#&gt; hwy   -0.6536974  0.8628045  1.0000000\ncorrelation::correlation(df,method = \"kendall\",p_adjust = \"holm\")\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nParameter1\nParameter2\ntau\nCI\nCI_low\nCI_high\nz\np\nMethod\nn_Obs\n\n\n\ndispl\ncty\n-0.7210828\n0.95\n-0.7596258\n-0.6774923\n-15.53533\n0\nKendall correlation\n234\n\n\ndispl\nhwy\n-0.6536974\n0.95\n-0.6999287\n-0.6020109\n-14.13933\n0\nKendall correlation\n234\n\n\ncty\nhwy\n0.8628045\n0.95\n0.8392948\n0.8830936\n18.39871\n0\nKendall correlation\n234\n\n\n\n\n\n\n\n15.2.0.2 相关图（correlogram）\n\nCodeggcorrplot::ggcorrplot(\n    corr = cor(df,use = \"everything\",method=\"pearson\") ,\n    lab = T\n)\n\n\n\n\n\n\n\n\n15.2.0.3 显著性检验\n　　零假设为变量之间不相关（即两个总体的相关系数为 0 ） 。函数 cor.test( ) 可用于对相关系数进行显著性检 验。\n统计量\n\\[\nt=\\frac{r\\sqrt{n-2}}{\\sqrt{1-r^2}}\n\\]\n\nCodecor.test(df$displ,df$hwy)\n#&gt; \n#&gt;  Pearson's product-moment correlation\n#&gt; \n#&gt; data:  df$displ and df$hwy\n#&gt; t = -18.151, df = 232, p-value &lt; 2.2e-16\n#&gt; alternative hypothesis: true correlation is not equal to 0\n#&gt; 95 percent confidence interval:\n#&gt;  -0.8142727 -0.7072539\n#&gt; sample estimates:\n#&gt;      cor \n#&gt; -0.76602\n\n\npsych包corr.test() 计算相关系数矩阵和显著性检验\n\nCodepsych::corr.test(df)\n#&gt; Call:psych::corr.test(x = df)\n#&gt; Correlation matrix \n#&gt;       displ   cty   hwy\n#&gt; displ  1.00 -0.80 -0.77\n#&gt; cty   -0.80  1.00  0.96\n#&gt; hwy   -0.77  0.96  1.00\n#&gt; Sample Size \n#&gt; [1] 234\n#&gt; Probability values (Entries above the diagonal are adjusted for multiple tests.) \n#&gt;       displ cty hwy\n#&gt; displ     0   0   0\n#&gt; cty       0   0   0\n#&gt; hwy       0   0   0\n#&gt; \n#&gt;  To see confidence intervals of the correlations, print with the short=FALSE option\n\nprint(psych::corr.test(df), short = FALSE)\n#&gt; Call:psych::corr.test(x = df)\n#&gt; Correlation matrix \n#&gt;       displ   cty   hwy\n#&gt; displ  1.00 -0.80 -0.77\n#&gt; cty   -0.80  1.00  0.96\n#&gt; hwy   -0.77  0.96  1.00\n#&gt; Sample Size \n#&gt; [1] 234\n#&gt; Probability values (Entries above the diagonal are adjusted for multiple tests.) \n#&gt;       displ cty hwy\n#&gt; displ     0   0   0\n#&gt; cty       0   0   0\n#&gt; hwy       0   0   0\n#&gt; \n#&gt;  Confidence intervals based upon normal theory.  To get bootstrapped values, try cor.ci\n#&gt;           raw.lower raw.r raw.upper raw.p lower.adj upper.adj\n#&gt; displ-cty     -0.84 -0.80     -0.75     0     -0.85     -0.74\n#&gt; displ-hwy     -0.81 -0.77     -0.71     0     -0.81     -0.71\n#&gt; cty-hwy        0.94  0.96      0.97     0      0.94      0.97",
    "crumbs": [
      "概率论与数理统计",
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>相关性</span>"
    ]
  },
  {
    "objectID": "LinearRegression.html",
    "href": "LinearRegression.html",
    "title": "\n16  线性回归\n",
    "section": "",
    "text": "16.1 一元线性回归",
    "crumbs": [
      "统计模型",
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>线性回归</span>"
    ]
  },
  {
    "objectID": "LinearRegression.html#一元线性回归",
    "href": "LinearRegression.html#一元线性回归",
    "title": "\n16  线性回归\n",
    "section": "",
    "text": "16.1.1 lm\n\nCode#linear model specification 线性模型规范\nlm_spec &lt;-linear_reg() |&gt;\n  set_mode(\"regression\") |&gt;\n  set_engine(\"lm\")  \nlm_spec\n#&gt; Linear Regression Model Specification (regression)\n#&gt; \n#&gt; Computational engine: lm\n\n\nlinear regression model：\n\\[\nY_i=\\beta_0+ \\beta_1 X_i+\\epsilon_i,其中\\epsilon_i\\sim N(0,\\sigma^2)\n\\]\n\nCodep_sales&lt;-function(x){\n  ggplot(advertising,aes({{x}},sales))+\n           geom_point(shape=21,color=\"red\")+\n           geom_smooth(formula = 'y ~ x',method = \"lm\",se=FALSE)\n}\np_sales(TV)|p_sales(radio)|p_sales(newspaper)\n\n\n\n\n\n\n\n\nCodelm_sales_tv &lt;- lm_spec |&gt;  fit(sales ~ TV, data = advertising)\n# 模型摘要\nlm_sales_tv  # lm_sales_tv |&gt;  pluck(\"fit\")\n#&gt; parsnip model object\n#&gt; \n#&gt; \n#&gt; Call:\n#&gt; stats::lm(formula = sales ~ TV, data = data)\n#&gt; \n#&gt; Coefficients:\n#&gt; (Intercept)           TV  \n#&gt;     7.03259      0.04754\nsummary(lm_sales_tv$fit)  # lm_sales_tv |&gt;pluck(\"fit\") |&gt;summary()\n#&gt; \n#&gt; Call:\n#&gt; stats::lm(formula = sales ~ TV, data = data)\n#&gt; \n#&gt; Residuals:\n#&gt;     Min      1Q  Median      3Q     Max \n#&gt; -8.3860 -1.9545 -0.1913  2.0671  7.2124 \n#&gt; \n#&gt; Coefficients:\n#&gt;             Estimate Std. Error t value Pr(&gt;|t|)    \n#&gt; (Intercept) 7.032594   0.457843   15.36   &lt;2e-16 ***\n#&gt; TV          0.047537   0.002691   17.67   &lt;2e-16 ***\n#&gt; ---\n#&gt; Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n#&gt; \n#&gt; Residual standard error: 3.259 on 198 degrees of freedom\n#&gt; Multiple R-squared:  0.6119, Adjusted R-squared:  0.6099 \n#&gt; F-statistic: 312.1 on 1 and 198 DF,  p-value: &lt; 2.2e-16\n\n\n# 参数估计值、标准误、统计量、p值\nbroom::tidy(lm_sales_tv)\n\n\n\n\nterm\nestimate\nstd.error\nstatistic\np.value\n\n\n\n(Intercept)\n7.0325935\n0.4578429\n15.36028\n0\n\n\nTV\n0.0475366\n0.0026906\n17.66763\n0\n\n\n\n\n\nCode# 模型统计信息\nbroom::glance(lm_sales_tv) \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nr.squared\nadj.r.squared\nsigma\nstatistic\np.value\ndf\nlogLik\nAIC\nBIC\ndeviance\ndf.residual\nnobs\n\n\n0.6118751\n0.6099148\n3.258656\n312.145\n0\n1\n-519.0457\n1044.091\n1053.986\n2102.531\n198\n200\n\n\n\n\n\n\n16.1.2 预测\n\nCode# 预测\nstats::predict(lm_sales_tv, new_data = advertising)\n\n\n\n\n.pred\n\n\n\n17.970775\n\n\n9.147974\n\n\n7.850224\n\n\n14.234395\n\n\n15.627218\n\n\n7.446162\n\n\n9.765950\n\n\n12.746498\n\n\n7.441409\n\n\n16.530414\n\n\n10.174765\n\n\n17.238710\n\n\n8.163966\n\n\n11.667416\n\n\n16.734822\n\n\n16.321253\n\n\n10.255578\n\n\n20.409404\n\n\n10.322129\n\n\n14.034741\n\n\n17.414596\n\n\n18.317792\n\n\n7.660077\n\n\n17.885209\n\n\n9.994126\n\n\n19.529976\n\n\n13.825579\n\n\n18.446141\n\n\n18.859710\n\n\n10.388680\n\n\n20.956076\n\n\n12.399480\n\n\n11.653155\n\n\n19.658325\n\n\n11.581850\n\n\n20.851495\n\n\n19.720123\n\n\n10.583581\n\n\n9.081423\n\n\n17.870948\n\n\n16.658763\n\n\n15.446579\n\n\n20.989351\n\n\n16.867925\n\n\n8.225763\n\n\n15.356259\n\n\n11.296630\n\n\n18.436634\n\n\n17.832918\n\n\n10.212795\n\n\n16.530414\n\n\n11.805272\n\n\n17.319523\n\n\n15.712784\n\n\n19.520469\n\n\n16.487631\n\n\n7.379611\n\n\n13.507084\n\n\n17.053317\n\n\n17.048564\n\n\n9.575804\n\n\n19.453918\n\n\n18.408112\n\n\n11.914606\n\n\n13.264647\n\n\n10.312622\n\n\n8.529998\n\n\n13.654448\n\n\n18.317792\n\n\n17.338537\n\n\n16.497139\n\n\n12.252117\n\n\n8.306575\n\n\n13.183835\n\n\n17.176913\n\n\n7.835963\n\n\n8.339851\n\n\n12.760759\n\n\n7.289291\n\n\n12.546844\n\n\n10.664393\n\n\n18.431880\n\n\n10.612103\n\n\n10.284100\n\n\n17.181666\n\n\n16.216673\n\n\n10.659639\n\n\n12.294900\n\n\n11.230079\n\n\n12.252117\n\n\n13.416764\n\n\n8.392141\n\n\n17.381320\n\n\n18.959537\n\n\n12.138029\n\n\n14.795327\n\n\n16.425834\n\n\n15.822118\n\n\n20.803958\n\n\n13.459547\n\n\n17.604742\n\n\n21.122454\n\n\n20.352360\n\n\n15.964728\n\n\n18.355821\n\n\n13.587896\n\n\n8.221010\n\n\n11.329906\n\n\n7.655323\n\n\n19.173451\n\n\n17.766367\n\n\n18.522199\n\n\n15.384781\n\n\n16.996273\n\n\n10.749959\n\n\n10.602595\n\n\n13.649694\n\n\n10.664393\n\n\n13.007949\n\n\n7.954804\n\n\n13.749521\n\n\n7.926282\n\n\n17.680801\n\n\n12.884354\n\n\n17.942252\n\n\n11.177789\n\n\n7.403379\n\n\n10.845032\n\n\n17.504915\n\n\n9.865777\n\n\n7.065869\n\n\n19.639311\n\n\n7.431901\n\n\n17.481147\n\n\n8.786696\n\n\n9.328613\n\n\n8.249531\n\n\n20.043372\n\n\n9.076669\n\n\n15.822118\n\n\n10.521783\n\n\n16.240441\n\n\n17.514423\n\n\n12.004926\n\n\n11.605618\n\n\n13.701984\n\n\n18.446141\n\n\n18.593505\n\n\n8.838986\n\n\n9.157481\n\n\n20.376129\n\n\n12.784527\n\n\n16.425834\n\n\n15.175620\n\n\n15.959975\n\n\n7.227494\n\n\n11.496284\n\n\n14.153582\n\n\n7.588772\n\n\n13.293169\n\n\n15.232664\n\n\n11.106484\n\n\n15.988497\n\n\n14.804834\n\n\n12.603888\n\n\n18.179936\n\n\n7.883499\n\n\n16.863171\n\n\n17.271986\n\n\n20.547260\n\n\n9.409426\n\n\n14.852371\n\n\n7.964312\n\n\n15.037764\n\n\n17.604742\n\n\n20.195489\n\n\n18.840695\n\n\n15.123330\n\n\n20.185982\n\n\n14.904661\n\n\n14.476831\n\n\n17.419349\n\n\n9.704153\n\n\n20.704131\n\n\n19.097393\n\n\n16.777605\n\n\n13.663955\n\n\n16.116846\n\n\n20.628073\n\n\n7.921529\n\n\n8.910291\n\n\n10.621610\n\n\n7.850224\n\n\n14.961705\n\n\n14.148829\n\n\n8.848493\n\n\n11.510545\n\n\n15.446579\n\n\n20.513985\n\n\n18.065848\n\n\n\n\n\nCodepredict(lm_sales_tv, new_data = advertising, type = \"conf_int\")\n\n\n\n\n.pred_lower\n.pred_upper\n\n\n\n17.337774\n18.603775\n\n\n8.439101\n9.856848\n\n\n7.024932\n8.675515\n\n\n13.779384\n14.689405\n\n\n15.138794\n16.115642\n\n\n6.582865\n8.309460\n\n\n9.108530\n10.423370\n\n\n12.270304\n13.222691\n\n\n6.577660\n8.305157\n\n\n15.996715\n17.064114\n\n\n9.549526\n10.800005\n\n\n16.659619\n17.817801\n\n\n7.367674\n8.960258\n\n\n11.142463\n12.192369\n\n\n16.188810\n17.280833\n\n\n15.799420\n16.843086\n\n\n9.636500\n10.874656\n\n\n19.564011\n21.254797\n\n\n9.708072\n10.936186\n\n\n13.580343\n14.489139\n\n\n16.823134\n18.006057\n\n\n17.657240\n18.978344\n\n\n6.816987\n8.503167\n\n\n17.258820\n18.511597\n\n\n9.354869\n10.633383\n\n\n18.765535\n20.294417\n\n\n13.370652\n14.280507\n\n\n17.775119\n19.117163\n\n\n18.154028\n19.565391\n\n\n9.779595\n10.997766\n\n\n20.058629\n21.853522\n\n\n11.910304\n12.888657\n\n\n11.127403\n12.178907\n\n\n18.882317\n20.434333\n\n\n11.052050\n12.111650\n\n\n19.964095\n21.738895\n\n\n18.938513\n20.501733\n\n\n9.988760\n11.178401\n\n\n8.366832\n9.796014\n\n\n17.245654\n18.496242\n\n\n16.117413\n17.200114\n\n\n14.965184\n15.927974\n\n\n20.088700\n21.890003\n\n\n16.313537\n17.422311\n\n\n7.435126\n9.016401\n\n\n14.878098\n15.834421\n\n\n10.749779\n11.843482\n\n\n17.766392\n19.106875\n\n\n17.210533\n18.455304\n\n\n9.590464\n10.835126\n\n\n15.996715\n17.064114\n\n\n11.287853\n12.322691\n\n\n16.734797\n17.904248\n\n\n15.220778\n16.204790\n\n\n18.756881\n20.284057\n\n\n15.956421\n17.018841\n\n\n6.509989\n8.249233\n\n\n13.049061\n13.965107\n\n\n16.486822\n17.619813\n\n\n16.482385\n17.614743\n\n\n8.902886\n10.248722\n\n\n18.696287\n20.211548\n\n\n17.740207\n19.076017\n\n\n11.402912\n12.426301\n\n\n12.802445\n13.726849\n\n\n9.697850\n10.927393\n\n\n7.766900\n9.293095\n\n\n13.198199\n14.110697\n\n\n17.657240\n18.978344\n\n\n16.752474\n17.924601\n\n\n15.965378\n17.028899\n\n\n11.756613\n12.747620\n\n\n7.523303\n9.089849\n\n\n12.719897\n13.647773\n\n\n16.602072\n17.751753\n\n\n7.009342\n8.662584\n\n\n7.559601\n9.120102\n\n\n12.285039\n13.236479\n\n\n6.411058\n8.167525\n\n\n12.063517\n13.030171\n\n\n10.075353\n11.253433\n\n\n17.762028\n19.101732\n\n\n10.019331\n11.204874\n\n\n9.667179\n10.901020\n\n\n16.606501\n17.756832\n\n\n15.700479\n16.732866\n\n\n10.070261\n11.249017\n\n\n11.801281\n12.788518\n\n\n10.679060\n11.781098\n\n\n11.756613\n12.747620\n\n\n12.957366\n13.876163\n\n\n7.616628\n9.167655\n\n\n16.792229\n17.970411\n\n\n18.245294\n19.673779\n\n\n11.637311\n12.638747\n\n\n14.332816\n15.257838\n\n\n15.898163\n16.953504\n\n\n15.325305\n16.318932\n\n\n19.921111\n21.686805\n\n\n13.000827\n13.918267\n\n\n16.999475\n18.210010\n\n\n20.208944\n22.035963\n\n\n19.512330\n21.192391\n\n\n15.461268\n16.468188\n\n\n17.692182\n19.019460\n\n\n13.130918\n14.044874\n\n\n7.429938\n9.012081\n\n\n10.785112\n11.874700\n\n\n6.811787\n8.498860\n\n\n18.440630\n19.906273\n\n\n17.149034\n18.383700\n\n\n17.844906\n19.199493\n\n\n14.905619\n15.863943\n\n\n16.433557\n17.558990\n\n\n10.166949\n11.332968\n\n\n10.009142\n11.196049\n\n\n13.193397\n14.105991\n\n\n10.075353\n11.253433\n\n\n12.539655\n13.476243\n\n\n7.139232\n8.770377\n\n\n13.294105\n14.204937\n\n\n7.108064\n8.744501\n\n\n17.069892\n18.291710\n\n\n12.412534\n13.356174\n\n\n17.311465\n18.573041\n\n\n10.623447\n11.732130\n\n\n6.536018\n8.270741\n\n\n10.268612\n11.421452\n\n\n16.906950\n18.102881\n\n\n9.216364\n10.515190\n\n\n6.166202\n7.965536\n\n\n18.865022\n20.413599\n\n\n6.567250\n8.296553\n\n\n16.884903\n18.077391\n\n\n8.046420\n9.526971\n\n\n8.635095\n10.022132\n\n\n7.461064\n9.037999\n\n\n19.232134\n20.854610\n\n\n8.361669\n9.791669\n\n\n15.325305\n16.318932\n\n\n9.922488\n11.121078\n\n\n15.722983\n16.757898\n\n\n16.915767\n18.113078\n\n\n11.497788\n12.512064\n\n\n11.077178\n12.134059\n\n\n13.246182\n14.157786\n\n\n17.775119\n19.117163\n\n\n17.910289\n19.276720\n\n\n8.103309\n9.574663\n\n\n8.449422\n9.865541\n\n\n19.533866\n21.218391\n\n\n12.309586\n13.259468\n\n\n15.898163\n16.953504\n\n\n14.703347\n15.647893\n\n\n15.456743\n16.463206\n\n\n6.343350\n8.111637\n\n\n10.961511\n12.031058\n\n\n13.698951\n14.608214\n\n\n6.738968\n8.438577\n\n\n12.831539\n13.754799\n\n\n14.758617\n15.706712\n\n\n10.547545\n11.665422\n\n\n15.483889\n16.493105\n\n\n14.342124\n15.267544\n\n\n12.122694\n13.085082\n\n\n17.530466\n18.829406\n\n\n7.061306\n8.705693\n\n\n16.309088\n17.417254\n\n\n16.690585\n17.853386\n\n\n19.688852\n21.405668\n\n\n8.722696\n10.096155\n\n\n14.388630\n15.316112\n\n\n7.149620\n8.779003\n\n\n14.569451\n15.506077\n\n\n16.999475\n18.210010\n\n\n19.370131\n21.020847\n\n\n18.136636\n19.544754\n\n\n14.652614\n15.594045\n\n\n19.361510\n21.010454\n\n\n14.439719\n15.369603\n\n\n14.019615\n14.934048\n\n\n16.827548\n18.011151\n\n\n9.041731\n10.366575\n\n\n19.830819\n21.577444\n\n\n18.371212\n19.823573\n\n\n16.228931\n17.326279\n\n\n13.207800\n14.120110\n\n\n15.605845\n16.627847\n\n\n19.761999\n21.494146\n\n\n7.102869\n8.740188\n\n\n8.180857\n9.639725\n\n\n10.029519\n11.213700\n\n\n7.024932\n8.675515\n\n\n14.495373\n15.428037\n\n\n13.694214\n14.603443\n\n\n8.113651\n9.583336\n\n\n10.976609\n12.044481\n\n\n14.965184\n15.927974\n\n\n19.658726\n21.369244\n\n\n17.425414\n18.706281\n\n\n\n\n\nCode\n\n\n# 比较观测值与预测值\nbind_cols( predict(lm_sales_tv, new_data = advertising), advertising)\n\n\n\n\n.pred\n…2\nTV\nradio\nnewspaper\nsales\n\n\n\n17.970775\n1\n230.1\n37.8\n69.2\n22.1\n\n\n9.147974\n2\n44.5\n39.3\n45.1\n10.4\n\n\n7.850224\n3\n17.2\n45.9\n69.3\n9.3\n\n\n14.234395\n4\n151.5\n41.3\n58.5\n18.5\n\n\n15.627218\n5\n180.8\n10.8\n58.4\n12.9\n\n\n7.446162\n6\n8.7\n48.9\n75.0\n7.2\n\n\n9.765950\n7\n57.5\n32.8\n23.5\n11.8\n\n\n12.746498\n8\n120.2\n19.6\n11.6\n13.2\n\n\n7.441409\n9\n8.6\n2.1\n1.0\n4.8\n\n\n16.530414\n10\n199.8\n2.6\n21.2\n10.6\n\n\n10.174765\n11\n66.1\n5.8\n24.2\n8.6\n\n\n17.238710\n12\n214.7\n24.0\n4.0\n17.4\n\n\n8.163966\n13\n23.8\n35.1\n65.9\n9.2\n\n\n11.667416\n14\n97.5\n7.6\n7.2\n9.7\n\n\n16.734822\n15\n204.1\n32.9\n46.0\n19.0\n\n\n16.321253\n16\n195.4\n47.7\n52.9\n22.4\n\n\n10.255578\n17\n67.8\n36.6\n114.0\n12.5\n\n\n20.409404\n18\n281.4\n39.6\n55.8\n24.4\n\n\n10.322129\n19\n69.2\n20.5\n18.3\n11.3\n\n\n14.034741\n20\n147.3\n23.9\n19.1\n14.6\n\n\n17.414596\n21\n218.4\n27.7\n53.4\n18.0\n\n\n18.317792\n22\n237.4\n5.1\n23.5\n12.5\n\n\n7.660077\n23\n13.2\n15.9\n49.6\n5.6\n\n\n17.885209\n24\n228.3\n16.9\n26.2\n15.5\n\n\n9.994126\n25\n62.3\n12.6\n18.3\n9.7\n\n\n19.529976\n26\n262.9\n3.5\n19.5\n12.0\n\n\n13.825579\n27\n142.9\n29.3\n12.6\n15.0\n\n\n18.446141\n28\n240.1\n16.7\n22.9\n15.9\n\n\n18.859710\n29\n248.8\n27.1\n22.9\n18.9\n\n\n10.388680\n30\n70.6\n16.0\n40.8\n10.5\n\n\n20.956076\n31\n292.9\n28.3\n43.2\n21.4\n\n\n12.399480\n32\n112.9\n17.4\n38.6\n11.9\n\n\n11.653155\n33\n97.2\n1.5\n30.0\n9.6\n\n\n19.658325\n34\n265.6\n20.0\n0.3\n17.4\n\n\n11.581850\n35\n95.7\n1.4\n7.4\n9.5\n\n\n20.851495\n36\n290.7\n4.1\n8.5\n12.8\n\n\n19.720123\n37\n266.9\n43.8\n5.0\n25.4\n\n\n10.583581\n38\n74.7\n49.4\n45.7\n14.7\n\n\n9.081423\n39\n43.1\n26.7\n35.1\n10.1\n\n\n17.870948\n40\n228.0\n37.7\n32.0\n21.5\n\n\n16.658763\n41\n202.5\n22.3\n31.6\n16.6\n\n\n15.446579\n42\n177.0\n33.4\n38.7\n17.1\n\n\n20.989351\n43\n293.6\n27.7\n1.8\n20.7\n\n\n16.867925\n44\n206.9\n8.4\n26.4\n12.9\n\n\n8.225763\n45\n25.1\n25.7\n43.3\n8.5\n\n\n15.356259\n46\n175.1\n22.5\n31.5\n14.9\n\n\n11.296630\n47\n89.7\n9.9\n35.7\n10.6\n\n\n18.436634\n48\n239.9\n41.5\n18.5\n23.2\n\n\n17.832918\n49\n227.2\n15.8\n49.9\n14.8\n\n\n10.212795\n50\n66.9\n11.7\n36.8\n9.7\n\n\n16.530414\n51\n199.8\n3.1\n34.6\n11.4\n\n\n11.805272\n52\n100.4\n9.6\n3.6\n10.7\n\n\n17.319523\n53\n216.4\n41.7\n39.6\n22.6\n\n\n15.712784\n54\n182.6\n46.2\n58.7\n21.2\n\n\n19.520469\n55\n262.7\n28.8\n15.9\n20.2\n\n\n16.487631\n56\n198.9\n49.4\n60.0\n23.7\n\n\n7.379611\n57\n7.3\n28.1\n41.4\n5.5\n\n\n13.507084\n58\n136.2\n19.2\n16.6\n13.2\n\n\n17.053317\n59\n210.8\n49.6\n37.7\n23.8\n\n\n17.048564\n60\n210.7\n29.5\n9.3\n18.4\n\n\n9.575804\n61\n53.5\n2.0\n21.4\n8.1\n\n\n19.453918\n62\n261.3\n42.7\n54.7\n24.2\n\n\n18.408112\n63\n239.3\n15.5\n27.3\n15.7\n\n\n11.914606\n64\n102.7\n29.6\n8.4\n14.0\n\n\n13.264647\n65\n131.1\n42.8\n28.9\n18.0\n\n\n10.312622\n66\n69.0\n9.3\n0.9\n9.3\n\n\n8.529998\n67\n31.5\n24.6\n2.2\n9.5\n\n\n13.654448\n68\n139.3\n14.5\n10.2\n13.4\n\n\n18.317792\n69\n237.4\n27.5\n11.0\n18.9\n\n\n17.338537\n70\n216.8\n43.9\n27.2\n22.3\n\n\n16.497139\n71\n199.1\n30.6\n38.7\n18.3\n\n\n12.252117\n72\n109.8\n14.3\n31.7\n12.4\n\n\n8.306575\n73\n26.8\n33.0\n19.3\n8.8\n\n\n13.183835\n74\n129.4\n5.7\n31.3\n11.0\n\n\n17.176913\n75\n213.4\n24.6\n13.1\n17.0\n\n\n7.835963\n76\n16.9\n43.7\n89.4\n8.7\n\n\n8.339851\n77\n27.5\n1.6\n20.7\n6.9\n\n\n12.760759\n78\n120.5\n28.5\n14.2\n14.2\n\n\n7.289291\n79\n5.4\n29.9\n9.4\n5.3\n\n\n12.546844\n80\n116.0\n7.7\n23.1\n11.0\n\n\n10.664393\n81\n76.4\n26.7\n22.3\n11.8\n\n\n18.431880\n82\n239.8\n4.1\n36.9\n12.3\n\n\n10.612103\n83\n75.3\n20.3\n32.5\n11.3\n\n\n10.284100\n84\n68.4\n44.5\n35.6\n13.6\n\n\n17.181666\n85\n213.5\n43.0\n33.8\n21.7\n\n\n16.216673\n86\n193.2\n18.4\n65.7\n15.2\n\n\n10.659639\n87\n76.3\n27.5\n16.0\n12.0\n\n\n12.294900\n88\n110.7\n40.6\n63.2\n16.0\n\n\n11.230079\n89\n88.3\n25.5\n73.4\n12.9\n\n\n12.252117\n90\n109.8\n47.8\n51.4\n16.7\n\n\n13.416764\n91\n134.3\n4.9\n9.3\n11.2\n\n\n8.392141\n92\n28.6\n1.5\n33.0\n7.3\n\n\n17.381320\n93\n217.7\n33.5\n59.0\n19.4\n\n\n18.959537\n94\n250.9\n36.5\n72.3\n22.2\n\n\n12.138029\n95\n107.4\n14.0\n10.9\n11.5\n\n\n14.795327\n96\n163.3\n31.6\n52.9\n16.9\n\n\n16.425834\n97\n197.6\n3.5\n5.9\n11.7\n\n\n15.822118\n98\n184.9\n21.0\n22.0\n15.5\n\n\n20.803958\n99\n289.7\n42.3\n51.2\n25.4\n\n\n13.459547\n100\n135.2\n41.7\n45.9\n17.2\n\n\n17.604742\n101\n222.4\n4.3\n49.8\n11.7\n\n\n21.122454\n102\n296.4\n36.3\n100.9\n23.8\n\n\n20.352360\n103\n280.2\n10.1\n21.4\n14.8\n\n\n15.964728\n104\n187.9\n17.2\n17.9\n14.7\n\n\n18.355821\n105\n238.2\n34.3\n5.3\n20.7\n\n\n13.587896\n106\n137.9\n46.4\n59.0\n19.2\n\n\n8.221010\n107\n25.0\n11.0\n29.7\n7.2\n\n\n11.329906\n108\n90.4\n0.3\n23.2\n8.7\n\n\n7.655323\n109\n13.1\n0.4\n25.6\n5.3\n\n\n19.173451\n110\n255.4\n26.9\n5.5\n19.8\n\n\n17.766367\n111\n225.8\n8.2\n56.5\n13.4\n\n\n18.522199\n112\n241.7\n38.0\n23.2\n21.8\n\n\n15.384781\n113\n175.7\n15.4\n2.4\n14.1\n\n\n16.996273\n114\n209.6\n20.6\n10.7\n15.9\n\n\n10.749959\n115\n78.2\n46.8\n34.5\n14.6\n\n\n10.602595\n116\n75.1\n35.0\n52.7\n12.6\n\n\n13.649694\n117\n139.2\n14.3\n25.6\n12.2\n\n\n10.664393\n118\n76.4\n0.8\n14.8\n9.4\n\n\n13.007949\n119\n125.7\n36.9\n79.2\n15.9\n\n\n7.954804\n120\n19.4\n16.0\n22.3\n6.6\n\n\n13.749521\n121\n141.3\n26.8\n46.2\n15.5\n\n\n7.926282\n122\n18.8\n21.7\n50.4\n7.0\n\n\n17.680801\n123\n224.0\n2.4\n15.6\n11.6\n\n\n12.884354\n124\n123.1\n34.6\n12.4\n15.2\n\n\n17.942252\n125\n229.5\n32.3\n74.2\n19.7\n\n\n11.177789\n126\n87.2\n11.8\n25.9\n10.6\n\n\n7.403379\n127\n7.8\n38.9\n50.6\n6.6\n\n\n10.845032\n128\n80.2\n0.0\n9.2\n8.8\n\n\n17.504915\n129\n220.3\n49.0\n3.2\n24.7\n\n\n9.865777\n130\n59.6\n12.0\n43.1\n9.7\n\n\n7.065869\n131\n0.7\n39.6\n8.7\n1.6\n\n\n19.639311\n132\n265.2\n2.9\n43.0\n12.7\n\n\n7.431901\n133\n8.4\n27.2\n2.1\n5.7\n\n\n17.481147\n134\n219.8\n33.5\n45.1\n19.6\n\n\n8.786696\n135\n36.9\n38.6\n65.6\n10.8\n\n\n9.328613\n136\n48.3\n47.0\n8.5\n11.6\n\n\n8.249531\n137\n25.6\n39.0\n9.3\n9.5\n\n\n20.043372\n138\n273.7\n28.9\n59.7\n20.8\n\n\n9.076669\n139\n43.0\n25.9\n20.5\n9.6\n\n\n15.822118\n140\n184.9\n43.9\n1.7\n20.7\n\n\n10.521783\n141\n73.4\n17.0\n12.9\n10.9\n\n\n16.240441\n142\n193.7\n35.4\n75.6\n19.2\n\n\n17.514423\n143\n220.5\n33.2\n37.9\n20.1\n\n\n12.004926\n144\n104.6\n5.7\n34.4\n10.4\n\n\n11.605618\n145\n96.2\n14.8\n38.9\n11.4\n\n\n13.701984\n146\n140.3\n1.9\n9.0\n10.3\n\n\n18.446141\n147\n240.1\n7.3\n8.7\n13.2\n\n\n18.593505\n148\n243.2\n49.0\n44.3\n25.4\n\n\n8.838986\n149\n38.0\n40.3\n11.9\n10.9\n\n\n9.157481\n150\n44.7\n25.8\n20.6\n10.1\n\n\n20.376129\n151\n280.7\n13.9\n37.0\n16.1\n\n\n12.784527\n152\n121.0\n8.4\n48.7\n11.6\n\n\n16.425834\n153\n197.6\n23.3\n14.2\n16.6\n\n\n15.175620\n154\n171.3\n39.7\n37.7\n19.0\n\n\n15.959975\n155\n187.8\n21.1\n9.5\n15.6\n\n\n7.227494\n156\n4.1\n11.6\n5.7\n3.2\n\n\n11.496284\n157\n93.9\n43.5\n50.5\n15.3\n\n\n14.153582\n158\n149.8\n1.3\n24.3\n10.1\n\n\n7.588772\n159\n11.7\n36.9\n45.2\n7.3\n\n\n13.293169\n160\n131.7\n18.4\n34.6\n12.9\n\n\n15.232664\n161\n172.5\n18.1\n30.7\n14.4\n\n\n11.106484\n162\n85.7\n35.8\n49.3\n13.3\n\n\n15.988497\n163\n188.4\n18.1\n25.6\n14.9\n\n\n14.804834\n164\n163.5\n36.8\n7.4\n18.0\n\n\n12.603888\n165\n117.2\n14.7\n5.4\n11.9\n\n\n18.179936\n166\n234.5\n3.4\n84.8\n11.9\n\n\n7.883499\n167\n17.9\n37.6\n21.6\n8.0\n\n\n16.863171\n168\n206.8\n5.2\n19.4\n12.2\n\n\n17.271986\n169\n215.4\n23.6\n57.6\n17.1\n\n\n20.547260\n170\n284.3\n10.6\n6.4\n15.0\n\n\n9.409426\n171\n50.0\n11.6\n18.4\n8.4\n\n\n14.852371\n172\n164.5\n20.9\n47.4\n14.5\n\n\n7.964312\n173\n19.6\n20.1\n17.0\n7.6\n\n\n15.037764\n174\n168.4\n7.1\n12.8\n11.7\n\n\n17.604742\n175\n222.4\n3.4\n13.1\n11.5\n\n\n20.195489\n176\n276.9\n48.9\n41.8\n27.0\n\n\n18.840695\n177\n248.4\n30.2\n20.3\n20.2\n\n\n15.123330\n178\n170.2\n7.8\n35.2\n11.7\n\n\n20.185982\n179\n276.7\n2.3\n23.7\n11.8\n\n\n14.904661\n180\n165.6\n10.0\n17.6\n12.6\n\n\n14.476831\n181\n156.6\n2.6\n8.3\n10.5\n\n\n17.419349\n182\n218.5\n5.4\n27.4\n12.2\n\n\n9.704153\n183\n56.2\n5.7\n29.7\n8.7\n\n\n20.704131\n184\n287.6\n43.0\n71.8\n26.2\n\n\n19.097393\n185\n253.8\n21.3\n30.0\n17.6\n\n\n16.777605\n186\n205.0\n45.1\n19.6\n22.6\n\n\n13.663955\n187\n139.5\n2.1\n26.6\n10.3\n\n\n16.116846\n188\n191.1\n28.7\n18.2\n17.3\n\n\n20.628073\n189\n286.0\n13.9\n3.7\n15.9\n\n\n7.921529\n190\n18.7\n12.1\n23.4\n6.7\n\n\n8.910291\n191\n39.5\n41.1\n5.8\n10.8\n\n\n10.621610\n192\n75.5\n10.8\n6.0\n9.9\n\n\n7.850224\n193\n17.2\n4.1\n31.6\n5.9\n\n\n14.961705\n194\n166.8\n42.0\n3.6\n19.6\n\n\n14.148829\n195\n149.7\n35.6\n6.0\n17.3\n\n\n8.848493\n196\n38.2\n3.7\n13.8\n7.6\n\n\n11.510545\n197\n94.2\n4.9\n8.1\n9.7\n\n\n15.446579\n198\n177.0\n9.3\n6.4\n12.8\n\n\n20.513985\n199\n283.6\n42.0\n66.2\n25.5\n\n\n18.065848\n200\n232.1\n8.6\n8.7\n13.4\n\n\n\n\n\nCode    \nbind_cols( predict(lm_sales_tv, new_data = advertising), advertising) |&gt; \n  select(sales, .pred)\n\n\n\n\nsales\n.pred\n\n\n\n22.1\n17.970775\n\n\n10.4\n9.147974\n\n\n9.3\n7.850224\n\n\n18.5\n14.234395\n\n\n12.9\n15.627218\n\n\n7.2\n7.446162\n\n\n11.8\n9.765950\n\n\n13.2\n12.746498\n\n\n4.8\n7.441409\n\n\n10.6\n16.530414\n\n\n8.6\n10.174765\n\n\n17.4\n17.238710\n\n\n9.2\n8.163966\n\n\n9.7\n11.667416\n\n\n19.0\n16.734822\n\n\n22.4\n16.321253\n\n\n12.5\n10.255578\n\n\n24.4\n20.409404\n\n\n11.3\n10.322129\n\n\n14.6\n14.034741\n\n\n18.0\n17.414596\n\n\n12.5\n18.317792\n\n\n5.6\n7.660077\n\n\n15.5\n17.885209\n\n\n9.7\n9.994126\n\n\n12.0\n19.529976\n\n\n15.0\n13.825579\n\n\n15.9\n18.446141\n\n\n18.9\n18.859710\n\n\n10.5\n10.388680\n\n\n21.4\n20.956076\n\n\n11.9\n12.399480\n\n\n9.6\n11.653155\n\n\n17.4\n19.658325\n\n\n9.5\n11.581850\n\n\n12.8\n20.851495\n\n\n25.4\n19.720123\n\n\n14.7\n10.583581\n\n\n10.1\n9.081423\n\n\n21.5\n17.870948\n\n\n16.6\n16.658763\n\n\n17.1\n15.446579\n\n\n20.7\n20.989351\n\n\n12.9\n16.867925\n\n\n8.5\n8.225763\n\n\n14.9\n15.356259\n\n\n10.6\n11.296630\n\n\n23.2\n18.436634\n\n\n14.8\n17.832918\n\n\n9.7\n10.212795\n\n\n11.4\n16.530414\n\n\n10.7\n11.805272\n\n\n22.6\n17.319523\n\n\n21.2\n15.712784\n\n\n20.2\n19.520469\n\n\n23.7\n16.487631\n\n\n5.5\n7.379611\n\n\n13.2\n13.507084\n\n\n23.8\n17.053317\n\n\n18.4\n17.048564\n\n\n8.1\n9.575804\n\n\n24.2\n19.453918\n\n\n15.7\n18.408112\n\n\n14.0\n11.914606\n\n\n18.0\n13.264647\n\n\n9.3\n10.312622\n\n\n9.5\n8.529998\n\n\n13.4\n13.654448\n\n\n18.9\n18.317792\n\n\n22.3\n17.338537\n\n\n18.3\n16.497139\n\n\n12.4\n12.252117\n\n\n8.8\n8.306575\n\n\n11.0\n13.183835\n\n\n17.0\n17.176913\n\n\n8.7\n7.835963\n\n\n6.9\n8.339851\n\n\n14.2\n12.760759\n\n\n5.3\n7.289291\n\n\n11.0\n12.546844\n\n\n11.8\n10.664393\n\n\n12.3\n18.431880\n\n\n11.3\n10.612103\n\n\n13.6\n10.284100\n\n\n21.7\n17.181666\n\n\n15.2\n16.216673\n\n\n12.0\n10.659639\n\n\n16.0\n12.294900\n\n\n12.9\n11.230079\n\n\n16.7\n12.252117\n\n\n11.2\n13.416764\n\n\n7.3\n8.392141\n\n\n19.4\n17.381320\n\n\n22.2\n18.959537\n\n\n11.5\n12.138029\n\n\n16.9\n14.795327\n\n\n11.7\n16.425834\n\n\n15.5\n15.822118\n\n\n25.4\n20.803958\n\n\n17.2\n13.459547\n\n\n11.7\n17.604742\n\n\n23.8\n21.122454\n\n\n14.8\n20.352360\n\n\n14.7\n15.964728\n\n\n20.7\n18.355821\n\n\n19.2\n13.587896\n\n\n7.2\n8.221010\n\n\n8.7\n11.329906\n\n\n5.3\n7.655323\n\n\n19.8\n19.173451\n\n\n13.4\n17.766367\n\n\n21.8\n18.522199\n\n\n14.1\n15.384781\n\n\n15.9\n16.996273\n\n\n14.6\n10.749959\n\n\n12.6\n10.602595\n\n\n12.2\n13.649694\n\n\n9.4\n10.664393\n\n\n15.9\n13.007949\n\n\n6.6\n7.954804\n\n\n15.5\n13.749521\n\n\n7.0\n7.926282\n\n\n11.6\n17.680801\n\n\n15.2\n12.884354\n\n\n19.7\n17.942252\n\n\n10.6\n11.177789\n\n\n6.6\n7.403379\n\n\n8.8\n10.845032\n\n\n24.7\n17.504915\n\n\n9.7\n9.865777\n\n\n1.6\n7.065869\n\n\n12.7\n19.639311\n\n\n5.7\n7.431901\n\n\n19.6\n17.481147\n\n\n10.8\n8.786696\n\n\n11.6\n9.328613\n\n\n9.5\n8.249531\n\n\n20.8\n20.043372\n\n\n9.6\n9.076669\n\n\n20.7\n15.822118\n\n\n10.9\n10.521783\n\n\n19.2\n16.240441\n\n\n20.1\n17.514423\n\n\n10.4\n12.004926\n\n\n11.4\n11.605618\n\n\n10.3\n13.701984\n\n\n13.2\n18.446141\n\n\n25.4\n18.593505\n\n\n10.9\n8.838986\n\n\n10.1\n9.157481\n\n\n16.1\n20.376129\n\n\n11.6\n12.784527\n\n\n16.6\n16.425834\n\n\n19.0\n15.175620\n\n\n15.6\n15.959975\n\n\n3.2\n7.227494\n\n\n15.3\n11.496284\n\n\n10.1\n14.153582\n\n\n7.3\n7.588772\n\n\n12.9\n13.293169\n\n\n14.4\n15.232664\n\n\n13.3\n11.106484\n\n\n14.9\n15.988497\n\n\n18.0\n14.804834\n\n\n11.9\n12.603888\n\n\n11.9\n18.179936\n\n\n8.0\n7.883499\n\n\n12.2\n16.863171\n\n\n17.1\n17.271986\n\n\n15.0\n20.547260\n\n\n8.4\n9.409426\n\n\n14.5\n14.852371\n\n\n7.6\n7.964312\n\n\n11.7\n15.037764\n\n\n11.5\n17.604742\n\n\n27.0\n20.195489\n\n\n20.2\n18.840695\n\n\n11.7\n15.123330\n\n\n11.8\n20.185982\n\n\n12.6\n14.904661\n\n\n10.5\n14.476831\n\n\n12.2\n17.419349\n\n\n8.7\n9.704153\n\n\n26.2\n20.704131\n\n\n17.6\n19.097393\n\n\n22.6\n16.777605\n\n\n10.3\n13.663955\n\n\n17.3\n16.116846\n\n\n15.9\n20.628073\n\n\n6.7\n7.921529\n\n\n10.8\n8.910291\n\n\n9.9\n10.621610\n\n\n5.9\n7.850224\n\n\n19.6\n14.961705\n\n\n17.3\n14.148829\n\n\n7.6\n8.848493\n\n\n9.7\n11.510545\n\n\n12.8\n15.446579\n\n\n25.5\n20.513985\n\n\n13.4\n18.065848\n\n\n\n\n\nCode\naugment(lm_sales_tv, new_data = advertising) |&gt;   \n  select(sales, .pred)\n\n\n\n\nsales\n.pred\n\n\n\n22.1\n17.970775\n\n\n10.4\n9.147974\n\n\n9.3\n7.850224\n\n\n18.5\n14.234395\n\n\n12.9\n15.627218\n\n\n7.2\n7.446162\n\n\n11.8\n9.765950\n\n\n13.2\n12.746498\n\n\n4.8\n7.441409\n\n\n10.6\n16.530414\n\n\n8.6\n10.174765\n\n\n17.4\n17.238710\n\n\n9.2\n8.163966\n\n\n9.7\n11.667416\n\n\n19.0\n16.734822\n\n\n22.4\n16.321253\n\n\n12.5\n10.255578\n\n\n24.4\n20.409404\n\n\n11.3\n10.322129\n\n\n14.6\n14.034741\n\n\n18.0\n17.414596\n\n\n12.5\n18.317792\n\n\n5.6\n7.660077\n\n\n15.5\n17.885209\n\n\n9.7\n9.994126\n\n\n12.0\n19.529976\n\n\n15.0\n13.825579\n\n\n15.9\n18.446141\n\n\n18.9\n18.859710\n\n\n10.5\n10.388680\n\n\n21.4\n20.956076\n\n\n11.9\n12.399480\n\n\n9.6\n11.653155\n\n\n17.4\n19.658325\n\n\n9.5\n11.581850\n\n\n12.8\n20.851495\n\n\n25.4\n19.720123\n\n\n14.7\n10.583581\n\n\n10.1\n9.081423\n\n\n21.5\n17.870948\n\n\n16.6\n16.658763\n\n\n17.1\n15.446579\n\n\n20.7\n20.989351\n\n\n12.9\n16.867925\n\n\n8.5\n8.225763\n\n\n14.9\n15.356259\n\n\n10.6\n11.296630\n\n\n23.2\n18.436634\n\n\n14.8\n17.832918\n\n\n9.7\n10.212795\n\n\n11.4\n16.530414\n\n\n10.7\n11.805272\n\n\n22.6\n17.319523\n\n\n21.2\n15.712784\n\n\n20.2\n19.520469\n\n\n23.7\n16.487631\n\n\n5.5\n7.379611\n\n\n13.2\n13.507084\n\n\n23.8\n17.053317\n\n\n18.4\n17.048564\n\n\n8.1\n9.575804\n\n\n24.2\n19.453918\n\n\n15.7\n18.408112\n\n\n14.0\n11.914606\n\n\n18.0\n13.264647\n\n\n9.3\n10.312622\n\n\n9.5\n8.529998\n\n\n13.4\n13.654448\n\n\n18.9\n18.317792\n\n\n22.3\n17.338537\n\n\n18.3\n16.497139\n\n\n12.4\n12.252117\n\n\n8.8\n8.306575\n\n\n11.0\n13.183835\n\n\n17.0\n17.176913\n\n\n8.7\n7.835963\n\n\n6.9\n8.339851\n\n\n14.2\n12.760759\n\n\n5.3\n7.289291\n\n\n11.0\n12.546844\n\n\n11.8\n10.664393\n\n\n12.3\n18.431880\n\n\n11.3\n10.612103\n\n\n13.6\n10.284100\n\n\n21.7\n17.181666\n\n\n15.2\n16.216673\n\n\n12.0\n10.659639\n\n\n16.0\n12.294900\n\n\n12.9\n11.230079\n\n\n16.7\n12.252117\n\n\n11.2\n13.416764\n\n\n7.3\n8.392141\n\n\n19.4\n17.381320\n\n\n22.2\n18.959537\n\n\n11.5\n12.138029\n\n\n16.9\n14.795327\n\n\n11.7\n16.425834\n\n\n15.5\n15.822118\n\n\n25.4\n20.803958\n\n\n17.2\n13.459547\n\n\n11.7\n17.604742\n\n\n23.8\n21.122454\n\n\n14.8\n20.352360\n\n\n14.7\n15.964728\n\n\n20.7\n18.355821\n\n\n19.2\n13.587896\n\n\n7.2\n8.221010\n\n\n8.7\n11.329906\n\n\n5.3\n7.655323\n\n\n19.8\n19.173451\n\n\n13.4\n17.766367\n\n\n21.8\n18.522199\n\n\n14.1\n15.384781\n\n\n15.9\n16.996273\n\n\n14.6\n10.749959\n\n\n12.6\n10.602595\n\n\n12.2\n13.649694\n\n\n9.4\n10.664393\n\n\n15.9\n13.007949\n\n\n6.6\n7.954804\n\n\n15.5\n13.749521\n\n\n7.0\n7.926282\n\n\n11.6\n17.680801\n\n\n15.2\n12.884354\n\n\n19.7\n17.942252\n\n\n10.6\n11.177789\n\n\n6.6\n7.403379\n\n\n8.8\n10.845032\n\n\n24.7\n17.504915\n\n\n9.7\n9.865777\n\n\n1.6\n7.065869\n\n\n12.7\n19.639311\n\n\n5.7\n7.431901\n\n\n19.6\n17.481147\n\n\n10.8\n8.786696\n\n\n11.6\n9.328613\n\n\n9.5\n8.249531\n\n\n20.8\n20.043372\n\n\n9.6\n9.076669\n\n\n20.7\n15.822118\n\n\n10.9\n10.521783\n\n\n19.2\n16.240441\n\n\n20.1\n17.514423\n\n\n10.4\n12.004926\n\n\n11.4\n11.605618\n\n\n10.3\n13.701984\n\n\n13.2\n18.446141\n\n\n25.4\n18.593505\n\n\n10.9\n8.838986\n\n\n10.1\n9.157481\n\n\n16.1\n20.376129\n\n\n11.6\n12.784527\n\n\n16.6\n16.425834\n\n\n19.0\n15.175620\n\n\n15.6\n15.959975\n\n\n3.2\n7.227494\n\n\n15.3\n11.496284\n\n\n10.1\n14.153582\n\n\n7.3\n7.588772\n\n\n12.9\n13.293169\n\n\n14.4\n15.232664\n\n\n13.3\n11.106484\n\n\n14.9\n15.988497\n\n\n18.0\n14.804834\n\n\n11.9\n12.603888\n\n\n11.9\n18.179936\n\n\n8.0\n7.883499\n\n\n12.2\n16.863171\n\n\n17.1\n17.271986\n\n\n15.0\n20.547260\n\n\n8.4\n9.409426\n\n\n14.5\n14.852371\n\n\n7.6\n7.964312\n\n\n11.7\n15.037764\n\n\n11.5\n17.604742\n\n\n27.0\n20.195489\n\n\n20.2\n18.840695\n\n\n11.7\n15.123330\n\n\n11.8\n20.185982\n\n\n12.6\n14.904661\n\n\n10.5\n14.476831\n\n\n12.2\n17.419349\n\n\n8.7\n9.704153\n\n\n26.2\n20.704131\n\n\n17.6\n19.097393\n\n\n22.6\n16.777605\n\n\n10.3\n13.663955\n\n\n17.3\n16.116846\n\n\n15.9\n20.628073\n\n\n6.7\n7.921529\n\n\n10.8\n8.910291\n\n\n9.9\n10.621610\n\n\n5.9\n7.850224\n\n\n19.6\n14.961705\n\n\n17.3\n14.148829\n\n\n7.6\n8.848493\n\n\n9.7\n11.510545\n\n\n12.8\n15.446579\n\n\n25.5\n20.513985\n\n\n13.4\n18.065848\n\n\n\n\n\n\n\n16.1.3 最小二乘法\n保证各实测点到回归直线的纵向距离的平方和最小，即使得残差平方和\n\\[\nQ=\\sum (Y-\\hat Y)^2\n\\]\n最小。\n\nCode# 可视化\nbind_cols(predict(lm_sales_tv, new_data = advertising), advertising) |&gt;\n    ggplot(aes(x = TV)) +\n    geom_linerange(aes(ymin = sales, ymax = .pred)) +\n    geom_point(aes(y = sales), color = \"red\") +\n    geom_abline(\n        intercept = coef(lm_sales_tv$fit)[1],\n        slope = coef(lm_sales_tv$fit)[2],\n        color = \"blue\",\n        size = 1\n    )\n\n\n\n\n\n\n\n\n16.1.4 回归诊断\n\n16.1.4.1 残差图\n\nCodeplot(lm_sales_tv$fit,1)  \n\n\n\n\n\n\n\n\nCode# 检查线性回归模型的残差是否与拟合值无关，即残差的分布是否随机。\n# 残差应该随机分布在0附近\ntibble(\n    `Fitted values`=lm_sales_tv$fit$fitted.values,\n    Residuals = lm_sales_tv$fit$residuals\n) |&gt; ggplot(aes(x = `Fitted values` , y = Residuals)) +\n  geom_point(pch=21) +\n    geom_smooth(formula = \"y~x\",color=\"red\",lwd=0.5)+\n  geom_hline(yintercept = 0,lty=2) +\n  labs(x = \"Fitted Values\", y = \"Residuals\")\n\n\n\n\n\n\n\n\nCode# 检查线性回归模型的残差是否与观测值无关，即残差的分布是否随机。\ntibble(Sales = lm_sales_tv$fit$model$sales,\n       Residuals = lm_sales_tv$fit$residuals,) |&gt; \n    ggplot(aes(x = Sales , y = Residuals)) +\n    geom_point(pch=21) +\n    geom_smooth(,color=\"red\",lwd=0.5) +\n    labs(x = \"Observed Values\", y = \"Residuals\")\n\n\n\n\n\n\n\n\nCodeplot(lm_sales_tv$fit,3)  \n\n\n\n\n\n\n\n\nCodetibble(\n    fitted_values=lm_sales_tv$fit$fitted.values,\n    StandardizedResiduals = rstudent(lm_sales_tv$fit) ,\n) |&gt;\n    ggplot(aes(x = fitted_values, y = sqrt(abs(StandardizedResiduals)))) +\n    geom_point(pch=21) +\n    geom_smooth(color=\"red\",lwd=0.5)+\n    labs(x = \"Fitted Values\", y = \"√|Standardized residuals|\")\n\n\n\n\n\n\n\n\n16.1.4.2 Q-Q图\n\nCodeplot(lm_sales_tv$fit,2)  \n\n\n\n\n\n\n\n\nCodetibble(\n       StandardizedResiduals =rstandard(lm_sales_tv$fit) ) |&gt; \n    ggplot(aes(sample=StandardizedResiduals)) +\n    stat_qq(pch=21)+\n    stat_qq_line(color=\"red\",lty=2)+\n    labs(x = \"Theoretical Quantiles\", y = \"Standardized residuals\")\n\n\n\n\n\n\n\n\n16.1.4.3 Cook’s距离\n\nCodeplot(lm_sales_tv$fit,4)  \n\n\n\n\n\n\n\n\nCodethreshold &lt;- 4 / (nrow(lm_sales_tv$fit$model) - length(coef(lm_sales_tv$fit)) - 2)\n\ntibble(x = 1:nrow(advertising),\n       CooksD = cooks.distance(lm_sales_tv$fit),\n       Threshold = CooksD &gt; threshold)|&gt;\n    ggplot() +\n    geom_segment(aes(x=x,xend=x,y=0,yend=CooksD,color=Threshold)) +\n    geom_text(aes(x=x,y=CooksD,label=if_else(Threshold,x,NA)),vjust=-0.2)+\n    labs(x = \"Observation Index\", y = \"Cook's Distance\")\n\n\n\n\n\n\n\n\n16.1.4.4 杠杆值图\n\nCodeplot(lm_sales_tv$fit,5)  \n\n\n\n\n\n\n\n\nCodetibble(\n    leverage = hatvalues(lm_sales_tv$fit),\n    StandardizedResiduals = rstandard(lm_sales_tv$fit) ,\n) |&gt;\n    ggplot(aes(x = leverage, y = StandardizedResiduals)) +\n    geom_point(pch=21) +\n    geom_smooth(color=\"red\",lwd=0.5)+\n    scale_x_continuous(limits = c(0, NA)) +\n    geom_vline(xintercept = 0, lty = 2) +\n    geom_hline(yintercept = 0, lty = 2) +\n    labs(x = \"Leverage Values\", y = \"Standardized residuals\")\n\n\n\n\n\n\n\n\nCodeplot(lm_sales_tv$fit,6)  \n\n\n\n\n\n\n\n\nCode\n\nthreshold &lt;- 4 / (nrow(lm_sales_tv$fit$model) - length(coef(lm_sales_tv$fit)) - 2)\n\ndf &lt;- tibble(\n    x = 1:nrow(advertising),\n    leverage = hatvalues(lm_sales_tv$fit),\n    CooksD = cooks.distance(lm_sales_tv$fit),\n    Threshold = CooksD &gt; threshold,\n) \n\n    ggplot(df,aes(leverage, CooksD)) +\n    geom_point(pch=21) +\n    xlim(c(0,NA))+\n    geom_text(aes(label=if_else(Threshold,as.character(x),NA)),vjust=-0.5)+\n    geom_abline(intercept = 0, slope = seq(0,6,by=1), \n                linetype = \"dotted\", color = \"black\")+\n    geom_abline(intercept = 0, slope = 0.5, \n                linetype = 1, color = \"red\")+\n    labs(x = \"Leverage\", y = \"Cook's Distance\")",
    "crumbs": [
      "统计模型",
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>线性回归</span>"
    ]
  },
  {
    "objectID": "LinearRegression.html#逐步回归",
    "href": "LinearRegression.html#逐步回归",
    "title": "\n16  线性回归\n",
    "section": "\n16.2 逐步回归",
    "text": "16.2 逐步回归\n逐步回归是筛选变量，有向前、向后和两个方向同时进行三个方法。\n\ndirection = \"both\"双向\ndirection = \"backward\"向后\ndirection = \"forward\"向前\n\n\nCode\nfit_lm &lt;- lm(sales~.,data = advertising[-1])\n\nfit_step &lt;- stats::step(fit_lm, direction = \"both\")\n#&gt; Start:  AIC=212.79\n#&gt; sales ~ TV + radio + newspaper\n#&gt; \n#&gt;             Df Sum of Sq    RSS    AIC\n#&gt; - newspaper  1      0.09  556.9 210.82\n#&gt; &lt;none&gt;                    556.8 212.79\n#&gt; - radio      1   1361.74 1918.6 458.20\n#&gt; - TV         1   3058.01 3614.8 584.90\n#&gt; \n#&gt; Step:  AIC=210.82\n#&gt; sales ~ TV + radio\n#&gt; \n#&gt;             Df Sum of Sq    RSS    AIC\n#&gt; &lt;none&gt;                    556.9 210.82\n#&gt; + newspaper  1      0.09  556.8 212.79\n#&gt; - radio      1   1545.62 2102.5 474.52\n#&gt; - TV         1   3061.57 3618.5 583.10\nsummary(fit_step)\n#&gt; \n#&gt; Call:\n#&gt; lm(formula = sales ~ TV + radio, data = advertising[-1])\n#&gt; \n#&gt; Residuals:\n#&gt;     Min      1Q  Median      3Q     Max \n#&gt; -8.7977 -0.8752  0.2422  1.1708  2.8328 \n#&gt; \n#&gt; Coefficients:\n#&gt;             Estimate Std. Error t value Pr(&gt;|t|)    \n#&gt; (Intercept)  2.92110    0.29449   9.919   &lt;2e-16 ***\n#&gt; TV           0.04575    0.00139  32.909   &lt;2e-16 ***\n#&gt; radio        0.18799    0.00804  23.382   &lt;2e-16 ***\n#&gt; ---\n#&gt; Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n#&gt; \n#&gt; Residual standard error: 1.681 on 197 degrees of freedom\n#&gt; Multiple R-squared:  0.8972, Adjusted R-squared:  0.8962 \n#&gt; F-statistic: 859.6 on 2 and 197 DF,  p-value: &lt; 2.2e-16",
    "crumbs": [
      "统计模型",
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>线性回归</span>"
    ]
  },
  {
    "objectID": "LinearRegression.html#多元线性回归",
    "href": "LinearRegression.html#多元线性回归",
    "title": "\n16  线性回归\n",
    "section": "\n16.3 多元线性回归",
    "text": "16.3 多元线性回归\n\\[\nY_i=\\beta_0+\\sum_{i=1}^p \\beta_p X_{pi}+\\epsilon_i,其中\\epsilon_i\\sim N(0,\\sigma^2)\n\\]\n\n16.3.1 rms::ols()\n\n\nCodeacl &lt;- read_rds(\"data/icpsr/advanced_acl_data.rds\")\nols_mlm &lt;- rms::ols(SWL_W1 ~ Sex + AGE_W1 + SESCategory ,data = acl)\n\ntexreg::texreg(ols_mlm)\n#&gt; \n#&gt; \\begin{table}\n#&gt; \\begin{center}\n#&gt; \\begin{tabular}{l c}\n#&gt; \\hline\n#&gt;  & Model 1 \\\\\n#&gt; \\hline\n#&gt; Intercept                                                                                                                               & $-0.71^{***}$ \\\\\n#&gt;                                                                                                                                         & $(0.08)$      \\\\\n#&gt; Sex=(2) FEMALE                                                                                                                          & $0.03$        \\\\\n#&gt;                                                                                                                                         & $(0.04)$      \\\\\n#&gt; AGE\\_W1                                                                                                                                 & $0.01^{***}$  \\\\\n#&gt;                                                                                                                                         & $(0.00)$      \\\\\n#&gt; SESCategory=(2) Lower-Middle SES 0-11 yrs of education and income $20, or more OR 12 or more yrs of education and income less than $20, & $-0.01$       \\\\\n#&gt;                                                                                                                                         & $(0.04)$      \\\\\n#&gt; SESCategory=(3) Upper-Middle SES... 12-15 years of education and income $20, or more.                                                   & $0.26^{***}$  \\\\\n#&gt;                                                                                                                                         & $(0.05)$      \\\\\n#&gt; SESCategory=(4) High SES...16 or more years of education and income $20, or more.                                                       & $0.27^{***}$  \\\\\n#&gt;                                                                                                                                         & $(0.06)$      \\\\\n#&gt; \\hline\n#&gt; Num. obs.                                                                                                                               & $3617$        \\\\\n#&gt; R$^2$                                                                                                                                   & $0.03$        \\\\\n#&gt; Adj. R$^2$                                                                                                                              & $0.03$        \\\\\n#&gt; L.R.                                                                                                                                    & $118.62$      \\\\\n#&gt; \\hline\n#&gt; \\multicolumn{2}{l}{\\scriptsize{$^{***}p&lt;0.001$; $^{**}p&lt;0.01$; $^{*}p&lt;0.05$}}\n#&gt; \\end{tabular}\n#&gt; \\caption{Statistical models}\n#&gt; \\label{table:coefficients}\n#&gt; \\end{center}\n#&gt; \\end{table}\n\ncar::vif(ols_mlm)\n#&gt;                  GVIF Df GVIF^(1/(2*Df))\n#&gt; Sex          2.733167  1        1.653229\n#&gt; AGE_W1      12.000335  1        3.464150\n#&gt; SESCategory  3.745646  3        1.246200\nanova(ols_mlm)\n#&gt;                 Analysis of Variance          Response: SWL_W1 \n#&gt; \n#&gt;  Factor      d.f. Partial SS   MS          F     P     \n#&gt;  Sex            1    0.7854499   0.7854499  0.73 0.3921\n#&gt;  AGE_W1         1  101.8301250 101.8301250 94.98 &lt;.0001\n#&gt;  SESCategory    3   53.6731656  17.8910552 16.69 &lt;.0001\n#&gt;  REGRESSION     5  129.0786440  25.8157288 24.08 &lt;.0001\n#&gt;  ERROR       3611 3871.6006314   1.0721685\n\n\n\n16.3.2 lm()\n\n\nCodelm_mlm &lt;- lm_spec |&gt; \n    fit(SWL_W1 ~ Sex + AGE_W1 + SESCategory ,data = acl)\n\nlm_mlm |&gt; glance()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nr.squared\nadj.r.squared\nsigma\nstatistic\np.value\ndf\nlogLik\nAIC\nBIC\ndeviance\ndf.residual\nnobs\n\n\n0.0322642\n0.0309242\n1.035456\n24.07805\n0\n5\n-5255.32\n10524.64\n10567.99\n3871.601\n3611\n3617\n\n\n\n\nCodelm_mlm |&gt; tidy()\n\n\n\n\n\n\n\n\n\n\n\nterm\nestimate\nstd.error\nstatistic\np.value\n\n\n\n(Intercept)\n-0.7056523\n0.0754901\n-9.3476094\n0.0000000\n\n\nSex(2) FEMALE\n0.0308272\n0.0360169\n0.8559092\n0.3921048\n\n\nAGE_W1\n0.0102952\n0.0010564\n9.7455557\n0.0000000\n\n\nSESCategory(2) Lower-Middle SES 0-11 yrs of education and income $20, or more OR 12 or more yrs of education and income less than $20,\n-0.0133284\n0.0446720\n-0.2983617\n0.7654443\n\n\nSESCategory(3) Upper-Middle SES… 12-15 years of education and income $20, or more.\n0.2557878\n0.0481855\n5.3083984\n0.0000001\n\n\nSESCategory(4) High SES…16 or more years of education and income $20, or more.\n0.2654396\n0.0635256\n4.1784695\n0.0000300\n\n\n\n\n\nCode\n\nlogLik(lm_mlm$fit)\n#&gt; 'log Lik.' -5255.32 (df=7)\ncar::vif(lm_mlm$fit)\n#&gt;                 GVIF Df GVIF^(1/(2*Df))\n#&gt; Sex         1.026165  1        1.012998\n#&gt; AGE_W1      1.168708  1        1.081068\n#&gt; SESCategory 1.182617  3        1.028349\n\n\n\n16.3.3 glm()\n\n\nCodeglm_mlm &lt;- linear_reg() %&gt;%\n    set_engine('glm',family=gaussian(link = \"identity\")) |&gt; \n    fit(SWL_W1 ~ Sex + AGE_W1 + SESCategory ,data = acl)\n\nglm_mlm |&gt; glance()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nnull.deviance\ndf.null\nlogLik\nAIC\nBIC\ndeviance\ndf.residual\nnobs\n\n\n4000.679\n3616\n-5255.32\n10524.64\n10567.99\n3871.601\n3611\n3617\n\n\n\n\nCodeglm_mlm |&gt; tidy()\n\n\n\n\n\n\n\n\n\n\n\nterm\nestimate\nstd.error\nstatistic\np.value\n\n\n\n(Intercept)\n-0.7056523\n0.0754901\n-9.3476094\n0.0000000\n\n\nSex(2) FEMALE\n0.0308272\n0.0360169\n0.8559092\n0.3921048\n\n\nAGE_W1\n0.0102952\n0.0010564\n9.7455557\n0.0000000\n\n\nSESCategory(2) Lower-Middle SES 0-11 yrs of education and income $20, or more OR 12 or more yrs of education and income less than $20,\n-0.0133284\n0.0446720\n-0.2983617\n0.7654443\n\n\nSESCategory(3) Upper-Middle SES… 12-15 years of education and income $20, or more.\n0.2557878\n0.0481855\n5.3083984\n0.0000001\n\n\nSESCategory(4) High SES…16 or more years of education and income $20, or more.\n0.2654396\n0.0635256\n4.1784695\n0.0000300\n\n\n\n\n\nCode\nsummary(glm_mlm$fit)\n#&gt; \n#&gt; Call:\n#&gt; stats::glm(formula = SWL_W1 ~ Sex + AGE_W1 + SESCategory, family = ~gaussian(link = \"identity\"), \n#&gt;     data = data)\n#&gt; \n#&gt; Coefficients:\n#&gt;                                                                                                                                         Estimate\n#&gt; (Intercept)                                                                                                                            -0.705652\n#&gt; Sex(2) FEMALE                                                                                                                           0.030827\n#&gt; AGE_W1                                                                                                                                  0.010295\n#&gt; SESCategory(2) Lower-Middle SES 0-11 yrs of education and income $20, or more OR 12 or more yrs of education and income less than $20, -0.013328\n#&gt; SESCategory(3) Upper-Middle SES... 12-15 years of education and income $20, or more.                                                    0.255788\n#&gt; SESCategory(4) High SES...16 or more years of education and income $20, or more.                                                        0.265440\n#&gt;                                                                                                                                        Std. Error\n#&gt; (Intercept)                                                                                                                              0.075490\n#&gt; Sex(2) FEMALE                                                                                                                            0.036017\n#&gt; AGE_W1                                                                                                                                   0.001056\n#&gt; SESCategory(2) Lower-Middle SES 0-11 yrs of education and income $20, or more OR 12 or more yrs of education and income less than $20,   0.044672\n#&gt; SESCategory(3) Upper-Middle SES... 12-15 years of education and income $20, or more.                                                     0.048186\n#&gt; SESCategory(4) High SES...16 or more years of education and income $20, or more.                                                         0.063526\n#&gt;                                                                                                                                        t value\n#&gt; (Intercept)                                                                                                                             -9.348\n#&gt; Sex(2) FEMALE                                                                                                                            0.856\n#&gt; AGE_W1                                                                                                                                   9.746\n#&gt; SESCategory(2) Lower-Middle SES 0-11 yrs of education and income $20, or more OR 12 or more yrs of education and income less than $20,  -0.298\n#&gt; SESCategory(3) Upper-Middle SES... 12-15 years of education and income $20, or more.                                                     5.308\n#&gt; SESCategory(4) High SES...16 or more years of education and income $20, or more.                                                         4.178\n#&gt;                                                                                                                                        Pr(&gt;|t|)\n#&gt; (Intercept)                                                                                                                             &lt; 2e-16\n#&gt; Sex(2) FEMALE                                                                                                                             0.392\n#&gt; AGE_W1                                                                                                                                  &lt; 2e-16\n#&gt; SESCategory(2) Lower-Middle SES 0-11 yrs of education and income $20, or more OR 12 or more yrs of education and income less than $20,    0.765\n#&gt; SESCategory(3) Upper-Middle SES... 12-15 years of education and income $20, or more.                                                   1.17e-07\n#&gt; SESCategory(4) High SES...16 or more years of education and income $20, or more.                                                       3.00e-05\n#&gt;                                                                                                                                           \n#&gt; (Intercept)                                                                                                                            ***\n#&gt; Sex(2) FEMALE                                                                                                                             \n#&gt; AGE_W1                                                                                                                                 ***\n#&gt; SESCategory(2) Lower-Middle SES 0-11 yrs of education and income $20, or more OR 12 or more yrs of education and income less than $20,    \n#&gt; SESCategory(3) Upper-Middle SES... 12-15 years of education and income $20, or more.                                                   ***\n#&gt; SESCategory(4) High SES...16 or more years of education and income $20, or more.                                                       ***\n#&gt; ---\n#&gt; Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n#&gt; \n#&gt; (Dispersion parameter for gaussian family taken to be 1.072169)\n#&gt; \n#&gt;     Null deviance: 4000.7  on 3616  degrees of freedom\n#&gt; Residual deviance: 3871.6  on 3611  degrees of freedom\n#&gt; AIC: 10525\n#&gt; \n#&gt; Number of Fisher Scoring iterations: 2\n\n\n\nCode#第一步，检测变量相关关系\nad &lt;- advertising |&gt; select(-1)\ncor(ad)\n#&gt;                   TV      radio  newspaper     sales\n#&gt; TV        1.00000000 0.05480866 0.05664787 0.7822244\n#&gt; radio     0.05480866 1.00000000 0.35410375 0.5762226\n#&gt; newspaper 0.05664787 0.35410375 1.00000000 0.2282990\n#&gt; sales     0.78222442 0.57622257 0.22829903 1.0000000\n\n#第二步，多元线性回归\nlm_sales_multi&lt;- lm_spec |&gt; fit(sales~TV+radio+newspaper,data = advertising)\nsummary(lm_sales_multi$fit)\n#&gt; \n#&gt; Call:\n#&gt; stats::lm(formula = sales ~ TV + radio + newspaper, data = data)\n#&gt; \n#&gt; Residuals:\n#&gt;     Min      1Q  Median      3Q     Max \n#&gt; -8.8277 -0.8908  0.2418  1.1893  2.8292 \n#&gt; \n#&gt; Coefficients:\n#&gt;              Estimate Std. Error t value Pr(&gt;|t|)    \n#&gt; (Intercept)  2.938889   0.311908   9.422   &lt;2e-16 ***\n#&gt; TV           0.045765   0.001395  32.809   &lt;2e-16 ***\n#&gt; radio        0.188530   0.008611  21.893   &lt;2e-16 ***\n#&gt; newspaper   -0.001037   0.005871  -0.177     0.86    \n#&gt; ---\n#&gt; Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n#&gt; \n#&gt; Residual standard error: 1.686 on 196 degrees of freedom\n#&gt; Multiple R-squared:  0.8972, Adjusted R-squared:  0.8956 \n#&gt; F-statistic: 570.3 on 3 and 196 DF,  p-value: &lt; 2.2e-16\n\ntidy(lm_sales_multi)\n\n\n\n\nterm\nestimate\nstd.error\nstatistic\np.value\n\n\n\n(Intercept)\n2.9388894\n0.3119082\n9.4222884\n0.0000000\n\n\nTV\n0.0457646\n0.0013949\n32.8086244\n0.0000000\n\n\nradio\n0.1885300\n0.0086112\n21.8934961\n0.0000000\n\n\nnewspaper\n-0.0010375\n0.0058710\n-0.1767146\n0.8599151\n\n\n\n\n\nCodeglance(lm_sales_multi)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nr.squared\nadj.r.squared\nsigma\nstatistic\np.value\ndf\nlogLik\nAIC\nBIC\ndeviance\ndf.residual\nnobs\n\n\n0.8972106\n0.8956373\n1.68551\n570.2707\n0\n3\n-386.1811\n782.3622\n798.8538\n556.8253\n196\n200",
    "crumbs": [
      "统计模型",
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>线性回归</span>"
    ]
  },
  {
    "objectID": "LinearRegression.html#交互项",
    "href": "LinearRegression.html#交互项",
    "title": "\n16  线性回归\n",
    "section": "\n16.4 交互项",
    "text": "16.4 交互项\n\nCodelm_sales_tv_radio &lt;- lm_spec |&gt;  fit(sales ~ TV*radio, data = advertising)\n\nlm_sales_tv_radio\n#&gt; parsnip model object\n#&gt; \n#&gt; \n#&gt; Call:\n#&gt; stats::lm(formula = sales ~ TV * radio, data = data)\n#&gt; \n#&gt; Coefficients:\n#&gt; (Intercept)           TV        radio     TV:radio  \n#&gt;    6.750220     0.019101     0.028860     0.001086\n\n\n\nCode# pre-processing specification\n\nrec_spec_interact &lt;- recipe(sales ~ TV+radio, data = advertising) |&gt;  \n  step_interact(~ TV:radio) \n\nrec_spec_interact\n\n# combine the linear regression model specification with the pre-processing specification\nlm_sales_tv_radio_interact &lt;- workflow() |&gt;  \n  add_model(lm_spec) |&gt;  \n  add_recipe(rec_spec_interact)  \n\nlm_sales_tv_radio_interact\n#&gt; ══ Workflow ════════════════════════════════════════════════════════════════════\n#&gt; Preprocessor: Recipe\n#&gt; Model: linear_reg()\n#&gt; \n#&gt; ── Preprocessor ────────────────────────────────────────────────────────────────\n#&gt; 1 Recipe Step\n#&gt; \n#&gt; • step_interact()\n#&gt; \n#&gt; ── Model ───────────────────────────────────────────────────────────────────────\n#&gt; Linear Regression Model Specification (regression)\n#&gt; \n#&gt; Computational engine: lm\n\nlm &lt;- lm_sales_tv_radio_interact |&gt; fit(advertising)\ntidy(lm)\n\n\n\n\nterm\nestimate\nstd.error\nstatistic\np.value\n\n\n\n(Intercept)\n6.7502202\n0.2478714\n27.232755\n0.0000000\n\n\nTV\n0.0191011\n0.0015041\n12.698954\n0.0000000\n\n\nradio\n0.0288603\n0.0089053\n3.240815\n0.0014005\n\n\nTV_x_radio\n0.0010865\n0.0000524\n20.726564\n0.0000000\n\n\n\n\n\nCodeglance(lm)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nr.squared\nadj.r.squared\nsigma\nstatistic\np.value\ndf\nlogLik\nAIC\nBIC\ndeviance\ndf.residual\nnobs\n\n\n0.9677905\n0.9672975\n0.9435154\n1963.057\n0\n3\n-270.1389\n550.2778\n566.7694\n174.4834\n196\n200",
    "crumbs": [
      "统计模型",
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>线性回归</span>"
    ]
  },
  {
    "objectID": "LinearRegression.html#变换",
    "href": "LinearRegression.html#变换",
    "title": "\n16  线性回归\n",
    "section": "\n16.5 变换",
    "text": "16.5 变换\n\n16.5.1 非线性变换\n\nCode\nrec_spec_square &lt;- recipe(sales ~ TV, data = advertising) |&gt;  \n  step_mutate(`TV^2` = TV^2)  \nrec_spec_square\n\nlm_wf_square &lt;- workflow() |&gt;  \n  add_model(lm_spec) |&gt;  \n  add_recipe(rec_spec_square)  \n\nlm_wf_square |&gt;\n  fit(advertising)\n#&gt; ══ Workflow [trained] ══════════════════════════════════════════════════════════\n#&gt; Preprocessor: Recipe\n#&gt; Model: linear_reg()\n#&gt; \n#&gt; ── Preprocessor ────────────────────────────────────────────────────────────────\n#&gt; 1 Recipe Step\n#&gt; \n#&gt; • step_mutate()\n#&gt; \n#&gt; ── Model ───────────────────────────────────────────────────────────────────────\n#&gt; \n#&gt; Call:\n#&gt; stats::lm(formula = ..y ~ ., data = data)\n#&gt; \n#&gt; Coefficients:\n#&gt; (Intercept)           TV       `TV^2`  \n#&gt;   6.114e+00    6.727e-02   -6.847e-05\n\n\n\n16.5.2 对数变换\n\nCoderec_spec_log &lt;- recipe(sales ~ TV, data = advertising) |&gt;  \n  step_log(TV)  \n\nlm_wf_log &lt;- workflow() |&gt; \n  add_model(lm_spec) |&gt;  \n  add_recipe(rec_spec_log) \n\nlm_wf_log |&gt;\n  fit(advertising)\n#&gt; ══ Workflow [trained] ══════════════════════════════════════════════════════════\n#&gt; Preprocessor: Recipe\n#&gt; Model: linear_reg()\n#&gt; \n#&gt; ── Preprocessor ────────────────────────────────────────────────────────────────\n#&gt; 1 Recipe Step\n#&gt; \n#&gt; • step_log()\n#&gt; \n#&gt; ── Model ───────────────────────────────────────────────────────────────────────\n#&gt; \n#&gt; Call:\n#&gt; stats::lm(formula = ..y ~ ., data = data)\n#&gt; \n#&gt; Coefficients:\n#&gt; (Intercept)           TV  \n#&gt;      -4.203        3.901",
    "crumbs": [
      "统计模型",
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>线性回归</span>"
    ]
  },
  {
    "objectID": "LinearRegression.html#回归诊断-1",
    "href": "LinearRegression.html#回归诊断-1",
    "title": "\n16  线性回归\n",
    "section": "\n16.6 回归诊断",
    "text": "16.6 回归诊断\nhttps://www.statmethods.net/stats/rdiagnostics.html\n\nCodelibrary(car)\n#回归检验\ncar::scatterplotMatrix(ad)  # 多重共线性\n\n\n\n\n\n\nCodeconfint(lm_sales_multi$fit)  # 95%置信区间\n#&gt;                   2.5 %     97.5 %\n#&gt; (Intercept)  2.32376228 3.55401646\n#&gt; TV           0.04301371 0.04851558\n#&gt; radio        0.17154745 0.20551259\n#&gt; newspaper   -0.01261595 0.01054097\nplot(lm_sales_multi$fit) #回归诊断图\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n16.6.0.1 线性假设\n残差图\n\nCodeplot(lm_sales_multi$fit,1)  \n\n\n\n\n\n\nCodecrPlots(lm_sales_multi$fit)\n\n\n\n\n\n\n\n\n16.6.0.2 正态性假设Q-Q图\nStandardized Residuals\n\nCodeplot(lm_sales_multi$fit,2) \n\n\n\n\n\n\nCodesummary(powerTransform(lm_sales_multi$fit))  \n#&gt; bcPower Transformation to Normality \n#&gt;    Est Power Rounded Pwr Wald Lwr Bnd Wald Upr Bnd\n#&gt; Y1    0.9074           1       0.7569       1.0578\n#&gt; \n#&gt; Likelihood ratio test that transformation parameter is equal to 0\n#&gt;  (log transformation)\n#&gt;                            LRT df       pval\n#&gt; LR test, lambda = (0) 147.1578  1 &lt; 2.22e-16\n#&gt; \n#&gt; Likelihood ratio test that no transformation is needed\n#&gt;                           LRT df    pval\n#&gt; LR test, lambda = (1) 1.41991  1 0.23342\n\n\n\nCodeplot(lm_sales_tv$fit,3)\n\n\n\n\n\n\n\n\n16.6.0.3 误差相关性\n\nCodedurbinWatsonTest(lm_sales_multi$fit)      #结果表明rho=0\n#&gt;  lag Autocorrelation D-W Statistic p-value\n#&gt;    1     -0.04687792      2.083648   0.554\n#&gt;  Alternative hypothesis: rho != 0\n\n\n\n16.6.0.4 误差项的方差齐性\n\nCodencvTest(lm_sales_multi$fit)\n#&gt; Non-constant Variance Score Test \n#&gt; Variance formula: ~ fitted.values \n#&gt; Chisquare = 5.355982, Df = 1, p = 0.020651\nspreadLevelPlot(lm_sales_multi$fit)\n\n\n\n\n\n\n#&gt; \n#&gt; Suggested power transformation:  1.499852\n\n\nCodetibble(\n    abs_studentized_residuals=abs(rstudent(lm_sales_multi$fit)),\n    fitted_values=lm_sales_multi$fit$model$sales\n) |&gt; ggplot(aes(fitted_values,abs_studentized_residuals))+\n    geom_point(pch=21)+\n    geom_smooth()\n\n\n\n\n\n\n\n\n16.6.0.5 异常观测点\n\nCode# studentized residual Plot\nresidplot&lt;-function(fit,nbreaks=10){\n  z&lt;-rstudent(fit)\n  hist(z,breaks=nbreaks,freq=FALSE)     #密度直方图\n  title(xlab=\"Studentized Residual\")\n  rug(z,col=\"brown\")                    #轴须图\n  curve(dnorm(x,mean=mean(z),sd=sd(z)),add=TRUE,col=\"blue\",lwd=2) #正态密度曲线\n  lines(density(z)$x,density(z)$y,col=\"red\",lwd=2)       #样本密度曲线\n  legend(\"topright\",c(\"Normal Curve\",\"Kernel Density Curve\"),#图例\n  lty = c(3,2),pch = c(21,22),col=c(\"blue\",\"red\"),cex=.7)\n}\nresidplot(lm_sales_tv$fit)\n\n\n\n\n\n\n\n\nCode#######################################################################\nlibrary(car)\noutlierTest(lm_sales_tv$fit)            #离群点\n#高杠杆值点\nhat.plot&lt;-function(fit){\n  p&lt;-length(coefficients(fit)) #模型估计的参数数目（包含截距项）\n  n&lt;-length(fitted(fit))       #样本量\n  plot(hatvalues(fit),main=\"Index Plot of Hat Values\")#帽子值\n  abline(h=c(2,3)*p/n,col=\"red\",lty=2)  #大于帽子均值p/n的2或3倍被认为是高杠杆值\n  identity(1:n,hatvalues(fit),names(hatvalues(fit)))\n}\nhat.plot(lm_sales_tv$fit)\n####强影响点\n#Cook's D图形    大于4/(n-k-1)  k为预测变量数目\ncutoff&lt;-4/(nrow(advertising)-length(lm_sales_tv$fit$coefficients)-2)\n{plot(lm_sales_tv$fit,which=4,cook.levels=cutoff)\nabline(h=cutoff,lty=2,col=\"red\")}\n#变量添加图\navPlots(lm_sales_tv$fit,ask=FALSE,id.method=\"identity\")\n\n###\ninfluencePlot(lm_sales_tv$fit,id.method=\"identity\",main=\"Influence Plot\")\n\n\nCook’s distance\n\nCodeplot(lm_sales_tv$fit,4)\n\n\n\n\n\n\n\nLeverage\n\nCodeplot(lm_sales_tv$fit,5)\n\n\n\n\n\n\n\n\nCodeplot(lm_sales_tv$fit,6)\n\n\n\n\n\n\n\n\n16.6.0.6 多重共线性\n\nCodevif(lm_sales_multi$fit)\n#&gt;        TV     radio newspaper \n#&gt;  1.004611  1.144952  1.145187\n\nsqrt(vif(lm_sales_multi$fit))&gt;=2       #vif平方根 ≥2 存在\n#&gt;        TV     radio newspaper \n#&gt;     FALSE     FALSE     FALSE",
    "crumbs": [
      "统计模型",
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>线性回归</span>"
    ]
  },
  {
    "objectID": "LinearRegression.html#模型选择和优化",
    "href": "LinearRegression.html#模型选择和优化",
    "title": "\n16  线性回归\n",
    "section": "\n16.7 模型选择和优化",
    "text": "16.7 模型选择和优化\n\nCode########################两模型比较\nlm1 &lt;- lm_spec |&gt; fit(sales~TV+radio+newspaper,data = advertising)\nlm2 &lt;- lm_spec |&gt; fit(sales~TV*radio*newspaper,data = advertising[-1])\n\nanova(lm2$fit,lm1$fit) #anova() 嵌套模型\n\n\n\n\nRes.Df\nRSS\nDf\nSum of Sq\nF\nPr(&gt;F)\n\n\n\n192\n169.8597\nNA\nNA\nNA\nNA\n\n\n196\n556.8253\n-4\n-386.9656\n109.3511\n0\n\n\n\n\n\nCode\n\n##########################################            AIC \nAIC(lm2$fit,lm1$fit)  # 赤池信息准则  AIC值小的优先选择\n\n\n\n\n\ndf\nAIC\n\n\nlm2\\(fit |  9| 552.9065|\n|lm1\\)fit\n5\n782.3622\n\n\n\n\nCode#BIC\n\n\n####################################相对重要性##################################\nad &lt;- scale(advertising[-1])\nad\n#&gt;                 TV        radio    newspaper        sales\n#&gt;   [1,]  0.96742460  0.979065591  1.774492530  1.548168135\n#&gt;   [2,] -1.19437904  1.080097401  0.667902716 -0.694303815\n#&gt;   [3,] -1.51235985  1.524637364  1.779084189 -0.905134512\n#&gt;   [4,]  0.05191939  1.214806480  1.283185019  0.858176766\n#&gt;   [5,]  0.39319551 -0.839506984  1.278593360 -0.215143142\n#&gt;   [6,] -1.61136487  1.726700983  2.040808751 -1.307629477\n#&gt;   [7,] -1.04295960  0.642292892 -0.323895625 -0.425973838\n#&gt;   [8,] -0.31265202 -0.246787034 -0.870303044 -0.157643861\n#&gt;   [9,] -1.61252963 -1.425491481 -1.357018896 -1.767623723\n#&gt;  [10,]  0.61450084 -1.391814211 -0.429503781 -0.655970962\n#&gt;  [11,] -0.94278982 -1.176279684 -0.291754012 -1.039299500\n#&gt;  [12,]  0.78805080  0.049572941 -1.219269126  0.647346069\n#&gt;  [13,] -1.43548537  0.797208333  1.622967784 -0.924300938\n#&gt;  [14,] -0.57705364 -1.055041512 -1.072336039 -0.828468804\n#&gt;  [15,]  0.66458573  0.649028346  0.709227646  0.954008900\n#&gt;  [16,]  0.56325118  1.645875535  1.026052116  1.605667416\n#&gt;  [17,] -0.92298882  0.898240143  3.831555755 -0.291808850\n#&gt;  [18,]  1.56494899  1.100303763  1.159210227  1.988995954\n#&gt;  [19,] -0.90668211 -0.186167948 -0.562661892 -0.521805973\n#&gt;  [20,]  0.00299927  0.042837487 -0.525928620  0.110686115\n#&gt;  [21,]  0.83114711  0.298784739  1.049010411  0.762344631\n#&gt;  [22,]  1.05245243 -1.223427861 -0.323895625 -0.291808850\n#&gt;  [23,] -1.55895045 -0.495998831  0.874527370 -1.614292308\n#&gt;  [24,]  0.94645883 -0.428644291 -0.199920832  0.283183958\n#&gt;  [25,] -0.98705089 -0.718268813 -0.562661892 -0.828468804\n#&gt;  [26,]  1.34946748 -1.331195125 -0.507561984 -0.387640985\n#&gt;  [27,] -0.04825039  0.406552002 -0.824386454  0.187351823\n#&gt;  [28,]  1.08390109 -0.442115199 -0.351445579  0.359849666\n#&gt;  [29,]  1.18523563  0.258372015 -0.351445579  0.934842473\n#&gt;  [30,] -0.89037540 -0.489263377  0.470461379 -0.675137388\n#&gt;  [31,]  1.69889695  0.339197463  0.580661195  1.414003146\n#&gt;  [32,] -0.39767985 -0.394967022  0.369444882 -0.406807411\n#&gt;  [33,] -0.58054794 -1.465904205 -0.025437791 -0.847635231\n#&gt;  [34,]  1.38091613 -0.219845218 -1.389160509  0.647346069\n#&gt;  [35,] -0.59801941 -1.472639659 -1.063152721 -0.866801658\n#&gt;  [36,]  1.67327212 -1.290782401 -1.012644472 -0.234309569\n#&gt;  [37,]  1.39605808  1.383192830 -1.173352536  2.180660223\n#&gt;  [38,] -0.84262004  1.760378253  0.695452669  0.129852542\n#&gt;  [39,] -1.21068574  0.231430199  0.208736817 -0.751803096\n#&gt;  [40,]  0.94296453  0.972330137  0.066395389  1.433169573\n#&gt;  [41,]  0.64594949 -0.064929776  0.048028753  0.494014654\n#&gt;  [42,]  0.34893444  0.682705616  0.374036541  0.589846789\n#&gt;  [43,]  1.70705030  0.298784739 -1.320285624  1.279838158\n#&gt;  [44,]  0.69719914 -1.001157880 -0.190737514 -0.215143142\n#&gt;  [45,] -1.42034342  0.164075659  0.585252854 -1.058465927\n#&gt;  [46,]  0.32680391 -0.051458868  0.043437094  0.168185396\n#&gt;  [47,] -0.66790531 -0.900126070  0.236286771 -0.655970962\n#&gt;  [48,]  1.08157156  1.228277388 -0.553478574  1.758998831\n#&gt;  [49,]  0.93364642 -0.502734285  0.888302347  0.149018969\n#&gt;  [50,] -0.93347170 -0.778887899  0.286795020 -0.828468804\n#&gt;  [51,]  0.61450084 -1.358136941  0.185778522 -0.502639546\n#&gt;  [52,] -0.54327546 -0.920332432 -1.237635762 -0.636804535\n#&gt;  [53,]  0.80785181  1.241748296  0.415361472  1.644000269\n#&gt;  [54,]  0.41416128  1.544843726  1.292368337  1.375670293\n#&gt;  [55,]  1.34713795  0.372874732 -0.672861707  1.184006023\n#&gt;  [56,]  0.60401795  1.760378253  1.352059904  1.854830966\n#&gt;  [57,] -1.62767157  0.325726555  0.498011333 -1.633458735\n#&gt;  [58,] -0.12628963 -0.273728850 -0.640720094 -0.157643861\n#&gt;  [59,]  0.74262497  1.773849161  0.328119951  1.873997393\n#&gt;  [60,]  0.74146021  0.420022910 -0.975911200  0.839010339\n#&gt;  [61,] -1.08955020 -1.432226935 -0.420320463 -1.135131635\n#&gt;  [62,]  1.33083124  1.309102836  1.108701978  1.950663100\n#&gt;  [63,]  1.07458297 -0.522940647 -0.149412583  0.321516812\n#&gt;  [64,] -0.51648587  0.426758364 -1.017236131 -0.004312446\n#&gt;  [65,] -0.18569264  1.315838290 -0.075946040  0.762344631\n#&gt;  [66,] -0.90901164 -0.940538794 -1.361610555 -0.905134512\n#&gt;  [67,] -1.34579847  0.089985665 -1.301918988 -0.866801658\n#&gt;  [68,] -0.09018192 -0.590295187 -0.934586269 -0.119311008\n#&gt;  [69,]  1.05245243  0.285313831 -0.897852997  0.934842473\n#&gt;  [70,]  0.81251087  1.389928284 -0.154004242  1.586500989\n#&gt;  [71,]  0.60634748  0.494112904  0.374036541  0.819843912\n#&gt;  [72,] -0.43378756 -0.603766095  0.052620412 -0.310975277\n#&gt;  [73,] -1.40054242  0.655763800 -0.516745302 -1.000966646\n#&gt;  [74,] -0.20549365 -1.183015138  0.034253776 -0.579305254\n#&gt;  [75,]  0.77290886  0.089985665 -0.801428159  0.570680362\n#&gt;  [76,] -1.51585415  1.376457376  2.702007645 -1.020133073\n#&gt;  [77,] -1.39238907 -1.459168751 -0.452462076 -1.365128758\n#&gt;  [78,] -0.30915772  0.352668371 -0.750919910  0.034020408\n#&gt;  [79,] -1.64980211  0.446964726 -0.971319541 -1.671791589\n#&gt;  [80,] -0.36157214 -1.048306058 -0.342262261 -0.579305254\n#&gt;  [81,] -0.82281904  0.231430199 -0.378995532 -0.425973838\n#&gt;  [82,]  1.08040679 -1.290782401  0.291386679 -0.330141704\n#&gt;  [83,] -0.83563145 -0.199638856  0.089353684 -0.521805973\n#&gt;  [84,] -0.91600023  1.430341008  0.231695112 -0.080978154\n#&gt;  [85,]  0.77407363  1.329309198  0.149045251  1.471502427\n#&gt;  [86,]  0.53762635 -0.327612482  1.613784466  0.225684677\n#&gt;  [87,] -0.82398380  0.285313831 -0.668270048 -0.387640985\n#&gt;  [88,] -0.42330468  1.167658302  1.498992991  0.379016092\n#&gt;  [89,] -0.68421201  0.150604751  1.967342208 -0.215143142\n#&gt;  [90,] -0.43378756  1.652610989  0.957177231  0.513181081\n#&gt;  [91,] -0.14842017 -1.236898769 -0.975911200 -0.540972400\n#&gt;  [92,] -1.37957665 -1.465904205  0.112311979 -1.288463050\n#&gt;  [93,]  0.82299375  0.689441070  1.306143314  1.030674608\n#&gt;  [94,]  1.20969569  0.891504689  1.916833959  1.567334562\n#&gt;  [95,] -0.46174192 -0.623972457 -0.902444656 -0.483473119\n#&gt;  [96,]  0.18936165  0.561467444  1.026052116  0.551513935\n#&gt;  [97,]  0.58887601 -1.331195125 -1.132027606 -0.445140265\n#&gt;  [98,]  0.44095087 -0.152490678 -0.392770509  0.283183958\n#&gt;  [99,]  1.66162447  1.282161020  0.947993914  2.180660223\n#&gt; [100,] -0.13793728  1.241748296  0.704635987  0.609013216\n#&gt; [101,]  0.87773770 -1.277311493  0.883710688 -0.445140265\n#&gt; [102,]  1.73966372  0.878033781  3.230048428  1.873997393\n#&gt; [103,]  1.55097181 -0.886655162 -0.420320463  0.149018969\n#&gt; [104,]  0.47589381 -0.408437930 -0.581028528  0.129852542\n#&gt; [105,]  1.06177055  0.743324702 -1.159577559  1.279838158\n#&gt; [106,] -0.10648863  1.558314633  1.306143314  0.992341754\n#&gt; [107,] -1.42150819 -0.826036076 -0.039212768 -1.307629477\n#&gt; [108,] -0.65975195 -1.546729653 -0.337670602 -1.020133073\n#&gt; [109,] -1.56011521 -1.539994199 -0.227470786 -1.671791589\n#&gt; [110,]  1.26211011  0.244901107 -1.150394241  1.107340316\n#&gt; [111,]  0.91733971 -1.014628788  1.191351840 -0.119311008\n#&gt; [112,]  1.10253732  0.992536499 -0.337670602  1.490668854\n#&gt; [113,]  0.33379250 -0.529676101 -1.292735670  0.014853981\n#&gt; [114,]  0.72864780 -0.179432494 -0.911627974  0.359849666\n#&gt; [115,] -0.80185327  1.585256449  0.181186863  0.110686115\n#&gt; [116,] -0.83796098  0.790472879  1.016868798 -0.272642423\n#&gt; [117,] -0.09134669 -0.603766095 -0.227470786 -0.349308131\n#&gt; [118,] -0.82281904 -1.513052383 -0.723369956 -0.885968085\n#&gt; [119,] -0.24858995  0.918446505  2.233658429  0.359849666\n#&gt; [120,] -1.48673502 -0.489263377 -0.378995532 -1.422628038\n#&gt; [121,] -0.06688662  0.238165653  0.718410964  0.283183958\n#&gt; [122,] -1.49372361 -0.105342500  0.911260642 -1.345962331\n#&gt; [123,]  0.89637394 -1.405285119 -0.686636684 -0.464306692\n#&gt; [124,] -0.27887383  0.763531064 -0.833569772  0.225684677\n#&gt; [125,]  0.96043601  0.608615622  2.004075480  1.088173889\n#&gt; [126,] -0.69702443 -0.772152445 -0.213695809 -0.655970962\n#&gt; [127,] -1.62184775  1.053155585  0.920443960 -1.422628038\n#&gt; [128,] -0.77855797 -1.566936015 -0.980502859 -1.000966646\n#&gt; [129,]  0.85327764  1.733436437 -1.256002398  2.046495235\n#&gt; [130,] -1.01849954 -0.758681537  0.576069536 -0.828468804\n#&gt; [131,] -1.70454606  1.100303763 -1.003461154 -2.380949385\n#&gt; [132,]  1.37625707 -1.371607849  0.571477877 -0.253475996\n#&gt; [133,] -1.61485916  0.265107469 -1.306510647 -1.595125881\n#&gt; [134,]  0.84745381  0.689441070  0.667902716  1.069007462\n#&gt; [135,] -1.28290117  1.032949223  1.609192807 -0.617638108\n#&gt; [136,] -1.15011797  1.598727357 -1.012644472 -0.464306692\n#&gt; [137,] -1.41451960  1.059891039 -0.975911200 -0.866801658\n#&gt; [138,]  1.47526209  0.379610186  1.338284927  1.299004585\n#&gt; [139,] -1.21185051  0.177546567 -0.461645394 -0.847635231\n#&gt; [140,]  0.44095087  1.389928284 -1.324877283  1.279838158\n#&gt; [141,] -0.85776198 -0.421908837 -0.810611477 -0.598471681\n#&gt; [142,]  0.54345018  0.817414695  2.068358705  0.992341754\n#&gt; [143,]  0.85560717  0.669234708  0.337303269  1.164839596\n#&gt; [144,] -0.49435534 -1.183015138  0.176595204 -0.694303815\n#&gt; [145,] -0.59219559 -0.570088825  0.383219859 -0.502639546\n#&gt; [146,] -0.07853427 -1.438962389 -0.989686177 -0.713470242\n#&gt; [147,]  1.08390109 -1.075247874 -1.003461154 -0.157643861\n#&gt; [148,]  1.12000880  1.733436437  0.631169444  2.180660223\n#&gt; [149,] -1.27008875  1.147451941 -0.856528067 -0.598471681\n#&gt; [150,] -1.19204951  0.170811113 -0.457053735 -0.751803096\n#&gt; [151,]  1.55679563 -0.630707911  0.295978338  0.398182519\n#&gt; [152,] -0.30333390 -1.001157880  0.833202439 -0.464306692\n#&gt; [153,]  0.58887601  0.002424763 -0.750919910  0.494014654\n#&gt; [154,]  0.28254284  1.107039217  0.328119951  0.954008900\n#&gt; [155,]  0.47472905 -0.145755224 -0.966727882  0.302350385\n#&gt; [156,] -1.66494405 -0.785623353 -1.141210924 -2.074286554\n#&gt; [157,] -0.61898518  1.362986468  0.915852301  0.244851104\n#&gt; [158,]  0.03211839 -1.479375113 -0.287162353 -0.751803096\n#&gt; [159,] -1.57642192  0.918446505  0.672494375 -1.288463050\n#&gt; [160,] -0.17870405 -0.327612482  0.185778522 -0.215143142\n#&gt; [161,]  0.29652002 -0.347818844  0.006703822  0.072353262\n#&gt; [162,] -0.71449590  0.844356511  0.860752393 -0.138477435\n#&gt; [163,]  0.48171764 -0.347818844 -0.227470786  0.168185396\n#&gt; [164,]  0.19169118  0.911711051 -1.063152721  0.762344631\n#&gt; [165,] -0.34759496 -0.576824279 -1.154985900 -0.406807411\n#&gt; [166,]  1.01867425 -1.337930579  2.490791332 -0.406807411\n#&gt; [167,] -1.50420650  0.965594683 -0.411137145 -1.154298062\n#&gt; [168,]  0.69603438 -1.216692407 -0.512153643 -0.349308131\n#&gt; [169,]  0.79620416  0.022631125  1.241860088  0.589846789\n#&gt; [170,]  1.59872717 -0.852977892 -1.109069311  0.187351823\n#&gt; [171,] -1.13031697 -0.785623353 -0.558070233 -1.077632354\n#&gt; [172,]  0.20333883 -0.159226132  0.773510872  0.091519689\n#&gt; [173,] -1.48440549 -0.213109764 -0.622353458 -1.230963769\n#&gt; [174,]  0.24876466 -1.088718782 -0.815203136 -0.445140265\n#&gt; [175,]  0.87773770 -1.337930579 -0.801428159 -0.483473119\n#&gt; [176,]  1.51253457  1.726700983  0.516377969  2.487323054\n#&gt; [177,]  1.18057657  0.467171088 -0.470828712  1.184006023\n#&gt; [178,]  0.26973043 -1.041570604  0.213328476 -0.445140265\n#&gt; [179,]  1.51020504 -1.412020573 -0.314712307 -0.425973838\n#&gt; [180,]  0.21615124 -0.893390616 -0.594803505 -0.272642423\n#&gt; [181,]  0.11132240 -1.391814211 -1.021827790 -0.675137388\n#&gt; [182,]  0.83231187 -1.203221500 -0.144820924 -0.349308131\n#&gt; [183,] -1.05810154 -1.183015138 -0.039212768 -1.020133073\n#&gt; [184,]  1.63716441  1.329309198  1.893875664  2.333991639\n#&gt; [185,]  1.24347388 -0.132284316 -0.025437791  0.685678923\n#&gt; [186,]  0.67506861  1.470753732 -0.502970325  1.644000269\n#&gt; [187,] -0.08785239 -1.425491481 -0.181554196 -0.713470242\n#&gt; [188,]  0.51316629  0.366139279 -0.567253551  0.628179642\n#&gt; [189,]  1.61852817 -0.630707911 -1.233044103  0.359849666\n#&gt; [190,] -1.49488838 -0.751946083 -0.328487284 -1.403461612\n#&gt; [191,] -1.25261728  1.201335572 -1.136619265 -0.617638108\n#&gt; [192,] -0.83330192 -0.839506984 -1.127435947 -0.790135950\n#&gt; [193,] -1.51235985 -1.290782401  0.048028753 -1.556793027\n#&gt; [194,]  0.23012842  1.261954658 -1.237635762  1.069007462\n#&gt; [195,]  0.03095363  0.830885603 -1.127435947  0.628179642\n#&gt; [196,] -1.26775922 -1.317724217 -0.769286546 -1.230963769\n#&gt; [197,] -0.61549089 -1.236898769 -1.031011108 -0.828468804\n#&gt; [198,]  0.34893444 -0.940538794 -1.109069311 -0.234309569\n#&gt; [199,]  1.59057381  1.261954658  1.636742761  2.199826650\n#&gt; [200,]  0.99071990 -0.987686972 -1.003461154 -0.119311008\n#&gt; attr(,\"scaled:center\")\n#&gt;        TV     radio newspaper     sales \n#&gt;  147.0425   23.2640   30.5540   14.0225 \n#&gt; attr(,\"scaled:scale\")\n#&gt;        TV     radio newspaper     sales \n#&gt; 85.854236 14.846809 21.778621  5.217457\n#R平方贡献率  #相对权重 \nrelweights&lt;-function(fit,...){\n  R&lt;-cor(fit$model)\n  nvar&lt;-ncol(R)\n  rxx&lt;-R[2:nvar,2:nvar]\n  rxy&lt;-R[2:nvar,1]\n  svd&lt;-eigen(rxx)\n  evec&lt;-svd$vectors\n  ev&lt;-svd$values\n  delta&lt;-diag(sqrt(ev))\n  lambda&lt;-evec %*%delta %*% t(evec)\n  lambdaasq&lt;-lambda^2\n  beta&lt;-solve(lambda) %*% rxy\n  r2&lt;-colSums(beta^2)\n  rawwgt&lt;-lambdaasq%*%beta^2\n  import&lt;-(rawwgt/r2)*100            #计算相对权重\n  import&lt;-data.frame(Weights=import)  #数据框化\n  row.names(import)&lt;-names(fit$model[2:nvar])\n  import&lt;-import[order(import$Weights),1,drop=FALSE] #升序排序\n  dotchart(import$Weights,labels=row.names(import),   #点图\n           xlab = \"% of R-Square\",pch=19,\n           main=\"Relative Importiance of Predictor Variables \",\n           sub=paste(\"Total R-Square =\",round(r2,digits = 3)),\n  ...)\nreturn(import)\n}\nrelweights(lm1$fit,col=\"blue\")\n\n\n\n\n\n\n\n\n\n\n\nWeights\n\n\n\nnewspaper\n2.468097\n\n\nradio\n32.198236\n\n\nTV\n65.333667",
    "crumbs": [
      "统计模型",
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>线性回归</span>"
    ]
  },
  {
    "objectID": "LinearRegression.html#线性可加模型",
    "href": "LinearRegression.html#线性可加模型",
    "title": "\n16  线性回归\n",
    "section": "\n16.8 线性可加模型",
    "text": "16.8 线性可加模型\nadditive model\n\\[\nY_i=\\beta_0+ \\beta_1 X_i+  \\beta_2 X_i^2+\\epsilon_i\n\\]\n\\[\nY_i=\\beta_0+ \\beta_1\\times \\log(X_i)+\\epsilon_i\n\\]\n\\[\nY_i=\\beta_0+ \\beta_1 (X_i\\times W_i)+\\epsilon_i\n\\]\n\\[\nY_i=\\beta_0+ \\beta_1\\times \\exp(X_i)+\\epsilon_i\n\\]\n\\[\nY_i=\\beta_0+ \\beta_1\\times \\sin(X_i)+\\epsilon_i\n\\]",
    "crumbs": [
      "统计模型",
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>线性回归</span>"
    ]
  },
  {
    "objectID": "GLM.html",
    "href": "GLM.html",
    "title": "\n17  广义线性模型\n",
    "section": "",
    "text": "17.1 广义线性模型组件\n\\[\n\\eta = \\mathbf{X} \\beta\n\\]\n\\[\nE(y)=\\mu\n\\]\n\\[\n\\eta =g(\\mu)=g(E(y))\n\\]\n\\[\nE(y)=g^{-1}(\\eta)\n\\]\nCodelibrary(tidymodels)\nlibrary(poissonreg)\nlibrary(patchwork)",
    "crumbs": [
      "统计模型",
      "<span class='chapter-number'>17</span>  <span class='chapter-title'>广义线性模型</span>"
    ]
  },
  {
    "objectID": "GLM.html#广义线性模型组件",
    "href": "GLM.html#广义线性模型组件",
    "title": "\n17  广义线性模型\n",
    "section": "",
    "text": "线性预测函数：\n\n\n\n期望值与线性预测函数的关系：\n\n\n\n连接函数 g(.) ：\n\n\n\n反连接函数g-1 (.)：",
    "crumbs": [
      "统计模型",
      "<span class='chapter-number'>17</span>  <span class='chapter-title'>广义线性模型</span>"
    ]
  },
  {
    "objectID": "GLM.html#高斯线性回归",
    "href": "GLM.html#高斯线性回归",
    "title": "\n17  广义线性模型\n",
    "section": "\n17.2 高斯线性回归",
    "text": "17.2 高斯线性回归\n高斯线性回归是一种简单的线性回归模型，其中假设响应变量服从正态分布，并且使用恒等连接函数（identity link function）。t-statistic\n\nCodelibrary(tidymodels)\n\n# 使用 glm() 函数进行高斯线性回归\nglm1 &lt;- linear_reg() |&gt; \n  set_engine(\"glm\", family = stats::gaussian(link = \"identity\")) |&gt; \n  fit(Fertility ~ Agriculture + Education + Catholic + Infant.Mortality,\n      data = swiss)\n\n# 查看模型的系数\ntidy(glm1)\n\n\n\n\nterm\nestimate\nstd.error\nstatistic\np.value\n\n\n\n(Intercept)\n62.1013116\n9.6048861\n6.465596\n0.0000001\n\n\nAgriculture\n-0.1546175\n0.0681899\n-2.267454\n0.0285697\n\n\nEducation\n-0.9802638\n0.1481367\n-6.617293\n0.0000001\n\n\nCatholic\n0.1246664\n0.0288935\n4.314686\n0.0000950\n\n\nInfant.Mortality\n1.0784422\n0.3818662\n2.824136\n0.0072204\n\n\n\n\n\nCode\n# 查看模型的 AIC 和 Deviance\nglance(glm1) |&gt; select(AIC, deviance)\n\n\n\n\nAIC\ndeviance\n\n\n325.2408\n2158.069",
    "crumbs": [
      "统计模型",
      "<span class='chapter-number'>17</span>  <span class='chapter-title'>广义线性模型</span>"
    ]
  },
  {
    "objectID": "GLM.html#逻辑回归",
    "href": "GLM.html#逻辑回归",
    "title": "\n17  广义线性模型\n",
    "section": "\n17.3 逻辑回归",
    "text": "17.3 逻辑回归\n逻辑回归用于处理二元分类问题。其模型假设响应变量的对数优势（log odds）服从线性模型。\nSigmoid 激活函数：\n\\[\nf(x)=\\frac{1}{1+e^{-x}}=\\frac{e^x}{1+e^x}\n\\]\n\nCodesigmoid &lt;- tibble(\n    x=seq(-6,6,length.out=1000),\n    y=1/(1+exp(-x)),\n)\nggplot(sigmoid,aes(x,y))+\n    geom_line()\n\n\n\n\n\n\n\n逻辑回归( logistic regression )的一般数学方程：\n\\[\n\\pi(Y=k|X=(X_1,X_2,...,X_p)=\\frac{e^{\\beta_{k0}+\\beta_{k1}X_1+\\beta_{k2}X_2+...+\\beta_{kp}X_p}}{1+\\sum_{l=1}^{K-1} e^{\\beta_{l0}+\\beta_{l1}X_1+\\beta_{l2}X_2+...+\\beta_{lp}X_p}}\n\\] 其中\\(\\pi\\) 是成功概率，\\(k=1,2,...,K-1\\)是因变量的水平数，\\(p\\) 是自变量个数。\n逻辑回归一般需要引入虚拟变量（哑变量，dummy variable），通常取值伪0或1。\n\n\n当\\(K=2\\)时，\\(k=l=p=1\\)即简单逻辑回归。\n极大似然法（maximum likelihood），likelihood function：\n\\[\n\\ell (\\beta_0,\\beta_1)=\\prod_{i:y_i=1}\\pi(x_i)\\prod_{i':y_{i'}=0}(1-\\pi(x_{i'}))\n\\]\n\n\n当\\(K=2\\)时，\\(k=l=1,p&gt;1\\)即多元逻辑回归（multiple logistic regression）。\n优势（odds）\n\\[\nOdds=\\frac{\\pi(X)}{1-\\pi(X)}=e^{\\beta_0+\\beta_1X_1+\\beta_2X_2+...+\\beta_pX_p}\n\\]\nlog odds (logit)\n\\[\nlogit(\\pi(X))=\\ln (\\frac{\\pi(X)}{1-\\pi(X)})=\\beta_0+\\beta_1X_1+\\beta_2X_2+...+\\beta_pX_p\n\\]\n\n\n当\\(K&gt;2\\)时，\\(k,l,p&gt;1\\)即多项逻辑回归（multinomial logistic regression）。\n\\[\n\\log (\\frac{P(Y=k|X=x)}{P(Y=K|X=x)})=\\beta_{k0}+\\beta_{k1}X_1+\\beta_{k2}X_2+...+\\beta_{kp}X_p\n\\]\n\n\n数据下载网站\n\nCodedf &lt;- read_csv(\"data/ISLR/Default.csv\")\ndf$default &lt;- factor(df$default,levels = c(\"No\",\"Yes\"),labels = c(0,1))\ndf$student&lt;- factor(df$student,levels = c(\"No\",\"Yes\"),labels = c(0,1))\n# 违约 学生 余额 收入\nhead(df)\n\n\n\n\ndefault\nstudent\nbalance\nincome\n\n\n\n0\n0\n729.5265\n44361.625\n\n\n0\n1\n817.1804\n12106.135\n\n\n0\n0\n1073.5492\n31767.139\n\n\n0\n0\n529.2506\n35704.494\n\n\n0\n0\n785.6559\n38463.496\n\n\n0\n1\n919.5885\n7491.559\n\n\n\n\n\nCodetable(df$default,df$student)\n#&gt;    \n#&gt;        0    1\n#&gt;   0 6850 2817\n#&gt;   1  206  127\n\n\n\nCodeggplot(df,aes(balance,income))+\n  geom_point(aes(shape=default,color=default),show.legend = F)|\nggplot(df,aes(default,balance,fill=default),)+\n  geom_boxplot(show.legend = F)+\nggplot(df,aes(default,income,fill=default))+\n  geom_boxplot()\n\n\n\n\n\n\n\n\n17.3.1 Binary logistic regression\n\n17.3.1.1 为什么不用线性回归\n\nCodelm_spec&lt;-linear_reg(mode =\"regression\",engine = \"lm\" )\n\nlm_default_balance&lt;-lm_spec |&gt; \n  fit(as.numeric(default)-1~balance,data=df)\nlm_default_balance$fit\n#&gt; \n#&gt; Call:\n#&gt; stats::lm(formula = as.numeric(default) - 1 ~ balance, data = data)\n#&gt; \n#&gt; Coefficients:\n#&gt; (Intercept)      balance  \n#&gt;  -0.0751920    0.0001299\n\nggplot(df,aes(balance,as.numeric(default)-1))+\n  geom_point(color=\"orange\",size=1.25)+\n  geom_smooth(method = \"lm\",se=FALSE)+\n  geom_hline(yintercept = c(0,1),linetype=2)+\n  ggtitle(\"linear regression\")\n\n\n\n\n\n\n\n\n17.3.1.2 逻辑回归\nlogit link function\nz-statistic\n\nCodelogit_spec &lt;- logistic_reg() |&gt;\n  set_engine(\"glm\",family= binomial(link = \"logit\")) \n\n\nlogit_default_balance &lt;- logit_spec |&gt; fit(default~balance,data=df)\n\nlogit_default_balance |&gt; glance()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nnull.deviance\ndf.null\nlogLik\nAIC\nBIC\ndeviance\ndf.residual\nnobs\n\n\n2920.65\n9999\n-798.2258\n1600.452\n1614.872\n1596.452\n9998\n10000\n\n\n\n\nCode\ntidy(logit_default_balance)\n\n\n\n\nterm\nestimate\nstd.error\nstatistic\np.value\n\n\n\n(Intercept)\n-10.6513306\n0.3611574\n-29.49221\n0\n\n\nbalance\n0.0054989\n0.0002204\n24.95309\n0\n\n\n\n\n\nCode\n\nggplot(df,aes(balance,as.numeric(default)-1))+\n  geom_point(color=\"orange\",size=1.25)+\n  geom_smooth(method = \"glm\",\n              method.args=list(family=binomial(link = \"logit\")),se=FALSE)+\n  geom_hline(yintercept = c(0,1),linetype=2)+\n  ggtitle(\"logistic regression\")\n\n\n\n\n\n\n\n\n17.3.1.3 自变量是分类变量\n\nCodelogit_default_student &lt;- logit_spec |&gt;fit(default ~ student, data = df)\n\ntidy(logit_default_student)\n\n\n\n\nterm\nestimate\nstd.error\nstatistic\np.value\n\n\n\n(Intercept)\n-3.5041278\n0.0707130\n-49.554219\n0.0000000\n\n\nstudent1\n0.4048871\n0.1150188\n3.520181\n0.0004313\n\n\n\n\n\nCode\ndf |&gt; \n  mutate(\n    prob=1/(1+exp(-(logit_default_student$fit$coefficients[1]+logit_default_student$fit$coefficients[2]*(as.numeric(student)-1)))),\n    logit=log(prob/(1-prob))\n  ) |&gt; select(student,prob)\n\n\n\n\nstudent\nprob\n\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n0\n0.0291950\n\n\n1\n0.0431386\n\n\n\n\n\n\n\n17.3.2 K=2,p&gt;1 多元逻辑回归\n\nCodelogit_multiple&lt;-logit_spec |&gt; fit(default~balance+income+student,data=df)\n\ntidy(logit_multiple)\n\n\n\n\nterm\nestimate\nstd.error\nstatistic\np.value\n\n\n\n(Intercept)\n-10.8690452\n0.4922555\n-22.080088\n0.0000000\n\n\nbalance\n0.0057365\n0.0002319\n24.737563\n0.0000000\n\n\nincome\n0.0000030\n0.0000082\n0.369815\n0.7115203\n\n\nstudent1\n-0.6467758\n0.2362525\n-2.737646\n0.0061881\n\n\n\n\n\nCode\n# confusion matrix 混淆矩阵\naugment(logit_multiple, new_data = df) |&gt;\n  conf_mat(truth = default, estimate = .pred_class) |&gt; \n    autoplot(type = \"heatmap\")\n\n\n\n\n\n\nCode\n#准确性 \n(9627+105)/(9627+105+40+228)\n#&gt; [1] 0.9732\naugment(logit_multiple, new_data = df) |&gt;\n  accuracy(truth = default, estimate = .pred_class)\n\n\n\n\n.metric\n.estimator\n.estimate\n\n\naccuracy\nbinary\n0.9732\n\n\n\n\n\n减少弱相关或无关变量\n\nCodelogit_multiple_2&lt;-logit_spec |&gt; fit(default~balance+student,data=df)\n\naugment(logit_multiple_2, new_data =df) |&gt;\n  conf_mat(truth = default, estimate = .pred_class) \n#&gt;           Truth\n#&gt; Prediction    0    1\n#&gt;          0 9628  228\n#&gt;          1   39  105\n\n\n预测特定值\n\nCodedf_new &lt;- tibble(\n  balance = c(1000, 2000), \n  student = factor(c(1, 0)),\n)\npredict(logit_multiple_2, new_data = df_new,type=\"class\")\n\n\n\n\n.pred_class\n\n\n\n0\n\n\n1\n\n\n\n\n\nCodepredict(logit_multiple_2, new_data = df_new, type = \"prob\")\n\n\n\n\n.pred_0\n.pred_1\n\n\n\n0.9967514\n0.0032486\n\n\n0.3259166\n0.6740834\n\n\n\n\n\n\n\n17.3.3 有序逻辑回归\n\\[\n    \\log \\left(\\frac{P(Y\\le k|X=x)}{1-P(Y\\le k|X=x)}\\right)\n\\]\n\nCodeacl &lt;- read_rds(\"data/icpsr/advanced_acl_data.rds\")\nacl$PhysActCat_W1 &lt;- factor(acl$PhysActCat_W1,ordered = T)\nlevels(acl$PhysActCat_W1)\n#&gt; [1] \"(1) Low_5th\"  \"(2) 2Low_5th\" \"(3) 3Low_5th\" \"(4) 4Low_5th\" \"(5) Hi_5th\"\n\nordered_logit &lt;- MASS::polr(PhysActCat_W1 ~ SelfEfficacy_W1, data = acl,\n                            method = \"logistic\")\nordered_logit |&gt; summary()\n#&gt; Call:\n#&gt; MASS::polr(formula = PhysActCat_W1 ~ SelfEfficacy_W1, data = acl, \n#&gt;     method = \"logistic\")\n#&gt; \n#&gt; Coefficients:\n#&gt;                  Value Std. Error t value\n#&gt; SelfEfficacy_W1 0.2431    0.02893   8.404\n#&gt; \n#&gt; Intercepts:\n#&gt;                           Value    Std. Error t value \n#&gt; (1) Low_5th|(2) 2Low_5th   -0.9332   0.0371   -25.1533\n#&gt; (2) 2Low_5th|(3) 3Low_5th  -0.2688   0.0338    -7.9606\n#&gt; (3) 3Low_5th|(4) 4Low_5th   0.8470   0.0364    23.2527\n#&gt; (4) 4Low_5th|(5) Hi_5th     1.5298   0.0435    35.1647\n#&gt; \n#&gt; Residual Deviance: 11196.86 \n#&gt; AIC: 11206.86\n\n\npredict(ordered_logit ,acl ,type = \"p\") |&gt; as_tibble()\n\n\n\n\n(1) Low_5th\n(2) 2Low_5th\n(3) 3Low_5th\n(4) 4Low_5th\n(5) Hi_5th\n\n\n\n0.2822723\n0.1509398\n0.2667328\n0.1220362\n0.1780188\n\n\n0.2227442\n0.1349732\n0.2718842\n0.1412808\n0.2291176\n\n\n0.3170197\n0.1572427\n0.2592959\n0.1113936\n0.1550482\n\n\n0.2386041\n0.1399036\n0.2716895\n0.1360916\n0.2137112\n\n\n0.2470295\n0.1423175\n0.2712006\n0.1333412\n0.2061111\n\n\n0.3202712\n0.1577267\n0.2584773\n0.1104286\n0.1530962\n\n\n0.3487268\n0.1612269\n0.2505810\n0.1022253\n0.1372400\n\n\n0.2730326\n0.1489036\n0.2682442\n0.1249587\n0.1848609\n\n\n0.3057289\n0.1554237\n0.2619872\n0.1147869\n0.1620732\n\n\n0.3342402\n0.1596080\n0.2547566\n0.1063468\n0.1450485\n\n\n0.3347759\n0.1596738\n0.2546076\n0.1061924\n0.1447503\n\n\n0.2816718\n0.1508122\n0.2668376\n0.1222251\n0.1784533\n\n\n0.2227442\n0.1349732\n0.2718842\n0.1412808\n0.2291176\n\n\n0.2468396\n0.1422647\n0.2712143\n0.1334031\n0.2062783\n\n\n0.2670993\n0.1475133\n0.2690951\n0.1268528\n0.1894395\n\n\n0.2874480\n0.1520129\n0.2657929\n0.1204148\n0.1743315\n\n\n0.3200014\n0.1576872\n0.2585459\n0.1105085\n0.1532571\n\n\n0.2630545\n0.1465278\n0.2696184\n0.1281510\n0.1926483\n\n\n0.2816718\n0.1508122\n0.2668376\n0.1222251\n0.1784533\n\n\n0.2227442\n0.1349732\n0.2718842\n0.1412808\n0.2291176\n\n\n0.2806448\n0.1505925\n0.2670148\n0.1225485\n0.1791995\n\n\n0.2468396\n0.1422647\n0.2712143\n0.1334031\n0.2062783\n\n\n0.2792725\n0.1502958\n0.2672475\n0.1229812\n0.1802030\n\n\n0.2468396\n0.1422647\n0.2712143\n0.1334031\n0.2062783\n\n\n0.3293404\n0.1589844\n0.2560978\n0.1077666\n0.1478107\n\n\n0.2468396\n0.1422647\n0.2712143\n0.1334031\n0.2062783\n\n\n0.3003169\n0.1544747\n0.2631885\n0.1164363\n0.1655835\n\n\n0.2227442\n0.1349732\n0.2718842\n0.1412808\n0.2291176\n\n\n0.2672992\n0.1475612\n0.2690681\n0.1267887\n0.1892828\n\n\n0.4031618\n0.1644594\n0.2326428\n0.0877623\n0.1119736\n\n\n0.2419861\n0.1408894\n0.2715235\n0.1349864\n0.2106146\n\n\n0.3281280\n0.1588241\n0.2564239\n0.1081200\n0.1485041\n\n\n0.2995919\n0.1543437\n0.2633449\n0.1166584\n0.1660611\n\n\n0.3376517\n0.1600193\n0.2538008\n0.1053659\n0.1431623\n\n\n0.2672992\n0.1475612\n0.2690681\n0.1267887\n0.1892828\n\n\n0.3738367\n0.1632621\n0.2426944\n0.0953537\n0.1248531\n\n\n0.3081079\n0.1558250\n0.2614404\n0.1140665\n0.1605601\n\n\n0.2705832\n0.1483376\n0.2686073\n0.1257390\n0.1867329\n\n\n0.2782900\n0.1500813\n0.2674111\n0.1232916\n0.1809260\n\n\n0.4899305\n0.1612375\n0.1995153\n0.0678634\n0.0814533\n\n\n0.2584197\n0.1453607\n0.2701586\n0.1296451\n0.1964158\n\n\n0.3003169\n0.1544747\n0.2631885\n0.1164363\n0.1655835\n\n\n0.3236894\n0.1582166\n0.2575967\n0.1094202\n0.1510771\n\n\n0.2470295\n0.1423175\n0.2712006\n0.1333412\n0.2061111\n\n\n0.2740423\n0.1491338\n0.2680899\n0.1246377\n0.1840964\n\n\n0.3186802\n0.1574921\n0.2588802\n0.1109001\n0.1540475\n\n\n0.2873285\n0.1519886\n0.2658153\n0.1204521\n0.1744155\n\n\n0.2929768\n0.1531063\n0.2647192\n0.1186961\n0.1705016\n\n\n0.3410147\n0.1604065\n0.2528416\n0.1044052\n0.1413320\n\n\n0.3924573\n0.1641652\n0.2364029\n0.0904799\n0.1164947\n\n\n0.2345774\n0.1387000\n0.2718321\n0.1374089\n0.2174815\n\n\n0.2795173\n0.1503490\n0.2672063\n0.1229040\n0.1800234\n\n\n0.2897241\n0.1524696\n0.2653594\n0.1197056\n0.1727414\n\n\n0.2470295\n0.1423175\n0.2712006\n0.1333412\n0.2061111\n\n\n0.2674993\n0.1476091\n0.2690409\n0.1267247\n0.1891261\n\n\n0.3367117\n0.1599078\n0.2540659\n0.1056356\n0.1436790\n\n\n0.3004038\n0.1544903\n0.2631697\n0.1164097\n0.1655264\n\n\n0.3005315\n0.1545133\n0.2631420\n0.1163706\n0.1654425\n\n\n0.2804387\n0.1505481\n0.2670501\n0.1226134\n0.1793497\n\n\n0.3113410\n0.1563548\n0.2606797\n0.1130921\n0.1585324\n\n\n0.2808510\n0.1506367\n0.2669795\n0.1224835\n0.1790493\n\n\n0.2595255\n0.1456429\n0.2700356\n0.1292880\n0.1955080\n\n\n0.3287125\n0.1589017\n0.2562670\n0.1079495\n0.1481693\n\n\n0.3917735\n0.1641409\n0.2366397\n0.0906556\n0.1167903\n\n\n0.3729209\n0.1632046\n0.2429948\n0.0955983\n0.1252814\n\n\n0.2782900\n0.1500813\n0.2674111\n0.1232916\n0.1809260\n\n\n0.2860805\n0.1517340\n0.2660475\n0.1208421\n0.1752959\n\n\n0.2849546\n0.1515019\n0.2662537\n0.1211945\n0.1760952\n\n\n0.2599182\n0.1457425\n0.2699910\n0.1291613\n0.1951869\n\n\n0.2797230\n0.1503936\n0.2671716\n0.1228391\n0.1798728\n\n\n0.2472195\n0.1423704\n0.2711867\n0.1332794\n0.2059441\n\n\n0.2601100\n0.1457911\n0.2699691\n0.1290995\n0.1950304\n\n\n0.2601100\n0.1457911\n0.2699691\n0.1290995\n0.1950304\n\n\n0.3565245\n0.1619619\n0.2482140\n0.1000544\n0.1332452\n\n\n0.2345774\n0.1387000\n0.2718321\n0.1374089\n0.2174815\n\n\n0.2345774\n0.1387000\n0.2718321\n0.1374089\n0.2174815\n\n\n0.2227442\n0.1349732\n0.2718842\n0.1412808\n0.2291176\n\n\n0.3391432\n0.1601932\n0.2533774\n0.1049391\n0.1423471\n\n\n0.3824866\n0.1637443\n0.2398138\n0.0930664\n0.1208889\n\n\n0.2510078\n0.1434089\n0.2708845\n0.1320468\n0.2026519\n\n\n0.2774752\n0.1499021\n0.2675450\n0.1235492\n0.1815285\n\n\n0.2750544\n0.1493625\n0.2679324\n0.1243163\n0.1833344\n\n\n0.2472195\n0.1423704\n0.2711867\n0.1332794\n0.2059441\n\n\n0.2597218\n0.1456927\n0.2700134\n0.1292247\n0.1953474\n\n\n0.4093488\n0.1645564\n0.2304272\n0.0862192\n0.1094484\n\n\n0.3124733\n0.1565362\n0.2604086\n0.1127521\n0.1578298\n\n\n0.3265380\n0.1586102\n0.2568477\n0.1085845\n0.1494196\n\n\n0.2347608\n0.1387556\n0.2718270\n0.1373489\n0.2173078\n\n\n0.2227442\n0.1349732\n0.2718842\n0.1412808\n0.2291176\n\n\n0.2386041\n0.1399036\n0.2716895\n0.1360916\n0.2137112\n\n\n0.2503593\n0.1432331\n0.2709396\n0.1322576\n0.2032103\n\n\n0.2897241\n0.1524696\n0.2653594\n0.1197056\n0.1727414\n\n\n0.2816718\n0.1508122\n0.2668376\n0.1222251\n0.1784533\n\n\n0.2584197\n0.1453607\n0.2701586\n0.1296451\n0.1964158\n\n\n0.2674993\n0.1476091\n0.2690409\n0.1267247\n0.1891261\n\n\n0.2638329\n0.1467199\n0.2695213\n0.1279008\n0.1920251\n\n\n0.2607000\n0.1459400\n0.2699009\n0.1289092\n0.1945499\n\n\n0.2227442\n0.1349732\n0.2718842\n0.1412808\n0.2291176\n\n\n0.2806448\n0.1505925\n0.2670148\n0.1225485\n0.1791995\n\n\n0.2227442\n0.1349732\n0.2718842\n0.1412808\n0.2291176\n\n\n0.2672992\n0.1475612\n0.2690681\n0.1267887\n0.1892828\n\n\n0.2806448\n0.1505925\n0.2670148\n0.1225485\n0.1791995\n\n\n0.3131371\n0.1566415\n0.2602485\n0.1125531\n0.1574198\n\n\n0.3325165\n0.1593930\n0.2552327\n0.1068448\n0.1460129\n\n\n0.2345774\n0.1387000\n0.2718321\n0.1374089\n0.2174815\n\n\n0.2670993\n0.1475133\n0.2690951\n0.1268528\n0.1894395\n\n\n0.3570378\n0.1620070\n0.2480554\n0.0999127\n0.1329871\n\n\n0.2227442\n0.1349732\n0.2718842\n0.1412808\n0.2291176\n\n\n0.2741874\n0.1491667\n0.2680675\n0.1245916\n0.1839868\n\n\n0.4017001\n0.1644288\n0.2331619\n0.0881298\n0.1125794\n\n\n0.2631629\n0.1465547\n0.2696050\n0.1281162\n0.1925613\n\n\n0.2491157\n0.1428937\n0.2710414\n0.1326621\n0.2042872\n\n\n0.2227442\n0.1349732\n0.2718842\n0.1412808\n0.2291176\n\n\n0.3455310\n0.1608983\n0.2515278\n0.1031247\n0.1389182\n\n\n0.2386041\n0.1399036\n0.2716895\n0.1360916\n0.2137112\n\n\n0.2505510\n0.1432852\n0.2709235\n0.1321953\n0.2030450\n\n\n0.2386041\n0.1399036\n0.2716895\n0.1360916\n0.2137112\n\n\n0.2890191\n0.1523291\n0.2654949\n0.1199250\n0.1732318\n\n\n0.2750544\n0.1493625\n0.2679324\n0.1243163\n0.1833344\n\n\n0.4144490\n0.1645967\n0.2285791\n0.0849621\n0.1074130\n\n\n0.2479759\n0.1425800\n0.2711302\n0.1330330\n0.2052809\n\n\n0.3084397\n0.1558802\n0.2613633\n0.1139663\n0.1603505\n\n\n0.3328296\n0.1594324\n0.2551466\n0.1067543\n0.1458372\n\n\n0.3405122\n0.1603498\n0.2529859\n0.1045484\n0.1416037\n\n\n0.3724036\n0.1631715\n0.2431641\n0.0957366\n0.1255241\n\n\n0.4901857\n0.1612142\n0.1994131\n0.0678101\n0.0813770\n\n\n0.4030214\n0.1644566\n0.2326927\n0.0877975\n0.1120317\n\n\n0.3545691\n0.1617865\n0.2488149\n0.1005957\n0.1342339\n\n\n0.2851627\n0.1515450\n0.2662158\n0.1211293\n0.1759471\n\n\n0.2345774\n0.1387000\n0.2718321\n0.1374089\n0.2174815\n\n\n0.3120348\n0.1564662\n0.2605139\n0.1128837\n0.1581015\n\n\n0.2227442\n0.1349732\n0.2718842\n0.1412808\n0.2291176\n\n\n0.3692950\n0.1629646\n0.2441754\n0.0965710\n0.1269939\n\n\n0.2875924\n0.1520421\n0.2657657\n0.1203698\n0.1742300\n\n\n0.2345774\n0.1387000\n0.2718321\n0.1374089\n0.2174815\n\n\n0.3186802\n0.1574921\n0.2588802\n0.1109001\n0.1540475\n\n\n0.2898842\n0.1525013\n0.2653284\n0.1196558\n0.1726303\n\n\n0.2896590\n0.1524566\n0.2653719\n0.1197258\n0.1727866\n\n\n0.3531182\n0.1616524\n0.2492576\n0.1009986\n0.1349731\n\n\n0.2468396\n0.1422647\n0.2712143\n0.1334031\n0.2062783\n\n\n0.2386041\n0.1399036\n0.2716895\n0.1360916\n0.2137112\n\n\n0.4211317\n0.1645959\n0.2261298\n0.0833354\n0.1048072\n\n\n0.3201548\n0.1577097\n0.2585069\n0.1104630\n0.1531656\n\n\n0.3146031\n0.1568715\n0.2598921\n0.1121143\n0.1565190\n\n\n0.2541703\n0.1442546\n0.2705962\n0.1310204\n0.1999586\n\n\n0.2227442\n0.1349732\n0.2718842\n0.1412808\n0.2291176\n\n\n0.2601100\n0.1457911\n0.2699691\n0.1290995\n0.1950304\n\n\n0.2416607\n0.1407955\n0.2715412\n0.1350927\n0.2109098\n\n\n0.3322953\n0.1593651\n0.2552935\n0.1069088\n0.1461373\n\n\n0.2470295\n0.1423175\n0.2712006\n0.1333412\n0.2061111\n\n\n0.2491157\n0.1428937\n0.2710414\n0.1326621\n0.2042872\n\n\n0.3361364\n0.1598389\n0.2542275\n0.1058009\n0.1439964\n\n\n0.2468396\n0.1422647\n0.2712143\n0.1334031\n0.2062783\n\n\n0.2730326\n0.1489036\n0.2682442\n0.1249587\n0.1848609\n\n\n0.4093488\n0.1645564\n0.2304272\n0.0862192\n0.1094484\n\n\n0.3935187\n0.1642016\n0.2360344\n0.0902077\n0.1160376\n\n\n0.2890491\n0.1523351\n0.2654892\n0.1199157\n0.1732110\n\n\n0.2610891\n0.1460379\n0.2698553\n0.1287838\n0.1942339\n\n\n0.2630545\n0.1465278\n0.2696184\n0.1281510\n0.1926483\n\n\n0.3655316\n0.1626948\n0.2453854\n0.0975883\n0.1288000\n\n\n0.2510078\n0.1434089\n0.2708845\n0.1320468\n0.2026519\n\n\n0.3328890\n0.1594399\n0.2551302\n0.1067371\n0.1458039\n\n\n0.2227442\n0.1349732\n0.2718842\n0.1412808\n0.2291176\n\n\n0.2992502\n0.1542817\n0.2634182\n0.1167631\n0.1662868\n\n\n0.4765015\n0.1623533\n0.2048677\n0.0707088\n0.0855687\n\n\n0.4011335\n0.1644161\n0.2333626\n0.0882726\n0.1128152\n\n\n0.2416607\n0.1407955\n0.2715412\n0.1350927\n0.2109098\n\n\n0.2630545\n0.1465278\n0.2696184\n0.1281510\n0.1926483\n\n\n0.2662055\n0.1472982\n0.2692148\n0.1271392\n0.1901424\n\n\n0.2670993\n0.1475133\n0.2690951\n0.1268528\n0.1894395\n\n\n0.2900945\n0.1525430\n0.2652877\n0.1195904\n0.1724845\n\n\n0.2960887\n0.1536979\n0.2640845\n0.1177349\n0.1683939\n\n\n0.2650151\n0.1470094\n0.2693706\n0.1275210\n0.1910838\n\n\n0.2946011\n0.1534172\n0.2643906\n0.1181938\n0.1693973\n\n\n0.2874480\n0.1520129\n0.2657929\n0.1204148\n0.1743315\n\n\n0.2795173\n0.1503490\n0.2672063\n0.1229040\n0.1800234\n\n\n0.3479486\n0.1611484\n0.2508128\n0.1024438\n0.1376464\n\n\n0.4019865\n0.1644350\n0.2330603\n0.0880577\n0.1124605\n\n\n0.2834708\n0.1511926\n0.2665209\n0.1216597\n0.1771560\n\n\n0.3248028\n0.1583720\n0.2573056\n0.1090930\n0.1504266\n\n\n0.2227442\n0.1349732\n0.2718842\n0.1412808\n0.2291176\n\n\n0.4008707\n0.1644100\n0.2334556\n0.0883389\n0.1129248\n\n\n0.2750156\n0.1493538\n0.2679385\n0.1243286\n0.1833635\n\n\n0.3453001\n0.1608739\n0.2515957\n0.1031899\n0.1390404\n\n\n0.2784951\n0.1501263\n0.2673772\n0.1232267\n0.1807747\n\n\n0.3899906\n0.1640744\n0.2372553\n0.0911148\n0.1175650\n\n\n0.3038897\n0.1551069\n0.2624021\n0.1153458\n0.1632554\n\n\n0.3146031\n0.1568715\n0.2598921\n0.1121143\n0.1565190\n\n\n0.2521523\n0.1437172\n0.2707839\n0.1316751\n0.2016715\n\n\n0.2844644\n0.1514002\n0.2663426\n0.1213481\n0.1764447\n\n\n0.2682956\n0.1477989\n0.2689314\n0.1264698\n0.1885042\n\n\n0.2662055\n0.1472982\n0.2692148\n0.1271392\n0.1901424\n\n\n0.2886346\n0.1522521\n0.2655684\n0.1200448\n0.1735001\n\n\n0.4070641\n0.1645268\n0.2312488\n0.0867867\n0.1103736\n\n\n0.2416607\n0.1407955\n0.2715412\n0.1350927\n0.2109098\n\n\n0.2780068\n0.1500192\n0.2674578\n0.1233811\n0.1811351\n\n\n0.2543639\n0.1443058\n0.2705775\n0.1309576\n0.1997953\n\n\n0.2386041\n0.1399036\n0.2716895\n0.1360916\n0.2137112\n\n\n0.2227442\n0.1349732\n0.2718842\n0.1412808\n0.2291176\n\n\n0.2816718\n0.1508122\n0.2668376\n0.1222251\n0.1784533\n\n\n0.2227442\n0.1349732\n0.2718842\n0.1412808\n0.2291176\n\n\n0.3480093\n0.1611545\n0.2507948\n0.1024268\n0.1376146\n\n\n0.2227442\n0.1349732\n0.2718842\n0.1412808\n0.2291176\n\n\n0.2227442\n0.1349732\n0.2718842\n0.1412808\n0.2291176\n\n\n0.2386041\n0.1399036\n0.2716895\n0.1360916\n0.2137112\n\n\n0.2416607\n0.1407955\n0.2715412\n0.1350927\n0.2109098\n\n\n0.2227442\n0.1349732\n0.2718842\n0.1412808\n0.2291176\n\n\n0.2816718\n0.1508122\n0.2668376\n0.1222251\n0.1784533\n\n\n0.3161359\n0.1571081\n0.2595152\n0.1116568\n0.1555840\n\n\n0.2227442\n0.1349732\n0.2718842\n0.1412808\n0.2291176\n\n\n0.3439164\n0.1607262\n0.2520008\n0.1035812\n0.1397754\n\n\n0.2730326\n0.1489036\n0.2682442\n0.1249587\n0.1848609\n\n\n0.3553596\n0.1618581\n0.2485725\n0.1003766\n0.1338332\n\n\n0.2941214\n0.1533259\n0.2644883\n0.1183420\n0.1697225\n\n\n0.3075433\n0.1557306\n0.2615712\n0.1142373\n0.1609176\n\n\n0.3120348\n0.1564662\n0.2605139\n0.1128837\n0.1581015\n\n\n0.3625933\n0.1624693\n0.2463188\n0.0983879\n0.1302308\n\n\n0.2726901\n0.1488252\n0.2682960\n0.1250677\n0.1851211\n\n\n0.2841429\n0.1513332\n0.2664006\n0.1214489\n0.1766745\n\n\n0.2819621\n0.1508740\n0.2667870\n0.1221338\n0.1782431\n\n\n0.2227442\n0.1349732\n0.2718842\n0.1412808\n0.2291176\n\n\n0.2356749\n0.1390313\n0.2717993\n0.1370497\n0.2164448\n\n\n0.3263295\n0.1585818\n0.2569030\n0.1086455\n0.1495401\n\n\n0.2642250\n0.1468162\n0.2694718\n0.1277748\n0.1917122\n\n\n0.2227442\n0.1349732\n0.2718842\n0.1412808\n0.2291176\n\n\n0.2752241\n0.1494007\n0.2679058\n0.1242624\n0.1832070\n\n\n0.2217482\n0.1346464\n0.2718622\n0.1416062\n0.2301369\n\n\n0.3657684\n0.1627124\n0.2453097\n0.0975240\n0.1286854\n\n\n0.2792725\n0.1502958\n0.2672475\n0.1229812\n0.1802030\n\n\n0.2584197\n0.1453607\n0.2701586\n0.1296451\n0.1964158\n\n\n0.2227442\n0.1349732\n0.2718842\n0.1412808\n0.2291176\n\n\n0.2345774\n0.1387000\n0.2718321\n0.1374089\n0.2174815\n\n\n0.3507173\n0.1614235\n0.2499843\n0.1016680\n0.1362069\n\n\n0.2503593\n0.1432331\n0.2709396\n0.1322576\n0.2032103\n\n\n0.2630545\n0.1465278\n0.2696184\n0.1281510\n0.1926483\n\n\n0.2935261\n0.1532119\n0.2646087\n0.1185261\n0.1701272\n\n\n0.2227442\n0.1349732\n0.2718842\n0.1412808\n0.2291176\n\n\n0.4879439\n0.1614160\n0.2003107\n0.0682793\n0.0820501\n\n\n0.2345774\n0.1387000\n0.2718321\n0.1374089\n0.2174815\n\n\n0.2750544\n0.1493625\n0.2679324\n0.1243163\n0.1833344\n\n\n0.2347608\n0.1387556\n0.2718270\n0.1373489\n0.2173078\n\n\n0.2468396\n0.1422647\n0.2712143\n0.1334031\n0.2062783\n\n\n0.3788182\n0.1635532\n0.2410447\n0.0940315\n0.1225524\n\n\n0.3655316\n0.1626948\n0.2453854\n0.0975883\n0.1288000\n\n\n0.2227442\n0.1349732\n0.2718842\n0.1412808\n0.2291176\n\n\n0.2618779\n0.1462354\n0.2697616\n0.1285297\n0.1935954\n\n\n0.2345774\n0.1387000\n0.2718321\n0.1374089\n0.2174815\n\n\n0.2227442\n0.1349732\n0.2718842\n0.1412808\n0.2291176\n\n\n0.2472195\n0.1423704\n0.2711867\n0.1332794\n0.2059441\n\n\n0.2386041\n0.1399036\n0.2716895\n0.1360916\n0.2137112\n\n\n0.3369072\n0.1599311\n0.2540109\n0.1055795\n0.1435714\n\n\n0.2227442\n0.1349732\n0.2718842\n0.1412808\n0.2291176\n\n\n0.3412825\n0.1604366\n0.2527645\n0.1043290\n0.1411875\n\n\n0.4222581\n0.1645898\n0.2257139\n0.0830635\n0.1043746\n\n\n0.3640893\n0.1625857\n0.2458448\n0.0979802\n0.1295000\n\n\n0.2822723\n0.1509398\n0.2667328\n0.1220362\n0.1780188\n\n\n0.2227442\n0.1349732\n0.2718842\n0.1412808\n0.2291176\n\n\n0.2670993\n0.1475133\n0.2690951\n0.1268528\n0.1894395\n\n\n0.3017442\n0.1547299\n0.2628775\n0.1159999\n0.1646485\n\n\n0.3422506\n0.1605443\n0.2524849\n0.1040537\n0.1406665\n\n\n0.2227442\n0.1349732\n0.2718842\n0.1412808\n0.2291176\n\n\n0.2227442\n0.1349732\n0.2718842\n0.1412808\n0.2291176\n\n\n0.3042910\n0.1551765\n0.2623122\n0.1152237\n0.1629965\n\n\n0.4795712\n0.1621172\n0.2036494\n0.0700512\n0.0846110\n\n\n0.2650151\n0.1470094\n0.2693706\n0.1275210\n0.1910838\n\n\n0.3155738\n0.1570218\n0.2596539\n0.1118244\n0.1559261\n\n\n0.2227442\n0.1349732\n0.2718842\n0.1412808\n0.2291176\n\n\n0.3377007\n0.1600250\n0.2537869\n0.1053519\n0.1431355\n\n\n0.3030315\n0.1549570\n0.2625934\n0.1156072\n0.1638108\n\n\n0.2851627\n0.1515450\n0.2662158\n0.1211293\n0.1759471\n\n\n0.2356749\n0.1390313\n0.2717993\n0.1370497\n0.2164448\n\n\n0.3380052\n0.1600608\n0.2537007\n0.1052647\n0.1429686\n\n\n0.3544133\n0.1617722\n0.2488626\n0.1006389\n0.1343130\n\n\n0.2640265\n0.1467675\n0.2694969\n0.1278385\n0.1918705\n\n\n0.2597218\n0.1456927\n0.2700134\n0.1292247\n0.1953474\n\n\n0.3579034\n0.1620822\n0.2477873\n0.0996740\n0.1325532\n\n\n0.2468396\n0.1422647\n0.2712143\n0.1334031\n0.2062783\n\n\n0.2227442\n0.1349732\n0.2718842\n0.1412808\n0.2291176\n\n\n0.2946011\n0.1534172\n0.2643906\n0.1181938\n0.1693973\n\n\n0.2386041\n0.1399036\n0.2716895\n0.1360916\n0.2137112\n\n\n0.2386041\n0.1399036\n0.2716895\n0.1360916\n0.2137112\n\n\n0.2356749\n0.1390313\n0.2717993\n0.1370497\n0.2164448\n\n\n0.2468396\n0.1422647\n0.2712143\n0.1334031\n0.2062783\n\n\n0.2841429\n0.1513332\n0.2664006\n0.1214489\n0.1766745\n\n\n0.2227442\n0.1349732\n0.2718842\n0.1412808\n0.2291176\n\n\n0.3003169\n0.1544747\n0.2631885\n0.1164363\n0.1655835\n\n\n0.3801350\n0.1636241\n0.2406044\n0.0936842\n0.1219523\n\n\n0.3917735\n0.1641409\n0.2366397\n0.0906556\n0.1167903\n\n\n0.2968037\n0.1538315\n0.2639357\n0.1175147\n0.1679144\n\n\n0.3096702\n0.1560832\n0.2610753\n0.1135950\n0.1595763\n\n\n0.2967073\n0.1538135\n0.2639558\n0.1175444\n0.1679790\n\n\n0.2416607\n0.1407955\n0.2715412\n0.1350927\n0.2109098\n\n\n0.4334407\n0.1644379\n0.2215420\n0.0803988\n0.1001806\n\n\n0.3229340\n0.1581100\n0.2577930\n0.1096425\n0.1515204\n\n\n0.3487599\n0.1612302\n0.2505711\n0.1022160\n0.1372227\n\n\n0.2227442\n0.1349732\n0.2718842\n0.1412808\n0.2291176\n\n\n0.2618779\n0.1462354\n0.2697616\n0.1285297\n0.1935954\n\n\n0.4070641\n0.1645268\n0.2312488\n0.0867867\n0.1103736\n\n\n0.3405122\n0.1603498\n0.2529859\n0.1045484\n0.1416037\n\n\n0.2853709\n0.1515880\n0.2661778\n0.1210641\n0.1757991\n\n\n0.3159205\n0.1570750\n0.2595684\n0.1117210\n0.1557150\n\n\n0.3189864\n0.1575376\n0.2588030\n0.1108092\n0.1538638\n\n\n0.2921767\n0.1529514\n0.2648789\n0.1189439\n0.1710491\n\n\n0.2862891\n0.1517768\n0.2660089\n0.1207769\n0.1751484\n\n\n0.2227442\n0.1349732\n0.2718842\n0.1412808\n0.2291176\n\n\n0.2764722\n0.1496799\n0.2677074\n0.1238667\n0.1822738\n\n\n0.3322953\n0.1593651\n0.2552935\n0.1069088\n0.1461373\n\n\n0.2867413\n0.1518692\n0.2659250\n0.1206355\n0.1748290\n\n\n0.2861997\n0.1517585\n0.2660255\n0.1208048\n0.1752116\n\n\n0.3148233\n0.1569057\n0.2598382\n0.1120485\n0.1563842\n\n\n0.3720286\n0.1631473\n0.2432867\n0.0958370\n0.1257003\n\n\n0.3038897\n0.1551069\n0.2624021\n0.1153458\n0.1632554\n\n\n0.3465654\n0.1610064\n0.2512229\n0.1028330\n0.1383724\n\n\n0.3310558\n0.1592071\n0.2556326\n0.1072681\n0.1468364\n\n\n0.2386041\n0.1399036\n0.2716895\n0.1360916\n0.2137112\n\n\n0.2595255\n0.1456429\n0.2700356\n0.1292880\n0.1955080\n\n\n0.3391432\n0.1601932\n0.2533774\n0.1049391\n0.1423471\n\n\n0.2946011\n0.1534172\n0.2643906\n0.1181938\n0.1693973\n\n\n0.2356749\n0.1390313\n0.2717993\n0.1370497\n0.2164448\n\n\n0.4753857\n0.1624363\n0.2053097\n0.0709489\n0.0859194\n\n\n0.3608252\n0.1623273\n0.2468755\n0.0988713\n0.1311007\n\n\n0.2888393\n0.1522931\n0.2655293\n0.1199810\n0.1733572\n\n\n0.2552179\n0.1445305\n0.2704936\n0.1306809\n0.1990772\n\n\n0.2468396\n0.1422647\n0.2712143\n0.1334031\n0.2062783\n\n\n0.2903048\n0.1525846\n0.2652469\n0.1195250\n0.1723388\n\n\n0.2416607\n0.1407955\n0.2715412\n0.1350927\n0.2109098\n\n\n0.2472195\n0.1423704\n0.2711867\n0.1332794\n0.2059441\n\n\n0.2772705\n0.1498569\n0.2675783\n0.1236140\n0.1816803\n\n\n0.2968037\n0.1538315\n0.2639357\n0.1175147\n0.1679144\n\n\n0.2386041\n0.1399036\n0.2716895\n0.1360916\n0.2137112\n\n\n0.2227442\n0.1349732\n0.2718842\n0.1412808\n0.2291176\n\n\n0.2750544\n0.1493625\n0.2679324\n0.1243163\n0.1833344\n\n\n0.2227442\n0.1349732\n0.2718842\n0.1412808\n0.2291176\n\n\n0.3367931\n0.1599175\n0.2540430\n0.1056122\n0.1436342\n\n\n0.2886346\n0.1522521\n0.2655684\n0.1200448\n0.1735001\n\n\n0.3317561\n0.1592967\n0.2554413\n0.1070650\n0.1464409\n\n\n0.3856844\n0.1638949\n0.2387300\n0.0922310\n0.1194597\n\n\n0.2599182\n0.1457425\n0.2699910\n0.1291613\n0.1951869\n\n\n0.2511953\n0.1434596\n0.2708683\n0.1319859\n0.2024909\n\n\n0.2672992\n0.1475612\n0.2690681\n0.1267887\n0.1892828\n\n\n0.2877967\n0.1520834\n0.2657273\n0.1203060\n0.1740866\n\n\n0.2227442\n0.1349732\n0.2718842\n0.1412808\n0.2291176\n\n\n0.2840242\n0.1513084\n0.2664219\n0.1214861\n0.1767594\n\n\n0.3135085\n0.1567001\n0.2601586\n0.1124418\n0.1571910\n\n\n0.2642250\n0.1468162\n0.2694718\n0.1277748\n0.1917122\n\n\n0.2730326\n0.1489036\n0.2682442\n0.1249587\n0.1848609\n\n\n0.3856844\n0.1638949\n0.2387300\n0.0922310\n0.1194597\n\n\n0.2491157\n0.1428937\n0.2710414\n0.1326621\n0.2042872\n\n\n0.2510078\n0.1434089\n0.2708845\n0.1320468\n0.2026519\n\n\n0.2227442\n0.1349732\n0.2718842\n0.1412808\n0.2291176\n\n\n0.2874480\n0.1520129\n0.2657929\n0.1204148\n0.1743315\n\n\n0.2885298\n0.1522311\n0.2655883\n0.1200774\n0.1735734\n\n\n0.2759133\n0.1495552\n0.2677967\n0.1240439\n0.1826909\n\n\n0.3039411\n0.1551158\n0.2623906\n0.1153302\n0.1632222\n\n\n0.2510078\n0.1434089\n0.2708845\n0.1320468\n0.2026519\n\n\n0.2650151\n0.1470094\n0.2693706\n0.1275210\n0.1910838\n\n\n0.2642250\n0.1468162\n0.2694718\n0.1277748\n0.1917122\n\n\n0.2468396\n0.1422647\n0.2712143\n0.1334031\n0.2062783\n\n\n0.2468396\n0.1422647\n0.2712143\n0.1334031\n0.2062783\n\n\n0.2416607\n0.1407955\n0.2715412\n0.1350927\n0.2109098\n\n\n0.2345774\n0.1387000\n0.2718321\n0.1374089\n0.2174815\n\n\n0.2650151\n0.1470094\n0.2693706\n0.1275210\n0.1910838\n\n\n0.2543639\n0.1443058\n0.2705775\n0.1309576\n0.1997953\n\n\n0.3980595\n0.1643393\n0.2344471\n0.0890501\n0.1141040\n\n\n0.3420590\n0.1605231\n0.2525403\n0.1041081\n0.1407694\n\n\n0.3334237\n0.1595068\n0.2549827\n0.1065825\n0.1455043\n\n\n0.3992368\n0.1643703\n0.2340327\n0.0887517\n0.1136086\n\n\n0.3805189\n0.1636443\n0.2404757\n0.0935831\n0.1217780\n\n\n0.2795173\n0.1503490\n0.2672063\n0.1229040\n0.1800234\n\n\n0.2227442\n0.1349732\n0.2718842\n0.1412808\n0.2291176\n\n\n0.2630545\n0.1465278\n0.2696184\n0.1281510\n0.1926483\n\n\n0.4191178\n0.1646025\n0.2268711\n0.0838232\n0.1055853\n\n\n0.2468396\n0.1422647\n0.2712143\n0.1334031\n0.2062783\n\n\n0.2227442\n0.1349732\n0.2718842\n0.1412808\n0.2291176\n\n\n0.2599182\n0.1457425\n0.2699910\n0.1291613\n0.1951869\n\n\n0.2491157\n0.1428937\n0.2710414\n0.1326621\n0.2042872\n\n\n0.2977382\n0.1540047\n0.2637395\n0.1172273\n0.1672903\n\n\n0.2595255\n0.1456429\n0.2700356\n0.1292880\n0.1955080\n\n\n0.2227442\n0.1349732\n0.2718842\n0.1412808\n0.2291176\n\n\n0.3419277\n0.1605085\n0.2525783\n0.1041454\n0.1408400\n\n\n0.2597218\n0.1456927\n0.2700134\n0.1292247\n0.1953474\n\n\n0.2705352\n0.1483264\n0.2686142\n0.1257544\n0.1867698\n\n\n0.2347608\n0.1387556\n0.2718270\n0.1373489\n0.2173078\n\n\n0.2386041\n0.1399036\n0.2716895\n0.1360916\n0.2137112\n\n\n0.2227442\n0.1349732\n0.2718842\n0.1412808\n0.2291176\n\n\n0.3586636\n0.1621472\n0.2475511\n0.0994647\n0.1321734\n\n\n0.2345774\n0.1387000\n0.2718321\n0.1374089\n0.2174815\n\n\n0.2386041\n0.1399036\n0.2716895\n0.1360916\n0.2137112\n\n\n0.2672992\n0.1475612\n0.2690681\n0.1267887\n0.1892828\n\n\n0.2510078\n0.1434089\n0.2708845\n0.1320468\n0.2026519\n\n\n0.4047658\n0.1644897\n0.2320713\n0.0873603\n0.1113129\n\n\n0.3584399\n0.1621281\n0.2476207\n0.0995262\n0.1322851\n\n\n0.2584197\n0.1453607\n0.2701586\n0.1296451\n0.1964158\n\n\n0.3603375\n0.1622873\n0.2470285\n0.0990050\n0.1313418\n\n\n0.2990922\n0.1542529\n0.2634520\n0.1168116\n0.1663913\n\n\n0.3986422\n0.1643549\n0.2342421\n0.0889023\n0.1138585\n\n\n0.3379889\n0.1600589\n0.2537053\n0.1052693\n0.1429775\n\n\n0.3357296\n0.1597898\n0.2543415\n0.1059178\n0.1442213\n\n\n0.3109971\n0.1562993\n0.2607616\n0.1131955\n0.1587465\n\n\n0.3287125\n0.1589017\n0.2562670\n0.1079495\n0.1481693\n\n\n0.2345774\n0.1387000\n0.2718321\n0.1374089\n0.2174815\n\n\n0.2479759\n0.1425800\n0.2711302\n0.1330330\n0.2052809\n\n\n0.2386041\n0.1399036\n0.2716895\n0.1360916\n0.2137112\n\n\n0.2782900\n0.1500813\n0.2674111\n0.1232916\n0.1809260\n\n\n0.2730326\n0.1489036\n0.2682442\n0.1249587\n0.1848609\n\n\n0.3133463\n0.1566745\n0.2601979\n0.1124904\n0.1572909\n\n\n0.2511953\n0.1434596\n0.2708683\n0.1319859\n0.2024909\n\n\n0.3450638\n0.1608489\n0.2516650\n0.1032566\n0.1391656\n\n\n0.3287125\n0.1589017\n0.2562670\n0.1079495\n0.1481693\n\n\n0.3334237\n0.1595068\n0.2549827\n0.1065825\n0.1455043\n\n\n0.3481748\n0.1611713\n0.2507455\n0.1023803\n0.1375281\n\n\n0.3050172\n0.1553018\n0.2621485\n0.1150030\n0.1625294\n\n\n0.3277047\n0.1587675\n0.2565371\n0.1082435\n0.1487472\n\n\n0.2584197\n0.1453607\n0.2701586\n0.1296451\n0.1964158\n\n\n0.4194079\n0.1646019\n0.2267645\n0.0837529\n0.1054729\n\n\n0.2990362\n0.1542427\n0.2634640\n0.1168288\n0.1664284\n\n\n0.3163673\n0.1571434\n0.2594579\n0.1115879\n0.1554435\n\n\n0.2227442\n0.1349732\n0.2718842\n0.1412808\n0.2291176\n\n\n0.2929768\n0.1531063\n0.2647192\n0.1186961\n0.1705016\n\n\n0.4650837\n0.1631315\n0.2093688\n0.0731925\n0.0892235\n\n\n0.2595255\n0.1456429\n0.2700356\n0.1292880\n0.1955080\n\n\n0.2227442\n0.1349732\n0.2718842\n0.1412808\n0.2291176\n\n\n0.2511953\n0.1434596\n0.2708683\n0.1319859\n0.2024909\n\n\n0.2853709\n0.1515880\n0.2661778\n0.1210641\n0.1757991\n\n\n0.2754569\n0.1494530\n0.2678691\n0.1241886\n0.1830324\n\n\n0.2510078\n0.1434089\n0.2708845\n0.1320468\n0.2026519\n\n\n0.2468396\n0.1422647\n0.2712143\n0.1334031\n0.2062783\n\n\n0.2356749\n0.1390313\n0.2717993\n0.1370497\n0.2164448\n\n\n0.3487268\n0.1612269\n0.2505810\n0.1022253\n0.1372400\n\n\n0.2784951\n0.1501263\n0.2673772\n0.1232267\n0.1807747\n\n\n0.3699124\n0.1630069\n0.2439754\n0.0964049\n0.1267004\n\n\n0.3917966\n0.1641417\n0.2366317\n0.0906497\n0.1167803\n\n\n0.2227442\n0.1349732\n0.2718842\n0.1412808\n0.2291176\n\n\n0.2827898\n0.1510493\n0.2666417\n0.1218736\n0.1776456\n\n\n0.2552179\n0.1445305\n0.2704936\n0.1306809\n0.1990772\n\n\n0.2227442\n0.1349732\n0.2718842\n0.1412808\n0.2291176\n\n\n0.2386041\n0.1399036\n0.2716895\n0.1360916\n0.2137112\n\n\n0.2227442\n0.1349732\n0.2718842\n0.1412808\n0.2291176\n\n\n0.2472195\n0.1423704\n0.2711867\n0.1332794\n0.2059441\n\n\n0.2227442\n0.1349732\n0.2718842\n0.1412808\n0.2291176\n\n\n0.2227442\n0.1349732\n0.2718842\n0.1412808\n0.2291176\n\n\n0.2227442\n0.1349732\n0.2718842\n0.1412808\n0.2291176\n\n\n0.2227442\n0.1349732\n0.2718842\n0.1412808\n0.2291176\n\n\n0.2553288\n0.1445596\n0.2704825\n0.1306449\n0.1989842\n\n\n0.2345774\n0.1387000\n0.2718321\n0.1374089\n0.2174815\n\n\n0.2670993\n0.1475133\n0.2690951\n0.1268528\n0.1894395\n\n\n0.2386041\n0.1399036\n0.2716895\n0.1360916\n0.2137112\n\n\n0.2992502\n0.1542817\n0.2634182\n0.1167631\n0.1662868\n\n\n0.2345774\n0.1387000\n0.2718321\n0.1374089\n0.2174815\n\n\n0.2227442\n0.1349732\n0.2718842\n0.1412808\n0.2291176\n\n\n0.2227442\n0.1349732\n0.2718842\n0.1412808\n0.2291176\n\n\n0.3576910\n0.1620638\n0.2478532\n0.0997325\n0.1326595\n\n\n0.2921767\n0.1529514\n0.2648789\n0.1189439\n0.1710491\n\n\n0.2356749\n0.1390313\n0.2717993\n0.1370497\n0.2164448\n\n\n0.3038897\n0.1551069\n0.2624021\n0.1153458\n0.1632554\n\n\n0.3201548\n0.1577097\n0.2585069\n0.1104630\n0.1531656\n\n\n0.2227442\n0.1349732\n0.2718842\n0.1412808\n0.2291176\n\n\n0.2521523\n0.1437172\n0.2707839\n0.1316751\n0.2016715\n\n\n0.2932287\n0.1531548\n0.2646686\n0.1186181\n0.1703298\n\n\n0.2468396\n0.1422647\n0.2712143\n0.1334031\n0.2062783\n\n\n0.4024366\n0.1644446\n0.2329006\n0.0879445\n0.1122738\n\n\n0.2854998\n0.1516146\n0.2661542\n0.1210238\n0.1757076\n\n\n0.2650151\n0.1470094\n0.2693706\n0.1275210\n0.1910838\n\n\n0.3127659\n0.1565827\n0.2603381\n0.1126643\n0.1576489\n\n\n0.2552179\n0.1445305\n0.2704936\n0.1306809\n0.1990772\n\n\n0.2468396\n0.1422647\n0.2712143\n0.1334031\n0.2062783\n\n\n0.2601100\n0.1457911\n0.2699691\n0.1290995\n0.1950304\n\n\n0.3030315\n0.1549570\n0.2625934\n0.1156072\n0.1638108\n\n\n0.2670993\n0.1475133\n0.2690951\n0.1268528\n0.1894395\n\n\n0.2468396\n0.1422647\n0.2712143\n0.1334031\n0.2062783\n\n\n0.3466700\n0.1610173\n0.2511920\n0.1028035\n0.1383173\n\n\n0.2227442\n0.1349732\n0.2718842\n0.1412808\n0.2291176\n\n\n0.2541703\n0.1442546\n0.2705962\n0.1310204\n0.1999586\n\n\n0.3436585\n0.1606983\n0.2520760\n0.1036542\n0.1399129\n\n\n0.2479759\n0.1425800\n0.2711302\n0.1330330\n0.2052809\n\n\n0.2874480\n0.1520129\n0.2657929\n0.1204148\n0.1743315\n\n\n0.3150489\n0.1569407\n0.2597829\n0.1119811\n0.1562464\n\n\n0.3059457\n0.1554607\n0.2619378\n0.1147212\n0.1619346\n\n\n0.2384407\n0.1398554\n0.2716964\n0.1361450\n0.2138624\n\n\n0.2359553\n0.1391155\n0.2717902\n0.1369580\n0.2161810\n\n\n0.3548251\n0.1618098\n0.2487365\n0.1005247\n0.1341039\n\n\n0.3450638\n0.1608489\n0.2516650\n0.1032566\n0.1391656\n\n\n0.3804158\n0.1636389\n0.2405103\n0.0936103\n0.1218248\n\n\n0.2670993\n0.1475133\n0.2690951\n0.1268528\n0.1894395\n\n\n0.4879439\n0.1614160\n0.2003107\n0.0682793\n0.0820501\n\n\n0.2861997\n0.1517585\n0.2660255\n0.1208048\n0.1752116\n\n\n0.2386041\n0.1399036\n0.2716895\n0.1360916\n0.2137112\n\n\n0.2227442\n0.1349732\n0.2718842\n0.1412808\n0.2291176\n\n\n0.2227442\n0.1349732\n0.2718842\n0.1412808\n0.2291176\n\n\n0.3498817\n0.1613417\n0.2502354\n0.1019017\n0.1366394\n\n\n0.2960887\n0.1536979\n0.2640845\n0.1177349\n0.1683939\n\n\n0.2831104\n0.1511169\n0.2665850\n0.1217729\n0.1774148\n\n\n0.2345774\n0.1387000\n0.2718321\n0.1374089\n0.2174815\n\n\n0.2227442\n0.1349732\n0.2718842\n0.1412808\n0.2291176\n\n\n0.2227442\n0.1349732\n0.2718842\n0.1412808\n0.2291176\n\n\n0.2227442\n0.1349732\n0.2718842\n0.1412808\n0.2291176\n\n\n0.2740423\n0.1491338\n0.2680899\n0.1246377\n0.1840964\n\n\n0.2227442\n0.1349732\n0.2718842\n0.1412808\n0.2291176\n\n\n0.2227442\n0.1349732\n0.2718842\n0.1412808\n0.2291176\n\n\n0.3049296\n0.1552868\n0.2621683\n0.1150296\n0.1625857\n\n\n0.2468396\n0.1422647\n0.2712143\n0.1334031\n0.2062783\n\n\n0.2470295\n0.1423175\n0.2712006\n0.1333412\n0.2061111\n\n\n0.2674993\n0.1476091\n0.2690409\n0.1267247\n0.1891261\n\n\n0.2916742\n0.1528535\n0.2649785\n0.1190998\n0.1713941\n\n\n0.2227442\n0.1349732\n0.2718842\n0.1412808\n0.2291176\n\n\n0.3416105\n0.1604732\n0.2526699\n0.1042356\n0.1410107\n\n\n0.2227442\n0.1349732\n0.2718842\n0.1412808\n0.2291176\n\n\n0.2491157\n0.1428937\n0.2710414\n0.1326621\n0.2042872\n\n\n0.2635544\n0.1466513\n0.2695563\n0.1279903\n0.1922478\n\n\n0.2861997\n0.1517585\n0.2660255\n0.1208048\n0.1752116\n\n\n0.2895190\n0.1524288\n0.2653989\n0.1197694\n0.1728839\n\n\n0.4274564\n0.1645398\n0.2237842\n0.0818169\n0.1024026\n\n\n0.2227442\n0.1349732\n0.2718842\n0.1412808\n0.2291176\n\n\n0.2865176\n0.1518235\n0.2659666\n0.1207054\n0.1749869\n\n\n0.3216702\n0.1579296\n0.2581193\n0.1100151\n0.1522658\n\n\n0.2774752\n0.1499021\n0.2675450\n0.1235492\n0.1815285\n\n\n0.2227442\n0.1349732\n0.2718842\n0.1412808\n0.2291176\n\n\n0.2826271\n0.1510149\n0.2666704\n0.1219247\n0.1777628\n\n\n0.2774752\n0.1499021\n0.2675450\n0.1235492\n0.1815285\n\n\n0.2584197\n0.1453607\n0.2701586\n0.1296451\n0.1964158\n\n\n0.2742407\n0.1491787\n0.2680592\n0.1245746\n0.1839467\n\n\n0.3820388\n0.1637220\n0.2399648\n0.0931838\n0.1210906\n\n\n0.4329154\n0.1644487\n0.2217397\n0.0805225\n0.1003736\n\n\n0.2674993\n0.1476091\n0.2690409\n0.1267247\n0.1891261\n\n\n0.3495113\n0.1613051\n0.2503465\n0.1020054\n0.1368317\n\n\n0.3814707\n0.1636934\n0.2401560\n0.0933329\n0.1213470\n\n\n0.2416607\n0.1407955\n0.2715412\n0.1350927\n0.2109098\n\n\n0.4254405\n0.1645635\n0.2245346\n0.0822987\n0.1031627\n\n\n0.3629418\n0.1624967\n0.2462086\n0.0982928\n0.1300601\n\n\n0.3030315\n0.1549570\n0.2625934\n0.1156072\n0.1638108\n\n\n0.4227624\n0.1645866\n0.2255275\n0.0829420\n0.1041816\n\n\n0.2227442\n0.1349732\n0.2718842\n0.1412808\n0.2291176\n\n\n0.4413200\n0.1642322\n0.2185581\n0.0785588\n0.0973309\n\n\n0.2227442\n0.1349732\n0.2718842\n0.1412808\n0.2291176\n\n\n0.3938030\n0.1642111\n0.2359355\n0.0901349\n0.1159154\n\n\n0.2543639\n0.1443058\n0.2705775\n0.1309576\n0.1997953\n\n\n0.2908962\n0.1527012\n0.2651315\n0.1193412\n0.1719299\n\n\n0.3347759\n0.1596738\n0.2546076\n0.1061924\n0.1447503\n\n\n0.3373908\n0.1599885\n0.2538745\n0.1054407\n0.1433055\n\n\n0.2468396\n0.1422647\n0.2712143\n0.1334031\n0.2062783\n\n\n0.2886346\n0.1522521\n0.2655684\n0.1200448\n0.1735001\n\n\n0.3005315\n0.1545133\n0.2631420\n0.1163706\n0.1654425\n\n\n0.2470295\n0.1423175\n0.2712006\n0.1333412\n0.2061111\n\n\n0.3474248\n0.1610950\n0.2509684\n0.1025911\n0.1379208\n\n\n0.3965982\n0.1642982\n0.2349598\n0.0894214\n0.1147224\n\n\n0.3138592\n0.1567552\n0.2600734\n0.1123368\n0.1569753\n\n\n0.2730326\n0.1489036\n0.2682442\n0.1249587\n0.1848609\n\n\n0.2541703\n0.1442546\n0.2705962\n0.1310204\n0.1999586\n\n\n0.3712167\n0.1630942\n0.2435515\n0.0960546\n0.1260829\n\n\n0.2607000\n0.1459400\n0.2699009\n0.1289092\n0.1945499\n\n\n0.3864970\n0.1639308\n0.2384530\n0.0920196\n0.1190995\n\n\n0.2597218\n0.1456927\n0.2700134\n0.1292247\n0.1953474\n\n\n0.4144963\n0.1645969\n0.2285619\n0.0849505\n0.1073943\n\n\n0.3070258\n0.1556437\n0.2616905\n0.1143939\n0.1612462\n\n\n0.3336453\n0.1595343\n0.2549214\n0.1065185\n0.1453804\n\n\n0.2851627\n0.1515450\n0.2662158\n0.1211293\n0.1759471\n\n\n0.3256511\n0.1584891\n0.2570824\n0.1088442\n0.1499332\n\n\n0.2468396\n0.1422647\n0.2712143\n0.1334031\n0.2062783\n\n\n0.2227442\n0.1349732\n0.2718842\n0.1412808\n0.2291176\n\n\n0.4231006\n0.1645842\n0.2254024\n0.0828605\n0.1040523\n\n\n0.2782900\n0.1500813\n0.2674111\n0.1232916\n0.1809260\n\n\n0.2416607\n0.1407955\n0.2715412\n0.1350927\n0.2109098\n\n\n0.2510078\n0.1434089\n0.2708845\n0.1320468\n0.2026519\n\n\n0.2227442\n0.1349732\n0.2718842\n0.1412808\n0.2291176\n\n\n0.4070641\n0.1645268\n0.2312488\n0.0867867\n0.1103736\n\n\n0.2650151\n0.1470094\n0.2693706\n0.1275210\n0.1910838\n\n\n0.2822723\n0.1509398\n0.2667328\n0.1220362\n0.1780188\n\n\n0.2227442\n0.1349732\n0.2718842\n0.1412808\n0.2291176\n\n\n0.3402829\n0.1603238\n0.2530517\n0.1046137\n0.1417279\n\n\n0.3120348\n0.1564662\n0.2605139\n0.1128837\n0.1581015\n\n\n0.2227442\n0.1349732\n0.2718842\n0.1412808\n0.2291176\n\n\n0.2468396\n0.1422647\n0.2712143\n0.1334031\n0.2062783\n\n\n0.2227442\n0.1349732\n0.2718842\n0.1412808\n0.2291176\n\n\n0.2806448\n0.1505925\n0.2670148\n0.1225485\n0.1791995\n\n\n0.3479486\n0.1611484\n0.2508128\n0.1024438\n0.1376464\n\n\n0.2227442\n0.1349732\n0.2718842\n0.1412808\n0.2291176\n\n\n0.3903434\n0.1640879\n0.2371337\n0.0910238\n0.1174112\n\n\n0.3615544\n0.1623864\n0.2466464\n0.0986717\n0.1307411\n\n\n0.2946011\n0.1534172\n0.2643906\n0.1181938\n0.1693973\n\n\n0.2386041\n0.1399036\n0.2716895\n0.1360916\n0.2137112\n\n\n0.2816718\n0.1508122\n0.2668376\n0.1222251\n0.1784533\n\n\n0.2776800\n0.1499473\n0.2675115\n0.1234844\n0.1813768\n\n\n0.3347759\n0.1596738\n0.2546076\n0.1061924\n0.1447503\n\n\n0.2652141\n0.1470578\n0.2693449\n0.1274572\n0.1909261\n\n\n0.3423819\n0.1605588\n0.2524469\n0.1040164\n0.1405960\n\n\n0.2714814\n0.1485465\n0.2684760\n0.1254526\n0.1860434\n\n\n0.3156998\n0.1570412\n0.2596228\n0.1117868\n0.1558493\n\n\n0.2682956\n0.1477989\n0.2689314\n0.1264698\n0.1885042\n\n\n0.2227442\n0.1349732\n0.2718842\n0.1412808\n0.2291176\n\n\n0.2227442\n0.1349732\n0.2718842\n0.1412808\n0.2291176\n\n\n0.2662055\n0.1472982\n0.2692148\n0.1271392\n0.1901424\n\n\n0.2227442\n0.1349732\n0.2718842\n0.1412808\n0.2291176\n\n\n0.2640265\n0.1467675\n0.2694969\n0.1278385\n0.1918705\n\n\n0.2584197\n0.1453607\n0.2701586\n0.1296451\n0.1964158\n\n\n0.4005145\n0.1644017\n0.2335816\n0.0884287\n0.1130735\n\n\n0.3292492\n0.1589724\n0.2561225\n0.1077932\n0.1478627\n\n\n0.2515064\n0.1435435\n0.2708412\n0.1318848\n0.2022240\n\n\n0.2730326\n0.1489036\n0.2682442\n0.1249587\n0.1848609\n\n\n0.3736887\n0.1632529\n0.2427430\n0.0953932\n0.1249222\n\n\n0.2472195\n0.1423704\n0.2711867\n0.1332794\n0.2059441\n\n\n0.2599182\n0.1457425\n0.2699910\n0.1291613\n0.1951869\n\n\n0.4124503\n0.1645852\n0.2293056\n0.0854531\n0.1082057\n\n\n0.2386041\n0.1399036\n0.2716895\n0.1360916\n0.2137112\n\n\n0.2812686\n0.1507262\n0.2669075\n0.1223520\n0.1787458\n\n\n0.2759133\n0.1495552\n0.2677967\n0.1240439\n0.1826909\n\n\n0.2511953\n0.1434596\n0.2708683\n0.1319859\n0.2024909\n\n\n0.2481664\n0.1426326\n0.2711157\n0.1329710\n0.2051144\n\n\n0.2227442\n0.1349732\n0.2718842\n0.1412808\n0.2291176\n\n\n0.2416607\n0.1407955\n0.2715412\n0.1350927\n0.2109098\n\n\n0.2470295\n0.1423175\n0.2712006\n0.1333412\n0.2061111\n\n\n0.3143987\n0.1568396\n0.2599420\n0.1121754\n0.1566442\n\n\n0.3523300\n0.1615783\n0.2494970\n0.1012180\n0.1353767\n\n\n0.2851627\n0.1515450\n0.2662158\n0.1211293\n0.1759471\n\n\n0.3688760\n0.1629356\n0.2443109\n0.0966839\n0.1271935\n\n\n0.2805712\n0.1505766\n0.2670274\n0.1225717\n0.1792531\n\n\n0.2468396\n0.1422647\n0.2712143\n0.1334031\n0.2062783\n\n\n0.2995919\n0.1543437\n0.2633449\n0.1166584\n0.1660611\n\n\n0.2345774\n0.1387000\n0.2718321\n0.1374089\n0.2174815\n\n\n0.3655316\n0.1626948\n0.2453854\n0.0975883\n0.1288000\n\n\n0.3173567\n0.1572937\n0.2592120\n0.1112933\n0.1548444\n\n\n0.3452561\n0.1608693\n0.2516086\n0.1032023\n0.1390637\n\n\n0.3469123\n0.1610423\n0.2511203\n0.1027353\n0.1381898\n\n\n0.3495113\n0.1613051\n0.2503465\n0.1020054\n0.1368317\n\n\n0.2939901\n0.1533008\n0.2645149\n0.1183826\n0.1698116\n\n\n0.2227442\n0.1349732\n0.2718842\n0.1412808\n0.2291176\n\n\n0.2227442\n0.1349732\n0.2718842\n0.1412808\n0.2291176\n\n\n0.3594525\n0.1622137\n0.2473052\n0.0992478\n0.1317807\n\n\n0.2227442\n0.1349732\n0.2718842\n0.1412808\n0.2291176\n\n\n0.2795173\n0.1503490\n0.2672063\n0.1229040\n0.1800234\n\n\n0.2854998\n0.1516146\n0.2661542\n0.1210238\n0.1757076\n\n\n0.2851627\n0.1515450\n0.2662158\n0.1211293\n0.1759471\n\n\n0.2822723\n0.1509398\n0.2667328\n0.1220362\n0.1780188\n\n\n0.5334414\n0.1561963\n0.1818547\n0.0591766\n0.0693310\n\n\n0.3362937\n0.1598578\n0.2541833\n0.1057556\n0.1439095\n\n\n0.2867413\n0.1518692\n0.2659250\n0.1206355\n0.1748290\n\n\n0.2227442\n0.1349732\n0.2718842\n0.1412808\n0.2291176\n\n\n0.2479759\n0.1425800\n0.2711302\n0.1330330\n0.2052809\n\n\n0.3263616\n0.1585862\n0.2568945\n0.1086361\n0.1495215\n\n\n0.2470295\n0.1423175\n0.2712006\n0.1333412\n0.2061111\n\n\n0.2227442\n0.1349732\n0.2718842\n0.1412808\n0.2291176\n\n\n0.2716834\n0.1485932\n0.2684462\n0.1253882\n0.1858889\n\n\n0.2911270\n0.1527465\n0.2650862\n0.1192696\n0.1717708\n\n\n0.3217020\n0.1579341\n0.2581111\n0.1100057\n0.1522470\n\n\n0.2990362\n0.1542427\n0.2634640\n0.1168288\n0.1664284\n\n\n0.2345774\n0.1387000\n0.2718321\n0.1374089\n0.2174815\n\n\n0.2468396\n0.1422647\n0.2712143\n0.1334031\n0.2062783\n\n\n0.3109971\n0.1562993\n0.2607616\n0.1131955\n0.1587465\n\n\n0.2865524\n0.1518306\n0.2659601\n0.1206945\n0.1749623\n\n\n0.2470295\n0.1423175\n0.2712006\n0.1333412\n0.2061111\n\n\n0.2822723\n0.1509398\n0.2667328\n0.1220362\n0.1780188\n\n\n0.2386041\n0.1399036\n0.2716895\n0.1360916\n0.2137112\n\n\n0.2510078\n0.1434089\n0.2708845\n0.1320468\n0.2026519\n\n\n0.3281547\n0.1588276\n0.2564167\n0.1081122\n0.1484888\n\n\n0.2861997\n0.1517585\n0.2660255\n0.1208048\n0.1752116\n\n\n0.2969255\n0.1538542\n0.2639102\n0.1174772\n0.1678329\n\n\n0.2227442\n0.1349732\n0.2718842\n0.1412808\n0.2291176\n\n\n0.3086576\n0.1559163\n0.2613125\n0.1139005\n0.1602131\n\n\n0.2470295\n0.1423175\n0.2712006\n0.1333412\n0.2061111\n\n\n0.3455310\n0.1608983\n0.2515278\n0.1031247\n0.1389182\n\n\n0.2730326\n0.1489036\n0.2682442\n0.1249587\n0.1848609\n\n\n0.3347759\n0.1596738\n0.2546076\n0.1061924\n0.1447503\n\n\n0.3729209\n0.1632046\n0.2429948\n0.0955983\n0.1252814\n\n\n0.2386041\n0.1399036\n0.2716895\n0.1360916\n0.2137112\n\n\n0.2227442\n0.1349732\n0.2718842\n0.1412808\n0.2291176\n\n\n0.2754569\n0.1494530\n0.2678691\n0.1241886\n0.1830324\n\n\n0.2864083\n0.1518012\n0.2659868\n0.1207396\n0.1750641\n\n\n0.2877967\n0.1520834\n0.2657273\n0.1203060\n0.1740866\n\n\n0.3530183\n0.1616431\n0.2492880\n0.1010264\n0.1350241\n\n\n0.3796310\n0.1635972\n0.2407732\n0.0938170\n0.1221816\n\n\n0.2227442\n0.1349732\n0.2718842\n0.1412808\n0.2291176\n\n\n0.3447012\n0.1608104\n0.2517713\n0.1033591\n0.1393580\n\n\n0.2345774\n0.1387000\n0.2718321\n0.1374089\n0.2174815\n\n\n0.2227442\n0.1349732\n0.2718842\n0.1412808\n0.2291176\n\n\n0.3075433\n0.1557306\n0.2615712\n0.1142373\n0.1609176\n\n\n0.3692950\n0.1629646\n0.2441754\n0.0965710\n0.1269939\n\n\n0.3305983\n0.1591482\n0.2557571\n0.1074009\n0.1470955\n\n\n0.3669480\n0.1627989\n0.2449319\n0.0972045\n0.1281167\n\n\n0.3647313\n0.1626347\n0.2456406\n0.0978056\n0.1291878\n\n\n0.2754569\n0.1494530\n0.2678691\n0.1241886\n0.1830324\n\n\n0.2347608\n0.1387556\n0.2718270\n0.1373489\n0.2173078\n\n\n0.2227442\n0.1349732\n0.2718842\n0.1412808\n0.2291176\n\n\n0.3098209\n0.1561079\n0.2610399\n0.1135496\n0.1594817\n\n\n0.2750544\n0.1493625\n0.2679324\n0.1243163\n0.1833344\n\n\n0.3444377\n0.1607822\n0.2518485\n0.1034337\n0.1394980\n\n\n0.2620706\n0.1462835\n0.2697384\n0.1284676\n0.1934399\n\n\n0.2970169\n0.1538711\n0.2638911\n0.1174491\n0.1677718\n\n\n0.2829082\n0.1510743\n0.2666208\n0.1218364\n0.1775604\n\n\n0.2599182\n0.1457425\n0.2699910\n0.1291613\n0.1951869\n\n\n0.2674993\n0.1476091\n0.2690409\n0.1267247\n0.1891261\n\n\n0.4039928\n0.1644756\n0.2323470\n0.0875539\n0.1116308\n\n\n0.2347608\n0.1387556\n0.2718270\n0.1373489\n0.2173078\n\n\n0.2584197\n0.1453607\n0.2701586\n0.1296451\n0.1964158\n\n\n0.2552179\n0.1445305\n0.2704936\n0.1306809\n0.1990772\n\n\n0.2347608\n0.1387556\n0.2718270\n0.1373489\n0.2173078\n\n\n0.2541703\n0.1442546\n0.2705962\n0.1310204\n0.1999586\n\n\n0.2705352\n0.1483264\n0.2686142\n0.1257544\n0.1867698\n\n\n0.3405122\n0.1603498\n0.2529859\n0.1045484\n0.1416037\n\n\n0.2470295\n0.1423175\n0.2712006\n0.1333412\n0.2061111\n\n\n0.3576464\n0.1620600\n0.2478670\n0.0997448\n0.1326818\n\n\n0.2552179\n0.1445305\n0.2704936\n0.1306809\n0.1990772\n\n\n0.3643539\n0.1626060\n0.2457607\n0.0979082\n0.1293712\n\n\n0.3156998\n0.1570412\n0.2596228\n0.1117868\n0.1558493\n\n\n0.3176095\n0.1573318\n0.2591488\n0.1112181\n0.1546918\n\n\n0.3030315\n0.1549570\n0.2625934\n0.1156072\n0.1638108\n\n\n0.2670993\n0.1475133\n0.2690951\n0.1268528\n0.1894395\n\n\n0.3038897\n0.1551069\n0.2624021\n0.1153458\n0.1632554\n\n\n0.2728299\n0.1488572\n0.2682749\n0.1250232\n0.1850148\n\n\n0.3125517\n0.1565487\n0.2603897\n0.1127286\n0.1577814\n\n\n0.3530183\n0.1616431\n0.2492880\n0.1010264\n0.1350241\n\n\n0.2227442\n0.1349732\n0.2718842\n0.1412808\n0.2291176\n\n\n0.2849546\n0.1515019\n0.2662537\n0.1211945\n0.1760952\n\n\n0.2849199\n0.1514948\n0.2662600\n0.1212053\n0.1761199\n\n\n0.2400559\n0.1403295\n0.2716233\n0.1356170\n0.2123742\n\n\n0.2386041\n0.1399036\n0.2716895\n0.1360916\n0.2137112\n\n\n0.3336453\n0.1595343\n0.2549214\n0.1065185\n0.1453804\n\n\n0.2967174\n0.1538154\n0.2639537\n0.1175412\n0.1679722\n\n\n0.2386041\n0.1399036\n0.2716895\n0.1360916\n0.2137112\n\n\n0.3535738\n0.1616949\n0.2491189\n0.1008720\n0.1347404\n\n\n0.3135085\n0.1567001\n0.2601586\n0.1124418\n0.1571910\n\n\n0.2635544\n0.1466513\n0.2695563\n0.1279903\n0.1922478\n\n\n0.3545691\n0.1617865\n0.2488149\n0.1005957\n0.1342339\n\n\n0.3334237\n0.1595068\n0.2549827\n0.1065825\n0.1455043\n\n\n0.2227442\n0.1349732\n0.2718842\n0.1412808\n0.2291176\n\n\n0.3665640\n0.1627709\n0.2450551\n0.0973084\n0.1283015\n\n\n0.4454541\n0.1640921\n0.2169790\n0.0776057\n0.0958691\n\n\n0.2227442\n0.1349732\n0.2718842\n0.1412808\n0.2291176\n\n\n0.2862891\n0.1517768\n0.2660089\n0.1207769\n0.1751484\n\n\n0.3932285\n0.1641918\n0.2361352\n0.0902821\n0.1161623\n\n\n0.2956582\n0.1536171\n0.2641736\n0.1178676\n0.1686835\n\n\n0.3554598\n0.1618671\n0.2485418\n0.1003488\n0.1337824\n\n\n0.2217482\n0.1346464\n0.2718622\n0.1416062\n0.2301369\n\n\n0.3530183\n0.1616431\n0.2492880\n0.1010264\n0.1350241\n\n\n0.3774175\n0.1634751\n0.2415112\n0.0944019\n0.1231944\n\n\n0.2386041\n0.1399036\n0.2716895\n0.1360916\n0.2137112\n\n\n0.2874480\n0.1520129\n0.2657929\n0.1204148\n0.1743315\n\n\n0.2714814\n0.1485465\n0.2684760\n0.1254526\n0.1860434\n\n\n0.2472195\n0.1423704\n0.2711867\n0.1332794\n0.2059441\n\n\n0.2683767\n0.1478182\n0.2689202\n0.1264439\n0.1884410\n\n\n0.2822723\n0.1509398\n0.2667328\n0.1220362\n0.1780188\n\n\n0.2978653\n0.1540281\n0.2637127\n0.1171882\n0.1672056\n\n\n0.3458390\n0.1609307\n0.2514372\n0.1030378\n0.1387554\n\n\n0.2630545\n0.1465278\n0.2696184\n0.1281510\n0.1926483\n\n\n0.3270247\n0.1586761\n0.2567184\n0.1084422\n0.1491386\n\n\n0.2356749\n0.1390313\n0.2717993\n0.1370497\n0.2164448\n\n\n0.2227442\n0.1349732\n0.2718842\n0.1412808\n0.2291176\n\n\n0.2670993\n0.1475133\n0.2690951\n0.1268528\n0.1894395\n\n\n0.2386041\n0.1399036\n0.2716895\n0.1360916\n0.2137112\n\n\n0.2776800\n0.1499473\n0.2675115\n0.1234844\n0.1813768\n\n\n0.3024875\n0.1548614\n0.2627139\n0.1157731\n0.1641642\n\n\n0.3889442\n0.1640332\n0.2376152\n0.0913851\n0.1180223\n\n\n0.3292223\n0.1589689\n0.2561297\n0.1078010\n0.1478781\n\n\n0.2227442\n0.1349732\n0.2718842\n0.1412808\n0.2291176\n\n\n0.2416607\n0.1407955\n0.2715412\n0.1350927\n0.2109098\n\n\n0.2552179\n0.1445305\n0.2704936\n0.1306809\n0.1990772\n\n\n0.2227442\n0.1349732\n0.2718842\n0.1412808\n0.2291176\n\n\n0.2903048\n0.1525846\n0.2652469\n0.1195250\n0.1723388\n\n\n0.3186802\n0.1574921\n0.2588802\n0.1109001\n0.1540475\n\n\n0.2386041\n0.1399036\n0.2716895\n0.1360916\n0.2137112\n\n\n0.2227442\n0.1349732\n0.2718842\n0.1412808\n0.2291176\n\n\n0.2670993\n0.1475133\n0.2690951\n0.1268528\n0.1894395\n\n\n0.3487268\n0.1612269\n0.2505810\n0.1022253\n0.1372400\n\n\n0.3913680\n0.1641262\n0.2367799\n0.0907599\n0.1169660\n\n\n0.3336453\n0.1595343\n0.2549214\n0.1065185\n0.1453804\n\n\n0.2553288\n0.1445596\n0.2704825\n0.1306449\n0.1989842\n\n\n0.3252454\n0.1584333\n0.2571893\n0.1089631\n0.1501689\n\n\n0.2227442\n0.1349732\n0.2718842\n0.1412808\n0.2291176\n\n\n0.3334561\n0.1595108\n0.2549737\n0.1065732\n0.1454862\n\n\n0.2345774\n0.1387000\n0.2718321\n0.1374089\n0.2174815\n\n\n0.2227442\n0.1349732\n0.2718842\n0.1412808\n0.2291176\n\n\n0.3608420\n0.1623286\n0.2468703\n0.0988667\n0.1310924\n\n\n0.3566081\n0.1619693\n0.2481881\n0.1000313\n0.1332031\n\n\n0.2386041\n0.1399036\n0.2716895\n0.1360916\n0.2137112\n\n\n0.2793655\n0.1503160\n0.2672319\n0.1229519\n0.1801347\n\n\n0.2227442\n0.1349732\n0.2718842\n0.1412808\n0.2291176\n\n\n0.3447012\n0.1608104\n0.2517713\n0.1033591\n0.1393580\n\n\n0.2227442\n0.1349732\n0.2718842\n0.1412808\n0.2291176\n\n\n0.2472195\n0.1423704\n0.2711867\n0.1332794\n0.2059441\n\n\n0.2541703\n0.1442546\n0.2705962\n0.1310204\n0.1999586\n\n\n0.2227442\n0.1349732\n0.2718842\n0.1412808\n0.2291176\n\n\n0.2227442\n0.1349732\n0.2718842\n0.1412808\n0.2291176\n\n\n0.2584197\n0.1453607\n0.2701586\n0.1296451\n0.1964158\n\n\n0.2386041\n0.1399036\n0.2716895\n0.1360916\n0.2137112\n\n\n0.2510078\n0.1434089\n0.2708845\n0.1320468\n0.2026519\n\n\n0.2956582\n0.1536171\n0.2641736\n0.1178676\n0.1686835\n\n\n0.3508003\n0.1614316\n0.2499593\n0.1016448\n0.1361640\n\n\n0.2472195\n0.1423704\n0.2711867\n0.1332794\n0.2059441\n\n\n0.2740423\n0.1491338\n0.2680899\n0.1246377\n0.1840964\n\n\n0.3824292\n0.1637415\n0.2398331\n0.0930814\n0.1209148\n\n\n0.3822225\n0.1637312\n0.2399028\n0.0931356\n0.1210078\n\n\n0.2539123\n0.1441863\n0.2706209\n0.1311040\n0.2001765\n\n\n0.2552179\n0.1445305\n0.2704936\n0.1306809\n0.1990772\n\n\n0.2371144\n0.1394621\n0.2717493\n0.1365788\n0.2150954\n\n\n0.2601100\n0.1457911\n0.2699691\n0.1290995\n0.1950304\n\n\n0.3093065\n0.1560235\n0.2611608\n0.1137047\n0.1598046\n\n\n0.3887420\n0.1640251\n0.2376846\n0.0914374\n0.1181109\n\n\n0.2833276\n0.1511625\n0.2665464\n0.1217047\n0.1772588\n\n\n0.3124733\n0.1565362\n0.2604086\n0.1127521\n0.1578298\n\n\n0.2844644\n0.1514002\n0.2663426\n0.1213481\n0.1764447\n\n\n0.2472195\n0.1423704\n0.2711867\n0.1332794\n0.2059441\n\n\n0.2951572\n0.1535226\n0.2642768\n0.1180221\n0.1690213\n\n\n0.3549698\n0.1618229\n0.2486921\n0.1004846\n0.1340306\n\n\n0.2907508\n0.1526726\n0.2651599\n0.1193864\n0.1720303\n\n\n0.2818784\n0.1508562\n0.2668016\n0.1221601\n0.1783036\n\n\n0.2670993\n0.1475133\n0.2690951\n0.1268528\n0.1894395\n\n\n0.2227442\n0.1349732\n0.2718842\n0.1412808\n0.2291176\n\n\n0.2510078\n0.1434089\n0.2708845\n0.1320468\n0.2026519\n\n\n0.2481664\n0.1426326\n0.2711157\n0.1329710\n0.2051144\n\n\n0.2468396\n0.1422647\n0.2712143\n0.1334031\n0.2062783\n\n\n0.2541703\n0.1442546\n0.2705962\n0.1310204\n0.1999586\n\n\n0.2584197\n0.1453607\n0.2701586\n0.1296451\n0.1964158\n\n\n0.2386041\n0.1399036\n0.2716895\n0.1360916\n0.2137112\n\n\n0.2227442\n0.1349732\n0.2718842\n0.1412808\n0.2291176\n\n\n0.4259339\n0.1645582\n0.2243512\n0.0821806\n0.1029761\n\n\n0.2541703\n0.1442546\n0.2705962\n0.1310204\n0.1999586\n\n\n0.2227442\n0.1349732\n0.2718842\n0.1412808\n0.2291176\n\n\n0.2227442\n0.1349732\n0.2718842\n0.1412808\n0.2291176\n\n\n0.3360224\n0.1598252\n0.2542594\n0.1058336\n0.1440593\n\n\n0.2630545\n0.1465278\n0.2696184\n0.1281510\n0.1926483\n\n\n0.4227624\n0.1645866\n0.2255275\n0.0829420\n0.1041816\n\n\n0.3126928\n0.1565711\n0.2603557\n0.1126863\n0.1576942\n\n\n0.2510078\n0.1434089\n0.2708845\n0.1320468\n0.2026519\n\n\n0.3197845\n0.1576554\n0.2586010\n0.1105727\n0.1533865\n\n\n0.3374288\n0.1599930\n0.2538637\n0.1054298\n0.1432846\n\n\n0.2888393\n0.1522931\n0.2655293\n0.1199810\n0.1733572\n\n\n0.2345774\n0.1387000\n0.2718321\n0.1374089\n0.2174815\n\n\n0.2468396\n0.1422647\n0.2712143\n0.1334031\n0.2062783\n\n\n0.2877967\n0.1520834\n0.2657273\n0.1203060\n0.1740866\n\n\n0.2740423\n0.1491338\n0.2680899\n0.1246377\n0.1840964\n\n\n0.2386041\n0.1399036\n0.2716895\n0.1360916\n0.2137112\n\n\n0.2227442\n0.1349732\n0.2718842\n0.1412808\n0.2291176\n\n\n0.2227442\n0.1349732\n0.2718842\n0.1412808\n0.2291176\n\n\n0.2510078\n0.1434089\n0.2708845\n0.1320468\n0.2026519\n\n\n0.2386041\n0.1399036\n0.2716895\n0.1360916\n0.2137112\n\n\n0.2521523\n0.1437172\n0.2707839\n0.1316751\n0.2016715\n\n\n0.2472195\n0.1423704\n0.2711867\n0.1332794\n0.2059441\n\n\n0.2347608\n0.1387556\n0.2718270\n0.1373489\n0.2173078\n\n\n0.3670271\n0.1628046\n0.2449065\n0.0971831\n0.1280787\n\n\n0.3100341\n0.1561428\n0.2609896\n0.1134853\n0.1593481\n\n\n0.3030007\n0.1549516\n0.2626003\n0.1156166\n0.1638308\n\n\n0.2545622\n0.1443581\n0.2705582\n0.1308933\n0.1996282\n\n\n0.3754373\n0.1633596\n0.2421672\n0.0949274\n0.1241085\n\n\n0.2886346\n0.1522521\n0.2655684\n0.1200448\n0.1735001\n\n\n0.2642250\n0.1468162\n0.2694718\n0.1277748\n0.1917122\n\n\n0.3146031\n0.1568715\n0.2598921\n0.1121143\n0.1565190\n\n\n0.2345774\n0.1387000\n0.2718321\n0.1374089\n0.2174815\n\n\n0.2552179\n0.1445305\n0.2704936\n0.1306809\n0.1990772\n\n\n0.2468396\n0.1422647\n0.2712143\n0.1334031\n0.2062783\n\n\n0.3038897\n0.1551069\n0.2624021\n0.1153458\n0.1632554\n\n\n0.2545622\n0.1443581\n0.2705582\n0.1308933\n0.1996282\n\n\n0.3138592\n0.1567552\n0.2600734\n0.1123368\n0.1569753\n\n\n0.2684961\n0.1478465\n0.2689036\n0.1264057\n0.1883481\n\n\n0.2384407\n0.1398554\n0.2716964\n0.1361450\n0.2138624\n\n\n0.2227442\n0.1349732\n0.2718842\n0.1412808\n0.2291176\n\n\n0.2584197\n0.1453607\n0.2701586\n0.1296451\n0.1964158\n\n\n0.2693804\n0.1480556\n0.2687795\n0.1261230\n0.1876614\n\n\n0.2386041\n0.1399036\n0.2716895\n0.1360916\n0.2137112\n\n\n0.3851949\n0.1638728\n0.2388965\n0.0923585\n0.1196772\n\n\n0.2584197\n0.1453607\n0.2701586\n0.1296451\n0.1964158\n\n\n0.2227442\n0.1349732\n0.2718842\n0.1412808\n0.2291176\n\n\n0.2693804\n0.1480556\n0.2687795\n0.1261230\n0.1876614\n\n\n0.2386041\n0.1399036\n0.2716895\n0.1360916\n0.2137112\n\n\n0.2227442\n0.1349732\n0.2718842\n0.1412808\n0.2291176\n\n\n0.2599182\n0.1457425\n0.2699910\n0.1291613\n0.1951869\n\n\n0.2472195\n0.1423704\n0.2711867\n0.1332794\n0.2059441\n\n\n0.3391432\n0.1601932\n0.2533774\n0.1049391\n0.1423471\n\n\n0.2227442\n0.1349732\n0.2718842\n0.1412808\n0.2291176\n\n\n0.2227442\n0.1349732\n0.2718842\n0.1412808\n0.2291176\n\n\n0.2345774\n0.1387000\n0.2718321\n0.1374089\n0.2174815\n\n\n0.3256831\n0.1584935\n0.2570739\n0.1088348\n0.1499146\n\n\n0.2479759\n0.1425800\n0.2711302\n0.1330330\n0.2052809\n\n\n0.2638329\n0.1467199\n0.2695213\n0.1279008\n0.1920251\n\n\n0.2822723\n0.1509398\n0.2667328\n0.1220362\n0.1780188\n\n\n0.3856844\n0.1638949\n0.2387300\n0.0922310\n0.1194597\n\n\n0.2227442\n0.1349732\n0.2718842\n0.1412808\n0.2291176\n\n\n0.2683767\n0.1478182\n0.2689202\n0.1264439\n0.1884410\n\n\n0.2725744\n0.1487986\n0.2683134\n0.1251045\n0.1852091\n\n\n0.2941012\n0.1533220\n0.2644924\n0.1183483\n0.1697362\n\n\n0.2416607\n0.1407955\n0.2715412\n0.1350927\n0.2109098\n\n\n0.2470295\n0.1423175\n0.2712006\n0.1333412\n0.2061111\n\n\n0.2503593\n0.1432331\n0.2709396\n0.1322576\n0.2032103\n\n\n0.3665302\n0.1627685\n0.2450659\n0.0973176\n0.1283178\n\n\n0.3064622\n0.1555485\n0.2618198\n0.1145646\n0.1616049\n\n\n0.2227442\n0.1349732\n0.2718842\n0.1412808\n0.2291176\n\n\n0.2227442\n0.1349732\n0.2718842\n0.1412808\n0.2291176\n\n\n0.2468396\n0.1422647\n0.2712143\n0.1334031\n0.2062783\n\n\n0.2903048\n0.1525846\n0.2652469\n0.1195250\n0.1723388\n\n\n0.2472195\n0.1423704\n0.2711867\n0.1332794\n0.2059441\n\n\n0.2826616\n0.1510222\n0.2666643\n0.1219139\n0.1777380\n\n\n0.2472195\n0.1423704\n0.2711867\n0.1332794\n0.2059441\n\n\n0.2851627\n0.1515450\n0.2662158\n0.1211293\n0.1759471\n\n\n0.2960887\n0.1536979\n0.2640845\n0.1177349\n0.1683939\n\n\n0.2227442\n0.1349732\n0.2718842\n0.1412808\n0.2291176\n\n\n0.2853709\n0.1515880\n0.2661778\n0.1210641\n0.1757991\n\n\n0.2754569\n0.1494530\n0.2678691\n0.1241886\n0.1830324\n\n\n0.2670993\n0.1475133\n0.2690951\n0.1268528\n0.1894395\n\n\n0.3003169\n0.1544747\n0.2631885\n0.1164363\n0.1655835\n\n\n0.4070641\n0.1645268\n0.2312488\n0.0867867\n0.1103736\n\n\n0.2510078\n0.1434089\n0.2708845\n0.1320468\n0.2026519\n\n\n0.2992502\n0.1542817\n0.2634182\n0.1167631\n0.1662868\n\n\n0.2750544\n0.1493625\n0.2679324\n0.1243163\n0.1833344\n\n\n0.2725744\n0.1487986\n0.2683134\n0.1251045\n0.1852091\n\n\n0.2956582\n0.1536171\n0.2641736\n0.1178676\n0.1686835\n\n\n0.2728299\n0.1488572\n0.2682749\n0.1250232\n0.1850148\n\n\n0.2468396\n0.1422647\n0.2712143\n0.1334031\n0.2062783\n\n\n0.2898842\n0.1525013\n0.2653284\n0.1196558\n0.1726303\n\n\n0.2650151\n0.1470094\n0.2693706\n0.1275210\n0.1910838\n\n\n0.3081079\n0.1558250\n0.2614404\n0.1140665\n0.1605601\n\n\n0.2730326\n0.1489036\n0.2682442\n0.1249587\n0.1848609\n\n\n0.2829082\n0.1510743\n0.2666208\n0.1218364\n0.1775604\n\n\n0.3306898\n0.1591600\n0.2557323\n0.1073743\n0.1470436\n\n\n0.3802782\n0.1636316\n0.2405564\n0.0936465\n0.1218873\n\n\n0.2608968\n0.1459896\n0.2698779\n0.1288458\n0.1943900\n\n\n0.2227442\n0.1349732\n0.2718842\n0.1412808\n0.2291176\n\n\n0.4526119\n0.1637980\n0.2142246\n0.0759751\n0.0933904\n\n\n0.2738392\n0.1490876\n0.2681212\n0.1247022\n0.1842498\n\n\n0.2998165\n0.1543844\n0.2632966\n0.1165896\n0.1659130\n\n\n0.2227442\n0.1349732\n0.2718842\n0.1412808\n0.2291176\n\n\n0.2217482\n0.1346464\n0.2718622\n0.1416062\n0.2301369\n\n\n0.2386041\n0.1399036\n0.2716895\n0.1360916\n0.2137112\n\n\n0.3487268\n0.1612269\n0.2505810\n0.1022253\n0.1372400\n\n\n0.2584197\n0.1453607\n0.2701586\n0.1296451\n0.1964158\n\n\n0.5046504\n0.1597715\n0.1935877\n0.0648356\n0.0771548\n\n\n0.3470335\n0.1610548\n0.2510844\n0.1027012\n0.1381261\n\n\n0.2846674\n0.1514424\n0.2663059\n0.1212845\n0.1762999\n\n\n0.2985268\n0.1541497\n0.2635725\n0.1169851\n0.1667660\n\n\n0.4413200\n0.1642322\n0.2185581\n0.0785588\n0.0973309\n\n\n0.2227442\n0.1349732\n0.2718842\n0.1412808\n0.2291176\n\n\n0.2640265\n0.1467675\n0.2694969\n0.1278385\n0.1918705\n\n\n0.2227442\n0.1349732\n0.2718842\n0.1412808\n0.2291176\n\n\n0.3003169\n0.1544747\n0.2631885\n0.1164363\n0.1655835\n\n\n0.3784750\n0.1635343\n0.2411592\n0.0941221\n0.1227093\n\n\n0.3323277\n0.1593692\n0.2552846\n0.1068995\n0.1461191\n\n\n0.3647313\n0.1626347\n0.2456406\n0.0978056\n0.1291878\n\n\n0.3042910\n0.1551765\n0.2623122\n0.1152237\n0.1629965\n\n\n0.2416607\n0.1407955\n0.2715412\n0.1350927\n0.2109098\n\n\n0.2479759\n0.1425800\n0.2711302\n0.1330330\n0.2052809\n\n\n0.2674993\n0.1476091\n0.2690409\n0.1267247\n0.1891261\n\n\n0.2849546\n0.1515019\n0.2662537\n0.1211945\n0.1760952\n\n\n0.2227442\n0.1349732\n0.2718842\n0.1412808\n0.2291176\n\n\n0.2227442\n0.1349732\n0.2718842\n0.1412808\n0.2291176\n\n\n0.3949760\n0.1642490\n0.2355269\n0.0898350\n0.1154131\n\n\n0.3184902\n0.1574638\n0.2589280\n0.1109565\n0.1541616\n\n\n0.3851949\n0.1638728\n0.2388965\n0.0923585\n0.1196772\n\n\n0.2472195\n0.1423704\n0.2711867\n0.1332794\n0.2059441\n\n\n0.2618779\n0.1462354\n0.2697616\n0.1285297\n0.1935954\n\n\n0.3565245\n0.1619619\n0.2482140\n0.1000544\n0.1332452\n\n\n0.2618779\n0.1462354\n0.2697616\n0.1285297\n0.1935954\n\n\n0.3075433\n0.1557306\n0.2615712\n0.1142373\n0.1609176\n\n\n0.3544356\n0.1617743\n0.2488558\n0.1006327\n0.1343017\n\n\n0.2864083\n0.1518012\n0.2659868\n0.1207396\n0.1750641\n\n\n0.2345774\n0.1387000\n0.2718321\n0.1374089\n0.2174815\n\n\n0.2985268\n0.1541497\n0.2635725\n0.1169851\n0.1667660\n\n\n0.2472195\n0.1423704\n0.2711867\n0.1332794\n0.2059441\n\n\n0.3656613\n0.1627044\n0.2453440\n0.0975531\n0.1287372\n\n\n0.2759133\n0.1495552\n0.2677967\n0.1240439\n0.1826909\n\n\n0.3135085\n0.1567001\n0.2601586\n0.1124418\n0.1571910\n\n\n0.2630545\n0.1465278\n0.2696184\n0.1281510\n0.1926483\n\n\n0.3173567\n0.1572937\n0.2592120\n0.1112933\n0.1548444\n\n\n0.2227442\n0.1349732\n0.2718842\n0.1412808\n0.2291176\n\n\n0.2946011\n0.1534172\n0.2643906\n0.1181938\n0.1693973\n\n\n0.2638329\n0.1467199\n0.2695213\n0.1279008\n0.1920251\n\n\n0.3405122\n0.1603498\n0.2529859\n0.1045484\n0.1416037\n\n\n0.3707118\n0.1630607\n0.2437158\n0.0961901\n0.1263216\n\n\n0.4676311\n0.1629717\n0.2083689\n0.0726331\n0.0883952\n\n\n0.2630545\n0.1465278\n0.2696184\n0.1281510\n0.1926483\n\n\n0.2416607\n0.1407955\n0.2715412\n0.1350927\n0.2109098\n\n\n0.2227442\n0.1349732\n0.2718842\n0.1412808\n0.2291176\n\n\n0.3001024\n0.1544361\n0.2632349\n0.1165020\n0.1657247\n\n\n0.2670993\n0.1475133\n0.2690951\n0.1268528\n0.1894395\n\n\n0.2584197\n0.1453607\n0.2701586\n0.1296451\n0.1964158\n\n\n0.2730326\n0.1489036\n0.2682442\n0.1249587\n0.1848609\n\n\n0.3222327\n0.1580102\n0.2579744\n0.1098491\n0.1519335\n\n\n0.2946011\n0.1534172\n0.2643906\n0.1181938\n0.1693973\n\n\n0.2998063\n0.1543826\n0.2632988\n0.1165927\n0.1659197\n\n\n0.2797230\n0.1503936\n0.2671716\n0.1228391\n0.1798728\n\n\n0.2227442\n0.1349732\n0.2718842\n0.1412808\n0.2291176\n\n\n0.2345774\n0.1387000\n0.2718321\n0.1374089\n0.2174815\n\n\n0.2468396\n0.1422647\n0.2712143\n0.1334031\n0.2062783\n\n\n0.2999798\n0.1544139\n0.2632613\n0.1165395\n0.1658054\n\n\n0.3135085\n0.1567001\n0.2601586\n0.1124418\n0.1571910\n\n\n0.2227442\n0.1349732\n0.2718842\n0.1412808\n0.2291176\n\n\n0.2730326\n0.1489036\n0.2682442\n0.1249587\n0.1848609\n\n\n0.2227442\n0.1349732\n0.2718842\n0.1412808\n0.2291176\n\n\n0.2491157\n0.1428937\n0.2710414\n0.1326621\n0.2042872\n\n\n0.2468396\n0.1422647\n0.2712143\n0.1334031\n0.2062783\n\n\n0.3479486\n0.1611484\n0.2508128\n0.1024438\n0.1376464\n\n\n0.3684912\n0.1629088\n0.2444352\n0.0967876\n0.1273771\n\n\n0.4540157\n0.1637327\n0.2136815\n0.0756582\n0.0929119\n\n\n0.2356749\n0.1390313\n0.2717993\n0.1370497\n0.2164448\n\n\n0.2759133\n0.1495552\n0.2677967\n0.1240439\n0.1826909\n\n\n0.3143830\n0.1568372\n0.2599458\n0.1121801\n0.1566539\n\n\n0.3862607\n0.1639205\n0.2385336\n0.0920811\n0.1192042\n\n\n0.2510078\n0.1434089\n0.2708845\n0.1320468\n0.2026519\n\n\n0.3617845\n0.1624049\n0.2465739\n0.0986088\n0.1306278\n\n\n0.2510078\n0.1434089\n0.2708845\n0.1320468\n0.2026519\n\n\n0.3146031\n0.1568715\n0.2598921\n0.1121143\n0.1565190\n\n\n0.3386203\n0.1601327\n0.2535262\n0.1050886\n0.1426323\n\n\n0.2227442\n0.1349732\n0.2718842\n0.1412808\n0.2291176\n\n\n0.2815980\n0.1507965\n0.2668504\n0.1222483\n0.1785068\n\n\n0.3272495\n0.1587064\n0.2566586\n0.1083765\n0.1490091\n\n\n0.3826704\n0.1637534\n0.2397518\n0.0930182\n0.1208063\n\n\n0.4413200\n0.1642322\n0.2185581\n0.0785588\n0.0973309\n\n\n0.2806448\n0.1505925\n0.2670148\n0.1225485\n0.1791995\n\n\n0.2681811\n0.1477717\n0.2689473\n0.1265065\n0.1885935\n\n\n0.2227442\n0.1349732\n0.2718842\n0.1412808\n0.2291176\n\n\n0.4400675\n0.1642703\n0.2190347\n0.0788492\n0.0977783\n\n\n0.3089482\n0.1559644\n0.2612446\n0.1138128\n0.1600300\n\n\n0.2921767\n0.1529514\n0.2648789\n0.1189439\n0.1710491\n\n\n0.3104764\n0.1562149\n0.2608851\n0.1133522\n0.1590715\n\n\n0.2511953\n0.1434596\n0.2708683\n0.1319859\n0.2024909\n\n\n0.2762680\n0.1496344\n0.2677401\n0.1239314\n0.1824261\n\n\n0.2227442\n0.1349732\n0.2718842\n0.1412808\n0.2291176\n\n\n0.2714814\n0.1485465\n0.2684760\n0.1254526\n0.1860434\n\n\n0.3684912\n0.1629088\n0.2444352\n0.0967876\n0.1273771\n\n\n0.2670993\n0.1475133\n0.2690951\n0.1268528\n0.1894395\n\n\n0.2227442\n0.1349732\n0.2718842\n0.1412808\n0.2291176\n\n\n0.2584197\n0.1453607\n0.2701586\n0.1296451\n0.1964158\n\n\n0.2759133\n0.1495552\n0.2677967\n0.1240439\n0.1826909\n\n\n0.2730326\n0.1489036\n0.2682442\n0.1249587\n0.1848609\n\n\n0.3606121\n0.1623098\n0.2469424\n0.0989297\n0.1312060\n\n\n0.2227442\n0.1349732\n0.2718842\n0.1412808\n0.2291176\n\n\n0.2670993\n0.1475133\n0.2690951\n0.1268528\n0.1894395\n\n\n0.2227442\n0.1349732\n0.2718842\n0.1412808\n0.2291176\n\n\n0.2227442\n0.1349732\n0.2718842\n0.1412808\n0.2291176\n\n\n0.2221723\n0.1347858\n0.2718721\n0.1414677\n0.2297021\n\n\n0.2808510\n0.1506367\n0.2669795\n0.1224835\n0.1790493\n\n\n0.3393666\n0.1602190\n0.2533137\n0.1048753\n0.1422254\n\n\n0.2670993\n0.1475133\n0.2690951\n0.1268528\n0.1894395\n\n\n0.3242698\n0.1582979\n0.2574452\n0.1092495\n0.1507376\n\n\n0.2227442\n0.1349732\n0.2718842\n0.1412808\n0.2291176\n\n\n0.2386041\n0.1399036\n0.2716895\n0.1360916\n0.2137112\n\n\n0.2468396\n0.1422647\n0.2712143\n0.1334031\n0.2062783\n\n\n0.2227442\n0.1349732\n0.2718842\n0.1412808\n0.2291176\n\n\n0.2227442\n0.1349732\n0.2718842\n0.1412808\n0.2291176\n\n\n0.2227442\n0.1349732\n0.2718842\n0.1412808\n0.2291176\n\n\n0.2970169\n0.1538711\n0.2638911\n0.1174491\n0.1677718\n\n\n0.3086265\n0.1559112\n0.2613198\n0.1139099\n0.1602327\n\n\n0.2217482\n0.1346464\n0.2718622\n0.1416062\n0.2301369\n\n\n0.2468396\n0.1422647\n0.2712143\n0.1334031\n0.2062783\n\n\n0.2386041\n0.1399036\n0.2716895\n0.1360916\n0.2137112\n\n\n0.2227442\n0.1349732\n0.2718842\n0.1412808\n0.2291176\n\n\n0.2716834\n0.1485932\n0.2684462\n0.1253882\n0.1858889\n\n\n0.3194250\n0.1576024\n0.2586921\n0.1106792\n0.1536013\n\n\n0.2682956\n0.1477989\n0.2689314\n0.1264698\n0.1885042\n\n\n0.3148286\n0.1569065\n0.2598369\n0.1120470\n0.1563810\n\n\n0.2742407\n0.1491787\n0.2680592\n0.1245746\n0.1839467\n\n\n0.2716834\n0.1485932\n0.2684462\n0.1253882\n0.1858889\n\n\n0.2694953\n0.1480826\n0.2687632\n0.1260864\n0.1875725\n\n\n0.2650151\n0.1470094\n0.2693706\n0.1275210\n0.1910838\n\n\n0.2774752\n0.1499021\n0.2675450\n0.1235492\n0.1815285\n\n\n0.2386041\n0.1399036\n0.2716895\n0.1360916\n0.2137112\n\n\n0.3376191\n0.1600154\n0.2538100\n0.1053753\n0.1431802\n\n\n0.2553288\n0.1445596\n0.2704825\n0.1306449\n0.1989842\n\n\n0.2345774\n0.1387000\n0.2718321\n0.1374089\n0.2174815\n\n\n0.2730326\n0.1489036\n0.2682442\n0.1249587\n0.1848609\n\n\n0.2911270\n0.1527465\n0.2650862\n0.1192696\n0.1717708\n\n\n0.3124316\n0.1565295\n0.2604186\n0.1127646\n0.1578557\n\n\n0.2227442\n0.1349732\n0.2718842\n0.1412808\n0.2291176\n\n\n0.2227442\n0.1349732\n0.2718842\n0.1412808\n0.2291176\n\n\n0.2818784\n0.1508562\n0.2668016\n0.1221601\n0.1783036\n\n\n0.3159205\n0.1570750\n0.2595684\n0.1117210\n0.1557150\n\n\n0.2227442\n0.1349732\n0.2718842\n0.1412808\n0.2291176\n\n\n0.3057289\n0.1554237\n0.2619872\n0.1147869\n0.1620732\n\n\n0.3149335\n0.1569228\n0.2598112\n0.1120156\n0.1563169\n\n\n0.2946011\n0.1534172\n0.2643906\n0.1181938\n0.1693973\n\n\n0.3146922\n0.1568853\n0.2598703\n0.1120877\n0.1564645\n\n\n0.2227442\n0.1349732\n0.2718842\n0.1412808\n0.2291176\n\n\n0.2946011\n0.1534172\n0.2643906\n0.1181938\n0.1693973\n\n\n0.3168881\n0.1572227\n0.2593287\n0.1114327\n0.1551278\n\n\n0.3501140\n0.1613646\n0.2501657\n0.1018367\n0.1365190\n\n\n0.4044906\n0.1644847\n0.2321695\n0.0874292\n0.1114260\n\n\n0.2533691\n0.1440422\n0.2706723\n0.1312802\n0.2006362\n\n\n0.3570992\n0.1620124\n0.2480364\n0.0998957\n0.1329563\n\n\n0.3856844\n0.1638949\n0.2387300\n0.0922310\n0.1194597\n\n\n0.3075433\n0.1557306\n0.2615712\n0.1142373\n0.1609176\n\n\n0.2227442\n0.1349732\n0.2718842\n0.1412808\n0.2291176\n\n\n0.4202013\n0.1645996\n0.2264726\n0.0835605\n0.1051659\n\n\n0.3106117\n0.1562369\n0.2608530\n0.1133114\n0.1589870\n\n\n0.3298347\n0.1590491\n0.2559643\n0.1076228\n0.1475292\n\n\n0.3003169\n0.1544747\n0.2631885\n0.1164363\n0.1655835\n\n\n0.2630545\n0.1465278\n0.2696184\n0.1281510\n0.1926483\n\n\n0.2227442\n0.1349732\n0.2718842\n0.1412808\n0.2291176\n\n\n0.2227442\n0.1349732\n0.2718842\n0.1412808\n0.2291176\n\n\n0.2516986\n0.1435953\n0.2708243\n0.1318224\n0.2020593\n\n\n0.2347608\n0.1387556\n0.2718270\n0.1373489\n0.2173078\n\n\n0.2877967\n0.1520834\n0.2657273\n0.1203060\n0.1740866\n\n\n0.3186802\n0.1574921\n0.2588802\n0.1109001\n0.1540475\n\n\n0.2345774\n0.1387000\n0.2718321\n0.1374089\n0.2174815\n\n\n0.2227442\n0.1349732\n0.2718842\n0.1412808\n0.2291176\n\n\n0.2595255\n0.1456429\n0.2700356\n0.1292880\n0.1955080\n\n\n0.2725744\n0.1487986\n0.2683134\n0.1251045\n0.1852091\n\n\n0.2503593\n0.1432331\n0.2709396\n0.1322576\n0.2032103\n\n\n0.2584197\n0.1453607\n0.2701586\n0.1296451\n0.1964158\n\n\n0.2932287\n0.1531548\n0.2646686\n0.1186181\n0.1703298\n\n\n0.2386041\n0.1399036\n0.2716895\n0.1360916\n0.2137112\n\n\n0.3408180\n0.1603844\n0.2528981\n0.1044612\n0.1414383\n\n\n0.3336453\n0.1595343\n0.2549214\n0.1065185\n0.1453804\n\n\n0.3809087\n0.1636645\n0.2403449\n0.0934806\n0.1216013\n\n\n0.2481664\n0.1426326\n0.2711157\n0.1329710\n0.2051144\n\n\n0.2705352\n0.1483264\n0.2686142\n0.1257544\n0.1867698\n\n\n0.2386041\n0.1399036\n0.2716895\n0.1360916\n0.2137112\n\n\n0.2670993\n0.1475133\n0.2690951\n0.1268528\n0.1894395\n\n\n0.2946011\n0.1534172\n0.2643906\n0.1181938\n0.1693973\n\n\n0.2861997\n0.1517585\n0.2660255\n0.1208048\n0.1752116\n\n\n0.2584570\n0.1453702\n0.2701545\n0.1296330\n0.1963851\n\n\n0.2521523\n0.1437172\n0.2707839\n0.1316751\n0.2016715\n\n\n0.2650151\n0.1470094\n0.2693706\n0.1275210\n0.1910838\n\n\n0.2816718\n0.1508122\n0.2668376\n0.1222251\n0.1784533\n\n\n0.3198956\n0.1576717\n0.2585728\n0.1105398\n0.1533202\n\n\n0.3479486\n0.1611484\n0.2508128\n0.1024438\n0.1376464\n\n\n0.3284121\n0.1588619\n0.2563477\n0.1080371\n0.1483413\n\n\n0.2650151\n0.1470094\n0.2693706\n0.1275210\n0.1910838\n\n\n0.3856844\n0.1638949\n0.2387300\n0.0922310\n0.1194597\n\n\n0.2921767\n0.1529514\n0.2648789\n0.1189439\n0.1710491\n\n\n0.3242698\n0.1582979\n0.2574452\n0.1092495\n0.1507376\n\n\n0.3115652\n0.1563909\n0.2606262\n0.1130247\n0.1583929\n\n\n0.2468396\n0.1422647\n0.2712143\n0.1334031\n0.2062783\n\n\n0.2468396\n0.1422647\n0.2712143\n0.1334031\n0.2062783\n\n\n0.2900644\n0.1525371\n0.2652935\n0.1195997\n0.1725053\n\n\n0.2874480\n0.1520129\n0.2657929\n0.1204148\n0.1743315\n\n\n0.2221723\n0.1347858\n0.2718721\n0.1414677\n0.2297021\n\n\n0.2227442\n0.1349732\n0.2718842\n0.1412808\n0.2291176\n\n\n0.2778019\n0.1499741\n0.2674915\n0.1234459\n0.1812866\n\n\n0.2607000\n0.1459400\n0.2699009\n0.1289092\n0.1945499\n\n\n0.2345774\n0.1387000\n0.2718321\n0.1374089\n0.2174815\n\n\n0.3225620\n0.1580572\n0.2578893\n0.1097521\n0.1517394\n\n\n0.2948184\n0.1534585\n0.2643462\n0.1181267\n0.1692502\n\n\n0.2227442\n0.1349732\n0.2718842\n0.1412808\n0.2291176\n\n\n0.2468396\n0.1422647\n0.2712143\n0.1334031\n0.2062783\n\n\n0.3016008\n0.1547044\n0.2629090\n0.1160437\n0.1647421\n\n\n0.2521523\n0.1437172\n0.2707839\n0.1316751\n0.2016715\n\n\n0.2386041\n0.1399036\n0.2716895\n0.1360916\n0.2137112\n\n\n0.3175779\n0.1573270\n0.2591567\n0.1112275\n0.1547108\n\n\n0.3305983\n0.1591482\n0.2557571\n0.1074009\n0.1470955\n\n\n0.2601100\n0.1457911\n0.2699691\n0.1290995\n0.1950304\n\n\n0.2468396\n0.1422647\n0.2712143\n0.1334031\n0.2062783\n\n\n0.2227442\n0.1349732\n0.2718842\n0.1412808\n0.2291176\n\n\n0.3057289\n0.1554237\n0.2619872\n0.1147869\n0.1620732\n\n\n0.3559669\n0.1619125\n0.2483858\n0.1002085\n0.1335263\n\n\n0.3457069\n0.1609168\n0.2514760\n0.1030750\n0.1388252\n\n\n0.2227442\n0.1349732\n0.2718842\n0.1412808\n0.2291176\n\n\n0.3300228\n0.1590736\n0.2559133\n0.1075681\n0.1474222\n\n\n0.2227442\n0.1349732\n0.2718842\n0.1412808\n0.2291176\n\n\n0.2778019\n0.1499741\n0.2674915\n0.1234459\n0.1812866\n\n\n0.2227442\n0.1349732\n0.2718842\n0.1412808\n0.2291176\n\n\n0.2227442\n0.1349732\n0.2718842\n0.1412808\n0.2291176\n\n\n0.3856844\n0.1638949\n0.2387300\n0.0922310\n0.1194597\n\n\n0.4716581\n0.1627028\n0.2067831\n0.0717550\n0.0871010\n\n\n0.2491157\n0.1428937\n0.2710414\n0.1326621\n0.2042872\n\n\n0.3298347\n0.1590491\n0.2559643\n0.1076228\n0.1475292\n\n\n0.3850510\n0.1638663\n0.2389454\n0.0923960\n0.1197413\n\n\n0.2227442\n0.1349732\n0.2718842\n0.1412808\n0.2291176\n\n\n0.3109085\n0.1562850\n0.2607826\n0.1132221\n0.1588017\n\n\n0.3396774\n0.1602547\n0.2532250\n0.1047865\n0.1420564\n\n\n0.4233559\n0.1645823\n0.2253079\n0.0827991\n0.1039549\n\n\n0.2227442\n0.1349732\n0.2718842\n0.1412808\n0.2291176\n\n\n0.3943371\n0.1642286\n0.2357496\n0.0899983\n0.1156864\n\n\n0.3180998\n0.1574054\n0.2590261\n0.1110724\n0.1543963\n\n\n0.3359085\n0.1598115\n0.2542913\n0.1058663\n0.1441223\n\n\n0.2607000\n0.1459400\n0.2699009\n0.1289092\n0.1945499\n\n\n0.3004038\n0.1544903\n0.2631697\n0.1164097\n0.1655264\n\n\n0.2521523\n0.1437172\n0.2707839\n0.1316751\n0.2016715\n\n\n0.2552179\n0.1445305\n0.2704936\n0.1306809\n0.1990772\n\n\n0.2742407\n0.1491787\n0.2680592\n0.1245746\n0.1839467\n\n\n0.2865524\n0.1518306\n0.2659601\n0.1206945\n0.1749623\n\n\n0.2386041\n0.1399036\n0.2716895\n0.1360916\n0.2137112\n\n\n0.3334237\n0.1595068\n0.2549827\n0.1065825\n0.1455043\n\n\n0.3271853\n0.1586978\n0.2566757\n0.1083952\n0.1490460\n\n\n0.2730326\n0.1489036\n0.2682442\n0.1249587\n0.1848609\n\n\n0.3458390\n0.1609307\n0.2514372\n0.1030378\n0.1387554\n\n\n0.2227442\n0.1349732\n0.2718842\n0.1412808\n0.2291176\n\n\n0.3377278\n0.1600282\n0.2537792\n0.1053441\n0.1431206\n\n\n0.2345774\n0.1387000\n0.2718321\n0.1374089\n0.2174815\n\n\n0.2907709\n0.1526765\n0.2651560\n0.1193802\n0.1720165\n\n\n0.2904150\n0.1526064\n0.2652254\n0.1194907\n0.1722625\n\n\n0.2662055\n0.1472982\n0.2692148\n0.1271392\n0.1901424\n\n\n0.2552179\n0.1445305\n0.2704936\n0.1306809\n0.1990772\n\n\n0.2356749\n0.1390313\n0.2717993\n0.1370497\n0.2164448\n\n\n0.3120870\n0.1564746\n0.2605013\n0.1128680\n0.1580691\n\n\n0.3287125\n0.1589017\n0.2562670\n0.1079495\n0.1481693\n\n\n0.2630545\n0.1465278\n0.2696184\n0.1281510\n0.1926483\n\n\n0.3443060\n0.1607681\n0.2518870\n0.1034709\n0.1395680\n\n\n0.2416607\n0.1407955\n0.2715412\n0.1350927\n0.2109098\n\n\n0.2510078\n0.1434089\n0.2708845\n0.1320468\n0.2026519\n\n\n0.2808510\n0.1506367\n0.2669795\n0.1224835\n0.1790493\n\n\n0.2470295\n0.1423175\n0.2712006\n0.1333412\n0.2061111\n\n\n0.2356749\n0.1390313\n0.2717993\n0.1370497\n0.2164448\n\n\n0.3050172\n0.1553018\n0.2621485\n0.1150030\n0.1625294\n\n\n0.3032164\n0.1549894\n0.2625523\n0.1155509\n0.1636910\n\n\n0.2851627\n0.1515450\n0.2662158\n0.1211293\n0.1759471\n\n\n0.2479759\n0.1425800\n0.2711302\n0.1330330\n0.2052809\n\n\n0.2356749\n0.1390313\n0.2717993\n0.1370497\n0.2164448\n\n\n0.3655316\n0.1626948\n0.2453854\n0.0975883\n0.1288000\n\n\n0.2227442\n0.1349732\n0.2718842\n0.1412808\n0.2291176\n\n\n0.3408180\n0.1603844\n0.2528981\n0.1044612\n0.1414383\n\n\n0.2995919\n0.1543437\n0.2633449\n0.1166584\n0.1660611\n\n\n0.3146031\n0.1568715\n0.2598921\n0.1121143\n0.1565190\n\n\n0.3355452\n0.1597675\n0.2543930\n0.1059709\n0.1443234\n\n\n0.3029904\n0.1549498\n0.2626025\n0.1156197\n0.1638375\n\n\n0.3410147\n0.1604065\n0.2528416\n0.1044052\n0.1413320\n\n\n0.2345774\n0.1387000\n0.2718321\n0.1374089\n0.2174815\n\n\n0.2386041\n0.1399036\n0.2716895\n0.1360916\n0.2137112\n\n\n0.2616429\n0.1461767\n0.2697897\n0.1286054\n0.1937853\n\n\n0.2932287\n0.1531548\n0.2646686\n0.1186181\n0.1703298\n\n\n0.3732620\n0.1632261\n0.2428830\n0.0955071\n0.1251217\n\n\n0.2227442\n0.1349732\n0.2718842\n0.1412808\n0.2291176\n\n\n0.2227442\n0.1349732\n0.2718842\n0.1412808\n0.2291176\n\n\n0.2911270\n0.1527465\n0.2650862\n0.1192696\n0.1717708\n\n\n0.2553288\n0.1445596\n0.2704825\n0.1306449\n0.1989842\n\n\n0.3197845\n0.1576554\n0.2586010\n0.1105727\n0.1533865\n\n\n0.3200014\n0.1576872\n0.2585459\n0.1105085\n0.1532571\n\n\n0.2416607\n0.1407955\n0.2715412\n0.1350927\n0.2109098\n\n\n0.2227442\n0.1349732\n0.2718842\n0.1412808\n0.2291176\n\n\n0.2386041\n0.1399036\n0.2716895\n0.1360916\n0.2137112\n\n\n0.3420590\n0.1605231\n0.2525403\n0.1041081\n0.1407694\n\n\n0.2719481\n0.1486544\n0.2684070\n0.1253039\n0.1856866\n\n\n0.2921767\n0.1529514\n0.2648789\n0.1189439\n0.1710491\n\n\n0.3422286\n0.1605419\n0.2524913\n0.1040599\n0.1406783\n\n\n0.2674993\n0.1476091\n0.2690409\n0.1267247\n0.1891261\n\n\n0.2227442\n0.1349732\n0.2718842\n0.1412808\n0.2291176\n\n\n0.3968076\n0.1643043\n0.2348865\n0.0893681\n0.1146335\n\n\n0.2227442\n0.1349732\n0.2718842\n0.1412808\n0.2291176\n\n\n0.2851627\n0.1515450\n0.2662158\n0.1211293\n0.1759471\n\n\n0.3184585\n0.1574590\n0.2589360\n0.1109659\n0.1541806\n\n\n0.2822723\n0.1509398\n0.2667328\n0.1220362\n0.1780188\n\n\n0.2227442\n0.1349732\n0.2718842\n0.1412808\n0.2291176\n\n\n0.3458390\n0.1609307\n0.2514372\n0.1030378\n0.1387554\n\n\n0.2227442\n0.1349732\n0.2718842\n0.1412808\n0.2291176\n\n\n0.2880060\n0.1521257\n0.2656877\n0.1202407\n0.1739399\n\n\n0.4371880\n0.1643501\n0.2201272\n0.0795199\n0.0988148\n\n\n0.2227442\n0.1349732\n0.2718842\n0.1412808\n0.2291176\n\n\n0.4004796\n0.1644009\n0.2335940\n0.0884375\n0.1130881\n\n\n0.3183213\n0.1574386\n0.2589704\n0.1110066\n0.1542631\n\n\n0.2227442\n0.1349732\n0.2718842\n0.1412808\n0.2291176\n\n\n0.3086472\n0.1559146\n0.2613149\n0.1139036\n0.1602196\n\n\n0.2227442\n0.1349732\n0.2718842\n0.1412808\n0.2291176\n\n\n0.2479759\n0.1425800\n0.2711302\n0.1330330\n0.2052809\n\n\n0.3559279\n0.1619090\n0.2483978\n0.1002193\n0.1335460\n\n\n0.2472195\n0.1423704\n0.2711867\n0.1332794\n0.2059441\n\n\n0.2765841\n0.1497048\n0.2676894\n0.1238313\n0.1821905\n\n\n0.2730326\n0.1489036\n0.2682442\n0.1249587\n0.1848609\n\n\n0.3455750\n0.1609029\n0.2515149\n0.1031123\n0.1388949\n\n\n0.2386041\n0.1399036\n0.2716895\n0.1360916\n0.2137112\n\n\n0.4194079\n0.1646019\n0.2267645\n0.0837529\n0.1054729\n\n\n0.2416607\n0.1407955\n0.2715412\n0.1350927\n0.2109098\n\n\n0.2227442\n0.1349732\n0.2718842\n0.1412808\n0.2291176\n\n\n0.2227442\n0.1349732\n0.2718842\n0.1412808\n0.2291176\n\n\n0.2552179\n0.1445305\n0.2704936\n0.1306809\n0.1990772\n\n\n0.3386529\n0.1601365\n0.2535169\n0.1050793\n0.1426144\n\n\n0.2227442\n0.1349732\n0.2718842\n0.1412808\n0.2291176\n\n\n0.2227442\n0.1349732\n0.2718842\n0.1412808\n0.2291176\n\n\n0.3756881\n0.1633746\n0.2420843\n0.0948607\n0.1239923\n\n\n0.3487268\n0.1612269\n0.2505810\n0.1022253\n0.1372400\n\n\n0.2510078\n0.1434089\n0.2708845\n0.1320468\n0.2026519\n\n\n0.3102630\n0.1561801\n0.2609356\n0.1134164\n0.1592049\n\n\n0.2491157\n0.1428937\n0.2710414\n0.1326621\n0.2042872\n\n\n0.2620706\n0.1462835\n0.2697384\n0.1284676\n0.1934399\n\n\n0.2599182\n0.1457425\n0.2699910\n0.1291613\n0.1951869\n\n\n0.2725744\n0.1487986\n0.2683134\n0.1251045\n0.1852091\n\n\n0.2714814\n0.1485465\n0.2684760\n0.1254526\n0.1860434\n\n\n0.2738392\n0.1490876\n0.2681212\n0.1247022\n0.1842498\n\n\n0.2867563\n0.1518722\n0.2659222\n0.1206308\n0.1748184\n\n\n0.2416607\n0.1407955\n0.2715412\n0.1350927\n0.2109098\n\n\n0.3875006\n0.1639739\n0.2381101\n0.0917590\n0.1186564\n\n\n0.3538072\n0.1617165\n0.2490477\n0.1008071\n0.1346214\n\n\n0.3111221\n0.1563195\n0.2607318\n0.1131579\n0.1586686\n\n\n0.3826704\n0.1637534\n0.2397518\n0.0930182\n0.1208063\n\n\n0.2345774\n0.1387000\n0.2718321\n0.1374089\n0.2174815\n\n\n0.3186802\n0.1574921\n0.2588802\n0.1109001\n0.1540475\n\n\n0.2818784\n0.1508562\n0.2668016\n0.1221601\n0.1783036\n\n\n0.2840242\n0.1513084\n0.2664219\n0.1214861\n0.1767594\n\n\n0.2356749\n0.1390313\n0.2717993\n0.1370497\n0.2164448\n\n\n0.2386041\n0.1399036\n0.2716895\n0.1360916\n0.2137112\n\n\n0.3856844\n0.1638949\n0.2387300\n0.0922310\n0.1194597\n\n\n0.2672992\n0.1475612\n0.2690681\n0.1267887\n0.1892828\n\n\n0.2810622\n0.1506820\n0.2669431\n0.1224170\n0.1788957\n\n\n0.2642250\n0.1468162\n0.2694718\n0.1277748\n0.1917122\n\n\n0.2759133\n0.1495552\n0.2677967\n0.1240439\n0.1826909\n\n\n0.2227442\n0.1349732\n0.2718842\n0.1412808\n0.2291176\n\n\n0.2416607\n0.1407955\n0.2715412\n0.1350927\n0.2109098\n\n\n0.2820803\n0.1508991\n0.2667664\n0.1220966\n0.1781576\n\n\n0.3496550\n0.1613194\n0.2503034\n0.1019652\n0.1367571\n\n\n0.2819621\n0.1508740\n0.2667870\n0.1221338\n0.1782431\n\n\n0.3102630\n0.1561801\n0.2609356\n0.1134164\n0.1592049\n\n\n0.2630545\n0.1465278\n0.2696184\n0.1281510\n0.1926483\n\n\n0.3728867\n0.1632024\n0.2430060\n0.0956074\n0.1252974\n\n\n0.2774752\n0.1499021\n0.2675450\n0.1235492\n0.1815285\n\n\n0.2762680\n0.1496344\n0.2677401\n0.1239314\n0.1824261\n\n\n0.2607000\n0.1459400\n0.2699009\n0.1289092\n0.1945499\n\n\n0.3881875\n0.1640025\n0.2378749\n0.0915810\n0.1183542\n\n\n0.2650151\n0.1470094\n0.2693706\n0.1275210\n0.1910838\n\n\n0.2861997\n0.1517585\n0.2660255\n0.1208048\n0.1752116\n\n\n0.3205306\n0.1577646\n0.2584111\n0.1103518\n0.1529418\n\n\n0.2584570\n0.1453702\n0.2701545\n0.1296330\n0.1963851\n\n\n0.2694953\n0.1480826\n0.2687632\n0.1260864\n0.1875725\n\n\n0.2356749\n0.1390313\n0.2717993\n0.1370497\n0.2164448\n\n\n0.3100341\n0.1561428\n0.2609896\n0.1134853\n0.1593481\n\n\n0.2816718\n0.1508122\n0.2668376\n0.1222251\n0.1784533\n\n\n0.2416607\n0.1407955\n0.2715412\n0.1350927\n0.2109098\n\n\n0.2553288\n0.1445596\n0.2704825\n0.1306449\n0.1989842\n\n\n0.2682956\n0.1477989\n0.2689314\n0.1264698\n0.1885042\n\n\n0.2818784\n0.1508562\n0.2668016\n0.1221601\n0.1783036\n\n\n0.2808510\n0.1506367\n0.2669795\n0.1224835\n0.1790493\n\n\n0.2730326\n0.1489036\n0.2682442\n0.1249587\n0.1848609\n\n\n0.2674993\n0.1476091\n0.2690409\n0.1267247\n0.1891261\n\n\n0.3334237\n0.1595068\n0.2549827\n0.1065825\n0.1455043\n\n\n0.2638329\n0.1467199\n0.2695213\n0.1279008\n0.1920251\n\n\n0.2541703\n0.1442546\n0.2705962\n0.1310204\n0.1999586\n\n\n0.2521523\n0.1437172\n0.2707839\n0.1316751\n0.2016715\n\n\n0.2470295\n0.1423175\n0.2712006\n0.1333412\n0.2061111\n\n\n0.2552179\n0.1445305\n0.2704936\n0.1306809\n0.1990772\n\n\n0.2552179\n0.1445305\n0.2704936\n0.1306809\n0.1990772\n\n\n0.2227442\n0.1349732\n0.2718842\n0.1412808\n0.2291176\n\n\n0.2631629\n0.1465547\n0.2696050\n0.1281162\n0.1925613\n\n\n0.2472195\n0.1423704\n0.2711867\n0.1332794\n0.2059441\n\n\n0.4045784\n0.1644863\n0.2321382\n0.0874072\n0.1113899\n\n\n0.2227442\n0.1349732\n0.2718842\n0.1412808\n0.2291176\n\n\n0.2726901\n0.1488252\n0.2682960\n0.1250677\n0.1851211\n\n\n0.3450638\n0.1608489\n0.2516650\n0.1032566\n0.1391656\n\n\n0.3159205\n0.1570750\n0.2595684\n0.1117210\n0.1557150\n\n\n0.2227442\n0.1349732\n0.2718842\n0.1412808\n0.2291176\n\n\n0.2416607\n0.1407955\n0.2715412\n0.1350927\n0.2109098\n\n\n0.3362937\n0.1598578\n0.2541833\n0.1057556\n0.1439095\n\n\n0.3324032\n0.1593787\n0.2552638\n0.1068776\n0.1460766\n\n\n0.3528184\n0.1616243\n0.2493488\n0.1010820\n0.1351264\n\n\n0.4941234\n0.1608455\n0.1978328\n0.0669914\n0.0802070\n\n\n0.3535738\n0.1616949\n0.2491189\n0.1008720\n0.1347404\n\n\n0.3146031\n0.1568715\n0.2598921\n0.1121143\n0.1565190\n\n\n0.3270676\n0.1586819\n0.2567070\n0.1084296\n0.1491139\n\n\n0.3259074\n0.1585242\n0.2570147\n0.1087691\n0.1497845\n\n\n0.4066651\n0.1645209\n0.2313919\n0.0868860\n0.1105361\n\n\n0.2227442\n0.1349732\n0.2718842\n0.1412808\n0.2291176\n\n\n0.2227442\n0.1349732\n0.2718842\n0.1412808\n0.2291176\n\n\n0.2597218\n0.1456927\n0.2700134\n0.1292247\n0.1953474\n\n\n0.3003169\n0.1544747\n0.2631885\n0.1164363\n0.1655835\n\n\n0.2227442\n0.1349732\n0.2718842\n0.1412808\n0.2291176\n\n\n0.2943132\n0.1533624\n0.2644493\n0.1182827\n0.1695924\n\n\n0.2714814\n0.1485465\n0.2684760\n0.1254526\n0.1860434\n\n\n0.2552179\n0.1445305\n0.2704936\n0.1306809\n0.1990772\n\n\n0.3792417\n0.1635763\n0.2409033\n0.0939197\n0.1223590\n\n\n0.2841429\n0.1513332\n0.2664006\n0.1214489\n0.1766745\n\n\n0.2468396\n0.1422647\n0.2712143\n0.1334031\n0.2062783\n\n\n0.3895221\n0.1640562\n0.2374165\n0.0912358\n0.1177694\n\n\n0.2511953\n0.1434596\n0.2708683\n0.1319859\n0.2024909\n\n\n0.2479759\n0.1425800\n0.2711302\n0.1330330\n0.2052809\n\n\n0.2903048\n0.1525846\n0.2652469\n0.1195250\n0.1723388\n\n\n0.2386041\n0.1399036\n0.2716895\n0.1360916\n0.2137112\n\n\n0.3064622\n0.1555485\n0.2618198\n0.1145646\n0.1616049\n\n\n0.2652141\n0.1470578\n0.2693449\n0.1274572\n0.1909261\n\n\n0.2470295\n0.1423175\n0.2712006\n0.1333412\n0.2061111\n\n\n0.3557328\n0.1618916\n0.2484578\n0.1002733\n0.1336445\n\n\n0.2682956\n0.1477989\n0.2689314\n0.1264698\n0.1885042\n\n\n0.2784951\n0.1501263\n0.2673772\n0.1232267\n0.1807747\n\n\n0.3135085\n0.1567001\n0.2601586\n0.1124418\n0.1571910\n\n\n0.4070641\n0.1645268\n0.2312488\n0.0867867\n0.1103736\n\n\n0.2227442\n0.1349732\n0.2718842\n0.1412808\n0.2291176\n\n\n0.2472195\n0.1423704\n0.2711867\n0.1332794\n0.2059441\n\n\n0.2822723\n0.1509398\n0.2667328\n0.1220362\n0.1780188\n\n\n0.3390669\n0.1601844\n0.2533991\n0.1049609\n0.1423886\n\n\n0.3162884\n0.1571314\n0.2594774\n0.1116114\n0.1554914\n\n\n0.3336453\n0.1595343\n0.2549214\n0.1065185\n0.1453804\n\n\n0.4161316\n0.1646022\n0.2279654\n0.0845504\n0.1067505\n\n\n0.2607000\n0.1459400\n0.2699009\n0.1289092\n0.1945499\n\n\n0.2985268\n0.1541497\n0.2635725\n0.1169851\n0.1667660\n\n\n0.2804387\n0.1505481\n0.2670501\n0.1226134\n0.1793497\n\n\n0.3856844\n0.1638949\n0.2387300\n0.0922310\n0.1194597\n\n\n0.2595255\n0.1456429\n0.2700356\n0.1292880\n0.1955080\n\n\n0.2345774\n0.1387000\n0.2718321\n0.1374089\n0.2174815\n\n\n0.4248463\n0.1645695\n0.2247553\n0.0824411\n0.1033878\n\n\n0.3254002\n0.1584546\n0.2571485\n0.1089178\n0.1500789\n\n\n0.2725744\n0.1487986\n0.2683134\n0.1251045\n0.1852091\n\n\n0.3046514\n0.1552388\n0.2622311\n0.1151142\n0.1627645\n\n\n0.2227442\n0.1349732\n0.2718842\n0.1412808\n0.2291176\n\n\n0.2227442\n0.1349732\n0.2718842\n0.1412808\n0.2291176\n\n\n0.2726901\n0.1488252\n0.2682960\n0.1250677\n0.1851211\n\n\n0.3856844\n0.1638949\n0.2387300\n0.0922310\n0.1194597\n\n\n0.2827898\n0.1510493\n0.2666417\n0.1218736\n0.1776456\n\n\n0.2630545\n0.1465278\n0.2696184\n0.1281510\n0.1926483\n\n\n0.2640265\n0.1467675\n0.2694969\n0.1278385\n0.1918705\n\n\n0.2345774\n0.1387000\n0.2718321\n0.1374089\n0.2174815\n\n\n0.3003169\n0.1544747\n0.2631885\n0.1164363\n0.1655835\n\n\n0.3038897\n0.1551069\n0.2624021\n0.1153458\n0.1632554\n\n\n0.2985268\n0.1541497\n0.2635725\n0.1169851\n0.1667660\n\n\n0.2932287\n0.1531548\n0.2646686\n0.1186181\n0.1703298\n\n\n0.3979196\n0.1643355\n0.2344962\n0.0890856\n0.1141631\n\n\n0.3537072\n0.1617072\n0.2490783\n0.1008349\n0.1346724\n\n\n0.3450638\n0.1608489\n0.2516650\n0.1032566\n0.1391656\n\n\n0.4017001\n0.1644288\n0.2331619\n0.0881298\n0.1125794\n\n\n0.3538072\n0.1617165\n0.2490477\n0.1008071\n0.1346214\n\n\n0.2240729\n0.1354060\n0.2719069\n0.1408464\n0.2277677\n\n\n0.3575123\n0.1620484\n0.2479085\n0.0997817\n0.1327490\n\n\n0.2521523\n0.1437172\n0.2707839\n0.1316751\n0.2016715\n\n\n0.3218612\n0.1579570\n0.2580702\n0.1099588\n0.1521529\n\n\n0.2356749\n0.1390313\n0.2717993\n0.1370497\n0.2164448\n\n\n0.2584197\n0.1453607\n0.2701586\n0.1296451\n0.1964158\n\n\n0.2584197\n0.1453607\n0.2701586\n0.1296451\n0.1964158\n\n\n0.3638586\n0.1625680\n0.2459181\n0.0980430\n0.1296124\n\n\n0.2227442\n0.1349732\n0.2718842\n0.1412808\n0.2291176\n\n\n0.2898842\n0.1525013\n0.2653284\n0.1196558\n0.1726303\n\n\n0.2491157\n0.1428937\n0.2710414\n0.1326621\n0.2042872\n\n\n0.3560672\n0.1619214\n0.2483549\n0.1001808\n0.1334756\n\n\n0.4017001\n0.1644288\n0.2331619\n0.0881298\n0.1125794\n\n\n0.2227442\n0.1349732\n0.2718842\n0.1412808\n0.2291176\n\n\n0.2227442\n0.1349732\n0.2718842\n0.1412808\n0.2291176\n\n\n0.2640265\n0.1467675\n0.2694969\n0.1278385\n0.1918705\n\n\n0.4549741\n0.1636867\n0.2133102\n0.0754424\n0.0925866\n\n\n0.3294747\n0.1590020\n0.2560616\n0.1077276\n0.1477341\n\n\n0.3473476\n0.1610871\n0.2509913\n0.1026128\n0.1379612\n\n\n0.3600629\n0.1622646\n0.2471144\n0.0990803\n0.1314778\n\n\n0.3017442\n0.1547299\n0.2628775\n0.1159999\n0.1646485\n\n\n0.3138592\n0.1567552\n0.2600734\n0.1123368\n0.1569753\n\n\n0.3003169\n0.1544747\n0.2631885\n0.1164363\n0.1655835\n\n\n0.3003169\n0.1544747\n0.2631885\n0.1164363\n0.1655835\n\n\n0.3334453\n0.1595095\n0.2549767\n0.1065763\n0.1454922\n\n\n0.3321820\n0.1593508\n0.2553246\n0.1069416\n0.1462010\n\n\n0.2599182\n0.1457425\n0.2699910\n0.1291613\n0.1951869\n\n\n0.3048008\n0.1552646\n0.2621974\n0.1150688\n0.1626684\n\n\n0.3804158\n0.1636389\n0.2405103\n0.0936103\n0.1218248\n\n\n0.2965906\n0.1537918\n0.2639802\n0.1175803\n0.1680571\n\n\n0.3060954\n0.1554862\n0.2619037\n0.1146758\n0.1618389\n\n\n0.3064622\n0.1555485\n0.2618198\n0.1145646\n0.1616049\n\n\n0.2841824\n0.1513415\n0.2663934\n0.1214365\n0.1766462\n\n\n0.2416607\n0.1407955\n0.2715412\n0.1350927\n0.2109098\n\n\n0.2479759\n0.1425800\n0.2711302\n0.1330330\n0.2052809\n\n\n0.3571327\n0.1620153\n0.2480261\n0.0998865\n0.1329394\n\n\n0.2227442\n0.1349732\n0.2718842\n0.1412808\n0.2291176\n\n\n0.3173883\n0.1572984\n0.2592041\n0.1112839\n0.1548253\n\n\n0.2386041\n0.1399036\n0.2716895\n0.1360916\n0.2137112\n\n\n0.2810622\n0.1506820\n0.2669431\n0.1224170\n0.1788957\n\n\n0.2472195\n0.1423704\n0.2711867\n0.1332794\n0.2059441\n\n\n0.2662055\n0.1472982\n0.2692148\n0.1271392\n0.1901424\n\n\n0.2898842\n0.1525013\n0.2653284\n0.1196558\n0.1726303\n\n\n0.3272923\n0.1587122\n0.2566472\n0.1083639\n0.1489844\n\n\n0.4093488\n0.1645564\n0.2304272\n0.0862192\n0.1094484\n\n\n0.2806448\n0.1505925\n0.2670148\n0.1225485\n0.1791995\n\n\n0.3100341\n0.1561428\n0.2609896\n0.1134853\n0.1593481\n\n\n0.3334237\n0.1595068\n0.2549827\n0.1065825\n0.1455043\n\n\n0.3162884\n0.1571314\n0.2594774\n0.1116114\n0.1554914\n\n\n0.3228596\n0.1580995\n0.2578123\n0.1096644\n0.1515642\n\n\n0.2640265\n0.1467675\n0.2694969\n0.1278385\n0.1918705\n\n\n0.2227442\n0.1349732\n0.2718842\n0.1412808\n0.2291176\n\n\n0.3334237\n0.1595068\n0.2549827\n0.1065825\n0.1455043\n\n\n0.2782900\n0.1500813\n0.2674111\n0.1232916\n0.1809260\n\n\n0.2873285\n0.1519886\n0.2658153\n0.1204521\n0.1744155\n\n\n0.2347608\n0.1387556\n0.2718270\n0.1373489\n0.2173078\n\n\n0.2672992\n0.1475612\n0.2690681\n0.1267887\n0.1892828\n\n\n0.2640265\n0.1467675\n0.2694969\n0.1278385\n0.1918705\n\n\n0.2759133\n0.1495552\n0.2677967\n0.1240439\n0.1826909\n\n\n0.2541703\n0.1442546\n0.2705962\n0.1310204\n0.1999586\n\n\n0.3300604\n0.1590785\n0.2559031\n0.1075572\n0.1474008\n\n\n0.2543639\n0.1443058\n0.2705775\n0.1309576\n0.1997953\n\n\n0.3173883\n0.1572984\n0.2592041\n0.1112839\n0.1548253\n\n\n0.4181710\n0.1646037\n0.2272187\n0.0840533\n0.1059533\n\n\n0.3856844\n0.1638949\n0.2387300\n0.0922310\n0.1194597\n\n\n0.3222009\n0.1580057\n0.2579826\n0.1098585\n0.1519523\n\n\n0.2227442\n0.1349732\n0.2718842\n0.1412808\n0.2291176\n\n\n0.2479759\n0.1425800\n0.2711302\n0.1330330\n0.2052809\n\n\n0.2934404\n0.1531955\n0.2646260\n0.1185526\n0.1701855\n\n\n0.2684961\n0.1478465\n0.2689036\n0.1264057\n0.1883481\n\n\n0.3259074\n0.1585242\n0.2570147\n0.1087691\n0.1497845\n\n\n0.3159783\n0.1570839\n0.2595541\n0.1117038\n0.1556799\n\n\n0.3036377\n0.1550630\n0.2624585\n0.1154225\n0.1634182\n\n\n0.2416607\n0.1407955\n0.2715412\n0.1350927\n0.2109098\n\n\n0.2227442\n0.1349732\n0.2718842\n0.1412808\n0.2291176\n\n\n0.2584197\n0.1453607\n0.2701586\n0.1296451\n0.1964158\n\n\n0.2911270\n0.1527465\n0.2650862\n0.1192696\n0.1717708\n\n\n0.3633241\n0.1625266\n0.2460876\n0.0981886\n0.1298732\n\n\n0.2601100\n0.1457911\n0.2699691\n0.1290995\n0.1950304\n\n\n0.3422834\n0.1605479\n0.2524754\n0.1040444\n0.1406489\n\n\n0.3624023\n0.1624542\n0.2463791\n0.0984400\n0.1303244\n\n\n0.2642250\n0.1468162\n0.2694718\n0.1277748\n0.1917122\n\n\n0.2227442\n0.1349732\n0.2718842\n0.1412808\n0.2291176\n\n\n0.2356749\n0.1390313\n0.2717993\n0.1370497\n0.2164448\n\n\n0.3045330\n0.1552184\n0.2622578\n0.1151502\n0.1628407\n\n\n0.3104764\n0.1562149\n0.2608851\n0.1133522\n0.1590715\n\n\n0.2597218\n0.1456927\n0.2700134\n0.1292247\n0.1953474\n\n\n0.3460370\n0.1609514\n0.2513788\n0.1029819\n0.1386509\n\n\n0.2662055\n0.1472982\n0.2692148\n0.1271392\n0.1901424\n\n\n0.3498817\n0.1613417\n0.2502354\n0.1019017\n0.1366394\n\n\n0.2227442\n0.1349732\n0.2718842\n0.1412808\n0.2291176\n\n\n0.3536071\n0.1616980\n0.2491088\n0.1008627\n0.1347234\n\n\n0.3839923\n0.1638171\n0.2393047\n0.0926723\n0.1202136\n\n\n0.3579257\n0.1620841\n0.2477804\n0.0996678\n0.1325420\n\n\n0.2227442\n0.1349732\n0.2718842\n0.1412808\n0.2291176\n\n\n0.2638329\n0.1467199\n0.2695213\n0.1279008\n0.1920251\n\n\n0.2599182\n0.1457425\n0.2699910\n0.1291613\n0.1951869\n\n\n0.3455310\n0.1608983\n0.2515278\n0.1031247\n0.1389182\n\n\n0.2416607\n0.1407955\n0.2715412\n0.1350927\n0.2109098\n\n\n0.2976315\n0.1539850\n0.2637620\n0.1172601\n0.1673614\n\n\n0.2976162\n0.1539822\n0.2637652\n0.1172648\n0.1673716\n\n\n0.2386041\n0.1399036\n0.2716895\n0.1360916\n0.2137112\n\n\n0.2640265\n0.1467675\n0.2694969\n0.1278385\n0.1918705\n\n\n0.2227442\n0.1349732\n0.2718842\n0.1412808\n0.2291176\n\n\n0.3083257\n0.1558612\n0.2613898\n0.1140007\n0.1604226\n\n\n0.2227442\n0.1349732\n0.2718842\n0.1412808\n0.2291176\n\n\n0.3747306\n0.1633170\n0.2424003\n0.0951155\n0.1244366\n\n\n0.2827898\n0.1510493\n0.2666417\n0.1218736\n0.1776456\n\n\n0.3231733\n0.1581439\n0.2577309\n0.1095720\n0.1513798\n\n\n0.2874480\n0.1520129\n0.2657929\n0.1204148\n0.1743315\n\n\n0.2386041\n0.1399036\n0.2716895\n0.1360916\n0.2137112\n\n\n0.2217482\n0.1346464\n0.2718622\n0.1416062\n0.2301369\n\n\n0.2670993\n0.1475133\n0.2690951\n0.1268528\n0.1894395\n\n\n0.3334237\n0.1595068\n0.2549827\n0.1065825\n0.1455043\n\n\n0.4098897\n0.1645624\n0.2302321\n0.0860852\n0.1092306\n\n\n0.2227442\n0.1349732\n0.2718842\n0.1412808\n0.2291176\n\n\n0.2730326\n0.1489036\n0.2682442\n0.1249587\n0.1848609\n\n\n0.3281280\n0.1588241\n0.2564239\n0.1081200\n0.1485041\n\n\n0.2468396\n0.1422647\n0.2712143\n0.1334031\n0.2062783\n\n\n0.3110492\n0.1563077\n0.2607492\n0.1131798\n0.1587141\n\n\n0.2386041\n0.1399036\n0.2716895\n0.1360916\n0.2137112\n\n\n0.2759133\n0.1495552\n0.2677967\n0.1240439\n0.1826909\n\n\n0.2992502\n0.1542817\n0.2634182\n0.1167631\n0.1662868\n\n\n0.3057289\n0.1554237\n0.2619872\n0.1147869\n0.1620732\n\n\n0.2347608\n0.1387556\n0.2718270\n0.1373489\n0.2173078\n\n\n0.2227442\n0.1349732\n0.2718842\n0.1412808\n0.2291176\n\n\n0.2950308\n0.1534987\n0.2643027\n0.1180611\n0.1691067\n\n\n0.2662055\n0.1472982\n0.2692148\n0.1271392\n0.1901424\n\n\n0.2610891\n0.1460379\n0.2698553\n0.1287838\n0.1942339\n\n\n0.2670993\n0.1475133\n0.2690951\n0.1268528\n0.1894395\n\n\n0.3980595\n0.1643393\n0.2344471\n0.0890501\n0.1141040\n\n\n0.2630545\n0.1465278\n0.2696184\n0.1281510\n0.1926483\n\n\n0.2227442\n0.1349732\n0.2718842\n0.1412808\n0.2291176\n\n\n0.2386041\n0.1399036\n0.2716895\n0.1360916\n0.2137112\n\n\n0.2227442\n0.1349732\n0.2718842\n0.1412808\n0.2291176\n\n\n0.2470295\n0.1423175\n0.2712006\n0.1333412\n0.2061111\n\n\n0.2959570\n0.1536732\n0.2641118\n0.1177755\n0.1684825\n\n\n0.2886346\n0.1522521\n0.2655684\n0.1200448\n0.1735001\n\n\n0.2941214\n0.1533259\n0.2644883\n0.1183420\n0.1697225\n\n\n0.2730326\n0.1489036\n0.2682442\n0.1249587\n0.1848609\n\n\n0.2567320\n0.1449256\n0.2703392\n0.1301907\n0.1978126\n\n\n0.2682956\n0.1477989\n0.2689314\n0.1264698\n0.1885042\n\n\n0.2816718\n0.1508122\n0.2668376\n0.1222251\n0.1784533\n\n\n0.2601100\n0.1457911\n0.2699691\n0.1290995\n0.1950304\n\n\n0.2468396\n0.1422647\n0.2712143\n0.1334031\n0.2062783\n\n\n0.2822969\n0.1509451\n0.2667285\n0.1220285\n0.1780010\n\n\n0.2778019\n0.1499741\n0.2674915\n0.1234459\n0.1812866\n\n\n0.3138592\n0.1567552\n0.2600734\n0.1123368\n0.1569753\n\n\n0.2345774\n0.1387000\n0.2718321\n0.1374089\n0.2174815\n\n\n0.2904150\n0.1526064\n0.2652254\n0.1194907\n0.1722625\n\n\n0.2888393\n0.1522931\n0.2655293\n0.1199810\n0.1733572\n\n\n0.3407853\n0.1603807\n0.2529075\n0.1044706\n0.1414560\n\n\n0.2227442\n0.1349732\n0.2718842\n0.1412808\n0.2291176\n\n\n0.3305983\n0.1591482\n0.2557571\n0.1074009\n0.1470955\n\n\n0.2584197\n0.1453607\n0.2701586\n0.1296451\n0.1964158\n\n\n0.2841824\n0.1513415\n0.2663934\n0.1214365\n0.1766462\n\n\n0.2618779\n0.1462354\n0.2697616\n0.1285297\n0.1935954\n\n\n0.3093896\n0.1560372\n0.2611413\n0.1136796\n0.1597524\n\n\n0.3571327\n0.1620153\n0.2480261\n0.0998865\n0.1329394\n\n\n0.2347608\n0.1387556\n0.2718270\n0.1373489\n0.2173078\n\n\n0.2662055\n0.1472982\n0.2692148\n0.1271392\n0.1901424\n\n\n0.2416607\n0.1407955\n0.2715412\n0.1350927\n0.2109098\n\n\n0.2607000\n0.1459400\n0.2699009\n0.1289092\n0.1945499\n\n\n0.2227442\n0.1349732\n0.2718842\n0.1412808\n0.2291176\n\n\n0.3070258\n0.1556437\n0.2616905\n0.1143939\n0.1612462\n\n\n0.2227442\n0.1349732\n0.2718842\n0.1412808\n0.2291176\n\n\n0.2227442\n0.1349732\n0.2718842\n0.1412808\n0.2291176\n\n\n0.2347608\n0.1387556\n0.2718270\n0.1373489\n0.2173078\n\n\n0.2672992\n0.1475612\n0.2690681\n0.1267887\n0.1892828\n\n\n0.2227442\n0.1349732\n0.2718842\n0.1412808\n0.2291176\n\n\n0.2846773\n0.1514444\n0.2663041\n0.1212814\n0.1762929\n\n\n0.2939901\n0.1533008\n0.2645149\n0.1183826\n0.1698116\n\n\n0.2946011\n0.1534172\n0.2643906\n0.1181938\n0.1693973\n\n\n0.2470295\n0.1423175\n0.2712006\n0.1333412\n0.2061111\n\n\n0.2990362\n0.1542427\n0.2634640\n0.1168288\n0.1664284\n\n\n0.2227442\n0.1349732\n0.2718842\n0.1412808\n0.2291176\n\n\n0.2782900\n0.1500813\n0.2674111\n0.1232916\n0.1809260\n\n\n0.2521523\n0.1437172\n0.2707839\n0.1316751\n0.2016715\n\n\n0.2227442\n0.1349732\n0.2718842\n0.1412808\n0.2291176\n\n\n0.3057289\n0.1554237\n0.2619872\n0.1147869\n0.1620732\n\n\n0.2386041\n0.1399036\n0.2716895\n0.1360916\n0.2137112\n\n\n0.4093488\n0.1645564\n0.2304272\n0.0862192\n0.1094484\n\n\n0.2541703\n0.1442546\n0.2705962\n0.1310204\n0.1999586\n\n\n0.2990362\n0.1542427\n0.2634640\n0.1168288\n0.1664284\n\n\n0.2470295\n0.1423175\n0.2712006\n0.1333412\n0.2061111\n\n\n0.2345774\n0.1387000\n0.2718321\n0.1374089\n0.2174815\n\n\n0.2472195\n0.1423704\n0.2711867\n0.1332794\n0.2059441\n\n\n0.2643479\n0.1468463\n0.2694562\n0.1277353\n0.1916143\n\n\n0.3795165\n0.1635911\n0.2408115\n0.0938472\n0.1222338\n\n\n0.3067775\n0.1556018\n0.2617475\n0.1144690\n0.1614041\n\n\n0.2752532\n0.1494073\n0.2679012\n0.1242532\n0.1831852\n\n\n0.3897650\n0.1640657\n0.2373329\n0.0911730\n0.1176634\n\n\n0.2227442\n0.1349732\n0.2718842\n0.1412808\n0.2291176\n\n\n0.3173567\n0.1572937\n0.2592120\n0.1112933\n0.1548444\n\n\n0.3412825\n0.1604366\n0.2527645\n0.1043290\n0.1411875\n\n\n0.2714814\n0.1485465\n0.2684760\n0.1254526\n0.1860434\n\n\n0.3040749\n0.1551391\n0.2623607\n0.1152895\n0.1631359\n\n\n0.3259074\n0.1585242\n0.2570147\n0.1087691\n0.1497845\n\n\n0.2227442\n0.1349732\n0.2718842\n0.1412808\n0.2291176\n\n\n0.3102630\n0.1561801\n0.2609356\n0.1134164\n0.1592049\n\n\n0.2541703\n0.1442546\n0.2705962\n0.1310204\n0.1999586\n\n\n0.2227442\n0.1349732\n0.2718842\n0.1412808\n0.2291176\n\n\n0.3930255\n0.1641849\n0.2362057\n0.0903341\n0.1162497\n\n\n0.2806448\n0.1505925\n0.2670148\n0.1225485\n0.1791995\n\n\n0.2880060\n0.1521257\n0.2656877\n0.1202407\n0.1739399\n\n\n0.3649848\n0.1626538\n0.2455599\n0.0977367\n0.1290648\n\n\n0.2822723\n0.1509398\n0.2667328\n0.1220362\n0.1780188\n\n\n0.3175779\n0.1573270\n0.2591567\n0.1112275\n0.1547108\n\n\n0.2386041\n0.1399036\n0.2716895\n0.1360916\n0.2137112\n\n\n0.3146031\n0.1568715\n0.2598921\n0.1121143\n0.1565190\n\n\n0.2808510\n0.1506367\n0.2669795\n0.1224835\n0.1790493\n\n\n0.3443279\n0.1607704\n0.2518806\n0.1034647\n0.1395564\n\n\n0.2386041\n0.1399036\n0.2716895\n0.1360916\n0.2137112\n\n\n0.3144773\n0.1568519\n0.2599228\n0.1121519\n0.1565961\n\n\n0.3558276\n0.1619001\n0.2484287\n0.1002471\n0.1335966\n\n\n0.2948083\n0.1534566\n0.2643483\n0.1181298\n0.1692571\n\n\n0.2511953\n0.1434596\n0.2708683\n0.1319859\n0.2024909\n\n\n0.2227442\n0.1349732\n0.2718842\n0.1412808\n0.2291176\n\n\n0.2227442\n0.1349732\n0.2718842\n0.1412808\n0.2291176\n\n\n0.3205306\n0.1577646\n0.2584111\n0.1103518\n0.1529418\n\n\n0.2468396\n0.1422647\n0.2712143\n0.1334031\n0.2062783\n\n\n0.2416607\n0.1407955\n0.2715412\n0.1350927\n0.2109098\n\n\n0.2808510\n0.1506367\n0.2669795\n0.1224835\n0.1790493\n\n\n0.2552179\n0.1445305\n0.2704936\n0.1306809\n0.1990772\n\n\n0.2227442\n0.1349732\n0.2718842\n0.1412808\n0.2291176\n\n\n0.2630545\n0.1465278\n0.2696184\n0.1281510\n0.1926483\n\n\n0.3173883\n0.1572984\n0.2592041\n0.1112839\n0.1548253\n\n\n0.2227442\n0.1349732\n0.2718842\n0.1412808\n0.2291176\n\n\n0.2992502\n0.1542817\n0.2634182\n0.1167631\n0.1662868\n\n\n0.2638329\n0.1467199\n0.2695213\n0.1279008\n0.1920251\n\n\n0.2694953\n0.1480826\n0.2687632\n0.1260864\n0.1875725\n\n\n0.2890491\n0.1523351\n0.2654892\n0.1199157\n0.1732110\n\n\n0.2584197\n0.1453607\n0.2701586\n0.1296451\n0.1964158\n\n\n0.2946011\n0.1534172\n0.2643906\n0.1181938\n0.1693973\n\n\n0.2227442\n0.1349732\n0.2718842\n0.1412808\n0.2291176\n\n\n0.2807479\n0.1506146\n0.2669972\n0.1225160\n0.1791244\n\n\n0.2541703\n0.1442546\n0.2705962\n0.1310204\n0.1999586\n\n\n0.2543639\n0.1443058\n0.2705775\n0.1309576\n0.1997953\n\n\n0.3039411\n0.1551158\n0.2623906\n0.1153302\n0.1632222\n\n\n0.2386041\n0.1399036\n0.2716895\n0.1360916\n0.2137112\n\n\n0.2541703\n0.1442546\n0.2705962\n0.1310204\n0.1999586\n\n\n0.3568592\n0.1619914\n0.2481106\n0.0999619\n0.1330768\n\n\n0.2670993\n0.1475133\n0.2690951\n0.1268528\n0.1894395\n\n\n0.3649172\n0.1626487\n0.2455814\n0.0977551\n0.1290976\n\n\n0.3538072\n0.1617165\n0.2490477\n0.1008071\n0.1346214\n\n\n0.2929366\n0.1530985\n0.2647273\n0.1187085\n0.1705292\n\n\n0.3776575\n0.1634886\n0.2414314\n0.0943383\n0.1230841\n\n\n0.4185260\n0.1646034\n0.2270885\n0.0839670\n0.1058152\n\n\n0.3132103\n0.1566531\n0.2602308\n0.1125311\n0.1573747\n\n\n0.2227442\n0.1349732\n0.2718842\n0.1412808\n0.2291176\n\n\n0.2553288\n0.1445596\n0.2704825\n0.1306449\n0.1989842\n\n\n0.2227442\n0.1349732\n0.2718842\n0.1412808\n0.2291176\n\n\n0.2470295\n0.1423175\n0.2712006\n0.1333412\n0.2061111\n\n\n0.2227442\n0.1349732\n0.2718842\n0.1412808\n0.2291176\n\n\n0.2890191\n0.1523291\n0.2654949\n0.1199250\n0.1732318\n\n\n0.2510078\n0.1434089\n0.2708845\n0.1320468\n0.2026519\n\n\n0.2584197\n0.1453607\n0.2701586\n0.1296451\n0.1964158\n\n\n0.2900945\n0.1525430\n0.2652877\n0.1195904\n0.1724845\n\n\n0.2584197\n0.1453607\n0.2701586\n0.1296451\n0.1964158\n\n\n0.2227442\n0.1349732\n0.2718842\n0.1412808\n0.2291176\n\n\n0.2607000\n0.1459400\n0.2699009\n0.1289092\n0.1945499\n\n\n0.2750544\n0.1493625\n0.2679324\n0.1243163\n0.1833344\n\n\n0.2787003\n0.1501711\n0.2673431\n0.1231619\n0.1806236\n\n\n0.2227442\n0.1349732\n0.2718842\n0.1412808\n0.2291176\n\n\n0.2778019\n0.1499741\n0.2674915\n0.1234459\n0.1812866\n\n\n0.2772705\n0.1498569\n0.2675783\n0.1236140\n0.1816803\n\n\n0.3734554\n0.1632383\n0.2428196\n0.0954555\n0.1250312\n\n\n0.2851627\n0.1515450\n0.2662158\n0.1211293\n0.1759471\n\n\n0.2227442\n0.1349732\n0.2718842\n0.1412808\n0.2291176\n\n\n0.2227442\n0.1349732\n0.2718842\n0.1412808\n0.2291176\n\n\n0.2468396\n0.1422647\n0.2712143\n0.1334031\n0.2062783\n\n\n0.2227442\n0.1349732\n0.2718842\n0.1412808\n0.2291176\n\n\n0.2584197\n0.1453607\n0.2701586\n0.1296451\n0.1964158\n\n\n0.2714814\n0.1485465\n0.2684760\n0.1254526\n0.1860434\n\n\n0.3714948\n0.1631125\n0.2434609\n0.0959800\n0.1259517\n\n\n0.2607000\n0.1459400\n0.2699009\n0.1289092\n0.1945499\n\n\n0.2345774\n0.1387000\n0.2718321\n0.1374089\n0.2174815\n\n\n0.2227442\n0.1349732\n0.2718842\n0.1412808\n0.2291176\n\n\n0.3774175\n0.1634751\n0.2415112\n0.0944019\n0.1231944\n\n\n0.2672992\n0.1475612\n0.2690681\n0.1267887\n0.1892828\n\n\n0.2769880\n0.1497944\n0.2676242\n0.1237034\n0.1818900\n\n\n0.3126928\n0.1565711\n0.2603557\n0.1126863\n0.1576942\n\n\n0.2683767\n0.1478182\n0.2689202\n0.1264439\n0.1884410\n\n\n0.2946011\n0.1534172\n0.2643906\n0.1181938\n0.1693973\n\n\n0.2227442\n0.1349732\n0.2718842\n0.1412808\n0.2291176\n\n\n0.3013857\n0.1546661\n0.2629560\n0.1161094\n0.1648827\n\n\n0.2849546\n0.1515019\n0.2662537\n0.1211945\n0.1760952\n\n\n0.2738392\n0.1490876\n0.2681212\n0.1247022\n0.1842498\n\n\n0.2227442\n0.1349732\n0.2718842\n0.1412808\n0.2291176\n\n\n0.2227442\n0.1349732\n0.2718842\n0.1412808\n0.2291176\n\n\n0.2607000\n0.1459400\n0.2699009\n0.1289092\n0.1945499\n\n\n0.2716834\n0.1485932\n0.2684462\n0.1253882\n0.1858889\n\n\n0.2914633\n0.1528123\n0.2650201\n0.1191652\n0.1715391\n\n\n0.2479759\n0.1425800\n0.2711302\n0.1330330\n0.2052809\n\n\n0.2607000\n0.1459400\n0.2699009\n0.1289092\n0.1945499\n\n\n0.3090572\n0.1559824\n0.2612191\n0.1137799\n0.1599614\n\n\n0.2808510\n0.1506367\n0.2669795\n0.1224835\n0.1790493\n\n\n0.2386041\n0.1399036\n0.2716895\n0.1360916\n0.2137112\n\n\n0.2347608\n0.1387556\n0.2718270\n0.1373489\n0.2173078\n\n\n0.2345774\n0.1387000\n0.2718321\n0.1374089\n0.2174815\n\n\n0.2635544\n0.1466513\n0.2695563\n0.1279903\n0.1922478\n\n\n0.2911270\n0.1527465\n0.2650862\n0.1192696\n0.1717708\n\n\n0.3236894\n0.1582166\n0.2575967\n0.1094202\n0.1510771\n\n\n0.2345774\n0.1387000\n0.2718321\n0.1374089\n0.2174815\n\n\n0.3127659\n0.1565827\n0.2603381\n0.1126643\n0.1576489\n\n\n0.4571756\n0.1635766\n0.2124557\n0.0749483\n0.0918437\n\n\n0.2227442\n0.1349732\n0.2718842\n0.1412808\n0.2291176\n\n\n0.3064622\n0.1555485\n0.2618198\n0.1145646\n0.1616049\n\n\n0.2345774\n0.1387000\n0.2718321\n0.1374089\n0.2174815\n\n\n0.2898842\n0.1525013\n0.2653284\n0.1196558\n0.1726303\n\n\n0.4150392\n0.1645991\n0.2283641\n0.0848175\n0.1071801\n\n\n0.3767094\n0.1634344\n0.2417462\n0.0945896\n0.1235204\n\n\n0.3146031\n0.1568715\n0.2598921\n0.1121143\n0.1565190\n\n\n0.3003169\n0.1544747\n0.2631885\n0.1164363\n0.1655835\n\n\n0.2730326\n0.1489036\n0.2682442\n0.1249587\n0.1848609\n\n\n0.2227442\n0.1349732\n0.2718842\n0.1412808\n0.2291176\n\n\n0.2849546\n0.1515019\n0.2662537\n0.1211945\n0.1760952\n\n\n0.2904150\n0.1526064\n0.2652254\n0.1194907\n0.1722625\n\n\n0.3305983\n0.1591482\n0.2557571\n0.1074009\n0.1470955\n\n\n0.3146031\n0.1568715\n0.2598921\n0.1121143\n0.1565190\n\n\n0.2416607\n0.1407955\n0.2715412\n0.1350927\n0.2109098\n\n\n0.2227442\n0.1349732\n0.2718842\n0.1412808\n0.2291176\n\n\n0.2670993\n0.1475133\n0.2690951\n0.1268528\n0.1894395\n\n\n0.3856844\n0.1638949\n0.2387300\n0.0922310\n0.1194597\n\n\n0.2386041\n0.1399036\n0.2716895\n0.1360916\n0.2137112\n\n\n0.2227442\n0.1349732\n0.2718842\n0.1412808\n0.2291176\n\n\n0.2227442\n0.1349732\n0.2718842\n0.1412808\n0.2291176\n\n\n0.2416607\n0.1407955\n0.2715412\n0.1350927\n0.2109098\n\n\n0.3135085\n0.1567001\n0.2601586\n0.1124418\n0.1571910\n\n\n0.3439164\n0.1607262\n0.2520008\n0.1035812\n0.1397754\n\n\n0.3229340\n0.1581100\n0.2577930\n0.1096425\n0.1515204\n\n\n0.3148233\n0.1569057\n0.2598382\n0.1120485\n0.1563842\n\n\n0.2386041\n0.1399036\n0.2716895\n0.1360916\n0.2137112\n\n\n0.2705352\n0.1483264\n0.2686142\n0.1257544\n0.1867698\n\n\n0.3141734\n0.1568044\n0.2599969\n0.1122428\n0.1567824\n\n\n0.3070671\n0.1556506\n0.2616810\n0.1143813\n0.1612199\n\n\n0.2227442\n0.1349732\n0.2718842\n0.1412808\n0.2291176\n\n\n0.3275922\n0.1587525\n0.2565672\n0.1082764\n0.1488118\n\n\n0.3001024\n0.1544361\n0.2632349\n0.1165020\n0.1657247\n\n\n0.3186802\n0.1574921\n0.2588802\n0.1109001\n0.1540475\n\n\n0.2356749\n0.1390313\n0.2717993\n0.1370497\n0.2164448\n\n\n0.3487268\n0.1612269\n0.2505810\n0.1022253\n0.1372400\n\n\n0.3284872\n0.1588718\n0.2563275\n0.1080152\n0.1482983\n\n\n0.2227442\n0.1349732\n0.2718842\n0.1412808\n0.2291176\n\n\n0.2227442\n0.1349732\n0.2718842\n0.1412808\n0.2291176\n\n\n0.2980281\n0.1540581\n0.2636783\n0.1171382\n0.1670973\n\n\n0.2946011\n0.1534172\n0.2643906\n0.1181938\n0.1693973\n\n\n0.2347608\n0.1387556\n0.2718270\n0.1373489\n0.2173078\n\n\n0.4655192\n0.1631047\n0.2091981\n0.0730966\n0.0890813\n\n\n0.4093488\n0.1645564\n0.2304272\n0.0862192\n0.1094484\n\n\n0.3558276\n0.1619001\n0.2484287\n0.1002471\n0.1335966\n\n\n0.2620706\n0.1462835\n0.2697384\n0.1284676\n0.1934399\n\n\n0.3336453\n0.1595343\n0.2549214\n0.1065185\n0.1453804\n\n\n0.2607000\n0.1459400\n0.2699009\n0.1289092\n0.1945499\n\n\n0.2379775\n0.1397184\n0.2717157\n0.1362965\n0.2142919\n\n\n0.2595255\n0.1456429\n0.2700356\n0.1292880\n0.1955080\n\n\n0.3400319\n0.1602952\n0.2531236\n0.1046853\n0.1418639\n\n\n0.2227442\n0.1349732\n0.2718842\n0.1412808\n0.2291176\n\n\n0.2227442\n0.1349732\n0.2718842\n0.1412808\n0.2291176\n\n\n0.3384243\n0.1601098\n0.2535819\n0.1051447\n0.1427393\n\n\n0.3156998\n0.1570412\n0.2596228\n0.1117868\n0.1558493\n\n\n0.3186802\n0.1574921\n0.2588802\n0.1109001\n0.1540475\n\n\n0.2637526\n0.1467001\n0.2695314\n0.1279266\n0.1920893\n\n\n0.2521523\n0.1437172\n0.2707839\n0.1316751\n0.2016715\n\n\n0.3743946\n0.1632965\n0.2425109\n0.0952050\n0.1245930\n\n\n0.2714814\n0.1485465\n0.2684760\n0.1254526\n0.1860434\n\n\n0.2904150\n0.1526064\n0.2652254\n0.1194907\n0.1722625\n\n\n0.2347608\n0.1387556\n0.2718270\n0.1373489\n0.2173078\n\n\n0.2227442\n0.1349732\n0.2718842\n0.1412808\n0.2291176\n\n\n0.2227442\n0.1349732\n0.2718842\n0.1412808\n0.2291176\n\n\n0.2227442\n0.1349732\n0.2718842\n0.1412808\n0.2291176\n\n\n0.2993063\n0.1542919\n0.2634061\n0.1167459\n0.1662497\n\n\n0.4655071\n0.1631055\n0.2092028\n0.0730993\n0.0890853\n\n\n0.4328079\n0.1644509\n0.2217801\n0.0805479\n0.1004132\n\n\n0.2861997\n0.1517585\n0.2660255\n0.1208048\n0.1752116\n\n\n0.2670993\n0.1475133\n0.2690951\n0.1268528\n0.1894395\n\n\n0.2681811\n0.1477717\n0.2689473\n0.1265065\n0.1885935\n\n\n0.4191178\n0.1646025\n0.2268711\n0.0838232\n0.1055853\n\n\n0.3846308\n0.1638469\n0.2390882\n0.0925056\n0.1199285\n\n\n0.2227442\n0.1349732\n0.2718842\n0.1412808\n0.2291176\n\n\n0.3321982\n0.1593528\n0.2553201\n0.1069370\n0.1461919\n\n\n0.2810524\n0.1506799\n0.2669448\n0.1224201\n0.1789028\n\n\n0.3709501\n0.1630766\n0.2436383\n0.0961261\n0.1262089\n\n\n0.4035421\n0.1644669\n0.2325075\n0.0876669\n0.1118166\n\n\n0.3727503\n0.1631937\n0.2430507\n0.0956439\n0.1253614\n\n\n0.3013857\n0.1546661\n0.2629560\n0.1161094\n0.1648827\n\n\n0.3366791\n0.1599039\n0.2540750\n0.1056449\n0.1436970\n\n\n0.2716834\n0.1485932\n0.2684462\n0.1253882\n0.1858889\n\n\n0.2470295\n0.1423175\n0.2712006\n0.1333412\n0.2061111\n\n\n0.2386041\n0.1399036\n0.2716895\n0.1360916\n0.2137112\n\n\n0.2958759\n0.1536580\n0.2641286\n0.1178005\n0.1685370\n\n\n0.3242698\n0.1582979\n0.2574452\n0.1092495\n0.1507376\n\n\n0.3386203\n0.1601327\n0.2535262\n0.1050886\n0.1426323\n\n\n0.4119495\n0.1645814\n0.2294872\n0.0855765\n0.1084053\n\n\n0.2227442\n0.1349732\n0.2718842\n0.1412808\n0.2291176\n\n\n0.2714814\n0.1485465\n0.2684760\n0.1254526\n0.1860434\n\n\n0.2607000\n0.1459400\n0.2699009\n0.1289092\n0.1945499\n\n\n0.2730326\n0.1489036\n0.2682442\n0.1249587\n0.1848609\n\n\n0.3487599\n0.1612302\n0.2505711\n0.1022160\n0.1372227\n\n\n0.2645418\n0.1468938\n0.2694315\n0.1276730\n0.1914599\n\n\n0.3287125\n0.1589017\n0.2562670\n0.1079495\n0.1481693\n\n\n0.2227442\n0.1349732\n0.2718842\n0.1412808\n0.2291176\n\n\n0.2944950\n0.1533971\n0.2644122\n0.1182266\n0.1694691\n\n\n0.2227442\n0.1349732\n0.2718842\n0.1412808\n0.2291176\n\n\n0.3001024\n0.1544361\n0.2632349\n0.1165020\n0.1657247\n\n\n0.2960887\n0.1536979\n0.2640845\n0.1177349\n0.1683939\n\n\n0.2844644\n0.1514002\n0.2663426\n0.1213481\n0.1764447\n\n\n0.2386041\n0.1399036\n0.2716895\n0.1360916\n0.2137112\n\n\n0.2386041\n0.1399036\n0.2716895\n0.1360916\n0.2137112\n\n\n0.2227442\n0.1349732\n0.2718842\n0.1412808\n0.2291176\n\n\n0.3848668\n0.1638578\n0.2390080\n0.0924441\n0.1198233\n\n\n0.3569541\n0.1619997\n0.2480813\n0.0999358\n0.1330292\n\n\n0.3229340\n0.1581100\n0.2577930\n0.1096425\n0.1515204\n\n\n0.2345774\n0.1387000\n0.2718321\n0.1374089\n0.2174815\n\n\n0.2227442\n0.1349732\n0.2718842\n0.1412808\n0.2291176\n\n\n0.2383833\n0.1398384\n0.2716989\n0.1361638\n0.2139156\n\n\n0.2670993\n0.1475133\n0.2690951\n0.1268528\n0.1894395\n\n\n0.2877967\n0.1520834\n0.2657273\n0.1203060\n0.1740866\n\n\n0.2227442\n0.1349732\n0.2718842\n0.1412808\n0.2291176\n\n\n0.2584197\n0.1453607\n0.2701586\n0.1296451\n0.1964158\n\n\n0.3146031\n0.1568715\n0.2598921\n0.1121143\n0.1565190\n\n\n0.4628525\n0.1632649\n0.2102424\n0.0736849\n0.0899552\n\n\n0.2491157\n0.1428937\n0.2710414\n0.1326621\n0.2042872\n\n\n0.2960887\n0.1536979\n0.2640845\n0.1177349\n0.1683939\n\n\n0.3042910\n0.1551765\n0.2623122\n0.1152237\n0.1629965\n\n\n0.2386041\n0.1399036\n0.2716895\n0.1360916\n0.2137112\n\n\n0.2682956\n0.1477989\n0.2689314\n0.1264698\n0.1885042\n\n\n0.2584197\n0.1453607\n0.2701586\n0.1296451\n0.1964158\n\n\n0.2995919\n0.1543437\n0.2633449\n0.1166584\n0.1660611\n\n\n0.3549698\n0.1618229\n0.2486921\n0.1004846\n0.1340306\n\n\n0.3186802\n0.1574921\n0.2588802\n0.1109001\n0.1540475\n\n\n0.2714814\n0.1485465\n0.2684760\n0.1254526\n0.1860434\n\n\n0.2227442\n0.1349732\n0.2718842\n0.1412808\n0.2291176\n\n\n0.2227442\n0.1349732\n0.2718842\n0.1412808\n0.2291176\n\n\n0.2539123\n0.1441863\n0.2706209\n0.1311040\n0.2001765\n\n\n0.2227442\n0.1349732\n0.2718842\n0.1412808\n0.2291176\n\n\n0.2227442\n0.1349732\n0.2718842\n0.1412808\n0.2291176\n\n\n0.2738392\n0.1490876\n0.2681212\n0.1247022\n0.1842498\n\n\n0.3259074\n0.1585242\n0.2570147\n0.1087691\n0.1497845\n\n\n0.2584197\n0.1453607\n0.2701586\n0.1296451\n0.1964158\n\n\n0.2808510\n0.1506367\n0.2669795\n0.1224835\n0.1790493\n\n\n0.2670993\n0.1475133\n0.2690951\n0.1268528\n0.1894395\n\n\n0.2479759\n0.1425800\n0.2711302\n0.1330330\n0.2052809\n\n\n0.2584197\n0.1453607\n0.2701586\n0.1296451\n0.1964158\n\n\n0.2683767\n0.1478182\n0.2689202\n0.1264439\n0.1884410\n\n\n0.2599182\n0.1457425\n0.2699910\n0.1291613\n0.1951869\n\n\n0.2345774\n0.1387000\n0.2718321\n0.1374089\n0.2174815\n\n\n0.2227442\n0.1349732\n0.2718842\n0.1412808\n0.2291176\n\n\n0.2883851\n0.1522020\n0.2656159\n0.1201225\n0.1736745\n\n\n0.2227442\n0.1349732\n0.2718842\n0.1412808\n0.2291176\n\n\n0.3044352\n0.1552015\n0.2622798\n0.1151799\n0.1629037\n\n\n0.2994593\n0.1543197\n0.2633733\n0.1166990\n0.1661487\n\n\n0.2599182\n0.1457425\n0.2699910\n0.1291613\n0.1951869\n\n\n0.3322144\n0.1593549\n0.2553157\n0.1069323\n0.1461828\n\n\n0.3030315\n0.1549570\n0.2625934\n0.1156072\n0.1638108\n\n\n0.2851627\n0.1515450\n0.2662158\n0.1211293\n0.1759471\n\n\n0.2950308\n0.1534987\n0.2643027\n0.1180611\n0.1691067\n\n\n0.3625821\n0.1624684\n0.2463223\n0.0983909\n0.1302363\n\n\n0.2468396\n0.1422647\n0.2712143\n0.1334031\n0.2062783\n\n\n0.2541703\n0.1442546\n0.2705962\n0.1310204\n0.1999586\n\n\n0.3299314\n0.1590617\n0.2559381\n0.1075947\n0.1474741\n\n\n0.3574174\n0.1620401\n0.2479380\n0.0998079\n0.1327966\n\n\n0.3909743\n0.1641117\n0.2369160\n0.0908612\n0.1171368\n\n\n0.2227442\n0.1349732\n0.2718842\n0.1412808\n0.2291176\n\n\n0.3126928\n0.1565711\n0.2603557\n0.1126863\n0.1576942\n\n\n0.2795173\n0.1503490\n0.2672063\n0.1229040\n0.1800234\n\n\n0.2491157\n0.1428937\n0.2710414\n0.1326621\n0.2042872\n\n\n0.3003169\n0.1544747\n0.2631885\n0.1164363\n0.1655835\n\n\n0.3932285\n0.1641918\n0.2361352\n0.0902821\n0.1161623\n\n\n0.2356749\n0.1390313\n0.2717993\n0.1370497\n0.2164448\n\n\n0.2774752\n0.1499021\n0.2675450\n0.1235492\n0.1815285\n\n\n0.2806448\n0.1505925\n0.2670148\n0.1225485\n0.1791995\n\n\n0.2356749\n0.1390313\n0.2717993\n0.1370497\n0.2164448\n\n\n0.2759133\n0.1495552\n0.2677967\n0.1240439\n0.1826909\n\n\n0.2849546\n0.1515019\n0.2662537\n0.1211945\n0.1760952\n\n\n0.3037251\n0.1550783\n0.2624389\n0.1153959\n0.1633617\n\n\n0.2227442\n0.1349732\n0.2718842\n0.1412808\n0.2291176\n\n\n0.2472195\n0.1423704\n0.2711867\n0.1332794\n0.2059441\n\n\n0.3652948\n0.1626771\n0.2454610\n0.0976525\n0.1289146\n\n\n0.2472195\n0.1423704\n0.2711867\n0.1332794\n0.2059441\n\n\n0.2491157\n0.1428937\n0.2710414\n0.1326621\n0.2042872\n\n\n0.2640265\n0.1467675\n0.2694969\n0.1278385\n0.1918705\n\n\n0.2900945\n0.1525430\n0.2652877\n0.1195904\n0.1724845\n\n\n0.2956582\n0.1536171\n0.2641736\n0.1178676\n0.1686835\n\n\n0.2227442\n0.1349732\n0.2718842\n0.1412808\n0.2291176\n\n\n0.2607000\n0.1459400\n0.2699009\n0.1289092\n0.1945499\n\n\n0.2853709\n0.1515880\n0.2661778\n0.1210641\n0.1757991\n\n\n0.2716834\n0.1485932\n0.2684462\n0.1253882\n0.1858889\n\n\n0.2227442\n0.1349732\n0.2718842\n0.1412808\n0.2291176\n\n\n0.2416607\n0.1407955\n0.2715412\n0.1350927\n0.2109098\n\n\n0.3202712\n0.1577267\n0.2584773\n0.1104286\n0.1530962\n\n\n0.2846674\n0.1514424\n0.2663059\n0.1212845\n0.1762999\n\n\n0.4131811\n0.1645900\n0.2290404\n0.0852734\n0.1079152\n\n\n0.2898842\n0.1525013\n0.2653284\n0.1196558\n0.1726303\n\n\n0.3287125\n0.1589017\n0.2562670\n0.1079495\n0.1481693\n\n\n0.3023490\n0.1548370\n0.2627445\n0.1158153\n0.1642542\n\n\n0.4621937\n0.1633032\n0.2105000\n0.0738307\n0.0901724\n\n\n0.2227442\n0.1349732\n0.2718842\n0.1412808\n0.2291176\n\n\n0.3326568\n0.1594107\n0.2551941\n0.1068042\n0.1459341\n\n\n0.3904823\n0.1640932\n0.2370858\n0.0909880\n0.1173507\n\n\n0.2227442\n0.1349732\n0.2718842\n0.1412808\n0.2291176\n\n\n0.3453001\n0.1608739\n0.2515957\n0.1031899\n0.1390404\n\n\n0.3075433\n0.1557306\n0.2615712\n0.1142373\n0.1609176\n\n\n0.4142602\n0.1645958\n0.2286479\n0.0850084\n0.1074876\n\n\n0.2738392\n0.1490876\n0.2681212\n0.1247022\n0.1842498\n\n\n0.3042910\n0.1551765\n0.2623122\n0.1152237\n0.1629965\n\n\n0.3530183\n0.1616431\n0.2492880\n0.1010264\n0.1350241\n\n\n0.2227442\n0.1349732\n0.2718842\n0.1412808\n0.2291176\n\n\n0.2914633\n0.1528123\n0.2650201\n0.1191652\n0.1715391\n\n\n0.3152168\n0.1569667\n0.2597417\n0.1119310\n0.1561438\n\n\n0.3362937\n0.1598578\n0.2541833\n0.1057556\n0.1439095\n\n\n0.2227442\n0.1349732\n0.2718842\n0.1412808\n0.2291176\n\n\n0.2345774\n0.1387000\n0.2718321\n0.1374089\n0.2174815\n\n\n0.2227442\n0.1349732\n0.2718842\n0.1412808\n0.2291176\n\n\n0.2481664\n0.1426326\n0.2711157\n0.1329710\n0.2051144\n\n\n0.2886346\n0.1522521\n0.2655684\n0.1200448\n0.1735001\n\n\n0.3334561\n0.1595108\n0.2549737\n0.1065732\n0.1454862\n\n\n0.2784951\n0.1501263\n0.2673772\n0.1232267\n0.1807747\n\n\n0.2726901\n0.1488252\n0.2682960\n0.1250677\n0.1851211\n\n\n0.2541703\n0.1442546\n0.2705962\n0.1310204\n0.1999586\n\n\n0.2808510\n0.1506367\n0.2669795\n0.1224835\n0.1790493\n\n\n0.3212618\n0.1578707\n0.2582241\n0.1101357\n0.1525077\n\n\n0.3895221\n0.1640562\n0.2374165\n0.0912358\n0.1177694\n\n\n0.2740423\n0.1491338\n0.2680899\n0.1246377\n0.1840964\n\n\n0.2227442\n0.1349732\n0.2718842\n0.1412808\n0.2291176\n\n\n0.2726901\n0.1488252\n0.2682960\n0.1250677\n0.1851211\n\n\n0.4329154\n0.1644487\n0.2217397\n0.0805225\n0.1003736\n\n\n0.2227442\n0.1349732\n0.2718842\n0.1412808\n0.2291176\n\n\n0.2227442\n0.1349732\n0.2718842\n0.1412808\n0.2291176\n\n\n0.2227442\n0.1349732\n0.2718842\n0.1412808\n0.2291176\n\n\n0.3579704\n0.1620879\n0.2477665\n0.0996555\n0.1325197\n\n\n0.3196470\n0.1576351\n0.2586359\n0.1106134\n0.1534686\n\n\n0.2227442\n0.1349732\n0.2718842\n0.1412808\n0.2291176\n\n\n0.3837220\n0.1638043\n0.2393962\n0.0927430\n0.1203345\n\n\n0.3986422\n0.1643549\n0.2342421\n0.0889023\n0.1138585\n\n\n0.4078917\n0.1645384\n0.2309517\n0.0865808\n0.1100375\n\n\n0.2227442\n0.1349732\n0.2718842\n0.1412808\n0.2291176\n\n\n0.4093488\n0.1645564\n0.2304272\n0.0862192\n0.1094484\n\n\n0.3284121\n0.1588619\n0.2563477\n0.1080371\n0.1483413\n\n\n0.2227442\n0.1349732\n0.2718842\n0.1412808\n0.2291176\n\n\n0.2714814\n0.1485465\n0.2684760\n0.1254526\n0.1860434\n\n\n0.3100341\n0.1561428\n0.2609896\n0.1134853\n0.1593481\n\n\n0.3549698\n0.1618229\n0.2486921\n0.1004846\n0.1340306\n\n\n0.2738392\n0.1490876\n0.2681212\n0.1247022\n0.1842498\n\n\n0.2977026\n0.1539981\n0.2637470\n0.1172382\n0.1673140\n\n\n0.2806448\n0.1505925\n0.2670148\n0.1225485\n0.1791995\n\n\n0.2345774\n0.1387000\n0.2718321\n0.1374089\n0.2174815\n\n\n0.2714814\n0.1485465\n0.2684760\n0.1254526\n0.1860434\n\n\n0.2849546\n0.1515019\n0.2662537\n0.1211945\n0.1760952\n\n\n0.3571327\n0.1620153\n0.2480261\n0.0998865\n0.1329394\n\n\n0.4150392\n0.1645991\n0.2283641\n0.0848175\n0.1071801\n\n\n0.3095455\n0.1560628\n0.2611047\n0.1136326\n0.1596545\n\n\n0.2472195\n0.1423704\n0.2711867\n0.1332794\n0.2059441\n\n\n0.2936471\n0.1532352\n0.2645843\n0.1184886\n0.1700448\n\n\n0.2227442\n0.1349732\n0.2718842\n0.1412808\n0.2291176\n\n\n0.2694953\n0.1480826\n0.2687632\n0.1260864\n0.1875725\n\n\n0.3705190\n0.1630478\n0.2437785\n0.0962418\n0.1264128\n\n\n0.2929366\n0.1530985\n0.2647273\n0.1187085\n0.1705292\n\n\n0.2468396\n0.1422647\n0.2712143\n0.1334031\n0.2062783\n\n\n0.2848060\n0.1514711\n0.2662807\n0.1212410\n0.1762011\n\n\n0.2217482\n0.1346464\n0.2718622\n0.1416062\n0.2301369\n\n\n0.2584197\n0.1453607\n0.2701586\n0.1296451\n0.1964158\n\n\n0.2584197\n0.1453607\n0.2701586\n0.1296451\n0.1964158\n\n\n0.3294747\n0.1590020\n0.2560616\n0.1077276\n0.1477341\n\n\n0.3383916\n0.1601060\n0.2535911\n0.1051540\n0.1427572\n\n\n0.2601100\n0.1457911\n0.2699691\n0.1290995\n0.1950304\n\n\n0.2914633\n0.1528123\n0.2650201\n0.1191652\n0.1715391\n\n\n0.3127659\n0.1565827\n0.2603381\n0.1126643\n0.1576489\n\n\n0.3120348\n0.1564662\n0.2605139\n0.1128837\n0.1581015\n\n\n0.2900644\n0.1525371\n0.2652935\n0.1195997\n0.1725053\n\n\n0.3663270\n0.1627536\n0.2451310\n0.0973726\n0.1284158\n\n\n0.3075019\n0.1557237\n0.2615808\n0.1142498\n0.1609439\n\n\n0.3692950\n0.1629646\n0.2441754\n0.0965710\n0.1269939\n\n\n0.2886346\n0.1522521\n0.2655684\n0.1200448\n0.1735001\n\n\n0.3162884\n0.1571314\n0.2594774\n0.1116114\n0.1554914\n\n\n0.2521523\n0.1437172\n0.2707839\n0.1316751\n0.2016715\n\n\n0.2227442\n0.1349732\n0.2718842\n0.1412808\n0.2291176\n\n\n0.2416607\n0.1407955\n0.2715412\n0.1350927\n0.2109098\n\n\n0.2740423\n0.1491338\n0.2680899\n0.1246377\n0.1840964\n\n\n0.2714814\n0.1485465\n0.2684760\n0.1254526\n0.1860434\n\n\n0.3916924\n0.1641380\n0.2366678\n0.0906764\n0.1168254\n\n\n0.2652141\n0.1470578\n0.2693449\n0.1274572\n0.1909261\n\n\n0.4402173\n0.1642658\n0.2189777\n0.0788145\n0.0977246\n\n\n0.3310235\n0.1592030\n0.2556414\n0.1072775\n0.1468547\n\n\n0.2356749\n0.1390313\n0.2717993\n0.1370497\n0.2164448\n\n\n0.2345774\n0.1387000\n0.2718321\n0.1374089\n0.2174815\n\n\n0.3336453\n0.1595343\n0.2549214\n0.1065185\n0.1453804\n\n\n0.3127659\n0.1565827\n0.2603381\n0.1126643\n0.1576489\n\n\n0.2601100\n0.1457911\n0.2699691\n0.1290995\n0.1950304\n\n\n0.2470295\n0.1423175\n0.2712006\n0.1333412\n0.2061111\n\n\n0.3895221\n0.1640562\n0.2374165\n0.0912358\n0.1177694\n\n\n0.2347608\n0.1387556\n0.2718270\n0.1373489\n0.2173078\n\n\n0.2345774\n0.1387000\n0.2718321\n0.1374089\n0.2174815\n\n\n0.2584197\n0.1453607\n0.2701586\n0.1296451\n0.1964158\n\n\n0.3559669\n0.1619125\n0.2483858\n0.1002085\n0.1335263\n\n\n0.2227442\n0.1349732\n0.2718842\n0.1412808\n0.2291176\n\n\n0.2864083\n0.1518012\n0.2659868\n0.1207396\n0.1750641\n\n\n0.2481664\n0.1426326\n0.2711157\n0.1329710\n0.2051144\n\n\n0.3737740\n0.1632582\n0.2427150\n0.0953704\n0.1248823\n\n\n0.2766036\n0.1497091\n0.2676862\n0.1238251\n0.1821760\n\n\n0.2819621\n0.1508740\n0.2667870\n0.1221338\n0.1782431\n\n\n0.2990362\n0.1542427\n0.2634640\n0.1168288\n0.1664284\n\n\n0.2472195\n0.1423704\n0.2711867\n0.1332794\n0.2059441\n\n\n0.3711827\n0.1630920\n0.2435626\n0.0960637\n0.1260990\n\n\n0.2553288\n0.1445596\n0.2704825\n0.1306449\n0.1989842\n\n\n0.2481664\n0.1426326\n0.2711157\n0.1329710\n0.2051144\n\n\n0.2479759\n0.1425800\n0.2711302\n0.1330330\n0.2052809\n\n\n0.3655316\n0.1626948\n0.2453854\n0.0975883\n0.1288000\n\n\n0.2620706\n0.1462835\n0.2697384\n0.1284676\n0.1934399\n\n\n0.2416607\n0.1407955\n0.2715412\n0.1350927\n0.2109098\n\n\n0.2345774\n0.1387000\n0.2718321\n0.1374089\n0.2174815\n\n\n0.2929768\n0.1531063\n0.2647192\n0.1186961\n0.1705016\n\n\n0.2682956\n0.1477989\n0.2689314\n0.1264698\n0.1885042\n\n\n0.2816718\n0.1508122\n0.2668376\n0.1222251\n0.1784533\n\n\n0.2227442\n0.1349732\n0.2718842\n0.1412808\n0.2291176\n\n\n0.3354911\n0.1597610\n0.2544082\n0.1059864\n0.1443534\n\n\n0.3146031\n0.1568715\n0.2598921\n0.1121143\n0.1565190\n\n\n0.3140896\n0.1567913\n0.2600174\n0.1122679\n0.1568338\n\n\n0.2227442\n0.1349732\n0.2718842\n0.1412808\n0.2291176\n\n\n0.2347608\n0.1387556\n0.2718270\n0.1373489\n0.2173078\n\n\n0.2345774\n0.1387000\n0.2718321\n0.1374089\n0.2174815\n\n\n0.2595255\n0.1456429\n0.2700356\n0.1292880\n0.1955080\n\n\n0.3081079\n0.1558250\n0.2614404\n0.1140665\n0.1605601\n\n\n0.2705352\n0.1483264\n0.2686142\n0.1257544\n0.1867698\n\n\n0.2754569\n0.1494530\n0.2678691\n0.1241886\n0.1830324\n\n\n0.2227442\n0.1349732\n0.2718842\n0.1412808\n0.2291176\n\n\n0.3589488\n0.1621714\n0.2474623\n0.0993862\n0.1320313\n\n\n0.4448597\n0.1641136\n0.2172066\n0.0777422\n0.0960779\n\n\n0.2886346\n0.1522521\n0.2655684\n0.1200448\n0.1735001\n\n\n0.2510078\n0.1434089\n0.2708845\n0.1320468\n0.2026519\n\n\n0.2595255\n0.1456429\n0.2700356\n0.1292880\n0.1955080\n\n\n0.2607000\n0.1459400\n0.2699009\n0.1289092\n0.1945499\n\n\n0.2774752\n0.1499021\n0.2675450\n0.1235492\n0.1815285\n\n\n0.3392958\n0.1602108\n0.2533339\n0.1048955\n0.1422640\n\n\n0.2662055\n0.1472982\n0.2692148\n0.1271392\n0.1901424\n\n\n0.2640218\n0.1467663\n0.2694975\n0.1278401\n0.1918743\n\n\n0.2904150\n0.1526064\n0.2652254\n0.1194907\n0.1722625\n\n\n0.2479759\n0.1425800\n0.2711302\n0.1330330\n0.2052809\n\n\n0.2584197\n0.1453607\n0.2701586\n0.1296451\n0.1964158\n\n\n0.3146031\n0.1568715\n0.2598921\n0.1121143\n0.1565190\n\n\n0.3659151\n0.1627233\n0.2452628\n0.0974843\n0.1286145\n\n\n0.2227442\n0.1349732\n0.2718842\n0.1412808\n0.2291176\n\n\n0.2584197\n0.1453607\n0.2701586\n0.1296451\n0.1964158\n\n\n0.2750544\n0.1493625\n0.2679324\n0.1243163\n0.1833344\n\n\n0.3043219\n0.1551819\n0.2623052\n0.1152143\n0.1629767\n\n\n0.3549698\n0.1618229\n0.2486921\n0.1004846\n0.1340306\n\n\n0.2227442\n0.1349732\n0.2718842\n0.1412808\n0.2291176\n\n\n0.2227442\n0.1349732\n0.2718842\n0.1412808\n0.2291176\n\n\n0.2784951\n0.1501263\n0.2673772\n0.1232267\n0.1807747\n\n\n0.3152693\n0.1569748\n0.2597288\n0.1119153\n0.1561118\n\n\n0.3315298\n0.1592678\n0.2555032\n0.1071306\n0.1465686\n\n\n0.2601100\n0.1457911\n0.2699691\n0.1290995\n0.1950304\n\n\n0.2750544\n0.1493625\n0.2679324\n0.1243163\n0.1833344\n\n\n0.2491157\n0.1428937\n0.2710414\n0.1326621\n0.2042872\n\n\n0.3126928\n0.1565711\n0.2603557\n0.1126863\n0.1576942\n\n\n0.3405122\n0.1603498\n0.2529859\n0.1045484\n0.1416037\n\n\n0.2642250\n0.1468162\n0.2694718\n0.1277748\n0.1917122\n\n\n0.2995919\n0.1543437\n0.2633449\n0.1166584\n0.1660611\n\n\n0.5284098\n0.1568870\n0.1839159\n0.0601413\n0.0706460\n\n\n0.3707118\n0.1630607\n0.2437158\n0.0961901\n0.1263216\n\n\n0.3265006\n0.1586051\n0.2568577\n0.1085955\n0.1494412\n\n\n0.2730326\n0.1489036\n0.2682442\n0.1249587\n0.1848609\n\n\n0.2227442\n0.1349732\n0.2718842\n0.1412808\n0.2291176\n\n\n0.2416607\n0.1407955\n0.2715412\n0.1350927\n0.2109098\n\n\n0.2822723\n0.1509398\n0.2667328\n0.1220362\n0.1780188\n\n\n0.2227442\n0.1349732\n0.2718842\n0.1412808\n0.2291176\n\n\n0.3692950\n0.1629646\n0.2441754\n0.0965710\n0.1269939\n\n\n0.3347759\n0.1596738\n0.2546076\n0.1061924\n0.1447503\n\n\n0.2386041\n0.1399036\n0.2716895\n0.1360916\n0.2137112\n\n\n0.3383916\n0.1601060\n0.2535911\n0.1051540\n0.1427572\n\n\n0.3459215\n0.1609393\n0.2514129\n0.1030145\n0.1387118\n\n\n0.3487268\n0.1612269\n0.2505810\n0.1022253\n0.1372400\n\n\n0.2468396\n0.1422647\n0.2712143\n0.1334031\n0.2062783\n\n\n0.3212194\n0.1578645\n0.2582350\n0.1101482\n0.1525328\n\n\n0.3530183\n0.1616431\n0.2492880\n0.1010264\n0.1350241\n\n\n0.4227624\n0.1645866\n0.2255275\n0.0829420\n0.1041816\n\n\n0.3551981\n0.1618436\n0.2486221\n0.1004213\n0.1339149\n\n\n0.3135085\n0.1567001\n0.2601586\n0.1124418\n0.1571910\n\n\n0.3724036\n0.1631715\n0.2431641\n0.0957366\n0.1255241\n\n\n0.2510078\n0.1434089\n0.2708845\n0.1320468\n0.2026519\n\n\n0.4352387\n0.1643981\n0.2208641\n0.0799762\n0.0995228\n\n\n0.2740423\n0.1491338\n0.2680899\n0.1246377\n0.1840964\n\n\n0.2345774\n0.1387000\n0.2718321\n0.1374089\n0.2174815\n\n\n0.2468396\n0.1422647\n0.2712143\n0.1334031\n0.2062783\n\n\n0.2638329\n0.1467199\n0.2695213\n0.1279008\n0.1920251\n\n\n0.3334237\n0.1595068\n0.2549827\n0.1065825\n0.1455043\n\n\n0.3042910\n0.1551765\n0.2623122\n0.1152237\n0.1629965\n\n\n0.2227442\n0.1349732\n0.2718842\n0.1412808\n0.2291176\n\n\n0.3415121\n0.1604623\n0.2526983\n0.1042636\n0.1410637\n\n\n0.2416607\n0.1407955\n0.2715412\n0.1350927\n0.2109098\n\n\n0.3057289\n0.1554237\n0.2619872\n0.1147869\n0.1620732\n\n\n0.2470295\n0.1423175\n0.2712006\n0.1333412\n0.2061111\n\n\n0.2227442\n0.1349732\n0.2718842\n0.1412808\n0.2291176\n\n\n0.3284121\n0.1588619\n0.2563477\n0.1080371\n0.1483413\n\n\n0.2860805\n0.1517340\n0.2660475\n0.1208421\n0.1752959\n\n\n0.3107731\n0.1562630\n0.2608148\n0.1132629\n0.1588862\n\n\n0.3035144\n0.1550415\n0.2624860\n0.1154601\n0.1634980\n\n\n0.2904150\n0.1526064\n0.2652254\n0.1194907\n0.1722625\n\n\n0.3322953\n0.1593651\n0.2552935\n0.1069088\n0.1461373\n\n\n0.2819621\n0.1508740\n0.2667870\n0.1221338\n0.1782431\n\n\n0.2386041\n0.1399036\n0.2716895\n0.1360916\n0.2137112\n\n\n0.2227442\n0.1349732\n0.2718842\n0.1412808\n0.2291176\n\n\n0.2584197\n0.1453607\n0.2701586\n0.1296451\n0.1964158\n\n\n0.2468396\n0.1422647\n0.2712143\n0.1334031\n0.2062783\n\n\n0.2716834\n0.1485932\n0.2684462\n0.1253882\n0.1858889\n\n\n0.2607000\n0.1459400\n0.2699009\n0.1289092\n0.1945499\n\n\n0.3102630\n0.1561801\n0.2609356\n0.1134164\n0.1592049\n\n\n0.2705352\n0.1483264\n0.2686142\n0.1257544\n0.1867698\n\n\n0.2990362\n0.1542427\n0.2634640\n0.1168288\n0.1664284\n\n\n0.2795173\n0.1503490\n0.2672063\n0.1229040\n0.1800234\n\n\n0.2491157\n0.1428937\n0.2710414\n0.1326621\n0.2042872\n\n\n0.2607000\n0.1459400\n0.2699009\n0.1289092\n0.1945499\n\n\n0.2227442\n0.1349732\n0.2718842\n0.1412808\n0.2291176\n\n\n0.3770977\n0.1634568\n0.2416174\n0.0944866\n0.1233415\n\n\n0.2607000\n0.1459400\n0.2699009\n0.1289092\n0.1945499\n\n\n0.3525464\n0.1615987\n0.2494314\n0.1011577\n0.1352657\n\n\n0.2227442\n0.1349732\n0.2718842\n0.1412808\n0.2291176\n\n\n0.3685252\n0.1629112\n0.2444242\n0.0967785\n0.1273609\n\n\n0.3643539\n0.1626060\n0.2457607\n0.0979082\n0.1293712\n\n\n0.3044352\n0.1552015\n0.2622798\n0.1151799\n0.1629037\n\n\n0.2650151\n0.1470094\n0.2693706\n0.1275210\n0.1910838\n\n\n0.2356749\n0.1390313\n0.2717993\n0.1370497\n0.2164448\n\n\n0.2944950\n0.1533971\n0.2644122\n0.1182266\n0.1694691\n\n\n0.3148233\n0.1569057\n0.2598382\n0.1120485\n0.1563842\n\n\n0.4093488\n0.1645564\n0.2304272\n0.0862192\n0.1094484\n\n\n0.2227442\n0.1349732\n0.2718842\n0.1412808\n0.2291176\n\n\n0.2960887\n0.1536979\n0.2640845\n0.1177349\n0.1683939\n\n\n0.2683767\n0.1478182\n0.2689202\n0.1264439\n0.1884410\n\n\n0.2672992\n0.1475612\n0.2690681\n0.1267887\n0.1892828\n\n\n0.2510078\n0.1434089\n0.2708845\n0.1320468\n0.2026519\n\n\n0.2468396\n0.1422647\n0.2712143\n0.1334031\n0.2062783\n\n\n0.2386041\n0.1399036\n0.2716895\n0.1360916\n0.2137112\n\n\n0.2985370\n0.1541515\n0.2635704\n0.1169819\n0.1667592\n\n\n0.3107783\n0.1562639\n0.2608135\n0.1132613\n0.1588830\n\n\n0.3028159\n0.1549192\n0.2626413\n0.1156729\n0.1639508\n\n\n0.3358001\n0.1597984\n0.2543217\n0.1058975\n0.1441823\n\n\n0.3776575\n0.1634886\n0.2414314\n0.0943383\n0.1230841\n\n\n0.2386041\n0.1399036\n0.2716895\n0.1360916\n0.2137112\n\n\n0.2227442\n0.1349732\n0.2718842\n0.1412808\n0.2291176\n\n\n0.2849546\n0.1515019\n0.2662537\n0.1211945\n0.1760952\n\n\n0.3142572\n0.1568175\n0.2599765\n0.1122177\n0.1567310\n\n\n0.3448331\n0.1608244\n0.2517327\n0.1033218\n0.1392880\n\n\n0.3129854\n0.1566175\n0.2602851\n0.1125985\n0.1575134\n\n\n0.2227442\n0.1349732\n0.2718842\n0.1412808\n0.2291176\n\n\n0.3610887\n0.1623487\n0.2467928\n0.0987992\n0.1309706\n\n\n0.3652892\n0.1626767\n0.2454628\n0.0976541\n0.1289173\n\n\n0.2356749\n0.1390313\n0.2717993\n0.1370497\n0.2164448\n\n\n0.2650151\n0.1470094\n0.2693706\n0.1275210\n0.1910838\n\n\n0.2822723\n0.1509398\n0.2667328\n0.1220362\n0.1780188\n\n\n0.3465654\n0.1610064\n0.2512229\n0.1028330\n0.1383724\n\n\n0.2861997\n0.1517585\n0.2660255\n0.1208048\n0.1752116\n\n\n0.2995919\n0.1543437\n0.2633449\n0.1166584\n0.1660611\n\n\n0.3138592\n0.1567552\n0.2600734\n0.1123368\n0.1569753\n\n\n0.2750544\n0.1493625\n0.2679324\n0.1243163\n0.1833344\n\n\n0.2227442\n0.1349732\n0.2718842\n0.1412808\n0.2291176\n\n\n0.2345774\n0.1387000\n0.2718321\n0.1374089\n0.2174815\n\n\n0.2227442\n0.1349732\n0.2718842\n0.1412808\n0.2291176\n\n\n0.3314058\n0.1592520\n0.2555371\n0.1071666\n0.1466385\n\n\n0.3458390\n0.1609307\n0.2514372\n0.1030378\n0.1387554\n\n\n0.2472195\n0.1423704\n0.2711867\n0.1332794\n0.2059441\n\n\n0.2865524\n0.1518306\n0.2659601\n0.1206945\n0.1749623\n\n\n0.2345774\n0.1387000\n0.2718321\n0.1374089\n0.2174815\n\n\n0.2732305\n0.1489489\n0.2682142\n0.1248957\n0.1847107\n\n\n0.2780068\n0.1500192\n0.2674578\n0.1233811\n0.1811351\n\n\n0.2716834\n0.1485932\n0.2684462\n0.1253882\n0.1858889\n\n\n0.2818784\n0.1508562\n0.2668016\n0.1221601\n0.1783036\n\n\n0.2643479\n0.1468463\n0.2694562\n0.1277353\n0.1916143\n\n\n0.2742407\n0.1491787\n0.2680592\n0.1245746\n0.1839467\n\n\n0.3186802\n0.1574921\n0.2588802\n0.1109001\n0.1540475\n\n\n0.3429734\n0.1606238\n0.2522753\n0.1038485\n0.1402790\n\n\n0.2674993\n0.1476091\n0.2690409\n0.1267247\n0.1891261\n\n\n0.2227442\n0.1349732\n0.2718842\n0.1412808\n0.2291176\n\n\n0.2227442\n0.1349732\n0.2718842\n0.1412808\n0.2291176\n\n\n0.2386041\n0.1399036\n0.2716895\n0.1360916\n0.2137112\n\n\n0.2416607\n0.1407955\n0.2715412\n0.1350927\n0.2109098\n\n\n0.2921767\n0.1529514\n0.2648789\n0.1189439\n0.1710491\n\n\n0.3574900\n0.1620464\n0.2479155\n0.0997879\n0.1327602\n\n\n0.3804158\n0.1636389\n0.2405103\n0.0936103\n0.1218248\n\n\n0.2584197\n0.1453607\n0.2701586\n0.1296451\n0.1964158\n\n\n0.2386041\n0.1399036\n0.2716895\n0.1360916\n0.2137112\n\n\n0.2479759\n0.1425800\n0.2711302\n0.1330330\n0.2052809\n\n\n0.2470295\n0.1423175\n0.2712006\n0.1333412\n0.2061111\n\n\n0.3403211\n0.1603281\n0.2530407\n0.1046028\n0.1417072\n\n\n0.3464497\n0.1609944\n0.2512570\n0.1028656\n0.1384332\n\n\n0.2861997\n0.1517585\n0.2660255\n0.1208048\n0.1752116\n\n\n0.2969255\n0.1538542\n0.2639102\n0.1174772\n0.1678329\n\n\n0.2638329\n0.1467199\n0.2695213\n0.1279008\n0.1920251\n\n\n0.2227442\n0.1349732\n0.2718842\n0.1412808\n0.2291176\n\n\n0.2541703\n0.1442546\n0.2705962\n0.1310204\n0.1999586\n\n\n0.2227442\n0.1349732\n0.2718842\n0.1412808\n0.2291176\n\n\n0.3176095\n0.1573318\n0.2591488\n0.1112181\n0.1546918\n\n\n0.2356749\n0.1390313\n0.2717993\n0.1370497\n0.2164448\n\n\n0.3449319\n0.1608349\n0.2517037\n0.1032939\n0.1392355\n\n\n0.2227442\n0.1349732\n0.2718842\n0.1412808\n0.2291176\n\n\n0.2714814\n0.1485465\n0.2684760\n0.1254526\n0.1860434\n\n\n0.2670993\n0.1475133\n0.2690951\n0.1268528\n0.1894395\n\n\n0.2491157\n0.1428937\n0.2710414\n0.1326621\n0.2042872\n\n\n0.2472195\n0.1423704\n0.2711867\n0.1332794\n0.2059441\n\n\n0.2662055\n0.1472982\n0.2692148\n0.1271392\n0.1901424\n\n\n0.3400319\n0.1602952\n0.2531236\n0.1046853\n0.1418639\n\n\n0.2227442\n0.1349732\n0.2718842\n0.1412808\n0.2291176\n\n\n0.3048008\n0.1552646\n0.2621974\n0.1150688\n0.1626684\n\n\n0.3487599\n0.1612302\n0.2505711\n0.1022160\n0.1372227\n\n\n0.2468396\n0.1422647\n0.2712143\n0.1334031\n0.2062783\n\n\n0.2468396\n0.1422647\n0.2712143\n0.1334031\n0.2062783\n\n\n0.2631629\n0.1465547\n0.2696050\n0.1281162\n0.1925613\n\n\n0.2539123\n0.1441863\n0.2706209\n0.1311040\n0.2001765\n\n\n0.4360815\n0.1643780\n0.2205458\n0.0797787\n0.0992161\n\n\n0.3614085\n0.1623746\n0.2466923\n0.0987116\n0.1308129\n\n\n0.3856844\n0.1638949\n0.2387300\n0.0922310\n0.1194597\n\n\n0.2630545\n0.1465278\n0.2696184\n0.1281510\n0.1926483\n\n\n0.2227442\n0.1349732\n0.2718842\n0.1412808\n0.2291176\n\n\n0.2820901\n0.1509012\n0.2667647\n0.1220935\n0.1781505\n\n\n0.2227442\n0.1349732\n0.2718842\n0.1412808\n0.2291176\n\n\n0.2521523\n0.1437172\n0.2707839\n0.1316751\n0.2016715\n\n\n0.4093488\n0.1645564\n0.2304272\n0.0862192\n0.1094484\n\n\n0.2618779\n0.1462354\n0.2697616\n0.1285297\n0.1935954\n\n\n0.2787003\n0.1501711\n0.2673431\n0.1231619\n0.1806236\n\n\n0.3711941\n0.1630927\n0.2435589\n0.0960607\n0.1260936\n\n\n0.2716834\n0.1485932\n0.2684462\n0.1253882\n0.1858889\n\n\n0.2221723\n0.1347858\n0.2718721\n0.1414677\n0.2297021\n\n\n0.2804387\n0.1505481\n0.2670501\n0.1226134\n0.1793497\n\n\n0.2595255\n0.1456429\n0.2700356\n0.1292880\n0.1955080\n\n\n0.3445585\n0.1607951\n0.2518131\n0.1033995\n0.1394338\n\n\n0.2861997\n0.1517585\n0.2660255\n0.1208048\n0.1752116\n\n\n0.2468396\n0.1422647\n0.2712143\n0.1334031\n0.2062783\n\n\n0.4404690\n0.1642583\n0.2188820\n0.0787561\n0.0976346\n\n\n0.2730326\n0.1489036\n0.2682442\n0.1249587\n0.1848609\n\n\n0.4248463\n0.1645695\n0.2247553\n0.0824411\n0.1033878\n\n\n0.2778019\n0.1499741\n0.2674915\n0.1234459\n0.1812866\n\n\n0.2227442\n0.1349732\n0.2718842\n0.1412808\n0.2291176\n\n\n0.2227442\n0.1349732\n0.2718842\n0.1412808\n0.2291176\n\n\n0.2468396\n0.1422647\n0.2712143\n0.1334031\n0.2062783\n\n\n0.2822969\n0.1509451\n0.2667285\n0.1220285\n0.1780010\n\n\n0.2674993\n0.1476091\n0.2690409\n0.1267247\n0.1891261\n\n\n0.3028159\n0.1549192\n0.2626413\n0.1156729\n0.1639508\n\n\n0.2227442\n0.1349732\n0.2718842\n0.1412808\n0.2291176\n\n\n0.2347608\n0.1387556\n0.2718270\n0.1373489\n0.2173078\n\n\n0.3248987\n0.1583853\n0.2572804\n0.1090649\n0.1503707\n\n\n0.2967174\n0.1538154\n0.2639537\n0.1175412\n0.1679722\n\n\n0.3458390\n0.1609307\n0.2514372\n0.1030378\n0.1387554\n\n\n0.3027851\n0.1549138\n0.2626481\n0.1156823\n0.1639708\n\n\n0.3035144\n0.1550415\n0.2624860\n0.1154601\n0.1634980\n\n\n0.2985268\n0.1541497\n0.2635725\n0.1169851\n0.1667660\n\n\n0.2584197\n0.1453607\n0.2701586\n0.1296451\n0.1964158\n\n\n0.2730326\n0.1489036\n0.2682442\n0.1249587\n0.1848609\n\n\n0.2227442\n0.1349732\n0.2718842\n0.1412808\n0.2291176\n\n\n0.2638329\n0.1467199\n0.2695213\n0.1279008\n0.1920251\n\n\n0.2416607\n0.1407955\n0.2715412\n0.1350927\n0.2109098\n\n\n0.2227442\n0.1349732\n0.2718842\n0.1412808\n0.2291176\n\n\n0.2638329\n0.1467199\n0.2695213\n0.1279008\n0.1920251\n\n\n0.3506674\n0.1614187\n0.2499993\n0.1016819\n0.1362327\n\n\n0.2543639\n0.1443058\n0.2705775\n0.1309576\n0.1997953\n\n\n0.2468396\n0.1422647\n0.2712143\n0.1334031\n0.2062783\n\n\n0.3259181\n0.1585257\n0.2570119\n0.1087660\n0.1497783\n\n\n0.2730326\n0.1489036\n0.2682442\n0.1249587\n0.1848609\n\n\n0.2227442\n0.1349732\n0.2718842\n0.1412808\n0.2291176\n\n\n0.2716834\n0.1485932\n0.2684462\n0.1253882\n0.1858889\n\n\n0.2674993\n0.1476091\n0.2690409\n0.1267247\n0.1891261\n\n\n0.2227442\n0.1349732\n0.2718842\n0.1412808\n0.2291176\n\n\n0.2992502\n0.1542817\n0.2634182\n0.1167631\n0.1662868\n\n\n0.3675130\n0.1628395\n0.2447504\n0.0970517\n0.1278454\n\n\n0.3268536\n0.1586530\n0.2567640\n0.1084922\n0.1492373\n\n\n0.2541703\n0.1442546\n0.2705962\n0.1310204\n0.1999586\n\n\n0.3487268\n0.1612269\n0.2505810\n0.1022253\n0.1372400\n\n\n0.2630545\n0.1465278\n0.2696184\n0.1281510\n0.1926483\n\n\n0.2840242\n0.1513084\n0.2664219\n0.1214861\n0.1767594\n\n\n0.2584197\n0.1453607\n0.2701586\n0.1296451\n0.1964158\n\n\n0.3125256\n0.1565445\n0.2603960\n0.1127364\n0.1577975\n\n\n0.2543639\n0.1443058\n0.2705775\n0.1309576\n0.1997953\n\n\n0.3647538\n0.1626364\n0.2456334\n0.0977995\n0.1291769\n\n\n0.2650151\n0.1470094\n0.2693706\n0.1275210\n0.1910838\n\n\n0.2730326\n0.1489036\n0.2682442\n0.1249587\n0.1848609\n\n\n0.3027851\n0.1549138\n0.2626481\n0.1156823\n0.1639708\n\n\n0.2841429\n0.1513332\n0.2664006\n0.1214489\n0.1766745\n\n\n0.3182317\n0.1574252\n0.2589930\n0.1110332\n0.1543170\n\n\n0.2386041\n0.1399036\n0.2716895\n0.1360916\n0.2137112\n\n\n0.2992502\n0.1542817\n0.2634182\n0.1167631\n0.1662868\n\n\n0.2597218\n0.1456927\n0.2700134\n0.1292247\n0.1953474\n\n\n0.3001024\n0.1544361\n0.2632349\n0.1165020\n0.1657247\n\n\n0.3138592\n0.1567552\n0.2600734\n0.1123368\n0.1569753\n\n\n0.2714814\n0.1485465\n0.2684760\n0.1254526\n0.1860434\n\n\n0.2552179\n0.1445305\n0.2704936\n0.1306809\n0.1990772\n\n\n0.2472195\n0.1423704\n0.2711867\n0.1332794\n0.2059441\n\n\n0.2472195\n0.1423704\n0.2711867\n0.1332794\n0.2059441\n\n\n0.2543639\n0.1443058\n0.2705775\n0.1309576\n0.1997953\n\n\n0.2227442\n0.1349732\n0.2718842\n0.1412808\n0.2291176\n\n\n0.2227442\n0.1349732\n0.2718842\n0.1412808\n0.2291176\n\n\n0.3383916\n0.1601060\n0.2535911\n0.1051540\n0.1427572\n\n\n0.2227442\n0.1349732\n0.2718842\n0.1412808\n0.2291176\n\n\n0.3557328\n0.1618916\n0.2484578\n0.1002733\n0.1336445\n\n\n0.2630545\n0.1465278\n0.2696184\n0.1281510\n0.1926483\n\n\n0.2227442\n0.1349732\n0.2718842\n0.1412808\n0.2291176\n\n\n0.2227442\n0.1349732\n0.2718842\n0.1412808\n0.2291176\n\n\n0.3450638\n0.1608489\n0.2516650\n0.1032566\n0.1391656\n\n\n0.2521523\n0.1437172\n0.2707839\n0.1316751\n0.2016715\n\n\n0.3418785\n0.1605031\n0.2525925\n0.1041594\n0.1408665\n\n\n0.3383916\n0.1601060\n0.2535911\n0.1051540\n0.1427572\n\n\n0.2960887\n0.1536979\n0.2640845\n0.1177349\n0.1683939\n\n\n0.4019398\n0.1644340\n0.2330769\n0.0880695\n0.1124799\n\n\n0.2638329\n0.1467199\n0.2695213\n0.1279008\n0.1920251\n\n\n0.2511953\n0.1434596\n0.2708683\n0.1319859\n0.2024909\n\n\n0.3273673\n0.1587223\n0.2566272\n0.1083420\n0.1489412\n\n\n0.3416706\n0.1604799\n0.2526526\n0.1042185\n0.1409783\n\n\n0.2553288\n0.1445596\n0.2704825\n0.1306449\n0.1989842\n\n\n0.2635544\n0.1466513\n0.2695563\n0.1279903\n0.1922478\n\n\n0.2584197\n0.1453607\n0.2701586\n0.1296451\n0.1964158\n\n\n0.2839797\n0.1512991\n0.2664299\n0.1215001\n0.1767912\n\n\n0.4573204\n0.1635692\n0.2123995\n0.0749159\n0.0917951\n\n\n0.2682956\n0.1477989\n0.2689314\n0.1264698\n0.1885042\n\n\n0.2227442\n0.1349732\n0.2718842\n0.1412808\n0.2291176\n\n\n0.2844644\n0.1514002\n0.2663426\n0.1213481\n0.1764447\n\n\n0.2730326\n0.1489036\n0.2682442\n0.1249587\n0.1848609\n\n\n0.3107783\n0.1562639\n0.2608135\n0.1132613\n0.1588830\n\n\n0.4886607\n0.1613521\n0.2000239\n0.0681290\n0.0818343\n\n\n0.4450517\n0.1641067\n0.2171331\n0.0776981\n0.0960104\n\n\n0.3537072\n0.1617072\n0.2490783\n0.1008349\n0.1346724\n\n\n0.3525464\n0.1615987\n0.2494314\n0.1011577\n0.1352657\n\n\n0.3707118\n0.1630607\n0.2437158\n0.0961901\n0.1263216\n\n\n0.2386041\n0.1399036\n0.2716895\n0.1360916\n0.2137112\n\n\n0.2470295\n0.1423175\n0.2712006\n0.1333412\n0.2061111\n\n\n0.3487268\n0.1612269\n0.2505810\n0.1022253\n0.1372400\n\n\n0.2227442\n0.1349732\n0.2718842\n0.1412808\n0.2291176\n\n\n0.3333427\n0.1594967\n0.2550051\n0.1066059\n0.1455497\n\n\n0.2227442\n0.1349732\n0.2718842\n0.1412808\n0.2291176\n\n\n0.2670993\n0.1475133\n0.2690951\n0.1268528\n0.1894395\n\n\n0.2978653\n0.1540281\n0.2637127\n0.1171882\n0.1672056\n\n\n0.2356749\n0.1390313\n0.2717993\n0.1370497\n0.2164448\n\n\n0.3421903\n0.1605376\n0.2525024\n0.1040708\n0.1406989\n\n\n0.2345774\n0.1387000\n0.2718321\n0.1374089\n0.2174815\n\n\n0.2345774\n0.1387000\n0.2718321\n0.1374089\n0.2174815\n\n\n0.3104764\n0.1562149\n0.2608851\n0.1133522\n0.1590715\n\n\n0.2932287\n0.1531548\n0.2646686\n0.1186181\n0.1703298\n\n\n0.2227442\n0.1349732\n0.2718842\n0.1412808\n0.2291176\n\n\n0.2958658\n0.1536561\n0.2641307\n0.1178036\n0.1685438\n\n\n0.2714814\n0.1485465\n0.2684760\n0.1254526\n0.1860434\n\n\n0.2510078\n0.1434089\n0.2708845\n0.1320468\n0.2026519\n\n\n0.3001024\n0.1544361\n0.2632349\n0.1165020\n0.1657247\n\n\n0.3046514\n0.1552388\n0.2622311\n0.1151142\n0.1627645\n\n\n0.2356749\n0.1390313\n0.2717993\n0.1370497\n0.2164448\n\n\n0.2416607\n0.1407955\n0.2715412\n0.1350927\n0.2109098\n\n\n0.2750544\n0.1493625\n0.2679324\n0.1243163\n0.1833344\n\n\n0.2946011\n0.1534172\n0.2643906\n0.1181938\n0.1693973\n\n\n0.2608968\n0.1459896\n0.2698779\n0.1288458\n0.1943900\n\n\n0.2907709\n0.1526765\n0.2651560\n0.1193802\n0.1720165\n\n\n0.2740423\n0.1491338\n0.2680899\n0.1246377\n0.1840964\n\n\n0.2670993\n0.1475133\n0.2690951\n0.1268528\n0.1894395\n\n\n0.3113515\n0.1563565\n0.2606772\n0.1130889\n0.1585259\n\n\n0.3696745\n0.1629907\n0.2440526\n0.0964689\n0.1268134\n\n\n0.2521523\n0.1437172\n0.2707839\n0.1316751\n0.2016715\n\n\n0.3399119\n0.1602815\n0.2531579\n0.1047196\n0.1419291\n\n\n0.3501140\n0.1613646\n0.2501657\n0.1018367\n0.1365190\n\n\n0.2874480\n0.1520129\n0.2657929\n0.1204148\n0.1743315\n\n\n0.3732051\n0.1632226\n0.2429017\n0.0955223\n0.1251483\n\n\n0.2558377\n0.1446927\n0.2704312\n0.1304801\n0.1985582\n\n\n0.2345774\n0.1387000\n0.2718321\n0.1374089\n0.2174815\n\n\n0.2960887\n0.1536979\n0.2640845\n0.1177349\n0.1683939\n\n\n0.3287125\n0.1589017\n0.2562670\n0.1079495\n0.1481693\n\n\n0.2713084\n0.1485063\n0.2685015\n0.1255078\n0.1861760\n\n\n0.3201548\n0.1577097\n0.2585069\n0.1104630\n0.1531656\n\n\n0.2584197\n0.1453607\n0.2701586\n0.1296451\n0.1964158\n\n\n0.2846773\n0.1514444\n0.2663041\n0.1212814\n0.1762929\n\n\n0.2599182\n0.1457425\n0.2699910\n0.1291613\n0.1951869\n\n\n0.2227442\n0.1349732\n0.2718842\n0.1412808\n0.2291176\n\n\n0.3487268\n0.1612269\n0.2505810\n0.1022253\n0.1372400\n\n\n0.3177940\n0.1573595\n0.2591027\n0.1111633\n0.1545805\n\n\n0.2227442\n0.1349732\n0.2718842\n0.1412808\n0.2291176\n\n\n0.2911270\n0.1527465\n0.2650862\n0.1192696\n0.1717708\n\n\n0.2491157\n0.1428937\n0.2710414\n0.1326621\n0.2042872\n\n\n0.2851627\n0.1515450\n0.2662158\n0.1211293\n0.1759471\n\n\n0.2995919\n0.1543437\n0.2633449\n0.1166584\n0.1660611\n\n\n0.2810524\n0.1506799\n0.2669448\n0.1224201\n0.1789028\n\n\n0.4352387\n0.1643981\n0.2208641\n0.0799762\n0.0995228\n\n\n0.3186802\n0.1574921\n0.2588802\n0.1109001\n0.1540475\n\n\n0.4059790\n0.1645102\n0.2316377\n0.0870572\n0.1108160\n\n\n0.2472195\n0.1423704\n0.2711867\n0.1332794\n0.2059441\n\n\n0.2782900\n0.1500813\n0.2674111\n0.1232916\n0.1809260\n\n\n0.2705352\n0.1483264\n0.2686142\n0.1257544\n0.1867698\n\n\n0.2479759\n0.1425800\n0.2711302\n0.1330330\n0.2052809\n\n\n0.2864083\n0.1518012\n0.2659868\n0.1207396\n0.1750641\n\n\n0.2960887\n0.1536979\n0.2640845\n0.1177349\n0.1683939\n\n\n0.3224239\n0.1580375\n0.2579251\n0.1097928\n0.1518208\n\n\n0.4749795\n0.1624662\n0.2054705\n0.0710364\n0.0860474\n\n\n0.3508446\n0.1614359\n0.2499460\n0.1016324\n0.1361411\n\n\n0.3485004\n0.1612042\n0.2506485\n0.1022889\n0.1373580\n\n\n0.2784951\n0.1501263\n0.2673772\n0.1232267\n0.1807747\n\n\n0.2849546\n0.1515019\n0.2662537\n0.1211945\n0.1760952\n\n\n0.3186802\n0.1574921\n0.2588802\n0.1109001\n0.1540475\n\n\n0.2345774\n0.1387000\n0.2718321\n0.1374089\n0.2174815\n\n\n0.3603823\n0.1622910\n0.2470144\n0.0989927\n0.1313196\n\n\n0.3231574\n0.1581416\n0.2577351\n0.1095767\n0.1513892\n\n\n0.2967174\n0.1538154\n0.2639537\n0.1175412\n0.1679722\n\n\n0.2597218\n0.1456927\n0.2700134\n0.1292247\n0.1953474\n\n\n0.2990362\n0.1542427\n0.2634640\n0.1168288\n0.1664284\n\n\n0.3399119\n0.1602815\n0.2531579\n0.1047196\n0.1419291\n\n\n0.3272923\n0.1587122\n0.2566472\n0.1083639\n0.1489844\n\n\n0.2650151\n0.1470094\n0.2693706\n0.1275210\n0.1910838\n\n\n0.4029747\n0.1644557\n0.2327094\n0.0878093\n0.1120510\n\n\n0.3868891\n0.1639478\n0.2383192\n0.0919177\n0.1189262\n\n\n0.3400319\n0.1602952\n0.2531236\n0.1046853\n0.1418639\n\n\n0.2958658\n0.1536561\n0.2641307\n0.1178036\n0.1685438\n\n\n0.3588929\n0.1621666\n0.2474797\n0.0994016\n0.1320592\n\n\n0.3559669\n0.1619125\n0.2483858\n0.1002085\n0.1335263\n\n\n0.3818551\n0.1637128\n0.2400266\n0.0932320\n0.1211734\n\n\n0.2468396\n0.1422647\n0.2712143\n0.1334031\n0.2062783\n\n\n0.4753857\n0.1624363\n0.2053097\n0.0709489\n0.0859194\n\n\n0.2584197\n0.1453607\n0.2701586\n0.1296451\n0.1964158\n\n\n0.2714814\n0.1485465\n0.2684760\n0.1254526\n0.1860434\n\n\n0.3144773\n0.1568519\n0.2599228\n0.1121519\n0.1565961\n\n\n0.2918852\n0.1528947\n0.2649367\n0.1190343\n0.1712491\n\n\n0.3209809\n0.1578300\n0.2582961\n0.1102187\n0.1526743\n\n\n0.2584197\n0.1453607\n0.2701586\n0.1296451\n0.1964158\n\n\n0.2946011\n0.1534172\n0.2643906\n0.1181938\n0.1693973\n\n\n0.2227442\n0.1349732\n0.2718842\n0.1412808\n0.2291176\n\n\n0.2386041\n0.1399036\n0.2716895\n0.1360916\n0.2137112\n\n\n0.2681811\n0.1477717\n0.2689473\n0.1265065\n0.1885935\n\n\n0.2468396\n0.1422647\n0.2712143\n0.1334031\n0.2062783\n\n\n0.3623910\n0.1624533\n0.2463827\n0.0984431\n0.1303299\n\n\n0.3072172\n0.1556759\n0.2616464\n0.1143359\n0.1611246\n\n\n0.3053678\n0.1553620\n0.2620692\n0.1148965\n0.1623045\n\n\n0.2635544\n0.1466513\n0.2695563\n0.1279903\n0.1922478\n\n\n0.3207531\n0.1577969\n0.2583544\n0.1102861\n0.1528096\n\n\n0.2379775\n0.1397184\n0.2717157\n0.1362965\n0.2142919\n\n\n0.3527796\n0.1616207\n0.2493606\n0.1010928\n0.1351463\n\n\n0.2479759\n0.1425800\n0.2711302\n0.1330330\n0.2052809\n\n\n0.3804158\n0.1636389\n0.2405103\n0.0936103\n0.1218248\n\n\n0.2356749\n0.1390313\n0.2717993\n0.1370497\n0.2164448\n\n\n0.2227442\n0.1349732\n0.2718842\n0.1412808\n0.2291176\n\n\n0.2531071\n0.1439725\n0.2706967\n0.1313652\n0.2008586\n\n\n0.3209067\n0.1578193\n0.2583151\n0.1102406\n0.1527183\n\n\n0.2227442\n0.1349732\n0.2718842\n0.1412808\n0.2291176\n\n\n0.3100341\n0.1561428\n0.2609896\n0.1134853\n0.1593481\n\n\n0.3509997\n0.1614509\n0.2498992\n0.1015891\n0.1360611\n\n\n0.2470295\n0.1423175\n0.2712006\n0.1333412\n0.2061111\n\n\n0.2227442\n0.1349732\n0.2718842\n0.1412808\n0.2291176\n\n\n0.3635547\n0.1625445\n0.2460145\n0.0981257\n0.1297606\n\n\n0.2862891\n0.1517768\n0.2660089\n0.1207769\n0.1751484\n\n\n0.2356749\n0.1390313\n0.2717993\n0.1370497\n0.2164448\n\n\n0.3217497\n0.1579410\n0.2580989\n0.1099916\n0.1522188\n\n\n0.3364837\n0.1598806\n0.2541300\n0.1057011\n0.1438047\n\n\n0.3645961\n0.1626244\n0.2456837\n0.0978423\n0.1292535\n\n\n0.2877967\n0.1520834\n0.2657273\n0.1203060\n0.1740866\n\n\n0.2650151\n0.1470094\n0.2693706\n0.1275210\n0.1910838\n\n\n0.2846773\n0.1514444\n0.2663041\n0.1212814\n0.1762929\n\n\n0.2861997\n0.1517585\n0.2660255\n0.1208048\n0.1752116\n\n\n0.2960887\n0.1536979\n0.2640845\n0.1177349\n0.1683939\n\n\n0.2347608\n0.1387556\n0.2718270\n0.1373489\n0.2173078\n\n\n0.2808510\n0.1506367\n0.2669795\n0.1224835\n0.1790493\n\n\n0.2990362\n0.1542427\n0.2634640\n0.1168288\n0.1664284\n\n\n0.2472195\n0.1423704\n0.2711867\n0.1332794\n0.2059441\n\n\n0.2227442\n0.1349732\n0.2718842\n0.1412808\n0.2291176\n\n\n0.2227442\n0.1349732\n0.2718842\n0.1412808\n0.2291176\n\n\n0.2227442\n0.1349732\n0.2718842\n0.1412808\n0.2291176\n\n\n0.2806448\n0.1505925\n0.2670148\n0.1225485\n0.1791995\n\n\n0.3131371\n0.1566415\n0.2602485\n0.1125531\n0.1574198\n\n\n0.2227442\n0.1349732\n0.2718842\n0.1412808\n0.2291176\n\n\n0.3514872\n0.1614979\n0.2497521\n0.1014530\n0.1358098\n\n\n0.3030007\n0.1549516\n0.2626003\n0.1156166\n0.1638308\n\n\n0.3399119\n0.1602815\n0.2531579\n0.1047196\n0.1419291\n\n\n0.2607000\n0.1459400\n0.2699009\n0.1289092\n0.1945499\n\n\n0.2782900\n0.1500813\n0.2674111\n0.1232916\n0.1809260\n\n\n0.2874480\n0.1520129\n0.2657929\n0.1204148\n0.1743315\n\n\n0.2227442\n0.1349732\n0.2718842\n0.1412808\n0.2291176\n\n\n0.2852172\n0.1515563\n0.2662059\n0.1211122\n0.1759084\n\n\n0.2877967\n0.1520834\n0.2657273\n0.1203060\n0.1740866\n\n\n0.3033448\n0.1550119\n0.2625238\n0.1155117\n0.1636078\n\n\n0.2977382\n0.1540047\n0.2637395\n0.1172273\n0.1672903\n\n\n0.2601100\n0.1457911\n0.2699691\n0.1290995\n0.1950304\n\n\n0.2510078\n0.1434089\n0.2708845\n0.1320468\n0.2026519\n\n\n0.3477390\n0.1611271\n0.2508751\n0.1025027\n0.1377561\n\n\n0.2638329\n0.1467199\n0.2695213\n0.1279008\n0.1920251\n\n\n0.2227442\n0.1349732\n0.2718842\n0.1412808\n0.2291176\n\n\n0.2468396\n0.1422647\n0.2712143\n0.1334031\n0.2062783\n\n\n0.2599182\n0.1457425\n0.2699910\n0.1291613\n0.1951869\n\n\n0.2904150\n0.1526064\n0.2652254\n0.1194907\n0.1722625\n\n\n0.3487268\n0.1612269\n0.2505810\n0.1022253\n0.1372400\n\n\n0.2853709\n0.1515880\n0.2661778\n0.1210641\n0.1757991\n\n\n0.2227442\n0.1349732\n0.2718842\n0.1412808\n0.2291176\n\n\n0.2861997\n0.1517585\n0.2660255\n0.1208048\n0.1752116\n\n\n0.2861997\n0.1517585\n0.2660255\n0.1208048\n0.1752116\n\n\n0.2468396\n0.1422647\n0.2712143\n0.1334031\n0.2062783\n\n\n0.2726901\n0.1488252\n0.2682960\n0.1250677\n0.1851211\n\n\n0.2607000\n0.1459400\n0.2699009\n0.1289092\n0.1945499\n\n\n0.2356749\n0.1390313\n0.2717993\n0.1370497\n0.2164448\n\n\n0.3772805\n0.1634672\n0.2415567\n0.0944382\n0.1232574\n\n\n0.2227442\n0.1349732\n0.2718842\n0.1412808\n0.2291176\n\n\n0.3965982\n0.1642982\n0.2349598\n0.0894214\n0.1147224\n\n\n0.3160098\n0.1570887\n0.2595463\n0.1116944\n0.1556607\n\n\n0.2416607\n0.1407955\n0.2715412\n0.1350927\n0.2109098\n\n\n0.2907508\n0.1526726\n0.2651599\n0.1193864\n0.1720303\n\n\n0.4122087\n0.1645834\n0.2293933\n0.0855126\n0.1083020\n\n\n0.2890491\n0.1523351\n0.2654892\n0.1199157\n0.1732110\n\n\n0.3032164\n0.1549894\n0.2625523\n0.1155509\n0.1636910\n\n\n0.2227442\n0.1349732\n0.2718842\n0.1412808\n0.2291176\n\n\n0.2620706\n0.1462835\n0.2697384\n0.1284676\n0.1934399\n\n\n0.2510078\n0.1434089\n0.2708845\n0.1320468\n0.2026519\n\n\n0.3336453\n0.1595343\n0.2549214\n0.1065185\n0.1453804\n\n\n0.2416607\n0.1407955\n0.2715412\n0.1350927\n0.2109098\n\n\n0.2227442\n0.1349732\n0.2718842\n0.1412808\n0.2291176\n\n\n0.2956582\n0.1536171\n0.2641736\n0.1178676\n0.1686835\n\n\n0.2640265\n0.1467675\n0.2694969\n0.1278385\n0.1918705\n\n\n0.2227442\n0.1349732\n0.2718842\n0.1412808\n0.2291176\n\n\n0.2584197\n0.1453607\n0.2701586\n0.1296451\n0.1964158\n\n\n0.4725731\n0.1626390\n0.2064219\n0.0715566\n0.0868095\n\n\n0.3600629\n0.1622646\n0.2471144\n0.0990803\n0.1314778\n\n\n0.2468396\n0.1422647\n0.2712143\n0.1334031\n0.2062783\n\n\n0.2778019\n0.1499741\n0.2674915\n0.1234459\n0.1812866\n\n\n0.2925137\n0.1530168\n0.2648118\n0.1188395\n0.1708182\n\n\n0.2345774\n0.1387000\n0.2718321\n0.1374089\n0.2174815\n\n\n0.2714814\n0.1485465\n0.2684760\n0.1254526\n0.1860434\n\n\n0.3104764\n0.1562149\n0.2608851\n0.1133522\n0.1590715\n\n\n0.3856844\n0.1638949\n0.2387300\n0.0922310\n0.1194597\n\n\n0.2861997\n0.1517585\n0.2660255\n0.1208048\n0.1752116\n\n\n0.3289378\n0.1589314\n0.2562064\n0.1078839\n0.1480405\n\n\n0.3028159\n0.1549192\n0.2626413\n0.1156729\n0.1639508\n\n\n0.2631629\n0.1465547\n0.2696050\n0.1281162\n0.1925613\n\n\n0.4804328\n0.1620489\n0.2033069\n0.0698674\n0.0843440\n\n\n0.3507173\n0.1614235\n0.2499843\n0.1016680\n0.1362069\n\n\n0.2470295\n0.1423175\n0.2712006\n0.1333412\n0.2061111\n\n\n0.3162726\n0.1571290\n0.2594813\n0.1116161\n0.1555010\n\n\n0.4311197\n0.1644831\n0.2224142\n0.0809467\n0.1010364\n\n\n0.3714948\n0.1631125\n0.2434609\n0.0959800\n0.1259517\n\n\n0.3266717\n0.1586283\n0.2568123\n0.1085454\n0.1493423\n\n\n0.2816718\n0.1508122\n0.2668376\n0.1222251\n0.1784533\n\n\n0.2597218\n0.1456927\n0.2700134\n0.1292247\n0.1953474\n\n\n0.2638329\n0.1467199\n0.2695213\n0.1279008\n0.1920251\n\n\n0.3253842\n0.1584524\n0.2571527\n0.1089225\n0.1500882\n\n\n0.2770708\n0.1498127\n0.2676107\n0.1236772\n0.1818285\n\n\n0.4360815\n0.1643780\n0.2205458\n0.0797787\n0.0992161\n\n\n0.3729209\n0.1632046\n0.2429948\n0.0955983\n0.1252814\n\n\n0.2543639\n0.1443058\n0.2705775\n0.1309576\n0.1997953\n\n\n0.2826616\n0.1510222\n0.2666643\n0.1219139\n0.1777380\n\n\n0.3242698\n0.1582979\n0.2574452\n0.1092495\n0.1507376\n\n\n0.3086265\n0.1559112\n0.2613198\n0.1139099\n0.1602327\n\n\n0.2227442\n0.1349732\n0.2718842\n0.1412808\n0.2291176\n\n\n0.3005315\n0.1545133\n0.2631420\n0.1163706\n0.1654425\n\n\n0.2386041\n0.1399036\n0.2716895\n0.1360916\n0.2137112\n\n\n0.2227442\n0.1349732\n0.2718842\n0.1412808\n0.2291176\n\n\n0.3082427\n0.1558474\n0.2614091\n0.1140258\n0.1604750\n\n\n0.3804158\n0.1636389\n0.2405103\n0.0936103\n0.1218248\n\n\n0.2386041\n0.1399036\n0.2716895\n0.1360916\n0.2137112\n\n\n0.2347608\n0.1387556\n0.2718270\n0.1373489\n0.2173078\n\n\n0.2345774\n0.1387000\n0.2718321\n0.1374089\n0.2174815\n\n\n0.2705352\n0.1483264\n0.2686142\n0.1257544\n0.1867698\n\n\n0.2714814\n0.1485465\n0.2684760\n0.1254526\n0.1860434\n\n\n0.2778019\n0.1499741\n0.2674915\n0.1234459\n0.1812866\n\n\n0.3030315\n0.1549570\n0.2625934\n0.1156072\n0.1638108\n\n\n0.2851627\n0.1515450\n0.2662158\n0.1211293\n0.1759471\n\n\n0.2345774\n0.1387000\n0.2718321\n0.1374089\n0.2174815\n\n\n0.2416607\n0.1407955\n0.2715412\n0.1350927\n0.2109098\n\n\n0.2674993\n0.1476091\n0.2690409\n0.1267247\n0.1891261\n\n\n0.2468396\n0.1422647\n0.2712143\n0.1334031\n0.2062783\n\n\n0.2865524\n0.1518306\n0.2659601\n0.1206945\n0.1749623\n\n\n0.2345774\n0.1387000\n0.2718321\n0.1374089\n0.2174815\n\n\n0.3726821\n0.1631894\n0.2430730\n0.0956621\n0.1253934\n\n\n0.2541703\n0.1442546\n0.2705962\n0.1310204\n0.1999586\n\n\n0.3535738\n0.1616949\n0.2491189\n0.1008720\n0.1347404\n\n\n0.3809087\n0.1636645\n0.2403449\n0.0934806\n0.1216013\n\n\n0.2347608\n0.1387556\n0.2718270\n0.1373489\n0.2173078\n\n\n0.2227442\n0.1349732\n0.2718842\n0.1412808\n0.2291176\n\n\n0.3743946\n0.1632965\n0.2425109\n0.0952050\n0.1245930\n\n\n0.3205306\n0.1577646\n0.2584111\n0.1103518\n0.1529418\n\n\n0.2816718\n0.1508122\n0.2668376\n0.1222251\n0.1784533\n\n\n0.4144963\n0.1645969\n0.2285619\n0.0849505\n0.1073943\n\n\n0.3726821\n0.1631894\n0.2430730\n0.0956621\n0.1253934\n\n\n0.2227442\n0.1349732\n0.2718842\n0.1412808\n0.2291176\n\n\n0.2227442\n0.1349732\n0.2718842\n0.1412808\n0.2291176\n\n\n0.3611729\n0.1623556\n0.2467663\n0.0987761\n0.1309291\n\n\n0.2468396\n0.1422647\n0.2712143\n0.1334031\n0.2062783\n\n\n0.2472195\n0.1423704\n0.2711867\n0.1332794\n0.2059441\n\n\n0.2681811\n0.1477717\n0.2689473\n0.1265065\n0.1885935\n\n\n0.3535738\n0.1616949\n0.2491189\n0.1008720\n0.1347404\n\n\n0.2347608\n0.1387556\n0.2718270\n0.1373489\n0.2173078\n\n\n0.2861997\n0.1517585\n0.2660255\n0.1208048\n0.1752116\n\n\n0.3140896\n0.1567913\n0.2600174\n0.1122679\n0.1568338\n\n\n0.3330564\n0.1594609\n0.2550841\n0.1066887\n0.1457100\n\n\n0.2472195\n0.1423704\n0.2711867\n0.1332794\n0.2059441\n\n\n0.2782900\n0.1500813\n0.2674111\n0.1232916\n0.1809260\n\n\n0.2907709\n0.1526765\n0.2651560\n0.1193802\n0.1720165\n\n\n0.2521523\n0.1437172\n0.2707839\n0.1316751\n0.2016715\n\n\n0.2638329\n0.1467199\n0.2695213\n0.1279008\n0.1920251\n\n\n0.2511953\n0.1434596\n0.2708683\n0.1319859\n0.2024909\n\n\n0.3453001\n0.1608739\n0.2515957\n0.1031899\n0.1390404\n\n\n0.2694953\n0.1480826\n0.2687632\n0.1260864\n0.1875725\n\n\n0.3173567\n0.1572937\n0.2592120\n0.1112933\n0.1548444\n\n\n0.3416159\n0.1604738\n0.2526683\n0.1042341\n0.1410078\n\n\n0.3068086\n0.1556070\n0.2617404\n0.1144596\n0.1613843\n\n\n0.3192030\n0.1575696\n0.2587483\n0.1107450\n0.1537341\n\n\n0.2643479\n0.1468463\n0.2694562\n0.1277353\n0.1916143\n\n\n0.3057289\n0.1554237\n0.2619872\n0.1147869\n0.1620732\n\n\n0.2227442\n0.1349732\n0.2718842\n0.1412808\n0.2291176\n\n\n0.3104764\n0.1562149\n0.2608851\n0.1133522\n0.1590715\n\n\n0.3294747\n0.1590020\n0.2560616\n0.1077276\n0.1477341\n\n\n0.2607000\n0.1459400\n0.2699009\n0.1289092\n0.1945499\n\n\n0.5019032\n0.1600641\n0.1946983\n0.0653936\n0.0779409\n\n\n0.2956582\n0.1536171\n0.2641736\n0.1178676\n0.1686835\n\n\n0.3146031\n0.1568715\n0.2598921\n0.1121143\n0.1565190\n\n\n0.2806448\n0.1505925\n0.2670148\n0.1225485\n0.1791995\n\n\n0.2861997\n0.1517585\n0.2660255\n0.1208048\n0.1752116\n\n\n0.2472195\n0.1423704\n0.2711867\n0.1332794\n0.2059441\n\n\n0.3505844\n0.1614106\n0.2500243\n0.1017051\n0.1362756\n\n\n0.2618779\n0.1462354\n0.2697616\n0.1285297\n0.1935954\n\n\n0.3596876\n0.1622334\n0.2472318\n0.0991833\n0.1316640\n\n\n0.2716834\n0.1485932\n0.2684462\n0.1253882\n0.1858889\n\n\n0.3042910\n0.1551765\n0.2623122\n0.1152237\n0.1629965\n\n\n0.3001024\n0.1544361\n0.2632349\n0.1165020\n0.1657247\n\n\n0.3287125\n0.1589017\n0.2562670\n0.1079495\n0.1481693\n\n\n0.2601100\n0.1457911\n0.2699691\n0.1290995\n0.1950304\n\n\n0.2904150\n0.1526064\n0.2652254\n0.1194907\n0.1722625\n\n\n0.3104764\n0.1562149\n0.2608851\n0.1133522\n0.1590715\n\n\n0.3732051\n0.1632226\n0.2429017\n0.0955223\n0.1251483\n\n\n0.3148233\n0.1569057\n0.2598382\n0.1120485\n0.1563842\n\n\n0.2552179\n0.1445305\n0.2704936\n0.1306809\n0.1990772\n\n\n0.4194079\n0.1646019\n0.2267645\n0.0837529\n0.1054729\n\n\n0.3205306\n0.1577646\n0.2584111\n0.1103518\n0.1529418\n\n\n0.2386041\n0.1399036\n0.2716895\n0.1360916\n0.2137112\n\n\n0.3830381\n0.1637713\n0.2396276\n0.0929219\n0.1206411\n\n\n0.2912574\n0.1527720\n0.2650606\n0.1192291\n0.1716809\n\n\n0.2227442\n0.1349732\n0.2718842\n0.1412808\n0.2291176\n\n\n0.3498817\n0.1613417\n0.2502354\n0.1019017\n0.1366394\n\n\n0.2816718\n0.1508122\n0.2668376\n0.1222251\n0.1784533\n\n\n0.2479759\n0.1425800\n0.2711302\n0.1330330\n0.2052809\n\n\n0.3909743\n0.1641117\n0.2369160\n0.0908612\n0.1171368\n\n\n0.2787003\n0.1501711\n0.2673431\n0.1231619\n0.1806236\n\n\n0.3503464\n0.1613873\n0.2500959\n0.1017717\n0.1363987\n\n\n0.3111221\n0.1563195\n0.2607318\n0.1131579\n0.1586686\n\n\n0.2347608\n0.1387556\n0.2718270\n0.1373489\n0.2173078\n\n\n0.2472195\n0.1423704\n0.2711867\n0.1332794\n0.2059441\n\n\n0.2983181\n0.1541114\n0.2636169\n0.1170491\n0.1669045\n\n\n0.3524132\n0.1615861\n0.2494718\n0.1011948\n0.1353340\n\n\n0.2468396\n0.1422647\n0.2712143\n0.1334031\n0.2062783\n\n\n0.3633860\n0.1625314\n0.2460680\n0.0981717\n0.1298429\n\n\n0.2356749\n0.1390313\n0.2717993\n0.1370497\n0.2164448\n\n\n0.4034075\n0.1644643\n0.2325554\n0.0877006\n0.1118721\n\n\n0.3147342\n0.1568919\n0.2598600\n0.1120752\n0.1564388\n\n\n0.2640265\n0.1467675\n0.2694969\n0.1278385\n0.1918705\n\n\n0.3455310\n0.1608983\n0.2515278\n0.1031247\n0.1389182\n\n\n0.3231255\n0.1581371\n0.2577434\n0.1095861\n0.1514079\n\n\n0.3312550\n0.1592327\n0.2555782\n0.1072103\n0.1467237\n\n\n0.2941214\n0.1533259\n0.2644883\n0.1183420\n0.1697225\n\n\n0.2610891\n0.1460379\n0.2698553\n0.1287838\n0.1942339\n\n\n0.2472195\n0.1423704\n0.2711867\n0.1332794\n0.2059441\n\n\n0.2345774\n0.1387000\n0.2718321\n0.1374089\n0.2174815\n\n\n0.2822723\n0.1509398\n0.2667328\n0.1220362\n0.1780188\n\n\n0.3042910\n0.1551765\n0.2623122\n0.1152237\n0.1629965\n\n\n0.2584197\n0.1453607\n0.2701586\n0.1296451\n0.1964158\n\n\n0.2552179\n0.1445305\n0.2704936\n0.1306809\n0.1990772\n\n\n0.2416607\n0.1407955\n0.2715412\n0.1350927\n0.2109098\n\n\n0.3146031\n0.1568715\n0.2598921\n0.1121143\n0.1565190\n\n\n0.3326568\n0.1594107\n0.2551941\n0.1068042\n0.1459341\n\n\n0.2979874\n0.1540506\n0.2636869\n0.1171507\n0.1671244\n\n\n0.2875924\n0.1520421\n0.2657657\n0.1203698\n0.1742300\n\n\n0.2682956\n0.1477989\n0.2689314\n0.1264698\n0.1885042\n\n\n0.2347608\n0.1387556\n0.2718270\n0.1373489\n0.2173078\n\n\n0.2227442\n0.1349732\n0.2718842\n0.1412808\n0.2291176\n\n\n0.3227321\n0.1580814\n0.2578453\n0.1097020\n0.1516392\n\n\n0.3756653\n0.1633732\n0.2420918\n0.0948668\n0.1240029\n\n\n0.3986422\n0.1643549\n0.2342421\n0.0889023\n0.1138585\n\n\n0.2967174\n0.1538154\n0.2639537\n0.1175412\n0.1679722\n\n\n0.2913377\n0.1527878\n0.2650448\n0.1192041\n0.1716255\n\n\n0.3011298\n0.1546205\n0.2630119\n0.1161877\n0.1650501\n\n\n0.2806448\n0.1505925\n0.2670148\n0.1225485\n0.1791995\n\n\n0.3416542\n0.1604781\n0.2526573\n0.1042232\n0.1409872\n\n\n0.2762680\n0.1496344\n0.2677401\n0.1239314\n0.1824261\n\n\n0.2932287\n0.1531548\n0.2646686\n0.1186181\n0.1703298\n\n\n0.2416607\n0.1407955\n0.2715412\n0.1350927\n0.2109098\n\n\n0.4093488\n0.1645564\n0.2304272\n0.0862192\n0.1094484\n\n\n0.3714948\n0.1631125\n0.2434609\n0.0959800\n0.1259517\n\n\n0.3530183\n0.1616431\n0.2492880\n0.1010264\n0.1350241\n\n\n0.2468396\n0.1422647\n0.2712143\n0.1334031\n0.2062783\n\n\n0.2472195\n0.1423704\n0.2711867\n0.1332794\n0.2059441\n\n\n0.2638329\n0.1467199\n0.2695213\n0.1279008\n0.1920251\n\n\n0.2849546\n0.1515019\n0.2662537\n0.1211945\n0.1760952\n\n\n0.3102526\n0.1561784\n0.2609380\n0.1134195\n0.1592114\n\n\n0.2725744\n0.1487986\n0.2683134\n0.1251045\n0.1852091\n\n\n0.2521523\n0.1437172\n0.2707839\n0.1316751\n0.2016715\n\n\n0.2416607\n0.1407955\n0.2715412\n0.1350927\n0.2109098\n\n\n0.2944950\n0.1533971\n0.2644122\n0.1182266\n0.1694691\n\n\n0.3734554\n0.1632383\n0.2428196\n0.0954555\n0.1250312\n\n\n0.2652141\n0.1470578\n0.2693449\n0.1274572\n0.1909261\n\n\n0.2921767\n0.1529514\n0.2648789\n0.1189439\n0.1710491\n\n\n0.2597218\n0.1456927\n0.2700134\n0.1292247\n0.1953474\n\n\n0.2890191\n0.1523291\n0.2654949\n0.1199250\n0.1732318\n\n\n0.2386041\n0.1399036\n0.2716895\n0.1360916\n0.2137112\n\n\n0.3180998\n0.1574054\n0.2590261\n0.1110724\n0.1543963\n\n\n0.2804387\n0.1505481\n0.2670501\n0.1226134\n0.1793497\n\n\n0.2714814\n0.1485465\n0.2684760\n0.1254526\n0.1860434\n\n\n0.2543639\n0.1443058\n0.2705775\n0.1309576\n0.1997953\n\n\n0.2227442\n0.1349732\n0.2718842\n0.1412808\n0.2291176\n\n\n0.2468396\n0.1422647\n0.2712143\n0.1334031\n0.2062783\n\n\n0.3186802\n0.1574921\n0.2588802\n0.1109001\n0.1540475\n\n\n0.4549741\n0.1636867\n0.2133102\n0.0754424\n0.0925866\n\n\n0.2468396\n0.1422647\n0.2712143\n0.1334031\n0.2062783\n\n\n0.3337858\n0.1595518\n0.2548825\n0.1064779\n0.1453019\n\n\n0.2479759\n0.1425800\n0.2711302\n0.1330330\n0.2052809\n\n\n0.3298347\n0.1590491\n0.2559643\n0.1076228\n0.1475292\n\n\n0.3003169\n0.1544747\n0.2631885\n0.1164363\n0.1655835\n\n\n0.2822723\n0.1509398\n0.2667328\n0.1220362\n0.1780188\n\n\n0.2816718\n0.1508122\n0.2668376\n0.1222251\n0.1784533\n\n\n0.2943132\n0.1533624\n0.2644493\n0.1182827\n0.1695924\n\n\n0.3104764\n0.1562149\n0.2608851\n0.1133522\n0.1590715\n\n\n0.3003169\n0.1544747\n0.2631885\n0.1164363\n0.1655835\n\n\n0.2347608\n0.1387556\n0.2718270\n0.1373489\n0.2173078\n\n\n0.2911270\n0.1527465\n0.2650862\n0.1192696\n0.1717708\n\n\n0.2810622\n0.1506820\n0.2669431\n0.1224170\n0.1788957\n\n\n0.2510078\n0.1434089\n0.2708845\n0.1320468\n0.2026519\n\n\n0.3856844\n0.1638949\n0.2387300\n0.0922310\n0.1194597\n\n\n0.2227442\n0.1349732\n0.2718842\n0.1412808\n0.2291176\n\n\n0.2510078\n0.1434089\n0.2708845\n0.1320468\n0.2026519\n\n\n0.2710057\n0.1484360\n0.2685458\n0.1256043\n0.1864082\n\n\n0.2227442\n0.1349732\n0.2718842\n0.1412808\n0.2291176\n\n\n0.2416607\n0.1407955\n0.2715412\n0.1350927\n0.2109098\n\n\n0.3168881\n0.1572227\n0.2593287\n0.1114327\n0.1551278\n\n\n0.3165882\n0.1571771\n0.2594032\n0.1115220\n0.1553095\n\n\n0.2995919\n0.1543437\n0.2633449\n0.1166584\n0.1660611\n\n\n0.2861997\n0.1517585\n0.2660255\n0.1208048\n0.1752116\n\n\n0.2416607\n0.1407955\n0.2715412\n0.1350927\n0.2109098\n\n\n0.3184902\n0.1574638\n0.2589280\n0.1109565\n0.1541616\n\n\n0.2597218\n0.1456927\n0.2700134\n0.1292247\n0.1953474\n\n\n0.3003169\n0.1544747\n0.2631885\n0.1164363\n0.1655835\n\n\n0.2543639\n0.1443058\n0.2705775\n0.1309576\n0.1997953\n\n\n0.2725744\n0.1487986\n0.2683134\n0.1251045\n0.1852091\n\n\n0.3292492\n0.1589724\n0.2561225\n0.1077932\n0.1478627\n\n\n0.2888393\n0.1522931\n0.2655293\n0.1199810\n0.1733572\n\n\n0.2227442\n0.1349732\n0.2718842\n0.1412808\n0.2291176\n\n\n0.3197845\n0.1576554\n0.2586010\n0.1105727\n0.1533865\n\n\n0.2541703\n0.1442546\n0.2705962\n0.1310204\n0.1999586\n\n\n0.2584570\n0.1453702\n0.2701545\n0.1296330\n0.1963851\n\n\n0.2541703\n0.1442546\n0.2705962\n0.1310204\n0.1999586\n\n\n0.2877967\n0.1520834\n0.2657273\n0.1203060\n0.1740866\n\n\n0.3860704\n0.1639121\n0.2385985\n0.0921305\n0.1192884\n\n\n0.2468396\n0.1422647\n0.2712143\n0.1334031\n0.2062783\n\n\n0.2877967\n0.1520834\n0.2657273\n0.1203060\n0.1740866\n\n\n0.3437682\n0.1607102\n0.2520440\n0.1036232\n0.1398544\n\n\n0.2386041\n0.1399036\n0.2716895\n0.1360916\n0.2137112\n\n\n0.3818207\n0.1637111\n0.2400382\n0.0932410\n0.1211890\n\n\n0.2510078\n0.1434089\n0.2708845\n0.1320468\n0.2026519\n\n\n0.3419605\n0.1605122\n0.2525688\n0.1041361\n0.1408224\n\n\n0.2227442\n0.1349732\n0.2718842\n0.1412808\n0.2291176\n\n\n0.2822723\n0.1509398\n0.2667328\n0.1220362\n0.1780188\n\n\n0.3949760\n0.1642490\n0.2355269\n0.0898350\n0.1154131\n\n\n0.3386203\n0.1601327\n0.2535262\n0.1050886\n0.1426323\n\n\n0.2543639\n0.1443058\n0.2705775\n0.1309576\n0.1997953\n\n\n0.3523134\n0.1615767\n0.2495021\n0.1012227\n0.1353852\n\n\n0.2347608\n0.1387556\n0.2718270\n0.1373489\n0.2173078\n\n\n0.3146031\n0.1568715\n0.2598921\n0.1121143\n0.1565190\n\n\n0.2630545\n0.1465278\n0.2696184\n0.1281510\n0.1926483\n\n\n0.2347608\n0.1387556\n0.2718270\n0.1373489\n0.2173078\n\n\n0.3050172\n0.1553018\n0.2621485\n0.1150030\n0.1625294\n\n\n0.2510078\n0.1434089\n0.2708845\n0.1320468\n0.2026519\n\n\n0.2511953\n0.1434596\n0.2708683\n0.1319859\n0.2024909\n\n\n0.2633609\n0.1466036\n0.2695804\n0.1280525\n0.1924026\n\n\n0.3171250\n0.1572586\n0.2592697\n0.1113622\n0.1549845\n\n\n0.2198324\n0.1340121\n0.2718080\n0.1422318\n0.2321157\n\n\n0.2607000\n0.1459400\n0.2699009\n0.1289092\n0.1945499\n\n\n0.3487268\n0.1612269\n0.2505810\n0.1022253\n0.1372400\n\n\n0.2633609\n0.1466036\n0.2695804\n0.1280525\n0.1924026\n\n\n0.3373962\n0.1599891\n0.2538729\n0.1054392\n0.1433025\n\n\n0.2630545\n0.1465278\n0.2696184\n0.1281510\n0.1926483\n\n\n0.3086265\n0.1559112\n0.2613198\n0.1139099\n0.1602327\n\n\n0.2985268\n0.1541497\n0.2635725\n0.1169851\n0.1667660\n\n\n0.2227442\n0.1349732\n0.2718842\n0.1412808\n0.2291176\n\n\n0.2902096\n0.1525658\n0.2652653\n0.1195546\n0.1724047\n\n\n0.2597218\n0.1456927\n0.2700134\n0.1292247\n0.1953474\n\n\n0.2347608\n0.1387556\n0.2718270\n0.1373489\n0.2173078\n\n\n0.2778019\n0.1499741\n0.2674915\n0.1234459\n0.1812866\n\n\n0.2948184\n0.1534585\n0.2643462\n0.1181267\n0.1692502\n\n\n0.2227442\n0.1349732\n0.2718842\n0.1412808\n0.2291176\n\n\n0.2670993\n0.1475133\n0.2690951\n0.1268528\n0.1894395\n\n\n0.2416607\n0.1407955\n0.2715412\n0.1350927\n0.2109098\n\n\n0.2345774\n0.1387000\n0.2718321\n0.1374089\n0.2174815\n\n\n0.3006746\n0.1545390\n0.2631110\n0.1163269\n0.1653485\n\n\n0.2996838\n0.1543604\n0.2633251\n0.1166302\n0.1660005\n\n\n0.2416607\n0.1407955\n0.2715412\n0.1350927\n0.2109098\n\n\n0.2227442\n0.1349732\n0.2718842\n0.1412808\n0.2291176\n\n\n0.2584197\n0.1453607\n0.2701586\n0.1296451\n0.1964158\n\n\n0.2867563\n0.1518722\n0.2659222\n0.1206308\n0.1748184\n\n\n0.2227442\n0.1349732\n0.2718842\n0.1412808\n0.2291176\n\n\n0.3140791\n0.1567897\n0.2600199\n0.1122710\n0.1568402\n\n\n0.3269177\n0.1586616\n0.2567469\n0.1084734\n0.1492003\n\n\n0.3638586\n0.1625680\n0.2459181\n0.0980430\n0.1296124\n\n\n0.2470295\n0.1423175\n0.2712006\n0.1333412\n0.2061111\n\n\n0.2991432\n0.1542622\n0.2634411\n0.1167959\n0.1663576\n\n\n0.2491157\n0.1428937\n0.2710414\n0.1326621\n0.2042872\n\n\n0.2584197\n0.1453607\n0.2701586\n0.1296451\n0.1964158\n\n\n0.2638329\n0.1467199\n0.2695213\n0.1279008\n0.1920251\n\n\n0.3042910\n0.1551765\n0.2623122\n0.1152237\n0.1629965\n\n\n0.2416607\n0.1407955\n0.2715412\n0.1350927\n0.2109098\n\n\n0.3545914\n0.1617885\n0.2488081\n0.1005895\n0.1342226\n\n\n0.3804158\n0.1636389\n0.2405103\n0.0936103\n0.1218248\n\n\n0.2347608\n0.1387556\n0.2718270\n0.1373489\n0.2173078\n\n\n0.4098957\n0.1645624\n0.2302300\n0.0860837\n0.1092282\n\n\n0.3334561\n0.1595108\n0.2549737\n0.1065732\n0.1454862\n\n\n0.3664681\n0.1627639\n0.2450858\n0.0973344\n0.1283477\n\n\n0.2468396\n0.1422647\n0.2712143\n0.1334031\n0.2062783\n\n\n0.2874480\n0.1520129\n0.2657929\n0.1204148\n0.1743315\n\n\n0.4093488\n0.1645564\n0.2304272\n0.0862192\n0.1094484\n\n\n0.3776232\n0.1634867\n0.2414428\n0.0943474\n0.1230998\n\n\n0.2227442\n0.1349732\n0.2718842\n0.1412808\n0.2291176\n\n\n0.2759133\n0.1495552\n0.2677967\n0.1240439\n0.1826909\n\n\n0.4215940\n0.1645936\n0.2259592\n0.0832238\n0.1046294\n\n\n0.2936471\n0.1532352\n0.2645843\n0.1184886\n0.1700448\n\n\n0.2347608\n0.1387556\n0.2718270\n0.1373489\n0.2173078\n\n\n0.2227442\n0.1349732\n0.2718842\n0.1412808\n0.2291176\n\n\n0.2227442\n0.1349732\n0.2718842\n0.1412808\n0.2291176\n\n\n0.2345774\n0.1387000\n0.2718321\n0.1374089\n0.2174815\n\n\n0.2934404\n0.1531955\n0.2646260\n0.1185526\n0.1701855\n\n\n0.2731774\n0.1489368\n0.2682223\n0.1249126\n0.1847510\n\n\n0.2911270\n0.1527465\n0.2650862\n0.1192696\n0.1717708\n\n\n0.3334237\n0.1595068\n0.2549827\n0.1065825\n0.1455043\n\n\n0.2227442\n0.1349732\n0.2718842\n0.1412808\n0.2291176\n\n\n0.2950308\n0.1534987\n0.2643027\n0.1180611\n0.1691067\n\n\n0.2732305\n0.1489489\n0.2682142\n0.1248957\n0.1847107\n\n\n0.2978958\n0.1540338\n0.2637063\n0.1171788\n0.1671853\n\n\n0.2227442\n0.1349732\n0.2718842\n0.1412808\n0.2291176\n\n\n0.2584197\n0.1453607\n0.2701586\n0.1296451\n0.1964158\n\n\n0.4848828\n0.1616820\n0.2015340\n0.0689235\n0.0829778\n\n\n0.2740423\n0.1491338\n0.2680899\n0.1246377\n0.1840964\n\n\n0.2597218\n0.1456927\n0.2700134\n0.1292247\n0.1953474\n\n\n0.2227442\n0.1349732\n0.2718842\n0.1412808\n0.2291176\n\n\n0.3188967\n0.1575242\n0.2588256\n0.1108358\n0.1539176\n\n\n0.2468396\n0.1422647\n0.2712143\n0.1334031\n0.2062783\n\n\n0.4023372\n0.1644425\n0.2329358\n0.0879695\n0.1123149\n\n\n0.2672992\n0.1475612\n0.2690681\n0.1267887\n0.1892828\n\n\n0.2227442\n0.1349732\n0.2718842\n0.1412808\n0.2291176\n\n\n0.2714814\n0.1485465\n0.2684760\n0.1254526\n0.1860434\n\n\n0.2347608\n0.1387556\n0.2718270\n0.1373489\n0.2173078\n\n\n0.2227442\n0.1349732\n0.2718842\n0.1412808\n0.2291176\n\n\n0.2470295\n0.1423175\n0.2712006\n0.1333412\n0.2061111\n\n\n0.3140791\n0.1567897\n0.2600199\n0.1122710\n0.1568402\n\n\n0.2730326\n0.1489036\n0.2682442\n0.1249587\n0.1848609\n\n\n0.3075019\n0.1557237\n0.2615808\n0.1142498\n0.1609439\n\n\n0.3095247\n0.1560594\n0.2611095\n0.1136389\n0.1596676\n\n\n0.2227442\n0.1349732\n0.2718842\n0.1412808\n0.2291176\n\n\n0.2386041\n0.1399036\n0.2716895\n0.1360916\n0.2137112\n\n\n0.3159205\n0.1570750\n0.2595684\n0.1117210\n0.1557150\n\n\n0.2510078\n0.1434089\n0.2708845\n0.1320468\n0.2026519\n\n\n0.2491157\n0.1428937\n0.2710414\n0.1326621\n0.2042872\n\n\n0.2386041\n0.1399036\n0.2716895\n0.1360916\n0.2137112\n\n\n0.2416607\n0.1407955\n0.2715412\n0.1350927\n0.2109098\n\n\n0.2694953\n0.1480826\n0.2687632\n0.1260864\n0.1875725\n\n\n0.2853709\n0.1515880\n0.2661778\n0.1210641\n0.1757991\n\n\n0.3372549\n0.1599724\n0.2539128\n0.1054797\n0.1433802\n\n\n0.2855842\n0.1516320\n0.2661388\n0.1209974\n0.1756477\n\n\n0.2227442\n0.1349732\n0.2718842\n0.1412808\n0.2291176\n\n\n0.2642250\n0.1468162\n0.2694718\n0.1277748\n0.1917122\n\n\n0.2618685\n0.1462330\n0.2697627\n0.1285327\n0.1936030\n\n\n0.2227442\n0.1349732\n0.2718842\n0.1412808\n0.2291176\n\n\n0.3533293\n0.1616721\n0.2491934\n0.1009399\n0.1348652\n\n\n0.2227442\n0.1349732\n0.2718842\n0.1412808\n0.2291176\n\n\n0.2995919\n0.1543437\n0.2633449\n0.1166584\n0.1660611\n\n\n0.2227442\n0.1349732\n0.2718842\n0.1412808\n0.2291176\n\n\n0.3003169\n0.1544747\n0.2631885\n0.1164363\n0.1655835\n\n\n0.2227442\n0.1349732\n0.2718842\n0.1412808\n0.2291176\n\n\n0.2714814\n0.1485465\n0.2684760\n0.1254526\n0.1860434\n\n\n0.3908933\n0.1641086\n0.2369440\n0.0908821\n0.1171720\n\n\n0.4311197\n0.1644831\n0.2224142\n0.0809467\n0.1010364\n\n\n0.3412825\n0.1604366\n0.2527645\n0.1043290\n0.1411875\n\n\n0.2227442\n0.1349732\n0.2718842\n0.1412808\n0.2291176\n\n\n0.3214845\n0.1579028\n0.2581670\n0.1100699\n0.1523757\n\n\n0.2345774\n0.1387000\n0.2718321\n0.1374089\n0.2174815\n\n\n0.2599182\n0.1457425\n0.2699910\n0.1291613\n0.1951869\n\n\n0.2227442\n0.1349732\n0.2718842\n0.1412808\n0.2291176\n\n\n0.2345774\n0.1387000\n0.2718321\n0.1374089\n0.2174815\n\n\n0.2595255\n0.1456429\n0.2700356\n0.1292880\n0.1955080\n\n\n0.3658756\n0.1627203\n0.2452755\n0.0974950\n0.1286336\n\n\n0.2601100\n0.1457911\n0.2699691\n0.1290995\n0.1950304\n\n\n0.2347608\n0.1387556\n0.2718270\n0.1373489\n0.2173078\n\n\n0.2227442\n0.1349732\n0.2718842\n0.1412808\n0.2291176\n\n\n0.3797054\n0.1636012\n0.2407483\n0.0937974\n0.1221477\n\n\n0.3142572\n0.1568175\n0.2599765\n0.1122177\n0.1567310\n\n\n0.3467636\n0.1610269\n0.2511643\n0.1027772\n0.1382680\n\n\n0.4093488\n0.1645564\n0.2304272\n0.0862192\n0.1094484\n\n\n0.2864083\n0.1518012\n0.2659868\n0.1207396\n0.1750641\n\n\n0.3161359\n0.1571081\n0.2595152\n0.1116568\n0.1555840\n\n\n0.2610891\n0.1460379\n0.2698553\n0.1287838\n0.1942339\n\n\n0.2227442\n0.1349732\n0.2718842\n0.1412808\n0.2291176\n\n\n0.2356749\n0.1390313\n0.2717993\n0.1370497\n0.2164448\n\n\n0.2808510\n0.1506367\n0.2669795\n0.1224835\n0.1790493\n\n\n0.3328836\n0.1594392\n0.2551317\n0.1067386\n0.1458069\n\n\n0.2227442\n0.1349732\n0.2718842\n0.1412808\n0.2291176\n\n\n0.4246859\n0.1645710\n0.2248148\n0.0824796\n0.1034487\n\n\n0.2822723\n0.1509398\n0.2667328\n0.1220362\n0.1780188\n\n\n0.2716834\n0.1485932\n0.2684462\n0.1253882\n0.1858889\n\n\n0.3135085\n0.1567001\n0.2601586\n0.1124418\n0.1571910\n\n\n0.3374778\n0.1599988\n0.2538499\n0.1054158\n0.1432578\n\n\n0.2347608\n0.1387556\n0.2718270\n0.1373489\n0.2173078\n\n\n0.2227442\n0.1349732\n0.2718842\n0.1412808\n0.2291176\n\n\n0.3501140\n0.1613646\n0.2501657\n0.1018367\n0.1365190\n\n\n0.2898842\n0.1525013\n0.2653284\n0.1196558\n0.1726303\n\n\n0.2670993\n0.1475133\n0.2690951\n0.1268528\n0.1894395\n\n\n0.3405122\n0.1603498\n0.2529859\n0.1045484\n0.1416037\n\n\n0.2806448\n0.1505925\n0.2670148\n0.1225485\n0.1791995\n\n\n0.3001024\n0.1544361\n0.2632349\n0.1165020\n0.1657247\n\n\n0.2782900\n0.1500813\n0.2674111\n0.1232916\n0.1809260\n\n\n0.3633241\n0.1625266\n0.2460876\n0.0981886\n0.1298732\n\n\n0.3032164\n0.1549894\n0.2625523\n0.1155509\n0.1636910\n\n\n0.2227442\n0.1349732\n0.2718842\n0.1412808\n0.2291176\n\n\n0.3096910\n0.1560866\n0.2610704\n0.1135887\n0.1595632\n\n\n0.3173883\n0.1572984\n0.2592041\n0.1112839\n0.1548253\n\n\n0.3201548\n0.1577097\n0.2585069\n0.1104630\n0.1531656\n\n\n0.3315890\n0.1592754\n0.2554870\n0.1071134\n0.1465351\n\n\n0.2227442\n0.1349732\n0.2718842\n0.1412808\n0.2291176\n\n\n0.3329430\n0.1594467\n0.2551153\n0.1067215\n0.1457736\n\n\n0.3287125\n0.1589017\n0.2562670\n0.1079495\n0.1481693\n\n\n0.2345774\n0.1387000\n0.2718321\n0.1374089\n0.2174815\n\n\n0.3259074\n0.1585242\n0.2570147\n0.1087691\n0.1497845\n\n\n0.3400319\n0.1602952\n0.2531236\n0.1046853\n0.1418639\n\n\n0.3000258\n0.1544222\n0.2632514\n0.1165255\n0.1657751\n\n\n0.3716538\n0.1631230\n0.2434090\n0.0959374\n0.1258768\n\n\n0.3132888\n0.1566655\n0.2602118\n0.1125076\n0.1573263\n\n\n0.2468396\n0.1422647\n0.2712143\n0.1334031\n0.2062783\n\n\n0.2638329\n0.1467199\n0.2695213\n0.1279008\n0.1920251\n\n\n0.2472195\n0.1423704\n0.2711867\n0.1332794\n0.2059441\n\n\n0.2345774\n0.1387000\n0.2718321\n0.1374089\n0.2174815\n\n\n0.2468396\n0.1422647\n0.2712143\n0.1334031\n0.2062783\n\n\n0.2650151\n0.1470094\n0.2693706\n0.1275210\n0.1910838\n\n\n0.2599182\n0.1457425\n0.2699910\n0.1291613\n0.1951869\n\n\n0.2227442\n0.1349732\n0.2718842\n0.1412808\n0.2291176\n\n\n0.2759133\n0.1495552\n0.2677967\n0.1240439\n0.1826909\n\n\n0.2716834\n0.1485932\n0.2684462\n0.1253882\n0.1858889\n\n\n0.2725744\n0.1487986\n0.2683134\n0.1251045\n0.1852091\n\n\n0.2505510\n0.1432852\n0.2709235\n0.1321953\n0.2030450\n\n\n0.2804387\n0.1505481\n0.2670501\n0.1226134\n0.1793497\n\n\n0.3003424\n0.1544793\n0.2631830\n0.1164285\n0.1655668\n\n\n0.2584197\n0.1453607\n0.2701586\n0.1296451\n0.1964158\n\n\n0.3012629\n0.1546442\n0.2629829\n0.1161470\n0.1649630\n\n\n0.2505510\n0.1432852\n0.2709235\n0.1321953\n0.2030450\n\n\n0.2227442\n0.1349732\n0.2718842\n0.1412808\n0.2291176\n\n\n0.2386041\n0.1399036\n0.2716895\n0.1360916\n0.2137112\n\n\n0.3487599\n0.1612302\n0.2505711\n0.1022160\n0.1372227\n\n\n0.3379291\n0.1600519\n0.2537223\n0.1052865\n0.1430103\n\n\n0.2472195\n0.1423704\n0.2711867\n0.1332794\n0.2059441\n\n\n0.2841429\n0.1513332\n0.2664006\n0.1214489\n0.1766745\n\n\n0.2898842\n0.1525013\n0.2653284\n0.1196558\n0.1726303\n\n\n0.2545622\n0.1443581\n0.2705582\n0.1308933\n0.1996282\n\n\n0.3030007\n0.1549516\n0.2626003\n0.1156166\n0.1638308\n\n\n0.2345774\n0.1387000\n0.2718321\n0.1374089\n0.2174815\n\n\n0.2227442\n0.1349732\n0.2718842\n0.1412808\n0.2291176\n\n\n0.2610891\n0.1460379\n0.2698553\n0.1287838\n0.1942339\n\n\n0.2227442\n0.1349732\n0.2718842\n0.1412808\n0.2291176\n\n\n0.2468396\n0.1422647\n0.2712143\n0.1334031\n0.2062783\n\n\n0.2925842\n0.1530304\n0.2647977\n0.1188177\n0.1707700\n\n\n0.2985268\n0.1541497\n0.2635725\n0.1169851\n0.1667660\n\n\n0.2990362\n0.1542427\n0.2634640\n0.1168288\n0.1664284\n\n\n0.2650151\n0.1470094\n0.2693706\n0.1275210\n0.1910838\n\n\n0.2705352\n0.1483264\n0.2686142\n0.1257544\n0.1867698\n\n\n0.2820901\n0.1509012\n0.2667647\n0.1220935\n0.1781505\n\n\n0.3070258\n0.1556437\n0.2616905\n0.1143939\n0.1612462\n\n\n0.3441522\n0.1607516\n0.2519319\n0.1035144\n0.1396498\n\n\n0.3042910\n0.1551765\n0.2623122\n0.1152237\n0.1629965\n\n\n0.2778019\n0.1499741\n0.2674915\n0.1234459\n0.1812866\n\n\n0.2762680\n0.1496344\n0.2677401\n0.1239314\n0.1824261\n\n\n0.2553288\n0.1445596\n0.2704825\n0.1306449\n0.1989842\n\n\n0.3525464\n0.1615987\n0.2494314\n0.1011577\n0.1352657\n\n\n0.2227442\n0.1349732\n0.2718842\n0.1412808\n0.2291176\n\n\n0.2386041\n0.1399036\n0.2716895\n0.1360916\n0.2137112\n\n\n0.2356749\n0.1390313\n0.2717993\n0.1370497\n0.2164448\n\n\n0.3102630\n0.1561801\n0.2609356\n0.1134164\n0.1592049\n\n\n0.3907080\n0.1641017\n0.2370079\n0.0909298\n0.1172526\n\n\n0.2386041\n0.1399036\n0.2716895\n0.1360916\n0.2137112\n\n\n0.3817174\n0.1637059\n0.2400730\n0.0932681\n0.1212356\n\n\n0.2553288\n0.1445596\n0.2704825\n0.1306449\n0.1989842\n\n\n0.2553288\n0.1445596\n0.2704825\n0.1306449\n0.1989842\n\n\n0.2416607\n0.1407955\n0.2715412\n0.1350927\n0.2109098\n\n\n0.2948184\n0.1534585\n0.2643462\n0.1181267\n0.1692502\n\n\n0.2227442\n0.1349732\n0.2718842\n0.1412808\n0.2291176\n\n\n0.2511953\n0.1434596\n0.2708683\n0.1319859\n0.2024909\n\n\n0.2684961\n0.1478465\n0.2689036\n0.1264057\n0.1883481\n\n\n0.2642250\n0.1468162\n0.2694718\n0.1277748\n0.1917122\n\n\n0.4064774\n0.1645180\n0.2314592\n0.0869328\n0.1106126\n\n\n0.2507793\n0.1433471\n0.2709041\n0.1321211\n0.2028484\n\n\n0.3192030\n0.1575696\n0.2587483\n0.1107450\n0.1537341\n\n\n0.3344187\n0.1596300\n0.2547070\n0.1062953\n0.1449490\n\n\n0.2227442\n0.1349732\n0.2718842\n0.1412808\n0.2291176\n\n\n0.2510078\n0.1434089\n0.2708845\n0.1320468\n0.2026519\n\n\n0.2726901\n0.1488252\n0.2682960\n0.1250677\n0.1851211\n\n\n0.2345774\n0.1387000\n0.2718321\n0.1374089\n0.2174815\n\n\n0.3142572\n0.1568175\n0.2599765\n0.1122177\n0.1567310\n\n\n0.2386041\n0.1399036\n0.2716895\n0.1360916\n0.2137112\n\n\n0.2510078\n0.1434089\n0.2708845\n0.1320468\n0.2026519\n\n\n0.2470295\n0.1423175\n0.2712006\n0.1333412\n0.2061111\n\n\n0.3917735\n0.1641409\n0.2366397\n0.0906556\n0.1167903\n\n\n0.2386041\n0.1399036\n0.2716895\n0.1360916\n0.2137112\n\n\n0.2818784\n0.1508562\n0.2668016\n0.1221601\n0.1783036\n\n\n0.2217482\n0.1346464\n0.2718622\n0.1416062\n0.2301369\n\n\n0.3135085\n0.1567001\n0.2601586\n0.1124418\n0.1571910\n\n\n0.3001024\n0.1544361\n0.2632349\n0.1165020\n0.1657247\n\n\n0.3692950\n0.1629646\n0.2441754\n0.0965710\n0.1269939\n\n\n0.2227442\n0.1349732\n0.2718842\n0.1412808\n0.2291176\n\n\n0.3030007\n0.1549516\n0.2626003\n0.1156166\n0.1638308\n\n\n0.2892340\n0.1523720\n0.2654537\n0.1198581\n0.1730822\n\n\n0.2227442\n0.1349732\n0.2718842\n0.1412808\n0.2291176\n\n\n0.3138592\n0.1567552\n0.2600734\n0.1123368\n0.1569753\n\n\n0.3024875\n0.1548614\n0.2627139\n0.1157731\n0.1641642\n\n\n0.2948083\n0.1534566\n0.2643483\n0.1181298\n0.1692571\n\n\n0.2470295\n0.1423175\n0.2712006\n0.1333412\n0.2061111\n\n\n0.3102630\n0.1561801\n0.2609356\n0.1134164\n0.1592049\n\n\n0.3331158\n0.1594683\n0.2550677\n0.1066715\n0.1456767\n\n\n0.2345774\n0.1387000\n0.2718321\n0.1374089\n0.2174815\n\n\n0.2808510\n0.1506367\n0.2669795\n0.1224835\n0.1790493\n\n\n0.2541703\n0.1442546\n0.2705962\n0.1310204\n0.1999586\n\n\n0.2759133\n0.1495552\n0.2677967\n0.1240439\n0.1826909\n\n\n0.2672992\n0.1475612\n0.2690681\n0.1267887\n0.1892828\n\n\n0.3100341\n0.1561428\n0.2609896\n0.1134853\n0.1593481\n\n\n0.2345774\n0.1387000\n0.2718321\n0.1374089\n0.2174815\n\n\n0.2510078\n0.1434089\n0.2708845\n0.1320468\n0.2026519\n\n\n0.2227442\n0.1349732\n0.2718842\n0.1412808\n0.2291176\n\n\n0.2386041\n0.1399036\n0.2716895\n0.1360916\n0.2137112\n\n\n0.2416607\n0.1407955\n0.2715412\n0.1350927\n0.2109098\n\n\n0.2943890\n0.1533769\n0.2644338\n0.1182593\n0.1695410\n\n\n0.3089482\n0.1559644\n0.2612446\n0.1138128\n0.1600300\n\n\n0.2924785\n0.1530099\n0.2648188\n0.1188504\n0.1708423\n\n\n0.3184585\n0.1574590\n0.2589360\n0.1109659\n0.1541806\n\n\n0.2818784\n0.1508562\n0.2668016\n0.1221601\n0.1783036\n\n\n0.2716834\n0.1485932\n0.2684462\n0.1253882\n0.1858889\n\n\n0.3663834\n0.1627577\n0.2451129\n0.0973573\n0.1283886\n\n\n0.3323277\n0.1593692\n0.2552846\n0.1068995\n0.1461191\n\n\n0.3384243\n0.1601098\n0.2535819\n0.1051447\n0.1427393\n\n\n0.2921767\n0.1529514\n0.2648789\n0.1189439\n0.1710491\n\n\n0.3770977\n0.1634568\n0.2416174\n0.0944866\n0.1233415\n\n\n0.3020619\n0.1547862\n0.2628077\n0.1159029\n0.1644412\n\n\n0.2227442\n0.1349732\n0.2718842\n0.1412808\n0.2291176\n\n\n0.3400319\n0.1602952\n0.2531236\n0.1046853\n0.1418639\n\n\n0.3536238\n0.1616995\n0.2491037\n0.1008581\n0.1347149\n\n\n0.4599041\n0.1634318\n0.2113937\n0.0743392\n0.0909312\n\n\n0.2472195\n0.1423704\n0.2711867\n0.1332794\n0.2059441\n\n\n0.3355452\n0.1597675\n0.2543930\n0.1059709\n0.1443234\n\n\n0.3030007\n0.1549516\n0.2626003\n0.1156166\n0.1638308\n\n\n0.2914633\n0.1528123\n0.2650201\n0.1191652\n0.1715391\n\n\n0.2468396\n0.1422647\n0.2712143\n0.1334031\n0.2062783\n\n\n0.2227442\n0.1349732\n0.2718842\n0.1412808\n0.2291176\n\n\n0.2491157\n0.1428937\n0.2710414\n0.1326621\n0.2042872\n\n\n0.3087354\n0.1559292\n0.2612943\n0.1138770\n0.1601640\n\n\n0.2227442\n0.1349732\n0.2718842\n0.1412808\n0.2291176\n\n\n0.2479759\n0.1425800\n0.2711302\n0.1330330\n0.2052809\n\n\n0.2595255\n0.1456429\n0.2700356\n0.1292880\n0.1955080\n\n\n0.3099093\n0.1561224\n0.2610190\n0.1135229\n0.1594263\n\n\n0.2227442\n0.1349732\n0.2718842\n0.1412808\n0.2291176\n\n\n0.2774752\n0.1499021\n0.2675450\n0.1235492\n0.1815285\n\n\n0.3106482\n0.1562428\n0.2608444\n0.1133005\n0.1589642\n\n\n0.2888393\n0.1522931\n0.2655293\n0.1199810\n0.1733572\n\n\n0.3659828\n0.1627283\n0.2452412\n0.0974659\n0.1285819\n\n\n0.2227442\n0.1349732\n0.2718842\n0.1412808\n0.2291176\n\n\n0.2851627\n0.1515450\n0.2662158\n0.1211293\n0.1759471\n\n\n0.4231006\n0.1645842\n0.2254024\n0.0828605\n0.1040523\n\n\n0.2345774\n0.1387000\n0.2718321\n0.1374089\n0.2174815\n\n\n0.3095247\n0.1560594\n0.2611095\n0.1136389\n0.1596676\n\n\n0.2543639\n0.1443058\n0.2705775\n0.1309576\n0.1997953\n\n\n0.3669593\n0.1627997\n0.2449283\n0.0972015\n0.1281113\n\n\n0.2345774\n0.1387000\n0.2718321\n0.1374089\n0.2174815\n\n\n0.2416607\n0.1407955\n0.2715412\n0.1350927\n0.2109098\n\n\n0.3319448\n0.1593207\n0.2553896\n0.1070104\n0.1463346\n\n\n0.2849546\n0.1515019\n0.2662537\n0.1211945\n0.1760952\n\n\n0.2227442\n0.1349732\n0.2718842\n0.1412808\n0.2291176\n\n\n0.3050172\n0.1553018\n0.2621485\n0.1150030\n0.1625294\n\n\n0.2584197\n0.1453607\n0.2701586\n0.1296451\n0.1964158\n\n\n0.2345774\n0.1387000\n0.2718321\n0.1374089\n0.2174815\n\n\n0.2345774\n0.1387000\n0.2718321\n0.1374089\n0.2174815\n\n\n0.2510078\n0.1434089\n0.2708845\n0.1320468\n0.2026519\n\n\n0.2730326\n0.1489036\n0.2682442\n0.1249587\n0.1848609\n\n\n0.2227442\n0.1349732\n0.2718842\n0.1412808\n0.2291176\n\n\n0.2227442\n0.1349732\n0.2718842\n0.1412808\n0.2291176\n\n\n0.2227442\n0.1349732\n0.2718842\n0.1412808\n0.2291176\n\n\n0.2778019\n0.1499741\n0.2674915\n0.1234459\n0.1812866\n\n\n0.3025490\n0.1548723\n0.2627003\n0.1157543\n0.1641241\n\n\n0.3641175\n0.1625879\n0.2458359\n0.0979725\n0.1294863\n\n\n0.2470295\n0.1423175\n0.2712006\n0.1333412\n0.2061111\n\n\n0.2801640\n0.1504889\n0.2670969\n0.1227000\n0.1795502\n\n\n0.2861997\n0.1517585\n0.2660255\n0.1208048\n0.1752116\n\n\n0.2904150\n0.1526064\n0.2652254\n0.1194907\n0.1722625\n\n\n0.2541703\n0.1442546\n0.2705962\n0.1310204\n0.1999586\n\n\n0.3019594\n0.1547681\n0.2628303\n0.1159342\n0.1645081\n\n\n0.2227442\n0.1349732\n0.2718842\n0.1412808\n0.2291176\n\n\n0.2472195\n0.1423704\n0.2711867\n0.1332794\n0.2059441\n\n\n0.2778019\n0.1499741\n0.2674915\n0.1234459\n0.1812866\n\n\n0.3102526\n0.1561784\n0.2609380\n0.1134195\n0.1592114\n\n\n0.2227442\n0.1349732\n0.2718842\n0.1412808\n0.2291176\n\n\n0.3038897\n0.1551069\n0.2624021\n0.1153458\n0.1632554\n\n\n0.4499208\n0.1639162\n0.2152631\n0.0765852\n0.0943147\n\n\n0.3557328\n0.1618916\n0.2484578\n0.1002733\n0.1336445\n\n\n0.2861997\n0.1517585\n0.2660255\n0.1208048\n0.1752116\n\n\n0.2907709\n0.1526765\n0.2651560\n0.1193802\n0.1720165\n\n\n0.2750544\n0.1493625\n0.2679324\n0.1243163\n0.1833344\n\n\n0.2726901\n0.1488252\n0.2682960\n0.1250677\n0.1851211\n\n\n0.3175779\n0.1573270\n0.2591567\n0.1112275\n0.1547108\n\n\n0.2227442\n0.1349732\n0.2718842\n0.1412808\n0.2291176\n\n\n0.2716834\n0.1485932\n0.2684462\n0.1253882\n0.1858889\n\n\n0.3041624\n0.1551542\n0.2623410\n0.1152629\n0.1630795\n\n\n0.2227442\n0.1349732\n0.2718842\n0.1412808\n0.2291176\n\n\n0.2595255\n0.1456429\n0.2700356\n0.1292880\n0.1955080\n\n\n0.2730326\n0.1489036\n0.2682442\n0.1249587\n0.1848609\n\n\n0.3655316\n0.1626948\n0.2453854\n0.0975883\n0.1288000\n\n\n0.4676311\n0.1629717\n0.2083689\n0.0726331\n0.0883952\n\n\n0.3209067\n0.1578193\n0.2583151\n0.1102406\n0.1527183\n\n\n0.2595255\n0.1456429\n0.2700356\n0.1292880\n0.1955080\n\n\n0.3003169\n0.1544747\n0.2631885\n0.1164363\n0.1655835\n\n\n0.2597218\n0.1456927\n0.2700134\n0.1292247\n0.1953474\n\n\n0.2806448\n0.1505925\n0.2670148\n0.1225485\n0.1791995\n\n\n0.2227442\n0.1349732\n0.2718842\n0.1412808\n0.2291176\n\n\n0.2552179\n0.1445305\n0.2704936\n0.1306809\n0.1990772\n\n\n0.2672992\n0.1475612\n0.2690681\n0.1267887\n0.1892828\n\n\n0.4300467\n0.1645015\n0.2228163\n0.0812009\n0.1014346\n\n\n0.2227442\n0.1349732\n0.2718842\n0.1412808\n0.2291176\n\n\n0.2595255\n0.1456429\n0.2700356\n0.1292880\n0.1955080\n\n\n0.2640265\n0.1467675\n0.2694969\n0.1278385\n0.1918705\n\n\n0.2726901\n0.1488252\n0.2682960\n0.1250677\n0.1851211\n\n\n0.2227442\n0.1349732\n0.2718842\n0.1412808\n0.2291176\n\n\n0.2740423\n0.1491338\n0.2680899\n0.1246377\n0.1840964\n\n\n0.2694953\n0.1480826\n0.2687632\n0.1260864\n0.1875725\n\n\n0.2347608\n0.1387556\n0.2718270\n0.1373489\n0.2173078\n\n\n0.4072049\n0.1645288\n0.2311983\n0.0867516\n0.1103164\n\n\n0.3336075\n0.1595296\n0.2549319\n0.1065294\n0.1454016\n\n\n0.2911270\n0.1527465\n0.2650862\n0.1192696\n0.1717708\n\n\n0.3610046\n0.1623419\n0.2468192\n0.0988222\n0.1310121\n\n\n0.3182317\n0.1574252\n0.2589930\n0.1110332\n0.1543170\n\n\n0.2227442\n0.1349732\n0.2718842\n0.1412808\n0.2291176\n\n\n0.2356749\n0.1390313\n0.2717993\n0.1370497\n0.2164448\n\n\n0.2521523\n0.1437172\n0.2707839\n0.1316751\n0.2016715\n\n\n0.2846674\n0.1514424\n0.2663059\n0.1212845\n0.1762999\n\n\n0.3487268\n0.1612269\n0.2505810\n0.1022253\n0.1372400\n\n\n0.2227442\n0.1349732\n0.2718842\n0.1412808\n0.2291176\n\n\n0.2468396\n0.1422647\n0.2712143\n0.1334031\n0.2062783\n\n\n0.2672992\n0.1475612\n0.2690681\n0.1267887\n0.1892828\n\n\n0.2798895\n0.1504296\n0.2671435\n0.1227865\n0.1797508\n\n\n0.2607000\n0.1459400\n0.2699009\n0.1289092\n0.1945499\n\n\n0.2510078\n0.1434089\n0.2708845\n0.1320468\n0.2026519\n\n\n0.3498817\n0.1613417\n0.2502354\n0.1019017\n0.1366394\n\n\n0.4233559\n0.1645823\n0.2253079\n0.0827991\n0.1039549\n\n\n0.2932287\n0.1531548\n0.2646686\n0.1186181\n0.1703298\n\n\n0.4234983\n0.1645812\n0.2252551\n0.0827649\n0.1039005\n\n\n0.2597218\n0.1456927\n0.2700134\n0.1292247\n0.1953474\n\n\n0.2655316\n0.1471350\n0.2693035\n0.1273553\n0.1906746\n\n\n0.2960887\n0.1536979\n0.2640845\n0.1177349\n0.1683939\n\n\n0.2943890\n0.1533769\n0.2644338\n0.1182593\n0.1695410\n\n\n0.2652141\n0.1470578\n0.2693449\n0.1274572\n0.1909261\n\n\n0.2903048\n0.1525846\n0.2652469\n0.1195250\n0.1723388\n\n\n0.2416607\n0.1407955\n0.2715412\n0.1350927\n0.2109098\n\n\n0.2608968\n0.1459896\n0.2698779\n0.1288458\n0.1943900\n\n\n0.3229340\n0.1581100\n0.2577930\n0.1096425\n0.1515204\n\n\n0.2806448\n0.1505925\n0.2670148\n0.1225485\n0.1791995\n\n\n0.3386529\n0.1601365\n0.2535169\n0.1050793\n0.1426144\n\n\n0.2468396\n0.1422647\n0.2712143\n0.1334031\n0.2062783\n\n\n0.2776020\n0.1499301\n0.2675242\n0.1235091\n0.1814346\n\n\n0.2813964\n0.1507535\n0.2668854\n0.1223118\n0.1786530\n\n\n0.3506674\n0.1614187\n0.2499993\n0.1016819\n0.1362327\n\n\n0.2227442\n0.1349732\n0.2718842\n0.1412808\n0.2291176\n\n\n0.2227442\n0.1349732\n0.2718842\n0.1412808\n0.2291176\n\n\n0.2800513\n0.1504646\n0.2671160\n0.1227355\n0.1796326\n\n\n0.2750544\n0.1493625\n0.2679324\n0.1243163\n0.1833344\n\n\n0.2416607\n0.1407955\n0.2715412\n0.1350927\n0.2109098\n\n\n0.3030007\n0.1549516\n0.2626003\n0.1156166\n0.1638308\n\n\n0.2227442\n0.1349732\n0.2718842\n0.1412808\n0.2291176\n\n\n0.2677042\n0.1476580\n0.2690129\n0.1266591\n0.1889658\n\n\n0.3004038\n0.1544903\n0.2631697\n0.1164097\n0.1655264\n\n\n0.2730326\n0.1489036\n0.2682442\n0.1249587\n0.1848609\n\n\n0.2227442\n0.1349732\n0.2718842\n0.1412808\n0.2291176\n\n\n0.2642250\n0.1468162\n0.2694718\n0.1277748\n0.1917122\n\n\n0.2829082\n0.1510743\n0.2666208\n0.1218364\n0.1775604\n\n\n0.2670993\n0.1475133\n0.2690951\n0.1268528\n0.1894395\n\n\n0.2826616\n0.1510222\n0.2666643\n0.1219139\n0.1777380\n\n\n0.2730326\n0.1489036\n0.2682442\n0.1249587\n0.1848609\n\n\n0.3113098\n0.1563498\n0.2606871\n0.1131015\n0.1585518\n\n\n0.2468396\n0.1422647\n0.2712143\n0.1334031\n0.2062783\n\n\n0.2227442\n0.1349732\n0.2718842\n0.1412808\n0.2291176\n\n\n0.2682956\n0.1477989\n0.2689314\n0.1264698\n0.1885042\n\n\n0.3186802\n0.1574921\n0.2588802\n0.1109001\n0.1540475\n\n\n0.2227442\n0.1349732\n0.2718842\n0.1412808\n0.2291176\n\n\n0.2386041\n0.1399036\n0.2716895\n0.1360916\n0.2137112\n\n\n0.2944950\n0.1533971\n0.2644122\n0.1182266\n0.1694691\n\n\n0.3530183\n0.1616431\n0.2492880\n0.1010264\n0.1350241\n\n\n0.2853709\n0.1515880\n0.2661778\n0.1210641\n0.1757991\n\n\n0.2345774\n0.1387000\n0.2718321\n0.1374089\n0.2174815\n\n\n0.2730326\n0.1489036\n0.2682442\n0.1249587\n0.1848609\n\n\n0.2240729\n0.1354060\n0.2719069\n0.1408464\n0.2277677\n\n\n0.3732051\n0.1632226\n0.2429017\n0.0955223\n0.1251483\n\n\n0.3646580\n0.1626291\n0.2456639\n0.0978255\n0.1292234\n\n\n0.3078903\n0.1557887\n0.2614909\n0.1141323\n0.1606978\n\n\n0.2472195\n0.1423704\n0.2711867\n0.1332794\n0.2059441\n\n\n0.2730326\n0.1489036\n0.2682442\n0.1249587\n0.1848609\n\n\n0.2472195\n0.1423704\n0.2711867\n0.1332794\n0.2059441\n\n\n0.2900945\n0.1525430\n0.2652877\n0.1195904\n0.1724845\n\n\n0.3383916\n0.1601060\n0.2535911\n0.1051540\n0.1427572\n\n\n0.3059457\n0.1554607\n0.2619378\n0.1147212\n0.1619346\n\n\n0.3809087\n0.1636645\n0.2403449\n0.0934806\n0.1216013\n\n\n0.2934404\n0.1531955\n0.2646260\n0.1185526\n0.1701855\n\n\n0.2472195\n0.1423704\n0.2711867\n0.1332794\n0.2059441\n\n\n0.2227442\n0.1349732\n0.2718842\n0.1412808\n0.2291176\n\n\n0.2227442\n0.1349732\n0.2718842\n0.1412808\n0.2291176\n\n\n0.2227442\n0.1349732\n0.2718842\n0.1412808\n0.2291176\n\n\n0.2227442\n0.1349732\n0.2718842\n0.1412808\n0.2291176\n\n\n0.2227442\n0.1349732\n0.2718842\n0.1412808\n0.2291176\n\n\n0.2630545\n0.1465278\n0.2696184\n0.1281510\n0.1926483\n\n\n0.2227442\n0.1349732\n0.2718842\n0.1412808\n0.2291176\n\n\n0.2416607\n0.1407955\n0.2715412\n0.1350927\n0.2109098\n\n\n0.2851627\n0.1515450\n0.2662158\n0.1211293\n0.1759471\n\n\n0.3386203\n0.1601327\n0.2535262\n0.1050886\n0.1426323\n\n\n0.2553288\n0.1445596\n0.2704825\n0.1306449\n0.1989842\n\n\n0.2468396\n0.1422647\n0.2712143\n0.1334031\n0.2062783\n\n\n0.2468396\n0.1422647\n0.2712143\n0.1334031\n0.2062783\n\n\n0.3417855\n0.1604927\n0.2526194\n0.1041859\n0.1409165\n\n\n0.2670993\n0.1475133\n0.2690951\n0.1268528\n0.1894395\n\n\n0.2416607\n0.1407955\n0.2715412\n0.1350927\n0.2109098\n\n\n0.2738392\n0.1490876\n0.2681212\n0.1247022\n0.1842498\n\n\n0.2470295\n0.1423175\n0.2712006\n0.1333412\n0.2061111\n\n\n0.2521523\n0.1437172\n0.2707839\n0.1316751\n0.2016715\n\n\n0.2969255\n0.1538542\n0.2639102\n0.1174772\n0.1678329\n\n\n0.2807479\n0.1506146\n0.2669972\n0.1225160\n0.1791244\n\n\n0.2227442\n0.1349732\n0.2718842\n0.1412808\n0.2291176\n\n\n0.2740423\n0.1491338\n0.2680899\n0.1246377\n0.1840964\n\n\n0.3138592\n0.1567552\n0.2600734\n0.1123368\n0.1569753\n\n\n0.2227442\n0.1349732\n0.2718842\n0.1412808\n0.2291176\n\n\n0.2227442\n0.1349732\n0.2718842\n0.1412808\n0.2291176\n\n\n0.2630545\n0.1465278\n0.2696184\n0.1281510\n0.1926483\n\n\n0.2672992\n0.1475612\n0.2690681\n0.1267887\n0.1892828\n\n\n0.3480093\n0.1611545\n0.2507948\n0.1024268\n0.1376146\n\n\n0.3353176\n0.1597399\n0.2544566\n0.1060364\n0.1444495\n\n\n0.2618779\n0.1462354\n0.2697616\n0.1285297\n0.1935954\n\n\n0.3517699\n0.1615250\n0.2496667\n0.1013741\n0.1356643\n\n\n0.2638329\n0.1467199\n0.2695213\n0.1279008\n0.1920251\n\n\n0.2620706\n0.1462835\n0.2697384\n0.1284676\n0.1934399\n\n\n0.2650151\n0.1470094\n0.2693706\n0.1275210\n0.1910838\n\n\n0.2345774\n0.1387000\n0.2718321\n0.1374089\n0.2174815\n\n\n0.2740423\n0.1491338\n0.2680899\n0.1246377\n0.1840964\n\n\n0.2416607\n0.1407955\n0.2715412\n0.1350927\n0.2109098\n\n\n0.3001024\n0.1544361\n0.2632349\n0.1165020\n0.1657247\n\n\n0.2470295\n0.1423175\n0.2712006\n0.1333412\n0.2061111\n\n\n0.2729795\n0.1488915\n0.2682523\n0.1249756\n0.1849012\n\n\n0.2599182\n0.1457425\n0.2699910\n0.1291613\n0.1951869\n\n\n0.3594525\n0.1622137\n0.2473052\n0.0992478\n0.1317807\n\n\n0.2790572\n0.1502490\n0.2672835\n0.1230492\n0.1803610\n\n\n0.2932287\n0.1531548\n0.2646686\n0.1186181\n0.1703298\n\n\n0.3874659\n0.1639724\n0.2381220\n0.0917680\n0.1186717\n\n\n0.2662055\n0.1472982\n0.2692148\n0.1271392\n0.1901424\n\n\n0.3003169\n0.1544747\n0.2631885\n0.1164363\n0.1655835\n\n\n0.3176095\n0.1573318\n0.2591488\n0.1112181\n0.1546918\n\n\n0.3336453\n0.1595343\n0.2549214\n0.1065185\n0.1453804\n\n\n0.3890308\n0.1640367\n0.2375854\n0.0913627\n0.1179843\n\n\n0.3133463\n0.1566745\n0.2601979\n0.1124904\n0.1572909\n\n\n0.2227442\n0.1349732\n0.2718842\n0.1412808\n0.2291176\n\n\n0.2386041\n0.1399036\n0.2716895\n0.1360916\n0.2137112\n\n\n0.2227442\n0.1349732\n0.2718842\n0.1412808\n0.2291176\n\n\n0.2693804\n0.1480556\n0.2687795\n0.1261230\n0.1876614\n\n\n0.4245968\n0.1645718\n0.2248479\n0.0825010\n0.1034825\n\n\n0.3732393\n0.1632247\n0.2428905\n0.0955132\n0.1251323\n\n\n0.3086265\n0.1559112\n0.2613198\n0.1139099\n0.1602327\n\n\n0.3565245\n0.1619619\n0.2482140\n0.1000544\n0.1332452\n\n\n0.3297057\n0.1590322\n0.2559992\n0.1076603\n0.1476025\n\n\n0.2998063\n0.1543826\n0.2632988\n0.1165927\n0.1659197\n\n\n0.2227442\n0.1349732\n0.2718842\n0.1412808\n0.2291176\n\n\n0.2345774\n0.1387000\n0.2718321\n0.1374089\n0.2174815\n\n\n0.2670993\n0.1475133\n0.2690951\n0.1268528\n0.1894395\n\n\n0.3188967\n0.1575242\n0.2588256\n0.1108358\n0.1539176\n\n\n0.2227442\n0.1349732\n0.2718842\n0.1412808\n0.2291176\n\n\n0.2345774\n0.1387000\n0.2718321\n0.1374089\n0.2174815\n\n\n0.2681811\n0.1477717\n0.2689473\n0.1265065\n0.1885935\n\n\n0.2750544\n0.1493625\n0.2679324\n0.1243163\n0.1833344\n\n\n0.3473476\n0.1610871\n0.2509913\n0.1026128\n0.1379612\n\n\n0.2227442\n0.1349732\n0.2718842\n0.1412808\n0.2291176\n\n\n0.2345774\n0.1387000\n0.2718321\n0.1374089\n0.2174815\n\n\n0.2616429\n0.1461767\n0.2697897\n0.1286054\n0.1937853\n\n\n0.2599182\n0.1457425\n0.2699910\n0.1291613\n0.1951869\n\n\n0.2227442\n0.1349732\n0.2718842\n0.1412808\n0.2291176\n\n\n0.2618779\n0.1462354\n0.2697616\n0.1285297\n0.1935954\n\n\n0.2227442\n0.1349732\n0.2718842\n0.1412808\n0.2291176\n\n\n0.2584197\n0.1453607\n0.2701586\n0.1296451\n0.1964158\n\n\n0.2347608\n0.1387556\n0.2718270\n0.1373489\n0.2173078\n\n\n0.2726901\n0.1488252\n0.2682960\n0.1250677\n0.1851211\n\n\n0.2511953\n0.1434596\n0.2708683\n0.1319859\n0.2024909\n\n\n0.2470295\n0.1423175\n0.2712006\n0.1333412\n0.2061111\n\n\n0.2919857\n0.1529142\n0.2649168\n0.1190031\n0.1711801\n\n\n0.2416607\n0.1407955\n0.2715412\n0.1350927\n0.2109098\n\n\n0.2662055\n0.1472982\n0.2692148\n0.1271392\n0.1901424\n\n\n0.3013857\n0.1546661\n0.2629560\n0.1161094\n0.1648827\n\n\n0.2934404\n0.1531955\n0.2646260\n0.1185526\n0.1701855\n\n\n0.2356749\n0.1390313\n0.2717993\n0.1370497\n0.2164448\n\n\n0.2345774\n0.1387000\n0.2718321\n0.1374089\n0.2174815\n\n\n0.2670993\n0.1475133\n0.2690951\n0.1268528\n0.1894395\n\n\n0.2607000\n0.1459400\n0.2699009\n0.1289092\n0.1945499\n\n\n0.2227442\n0.1349732\n0.2718842\n0.1412808\n0.2291176\n\n\n0.2782900\n0.1500813\n0.2674111\n0.1232916\n0.1809260\n\n\n0.2726901\n0.1488252\n0.2682960\n0.1250677\n0.1851211\n\n\n0.2227442\n0.1349732\n0.2718842\n0.1412808\n0.2291176\n\n\n0.2356749\n0.1390313\n0.2717993\n0.1370497\n0.2164448\n\n\n0.3530183\n0.1616431\n0.2492880\n0.1010264\n0.1350241\n\n\n0.2890191\n0.1523291\n0.2654949\n0.1199250\n0.1732318\n\n\n0.2778019\n0.1499741\n0.2674915\n0.1234459\n0.1812866\n\n\n0.3291686\n0.1589618\n0.2561442\n0.1078166\n0.1479087\n\n\n0.2227442\n0.1349732\n0.2718842\n0.1412808\n0.2291176\n\n\n0.2730326\n0.1489036\n0.2682442\n0.1249587\n0.1848609\n\n\n0.3404685\n0.1603448\n0.2529985\n0.1045608\n0.1416273\n\n\n0.2227442\n0.1349732\n0.2718842\n0.1412808\n0.2291176\n\n\n0.2345774\n0.1387000\n0.2718321\n0.1374089\n0.2174815\n\n\n0.2607000\n0.1459400\n0.2699009\n0.1289092\n0.1945499\n\n\n0.2584197\n0.1453607\n0.2701586\n0.1296451\n0.1964158\n\n\n0.2227442\n0.1349732\n0.2718842\n0.1412808\n0.2291176\n\n\n0.2601100\n0.1457911\n0.2699691\n0.1290995\n0.1950304\n\n\n0.3416706\n0.1604799\n0.2526526\n0.1042185\n0.1409783\n\n\n0.2765841\n0.1497048\n0.2676894\n0.1238313\n0.1821905\n\n\n0.2345774\n0.1387000\n0.2718321\n0.1374089\n0.2174815\n\n\n0.3006746\n0.1545390\n0.2631110\n0.1163269\n0.1653485\n\n\n0.2227442\n0.1349732\n0.2718842\n0.1412808\n0.2291176\n\n\n0.3287125\n0.1589017\n0.2562670\n0.1079495\n0.1481693\n\n\n0.2730326\n0.1489036\n0.2682442\n0.1249587\n0.1848609\n\n\n0.3084397\n0.1558802\n0.2613633\n0.1139663\n0.1603505\n\n\n0.3078903\n0.1557887\n0.2614909\n0.1141323\n0.1606978\n\n\n0.2914633\n0.1528123\n0.2650201\n0.1191652\n0.1715391\n\n\n0.3362937\n0.1598578\n0.2541833\n0.1057556\n0.1439095\n\n\n0.3030007\n0.1549516\n0.2626003\n0.1156166\n0.1638308\n\n\n0.2227442\n0.1349732\n0.2718842\n0.1412808\n0.2291176\n\n\n0.3075433\n0.1557306\n0.2615712\n0.1142373\n0.1609176\n\n\n0.2416607\n0.1407955\n0.2715412\n0.1350927\n0.2109098\n\n\n0.3684912\n0.1629088\n0.2444352\n0.0967876\n0.1273771\n\n\n0.2808510\n0.1506367\n0.2669795\n0.1224835\n0.1790493\n\n\n0.4288017\n0.1645211\n0.2232821\n0.0814966\n0.1018987\n\n\n0.3768978\n0.1634453\n0.2416837\n0.0945396\n0.1234335\n\n\n0.3003169\n0.1544747\n0.2631885\n0.1164363\n0.1655835\n\n\n0.2730326\n0.1489036\n0.2682442\n0.1249587\n0.1848609\n\n\n0.2345774\n0.1387000\n0.2718321\n0.1374089\n0.2174815\n\n\n0.3057289\n0.1554237\n0.2619872\n0.1147869\n0.1620732\n\n\n0.2772705\n0.1498569\n0.2675783\n0.1236140\n0.1816803\n\n\n0.2227442\n0.1349732\n0.2718842\n0.1412808\n0.2291176\n\n\n0.2468396\n0.1422647\n0.2712143\n0.1334031\n0.2062783\n\n\n0.2962965\n0.1537369\n0.2640414\n0.1176709\n0.1682544\n\n\n0.2541703\n0.1442546\n0.2705962\n0.1310204\n0.1999586\n\n\n0.2670993\n0.1475133\n0.2690951\n0.1268528\n0.1894395\n\n\n0.3186802\n0.1574921\n0.2588802\n0.1109001\n0.1540475\n\n\n0.2725744\n0.1487986\n0.2683134\n0.1251045\n0.1852091\n\n\n0.3003169\n0.1544747\n0.2631885\n0.1164363\n0.1655835\n\n\n0.3626270\n0.1624719\n0.2463081\n0.0983787\n0.1302142\n\n\n0.3634197\n0.1625340\n0.2460573\n0.0981625\n0.1298265\n\n\n0.2962965\n0.1537369\n0.2640414\n0.1176709\n0.1682544\n\n\n0.2683624\n0.1478148\n0.2689222\n0.1264485\n0.1884522\n\n\n0.2630545\n0.1465278\n0.2696184\n0.1281510\n0.1926483\n\n\n0.2227442\n0.1349732\n0.2718842\n0.1412808\n0.2291176\n\n\n0.2630545\n0.1465278\n0.2696184\n0.1281510\n0.1926483\n\n\n0.2851627\n0.1515450\n0.2662158\n0.1211293\n0.1759471\n\n\n0.2227442\n0.1349732\n0.2718842\n0.1412808\n0.2291176\n\n\n0.2227442\n0.1349732\n0.2718842\n0.1412808\n0.2291176\n\n\n0.2714814\n0.1485465\n0.2684760\n0.1254526\n0.1860434\n\n\n0.2227442\n0.1349732\n0.2718842\n0.1412808\n0.2291176\n\n\n0.3319448\n0.1593207\n0.2553896\n0.1070104\n0.1463346\n\n\n0.3173567\n0.1572937\n0.2592120\n0.1112933\n0.1548444\n\n\n0.2681811\n0.1477717\n0.2689473\n0.1265065\n0.1885935\n\n\n0.2468396\n0.1422647\n0.2712143\n0.1334031\n0.2062783\n\n\n0.3068086\n0.1556070\n0.2617404\n0.1144596\n0.1613843\n\n\n0.3625821\n0.1624684\n0.2463223\n0.0983909\n0.1302363\n\n\n0.3244403\n0.1583217\n0.2574006\n0.1091995\n0.1506380\n\n\n0.2670993\n0.1475133\n0.2690951\n0.1268528\n0.1894395\n\n\n0.2491157\n0.1428937\n0.2710414\n0.1326621\n0.2042872\n\n\n0.4039928\n0.1644756\n0.2323470\n0.0875539\n0.1116308\n\n\n0.2386041\n0.1399036\n0.2716895\n0.1360916\n0.2137112\n\n\n0.2716834\n0.1485932\n0.2684462\n0.1253882\n0.1858889\n\n\n0.2227442\n0.1349732\n0.2718842\n0.1412808\n0.2291176\n\n\n0.2750544\n0.1493625\n0.2679324\n0.1243163\n0.1833344\n\n\n0.2227442\n0.1349732\n0.2718842\n0.1412808\n0.2291176\n\n\n0.2386041\n0.1399036\n0.2716895\n0.1360916\n0.2137112\n\n\n0.3287125\n0.1589017\n0.2562670\n0.1079495\n0.1481693\n\n\n0.2967174\n0.1538154\n0.2639537\n0.1175412\n0.1679722\n\n\n0.2714814\n0.1485465\n0.2684760\n0.1254526\n0.1860434\n\n\n0.2584197\n0.1453607\n0.2701586\n0.1296451\n0.1964158\n\n\n0.2898492\n0.1524944\n0.2653352\n0.1196667\n0.1726546\n\n\n0.2778019\n0.1499741\n0.2674915\n0.1234459\n0.1812866\n\n\n0.2347608\n0.1387556\n0.2718270\n0.1373489\n0.2173078\n\n\n0.3254002\n0.1584546\n0.2571485\n0.1089178\n0.1500789\n\n\n0.2983181\n0.1541114\n0.2636169\n0.1170491\n0.1669045\n\n\n0.3985023\n0.1643512\n0.2342914\n0.0889378\n0.1139174\n\n\n0.2849546\n0.1515019\n0.2662537\n0.1211945\n0.1760952\n\n\n0.2511953\n0.1434596\n0.2708683\n0.1319859\n0.2024909\n\n\n0.2716834\n0.1485932\n0.2684462\n0.1253882\n0.1858889\n\n\n0.2951572\n0.1535226\n0.2642768\n0.1180221\n0.1690213\n\n\n0.2806448\n0.1505925\n0.2670148\n0.1225485\n0.1791995\n\n\n0.2728299\n0.1488572\n0.2682749\n0.1250232\n0.1850148\n\n\n0.2601100\n0.1457911\n0.2699691\n0.1290995\n0.1950304\n\n\n0.3598669\n0.1622483\n0.2471757\n0.0991341\n0.1315750\n\n\n0.2806448\n0.1505925\n0.2670148\n0.1225485\n0.1791995\n\n\n0.2345774\n0.1387000\n0.2718321\n0.1374089\n0.2174815\n\n\n0.2227442\n0.1349732\n0.2718842\n0.1412808\n0.2291176\n\n\n0.3332832\n0.1594892\n0.2550215\n0.1066231\n0.1455829\n\n\n0.2227442\n0.1349732\n0.2718842\n0.1412808\n0.2291176\n\n\n0.2584197\n0.1453607\n0.2701586\n0.1296451\n0.1964158\n\n\n0.2227442\n0.1349732\n0.2718842\n0.1412808\n0.2291176\n\n\n0.3420590\n0.1605231\n0.2525403\n0.1041081\n0.1407694\n\n\n0.2468396\n0.1422647\n0.2712143\n0.1334031\n0.2062783\n\n\n0.3575123\n0.1620484\n0.2479085\n0.0997817\n0.1327490\n\n\n0.2990362\n0.1542427\n0.2634640\n0.1168288\n0.1664284\n\n\n0.3045330\n0.1552184\n0.2622578\n0.1151502\n0.1628407\n\n\n0.3153953\n0.1569942\n0.2596978\n0.1118777\n0.1560349\n\n\n0.2849546\n0.1515019\n0.2662537\n0.1211945\n0.1760952\n\n\n0.2479759\n0.1425800\n0.2711302\n0.1330330\n0.2052809\n\n\n0.2227442\n0.1349732\n0.2718842\n0.1412808\n0.2291176\n\n\n0.2607000\n0.1459400\n0.2699009\n0.1289092\n0.1945499\n\n\n0.2642250\n0.1468162\n0.2694718\n0.1277748\n0.1917122\n\n\n0.2511953\n0.1434596\n0.2708683\n0.1319859\n0.2024909\n\n\n0.2227442\n0.1349732\n0.2718842\n0.1412808\n0.2291176\n\n\n0.2472195\n0.1423704\n0.2711867\n0.1332794\n0.2059441\n\n\n0.3391595\n0.1601951\n0.2533727\n0.1049344\n0.1423382\n\n\n0.2356749\n0.1390313\n0.2717993\n0.1370497\n0.2164448\n\n\n0.3298347\n0.1590491\n0.2559643\n0.1076228\n0.1475292\n\n\n0.4233559\n0.1645823\n0.2253079\n0.0827991\n0.1039549\n\n\n0.2468396\n0.1422647\n0.2712143\n0.1334031\n0.2062783\n\n\n0.3615207\n0.1623837\n0.2466570\n0.0986809\n0.1307577\n\n\n0.3485004\n0.1612042\n0.2506485\n0.1022889\n0.1373580\n\n\n0.2853709\n0.1515880\n0.2661778\n0.1210641\n0.1757991\n\n\n0.3336453\n0.1595343\n0.2549214\n0.1065185\n0.1453804\n\n\n0.3938030\n0.1642111\n0.2359355\n0.0901349\n0.1159154\n\n\n0.3822454\n0.1637324\n0.2398951\n0.0931296\n0.1209975\n\n\n0.2227442\n0.1349732\n0.2718842\n0.1412808\n0.2291176\n\n\n0.2795858\n0.1503638\n0.2671948\n0.1228823\n0.1799732\n\n\n0.2960887\n0.1536979\n0.2640845\n0.1177349\n0.1683939\n\n\n0.2227442\n0.1349732\n0.2718842\n0.1412808\n0.2291176\n\n\n0.2806448\n0.1505925\n0.2670148\n0.1225485\n0.1791995\n\n\n0.2599182\n0.1457425\n0.2699910\n0.1291613\n0.1951869\n\n\n0.2610891\n0.1460379\n0.2698553\n0.1287838\n0.1942339\n\n\n0.3324302\n0.1593821\n0.2552564\n0.1068698\n0.1460614\n\n\n0.2386041\n0.1399036\n0.2716895\n0.1360916\n0.2137112\n\n\n0.2356749\n0.1390313\n0.2717993\n0.1370497\n0.2164448\n\n\n0.4055920\n0.1645039\n0.2317761\n0.0871538\n0.1109743\n\n\n0.3573336\n0.1620328\n0.2479639\n0.0998310\n0.1328386\n\n\n0.4454541\n0.1640921\n0.2169790\n0.0776057\n0.0958691\n\n\n0.2745408\n0.1492467\n0.2680127\n0.1244793\n0.1837205\n\n\n0.3311850\n0.1592237\n0.2555973\n0.1072306\n0.1467633\n\n\n0.3070671\n0.1556506\n0.2616810\n0.1143813\n0.1612199\n\n\n0.2510078\n0.1434089\n0.2708845\n0.1320468\n0.2026519\n\n\n0.3336453\n0.1595343\n0.2549214\n0.1065185\n0.1453804\n\n\n0.2792725\n0.1502958\n0.2672475\n0.1229812\n0.1802030\n\n\n0.3013857\n0.1546661\n0.2629560\n0.1161094\n0.1648827\n\n\n0.2386041\n0.1399036\n0.2716895\n0.1360916\n0.2137112\n\n\n0.2416607\n0.1407955\n0.2715412\n0.1350927\n0.2109098\n\n\n0.2650151\n0.1470094\n0.2693706\n0.1275210\n0.1910838\n\n\n0.2916742\n0.1528535\n0.2649785\n0.1190998\n0.1713941\n\n\n0.2782900\n0.1500813\n0.2674111\n0.1232916\n0.1809260\n\n\n0.2416607\n0.1407955\n0.2715412\n0.1350927\n0.2109098\n\n\n0.2992502\n0.1542817\n0.2634182\n0.1167631\n0.1662868\n\n\n0.2227442\n0.1349732\n0.2718842\n0.1412808\n0.2291176\n\n\n0.2345774\n0.1387000\n0.2718321\n0.1374089\n0.2174815\n\n\n0.2227442\n0.1349732\n0.2718842\n0.1412808\n0.2291176\n\n\n0.2227442\n0.1349732\n0.2718842\n0.1412808\n0.2291176\n\n\n0.2607000\n0.1459400\n0.2699009\n0.1289092\n0.1945499\n\n\n0.3251601\n0.1584215\n0.2572117\n0.1089882\n0.1502185\n\n\n0.2962965\n0.1537369\n0.2640414\n0.1176709\n0.1682544\n\n\n0.2642250\n0.1468162\n0.2694718\n0.1277748\n0.1917122\n\n\n0.2468396\n0.1422647\n0.2712143\n0.1334031\n0.2062783\n\n\n0.2227442\n0.1349732\n0.2718842\n0.1412808\n0.2291176\n\n\n0.2345774\n0.1387000\n0.2718321\n0.1374089\n0.2174815\n\n\n0.2818784\n0.1508562\n0.2668016\n0.1221601\n0.1783036\n\n\n0.2345774\n0.1387000\n0.2718321\n0.1374089\n0.2174815\n\n\n0.2851627\n0.1515450\n0.2662158\n0.1211293\n0.1759471\n\n\n0.2345774\n0.1387000\n0.2718321\n0.1374089\n0.2174815\n\n\n0.2774752\n0.1499021\n0.2675450\n0.1235492\n0.1815285\n\n\n0.2227442\n0.1349732\n0.2718842\n0.1412808\n0.2291176\n\n\n0.2946011\n0.1534172\n0.2643906\n0.1181938\n0.1693973\n\n\n0.2510078\n0.1434089\n0.2708845\n0.1320468\n0.2026519\n\n\n0.2931884\n0.1531470\n0.2646767\n0.1186306\n0.1703573\n\n\n0.2345774\n0.1387000\n0.2718321\n0.1374089\n0.2174815\n\n\n0.2948184\n0.1534585\n0.2643462\n0.1181267\n0.1692502\n\n\n0.3005315\n0.1545133\n0.2631420\n0.1163706\n0.1654425\n\n\n0.2652141\n0.1470578\n0.2693449\n0.1274572\n0.1909261\n\n\n0.2584197\n0.1453607\n0.2701586\n0.1296451\n0.1964158\n\n\n0.2347608\n0.1387556\n0.2718270\n0.1373489\n0.2173078\n\n\n0.2227442\n0.1349732\n0.2718842\n0.1412808\n0.2291176\n\n\n0.2227442\n0.1349732\n0.2718842\n0.1412808\n0.2291176\n\n\n0.2630545\n0.1465278\n0.2696184\n0.1281510\n0.1926483\n\n\n0.2468396\n0.1422647\n0.2712143\n0.1334031\n0.2062783\n\n\n0.3240461\n0.1582666\n0.2575037\n0.1093153\n0.1508683\n\n\n0.3150384\n0.1569391\n0.2597855\n0.1119843\n0.1562528\n\n\n0.2227442\n0.1349732\n0.2718842\n0.1412808\n0.2291176\n\n\n0.2356749\n0.1390313\n0.2717993\n0.1370497\n0.2164448\n\n\n0.2227442\n0.1349732\n0.2718842\n0.1412808\n0.2291176\n\n\n0.2227442\n0.1349732\n0.2718842\n0.1412808\n0.2291176\n\n\n0.2615678\n0.1461579\n0.2697987\n0.1286296\n0.1938461\n\n\n0.3292492\n0.1589724\n0.2561225\n0.1077932\n0.1478627\n\n\n0.2682956\n0.1477989\n0.2689314\n0.1264698\n0.1885042\n\n\n0.2345774\n0.1387000\n0.2718321\n0.1374089\n0.2174815\n\n\n0.2386041\n0.1399036\n0.2716895\n0.1360916\n0.2137112\n\n\n0.2618779\n0.1462354\n0.2697616\n0.1285297\n0.1935954\n\n\n0.3781948\n0.1635188\n0.2412526\n0.0941962\n0.1228376\n\n\n0.3692950\n0.1629646\n0.2441754\n0.0965710\n0.1269939\n\n\n0.2227442\n0.1349732\n0.2718842\n0.1412808\n0.2291176\n\n\n0.3358001\n0.1597984\n0.2543217\n0.1058975\n0.1441823\n\n\n0.3570992\n0.1620124\n0.2480364\n0.0998957\n0.1329563\n\n\n0.3038897\n0.1551069\n0.2624021\n0.1153458\n0.1632554\n\n\n0.2851627\n0.1515450\n0.2662158\n0.1211293\n0.1759471\n\n\n0.2227442\n0.1349732\n0.2718842\n0.1412808\n0.2291176\n\n\n0.2386041\n0.1399036\n0.2716895\n0.1360916\n0.2137112\n\n\n0.2345774\n0.1387000\n0.2718321\n0.1374089\n0.2174815\n\n\n0.2356749\n0.1390313\n0.2717993\n0.1370497\n0.2164448\n\n\n0.3629249\n0.1624954\n0.2462140\n0.0982974\n0.1300684\n\n\n0.2822723\n0.1509398\n0.2667328\n0.1220362\n0.1780188\n\n\n0.2662055\n0.1472982\n0.2692148\n0.1271392\n0.1901424\n\n\n0.2479759\n0.1425800\n0.2711302\n0.1330330\n0.2052809\n\n\n0.2638329\n0.1467199\n0.2695213\n0.1279008\n0.1920251\n\n\n0.3088392\n0.1559464\n0.2612701\n0.1138457\n0.1600986\n\n\n0.2345774\n0.1387000\n0.2718321\n0.1374089\n0.2174815\n\n\n0.2227442\n0.1349732\n0.2718842\n0.1412808\n0.2291176\n\n\n0.2356749\n0.1390313\n0.2717993\n0.1370497\n0.2164448\n\n\n0.2227442\n0.1349732\n0.2718842\n0.1412808\n0.2291176\n\n\n0.2820901\n0.1509012\n0.2667647\n0.1220935\n0.1781505\n\n\n0.2356749\n0.1390313\n0.2717993\n0.1370497\n0.2164448\n\n\n0.2608968\n0.1459896\n0.2698779\n0.1288458\n0.1943900\n\n\n0.2541703\n0.1442546\n0.2705962\n0.1310204\n0.1999586\n\n\n0.2345774\n0.1387000\n0.2718321\n0.1374089\n0.2174815\n\n\n0.2670993\n0.1475133\n0.2690951\n0.1268528\n0.1894395\n\n\n0.2521523\n0.1437172\n0.2707839\n0.1316751\n0.2016715\n\n\n0.2227442\n0.1349732\n0.2718842\n0.1412808\n0.2291176\n\n\n0.2874480\n0.1520129\n0.2657929\n0.1204148\n0.1743315\n\n\n0.3115652\n0.1563909\n0.2606262\n0.1130247\n0.1583929\n\n\n0.2784951\n0.1501263\n0.2673772\n0.1232267\n0.1807747\n\n\n0.3186802\n0.1574921\n0.2588802\n0.1109001\n0.1540475\n\n\n0.2227442\n0.1349732\n0.2718842\n0.1412808\n0.2291176\n\n\n0.2584197\n0.1453607\n0.2701586\n0.1296451\n0.1964158\n\n\n0.3057289\n0.1554237\n0.2619872\n0.1147869\n0.1620732\n\n\n0.2888393\n0.1522931\n0.2655293\n0.1199810\n0.1733572\n\n\n0.2345774\n0.1387000\n0.2718321\n0.1374089\n0.2174815\n\n\n0.2608968\n0.1459896\n0.2698779\n0.1288458\n0.1943900\n\n\n0.3655316\n0.1626948\n0.2453854\n0.0975883\n0.1288000\n\n\n0.2990362\n0.1542427\n0.2634640\n0.1168288\n0.1664284\n\n\n0.2607000\n0.1459400\n0.2699009\n0.1289092\n0.1945499\n\n\n0.2818784\n0.1508562\n0.2668016\n0.1221601\n0.1783036\n\n\n0.2854205\n0.1515983\n0.2661688\n0.1210486\n0.1757639\n\n\n0.2347608\n0.1387556\n0.2718270\n0.1373489\n0.2173078\n\n\n0.3258754\n0.1585198\n0.2570232\n0.1087785\n0.1498031\n\n\n0.2227442\n0.1349732\n0.2718842\n0.1412808\n0.2291176\n\n\n0.2776800\n0.1499473\n0.2675115\n0.1234844\n0.1813768\n\n\n0.3883145\n0.1640077\n0.2378313\n0.0915481\n0.1182984\n\n\n0.2630545\n0.1465278\n0.2696184\n0.1281510\n0.1926483\n\n\n0.2998063\n0.1543826\n0.2632988\n0.1165927\n0.1659197\n\n\n0.2227442\n0.1349732\n0.2718842\n0.1412808\n0.2291176\n\n\n0.2630545\n0.1465278\n0.2696184\n0.1281510\n0.1926483\n\n\n0.2631629\n0.1465547\n0.2696050\n0.1281162\n0.1925613\n\n\n0.3280154\n0.1588091\n0.2564540\n0.1081528\n0.1485687\n\n\n0.2541703\n0.1442546\n0.2705962\n0.1310204\n0.1999586\n\n\n0.2759133\n0.1495552\n0.2677967\n0.1240439\n0.1826909\n\n\n0.2416607\n0.1407955\n0.2715412\n0.1350927\n0.2109098\n\n\n0.2635544\n0.1466513\n0.2695563\n0.1279903\n0.1922478\n\n\n0.3381521\n0.1600780\n0.2536591\n0.1052226\n0.1428882\n\n\n0.3327540\n0.1594229\n0.2551674\n0.1067761\n0.1458796\n\n\n0.3795222\n0.1635914\n0.2408096\n0.0938457\n0.1222312\n\n\n0.2946011\n0.1534172\n0.2643906\n0.1181938\n0.1693973\n\n\n0.2694953\n0.1480826\n0.2687632\n0.1260864\n0.1875725\n\n\n0.2479759\n0.1425800\n0.2711302\n0.1330330\n0.2052809\n\n\n0.2650151\n0.1470094\n0.2693706\n0.1275210\n0.1910838\n\n\n0.2934404\n0.1531955\n0.2646260\n0.1185526\n0.1701855\n\n\n0.3495113\n0.1613051\n0.2503465\n0.1020054\n0.1368317\n\n\n0.3383916\n0.1601060\n0.2535911\n0.1051540\n0.1427572\n\n\n0.2227442\n0.1349732\n0.2718842\n0.1412808\n0.2291176\n\n\n0.3113410\n0.1563548\n0.2606797\n0.1130921\n0.1585324\n\n\n0.2227442\n0.1349732\n0.2718842\n0.1412808\n0.2291176\n\n\n0.2846674\n0.1514424\n0.2663059\n0.1212845\n0.1762999\n\n\n0.2682956\n0.1477989\n0.2689314\n0.1264698\n0.1885042\n\n\n0.2971489\n0.1538956\n0.2638635\n0.1174085\n0.1676835\n\n\n0.3696745\n0.1629907\n0.2440526\n0.0964689\n0.1268134\n\n\n0.3139534\n0.1567700\n0.2600505\n0.1123086\n0.1569174\n\n\n0.3102630\n0.1561801\n0.2609356\n0.1134164\n0.1592049\n\n\n0.3102630\n0.1561801\n0.2609356\n0.1134164\n0.1592049\n\n\n0.3003169\n0.1544747\n0.2631885\n0.1164363\n0.1655835\n\n\n0.2864083\n0.1518012\n0.2659868\n0.1207396\n0.1750641\n\n\n0.3322953\n0.1593651\n0.2552935\n0.1069088\n0.1461373\n\n\n0.2479759\n0.1425800\n0.2711302\n0.1330330\n0.2052809\n\n\n0.3812298\n0.1636811\n0.2402370\n0.0933962\n0.1214560\n\n\n0.2227442\n0.1349732\n0.2718842\n0.1412808\n0.2291176\n\n\n0.2618779\n0.1462354\n0.2697616\n0.1285297\n0.1935954\n\n\n0.2345774\n0.1387000\n0.2718321\n0.1374089\n0.2174815\n\n\n0.2714814\n0.1485465\n0.2684760\n0.1254526\n0.1860434\n\n\n0.3063382\n0.1555274\n0.2618482\n0.1146022\n0.1616840\n\n\n0.2681238\n0.1477581\n0.2689552\n0.1265248\n0.1886381\n\n\n0.2468396\n0.1422647\n0.2712143\n0.1334031\n0.2062783\n\n\n0.2227442\n0.1349732\n0.2718842\n0.1412808\n0.2291176\n\n\n0.2726901\n0.1488252\n0.2682960\n0.1250677\n0.1851211\n\n\n0.3576464\n0.1620600\n0.2478670\n0.0997448\n0.1326818\n\n\n0.3305983\n0.1591482\n0.2557571\n0.1074009\n0.1470955\n\n\n0.2468396\n0.1422647\n0.2712143\n0.1334031\n0.2062783\n\n\n0.2227442\n0.1349732\n0.2718842\n0.1412808\n0.2291176\n\n\n0.2633609\n0.1466036\n0.2695804\n0.1280525\n0.1924026\n\n\n0.2740423\n0.1491338\n0.2680899\n0.1246377\n0.1840964\n\n\n0.2904150\n0.1526064\n0.2652254\n0.1194907\n0.1722625\n\n\n0.2774752\n0.1499021\n0.2675450\n0.1235492\n0.1815285\n\n\n0.2227442\n0.1349732\n0.2718842\n0.1412808\n0.2291176\n\n\n0.3336453\n0.1595343\n0.2549214\n0.1065185\n0.1453804\n\n\n0.2345774\n0.1387000\n0.2718321\n0.1374089\n0.2174815\n\n\n0.2227442\n0.1349732\n0.2718842\n0.1412808\n0.2291176\n\n\n0.3487268\n0.1612269\n0.2505810\n0.1022253\n0.1372400\n\n\n0.3250214\n0.1584023\n0.2572482\n0.1090289\n0.1502992\n\n\n0.2853709\n0.1515880\n0.2661778\n0.1210641\n0.1757991\n\n\n0.2227442\n0.1349732\n0.2718842\n0.1412808\n0.2291176\n\n\n0.2998165\n0.1543844\n0.2632966\n0.1165896\n0.1659130\n\n\n0.2468396\n0.1422647\n0.2712143\n0.1334031\n0.2062783\n\n\n0.2672992\n0.1475612\n0.2690681\n0.1267887\n0.1892828\n\n\n0.2543639\n0.1443058\n0.2705775\n0.1309576\n0.1997953\n\n\n0.2716834\n0.1485932\n0.2684462\n0.1253882\n0.1858889\n\n\n0.2662055\n0.1472982\n0.2692148\n0.1271392\n0.1901424\n\n\n0.2470295\n0.1423175\n0.2712006\n0.1333412\n0.2061111\n\n\n0.2584197\n0.1453607\n0.2701586\n0.1296451\n0.1964158\n\n\n0.2638329\n0.1467199\n0.2695213\n0.1279008\n0.1920251\n\n\n0.3156998\n0.1570412\n0.2596228\n0.1117868\n0.1558493\n\n\n0.3507173\n0.1614235\n0.2499843\n0.1016680\n0.1362069\n\n\n0.3283478\n0.1588533\n0.2563649\n0.1080559\n0.1483781\n\n\n0.2962965\n0.1537369\n0.2640414\n0.1176709\n0.1682544\n\n\n0.4655071\n0.1631055\n0.2092028\n0.0730993\n0.0890853\n\n\n0.2813964\n0.1507535\n0.2668854\n0.1223118\n0.1786530\n\n\n0.2227442\n0.1349732\n0.2718842\n0.1412808\n0.2291176\n\n\n0.2670993\n0.1475133\n0.2690951\n0.1268528\n0.1894395\n\n\n0.2765841\n0.1497048\n0.2676894\n0.1238313\n0.1821905\n\n\n0.2958759\n0.1536580\n0.2641286\n0.1178005\n0.1685370\n\n\n0.2638329\n0.1467199\n0.2695213\n0.1279008\n0.1920251\n\n\n0.2510078\n0.1434089\n0.2708845\n0.1320468\n0.2026519\n\n\n0.3180998\n0.1574054\n0.2590261\n0.1110724\n0.1543963\n\n\n0.2227442\n0.1349732\n0.2718842\n0.1412808\n0.2291176\n\n\n0.2468396\n0.1422647\n0.2712143\n0.1334031\n0.2062783\n\n\n0.2607000\n0.1459400\n0.2699009\n0.1289092\n0.1945499\n\n\n0.2740423\n0.1491338\n0.2680899\n0.1246377\n0.1840964\n\n\n0.3347759\n0.1596738\n0.2546076\n0.1061924\n0.1447503\n\n\n0.2479759\n0.1425800\n0.2711302\n0.1330330\n0.2052809\n\n\n0.3485004\n0.1612042\n0.2506485\n0.1022889\n0.1373580\n\n\n0.3487268\n0.1612269\n0.2505810\n0.1022253\n0.1372400\n\n\n0.2221723\n0.1347858\n0.2718721\n0.1414677\n0.2297021\n\n\n0.2227442\n0.1349732\n0.2718842\n0.1412808\n0.2291176\n\n\n0.2386041\n0.1399036\n0.2716895\n0.1360916\n0.2137112\n\n\n0.2844644\n0.1514002\n0.2663426\n0.1213481\n0.1764447\n\n\n0.2782900\n0.1500813\n0.2674111\n0.1232916\n0.1809260\n\n\n0.4070641\n0.1645268\n0.2312488\n0.0867867\n0.1103736\n\n\n0.2730326\n0.1489036\n0.2682442\n0.1249587\n0.1848609\n\n\n0.3102630\n0.1561801\n0.2609356\n0.1134164\n0.1592049\n\n\n0.2345774\n0.1387000\n0.2718321\n0.1374089\n0.2174815\n\n\n0.2468396\n0.1422647\n0.2712143\n0.1334031\n0.2062783\n\n\n0.2345774\n0.1387000\n0.2718321\n0.1374089\n0.2174815\n\n\n0.3609597\n0.1623382\n0.2468333\n0.0988345\n0.1310343\n\n\n0.2479759\n0.1425800\n0.2711302\n0.1330330\n0.2052809\n\n\n\n\n\n\n\n17.3.4 K&gt;2,p&gt;1 多分类逻辑回归\n用于处理具有多于两个类别的响应变量的情况。例如，分类问题中的三个或更多类别。\n\n17.3.4.1 nnet::multinom()\n\n\nCodemn_spec &lt;- multinom_reg(mode = \"classification\", engine = \"nnet\")\n\niris_mnlogit &lt;- mn_spec |&gt; \n    fit(Species ~ ., data = iris)\n\niris_mnlogit |&gt; glance()\n\n\n\n\nedf\ndeviance\nAIC\nnobs\n\n\n10\n11.89973\n31.89973\n150\n\n\n\n\nCodeiris_mnlogit |&gt; tidy()\n\n\n\n\n\n\n\n\n\n\n\n\ny.level\nterm\nestimate\nstd.error\nstatistic\np.value\n\n\n\nversicolor\n(Intercept)\n18.690374\n34.97116\n0.5344511\n0.5930295\n\n\nversicolor\nSepal.Length\n-5.458424\n89.89215\n-0.0607219\n0.9515807\n\n\nversicolor\nSepal.Width\n-8.707401\n157.04152\n-0.0554465\n0.9557828\n\n\nversicolor\nPetal.Length\n14.244770\n60.19170\n0.2366567\n0.8129231\n\n\nversicolor\nPetal.Width\n-3.097684\n45.48852\n-0.0680981\n0.9457075\n\n\nvirginica\n(Intercept)\n-23.836276\n35.76649\n-0.6664417\n0.5051288\n\n\nvirginica\nSepal.Length\n-7.923634\n89.91153\n-0.0881270\n0.9297757\n\n\nvirginica\nSepal.Width\n-15.370769\n157.11962\n-0.0978285\n0.9220685\n\n\nvirginica\nPetal.Length\n23.659779\n60.46753\n0.3912807\n0.6955898\n\n\nvirginica\nPetal.Width\n15.135300\n45.93406\n0.3295006\n0.7417773\n\n\n\n\n\nCode\n\naugment(iris_mnlogit, new_data = iris) |&gt;\n    conf_mat(truth = Species, estimate = .pred_class) |&gt;\n    autoplot(type = \"heatmap\")\n\n\n\n\n\n\n\n\n17.3.4.2 glmnet::glmnet()\n\n\nCodelibrary(glmnet) # 多项回归\niris_glmnet &lt;- glmnet(x = iris[, -5], y = iris[, 5], family = \"multinomial\")\niris_glmnet\n#&gt; \n#&gt; Call:  glmnet(x = iris[, -5], y = iris[, 5], family = \"multinomial\") \n#&gt; \n#&gt;     Df  %Dev  Lambda\n#&gt; 1    0  0.00 0.43500\n#&gt; 2    1  6.56 0.39640\n#&gt; 3    1 12.05 0.36110\n#&gt; 4    1 16.73 0.32910\n#&gt; 5    1 20.78 0.29980\n#&gt; 6    2 25.37 0.27320\n#&gt; 7    2 29.66 0.24890\n#&gt; 8    2 33.54 0.22680\n#&gt; 9    2 37.10 0.20670\n#&gt; 10   2 40.40 0.18830\n#&gt; 11   2 43.47 0.17160\n#&gt; 12   3 46.47 0.15630\n#&gt; 13   3 49.57 0.14240\n#&gt; 14   3 52.38 0.12980\n#&gt; 15   3 54.97 0.11830\n#&gt; 16   3 57.36 0.10780\n#&gt; 17   3 59.60 0.09818\n#&gt; 18   3 61.71 0.08946\n#&gt; 19   3 63.72 0.08151\n#&gt; 20   3 65.70 0.07427\n#&gt; 21   3 67.65 0.06767\n#&gt; 22   3 69.54 0.06166\n#&gt; 23   3 71.38 0.05618\n#&gt; 24   3 73.12 0.05119\n#&gt; 25   3 74.71 0.04664\n#&gt; 26   3 76.24 0.04250\n#&gt; 27   3 77.67 0.03872\n#&gt; 28   3 78.99 0.03528\n#&gt; 29   3 80.21 0.03215\n#&gt; 30   3 81.33 0.02929\n#&gt; 31   3 82.36 0.02669\n#&gt; 32   3 83.31 0.02432\n#&gt; 33   3 84.18 0.02216\n#&gt; 34   3 84.99 0.02019\n#&gt; 35   3 85.73 0.01840\n#&gt; 36   3 86.53 0.01676\n#&gt; 37   3 87.34 0.01527\n#&gt; 38   3 88.06 0.01392\n#&gt; 39   3 88.73 0.01268\n#&gt; 40   3 89.34 0.01155\n#&gt; 41   3 89.89 0.01053\n#&gt; 42   3 90.40 0.00959\n#&gt; 43   4 90.87 0.00874\n#&gt; 44   4 91.34 0.00796\n#&gt; 45   4 91.77 0.00726\n#&gt; 46   4 92.16 0.00661\n#&gt; 47   4 92.52 0.00602\n#&gt; 48   4 92.85 0.00549\n#&gt; 49   4 93.16 0.00500\n#&gt; 50   4 93.44 0.00456\n#&gt; 51   4 93.69 0.00415\n#&gt; 52   4 93.92 0.00378\n#&gt; 53   4 94.14 0.00345\n#&gt; 54   4 94.34 0.00314\n#&gt; 55   4 94.52 0.00286\n#&gt; 56   4 94.68 0.00261\n#&gt; 57   4 94.83 0.00238\n#&gt; 58   4 94.97 0.00216\n#&gt; 59   4 95.10 0.00197\n#&gt; 60   4 95.22 0.00180\n#&gt; 61   4 95.33 0.00164\n#&gt; 62   4 95.43 0.00149\n#&gt; 63   4 95.52 0.00136\n#&gt; 64   4 95.60 0.00124\n#&gt; 65   4 95.68 0.00113\n#&gt; 66   4 95.75 0.00103\n#&gt; 67   4 95.81 0.00094\n#&gt; 68   4 95.87 0.00085\n#&gt; 69   4 95.92 0.00078\n#&gt; 70   4 95.97 0.00071\n#&gt; 71   4 96.01 0.00065\n#&gt; 72   4 96.05 0.00059\n#&gt; 73   4 96.09 0.00054\n#&gt; 74   4 96.12 0.00049\n#&gt; 75   4 96.15 0.00045\n#&gt; 76   4 96.18 0.00041\n#&gt; 77   4 96.20 0.00037\n#&gt; 78   4 96.22 0.00034\n#&gt; 79   4 96.24 0.00031\n#&gt; 80   4 96.26 0.00028\n#&gt; 81   4 96.27 0.00025\n#&gt; 82   4 96.29 0.00023\n#&gt; 83   4 96.30 0.00021\n#&gt; 84   4 96.31 0.00019\n#&gt; 85   4 96.32 0.00018\n#&gt; 86   4 96.33 0.00016\n#&gt; 87   4 96.33 0.00015\n#&gt; 88   4 96.34 0.00013\n#&gt; 89   4 96.35 0.00012\n#&gt; 90   4 96.35 0.00011\n#&gt; 91   4 96.35 0.00010\n#&gt; 92   4 96.36 0.00009\n#&gt; 93   4 96.36 0.00008\n#&gt; 94   4 96.36 0.00008\n#&gt; 95   4 96.37 0.00007\n#&gt; 96   4 96.37 0.00006\n#&gt; 97   4 96.37 0.00006\n#&gt; 98   4 96.37 0.00005\n#&gt; 99   4 96.38 0.00005\n#&gt; 100  4 96.38 0.00004\nsummary(iris_glmnet )\n#&gt;            Length Class  Mode     \n#&gt; a0         300    -none- numeric  \n#&gt; beta         3    -none- list     \n#&gt; dfmat      300    -none- numeric  \n#&gt; df         100    -none- numeric  \n#&gt; dim          2    -none- numeric  \n#&gt; lambda     100    -none- numeric  \n#&gt; dev.ratio  100    -none- numeric  \n#&gt; nulldev      1    -none- numeric  \n#&gt; npasses      1    -none- numeric  \n#&gt; jerr         1    -none- numeric  \n#&gt; offset       1    -none- logical  \n#&gt; classnames   3    -none- character\n#&gt; grouped      1    -none- logical  \n#&gt; call         4    -none- call     \n#&gt; nobs         1    -none- numeric\nplot(iris_glmnet)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCodeplot(iris_glmnet$lambda,\n  ylab = expression(lambda), xlab = \"迭代次数\", main = \"惩罚系数的迭代路径\"\n)\n\n\n\n\n\n\nCode\n# 选择一个迭代趋于稳定时的 lambda，比如 iris_glmnet$lambda[80]\ncoef(iris_glmnet, s = 0.0002796185)\n#&gt; $setosa\n#&gt; 5 x 1 sparse Matrix of class \"dgCMatrix\"\n#&gt;                      1\n#&gt; (Intercept)  17.015429\n#&gt; Sepal.Length  .       \n#&gt; Sepal.Width   4.486992\n#&gt; Petal.Length -3.250342\n#&gt; Petal.Width  -3.315393\n#&gt; \n#&gt; $versicolor\n#&gt; 5 x 1 sparse Matrix of class \"dgCMatrix\"\n#&gt;                     1\n#&gt; (Intercept)  8.132656\n#&gt; Sepal.Length 2.123980\n#&gt; Sepal.Width  .       \n#&gt; Petal.Length .       \n#&gt; Petal.Width  .       \n#&gt; \n#&gt; $virginica\n#&gt; 5 x 1 sparse Matrix of class \"dgCMatrix\"\n#&gt;                       1\n#&gt; (Intercept)  -25.148085\n#&gt; Sepal.Length   .       \n#&gt; Sepal.Width   -5.176029\n#&gt; Petal.Length   7.536940\n#&gt; Petal.Width   14.481524\n\niris_pred_glmnet &lt;- predict(\n  object = iris_glmnet, newx = as.matrix(iris[, -5]),\n  s = 0.0002796185, type = \"class\"\n)\n\n\n\nCodemn_spec &lt;- multinom_reg(mode = \"classification\", engine = \"glmnet\" ,penalty = tune())\n\niris_mnlogit &lt;- mn_spec |&gt; \n    fit(Species ~ ., data = iris)\niris_mnlogit |&gt; glance()\n\n\n\n\nnulldev\nnpasses\nnobs\n\n\n329.5837\n6546\n150\n\n\n\n\nCodeiris_mnlogit$fit\n#&gt; \n#&gt; Call:  glmnet::glmnet(x = maybe_matrix(x), y = y, family = \"multinomial\") \n#&gt; \n#&gt;     Df  %Dev  Lambda\n#&gt; 1    0  0.00 0.43500\n#&gt; 2    1  6.56 0.39640\n#&gt; 3    1 12.05 0.36110\n#&gt; 4    1 16.73 0.32910\n#&gt; 5    1 20.78 0.29980\n#&gt; 6    2 25.37 0.27320\n#&gt; 7    2 29.66 0.24890\n#&gt; 8    2 33.54 0.22680\n#&gt; 9    2 37.10 0.20670\n#&gt; 10   2 40.40 0.18830\n#&gt; 11   2 43.47 0.17160\n#&gt; 12   3 46.47 0.15630\n#&gt; 13   3 49.57 0.14240\n#&gt; 14   3 52.38 0.12980\n#&gt; 15   3 54.97 0.11830\n#&gt; 16   3 57.36 0.10780\n#&gt; 17   3 59.60 0.09818\n#&gt; 18   3 61.71 0.08946\n#&gt; 19   3 63.72 0.08151\n#&gt; 20   3 65.70 0.07427\n#&gt; 21   3 67.65 0.06767\n#&gt; 22   3 69.54 0.06166\n#&gt; 23   3 71.38 0.05618\n#&gt; 24   3 73.12 0.05119\n#&gt; 25   3 74.71 0.04664\n#&gt; 26   3 76.24 0.04250\n#&gt; 27   3 77.67 0.03872\n#&gt; 28   3 78.99 0.03528\n#&gt; 29   3 80.21 0.03215\n#&gt; 30   3 81.33 0.02929\n#&gt; 31   3 82.36 0.02669\n#&gt; 32   3 83.31 0.02432\n#&gt; 33   3 84.18 0.02216\n#&gt; 34   3 84.99 0.02019\n#&gt; 35   3 85.73 0.01840\n#&gt; 36   3 86.53 0.01676\n#&gt; 37   3 87.34 0.01527\n#&gt; 38   3 88.06 0.01392\n#&gt; 39   3 88.73 0.01268\n#&gt; 40   3 89.34 0.01155\n#&gt; 41   3 89.89 0.01053\n#&gt; 42   3 90.40 0.00959\n#&gt; 43   4 90.87 0.00874\n#&gt; 44   4 91.34 0.00796\n#&gt; 45   4 91.77 0.00726\n#&gt; 46   4 92.16 0.00661\n#&gt; 47   4 92.52 0.00602\n#&gt; 48   4 92.85 0.00549\n#&gt; 49   4 93.16 0.00500\n#&gt; 50   4 93.44 0.00456\n#&gt; 51   4 93.69 0.00415\n#&gt; 52   4 93.92 0.00378\n#&gt; 53   4 94.14 0.00345\n#&gt; 54   4 94.34 0.00314\n#&gt; 55   4 94.52 0.00286\n#&gt; 56   4 94.68 0.00261\n#&gt; 57   4 94.83 0.00238\n#&gt; 58   4 94.97 0.00216\n#&gt; 59   4 95.10 0.00197\n#&gt; 60   4 95.22 0.00180\n#&gt; 61   4 95.33 0.00164\n#&gt; 62   4 95.43 0.00149\n#&gt; 63   4 95.52 0.00136\n#&gt; 64   4 95.60 0.00124\n#&gt; 65   4 95.68 0.00113\n#&gt; 66   4 95.75 0.00103\n#&gt; 67   4 95.81 0.00094\n#&gt; 68   4 95.87 0.00085\n#&gt; 69   4 95.92 0.00078\n#&gt; 70   4 95.97 0.00071\n#&gt; 71   4 96.01 0.00065\n#&gt; 72   4 96.05 0.00059\n#&gt; 73   4 96.09 0.00054\n#&gt; 74   4 96.12 0.00049\n#&gt; 75   4 96.15 0.00045\n#&gt; 76   4 96.18 0.00041\n#&gt; 77   4 96.20 0.00037\n#&gt; 78   4 96.22 0.00034\n#&gt; 79   4 96.24 0.00031\n#&gt; 80   4 96.26 0.00028\n#&gt; 81   4 96.27 0.00025\n#&gt; 82   4 96.29 0.00023\n#&gt; 83   4 96.30 0.00021\n#&gt; 84   4 96.31 0.00019\n#&gt; 85   4 96.32 0.00018\n#&gt; 86   4 96.33 0.00016\n#&gt; 87   4 96.33 0.00015\n#&gt; 88   4 96.34 0.00013\n#&gt; 89   4 96.35 0.00012\n#&gt; 90   4 96.35 0.00011\n#&gt; 91   4 96.35 0.00010\n#&gt; 92   4 96.36 0.00009\n#&gt; 93   4 96.36 0.00008\n#&gt; 94   4 96.36 0.00008\n#&gt; 95   4 96.37 0.00007\n#&gt; 96   4 96.37 0.00006\n#&gt; 97   4 96.37 0.00006\n#&gt; 98   4 96.37 0.00005\n#&gt; 99   4 96.38 0.00005\n#&gt; 100  4 96.38 0.00004",
    "crumbs": [
      "统计模型",
      "<span class='chapter-number'>17</span>  <span class='chapter-title'>广义线性模型</span>"
    ]
  },
  {
    "objectID": "GLM.html#泊松回归",
    "href": "GLM.html#泊松回归",
    "title": "\n17  广义线性模型\n",
    "section": "\n17.4 泊松回归",
    "text": "17.4 泊松回归\n泊松回归用于计数数据，假设响应变量服从泊松分布，并使用对数连接函数（log link function）。z-statistic\nfamily=poisson(link = \"log\")\nfamily = quasipoisson(link = \"log\"))\n\\[\nP(X=x;\\lambda)=\\frac{e^{-\\lambda}\\lambda ^x}{x!}\n\\]\n\nCode\nggplot(tibble(x=0:20,\n              y1=dpois(x,lambda = 2),\n              y2=dpois(x,lambda = 6),\n              ),\n       aes(x)\n       )+\n    geom_col(aes(y=y1),fill = \"lightblue\")+\n    geom_col(aes(y=y2),fill = \"yellow\",alpha=.3)+\n    ylab(\"Poisson Density\")\n\n\n\n\n\n\n\n\nCodelibrary(poissonreg)\ndf2 &lt;- read_csv(\"data/ISLR/Bikeshare.csv\")\n\n\n\nCode# 泊松回归模型\npois_spec &lt;- poisson_reg() |&gt; \n  set_mode(\"regression\") |&gt; \n  set_engine(\"glm\",family=poisson(link = \"log\"))\n\npois_rec_spec &lt;- recipe(bikers ~ mnth + hr + workingday + temp + weathersit, data = df2) |&gt; \n    step_dummy(all_nominal_predictors()) # 虚拟变量\n\npois_wf &lt;- workflow() |&gt; \n  add_recipe(pois_rec_spec) |&gt; \n  add_model(pois_spec)\n\npois_fit &lt;- pois_wf |&gt; fit(data = df2)\n\n\ntidy(pois_fit)\n\n\n\n\n\n\n\n\n\n\n\nterm\nestimate\nstd.error\nstatistic\np.value\n\n\n\n(Intercept)\n3.0117662\n0.0063169\n476.780725\n0.0000000\n\n\nhr\n0.0506926\n0.0001441\n351.838257\n0.0000000\n\n\nworkingday\n-0.0128398\n0.0019533\n-6.573519\n0.0000000\n\n\ntemp\n2.5638652\n0.0099520\n257.623318\n0.0000000\n\n\nmnth_Aug\n-0.2287982\n0.0046963\n-48.718729\n0.0000000\n\n\nmnth_Dec\n0.2980823\n0.0050089\n59.511067\n0.0000000\n\n\nmnth_Feb\n-0.1015251\n0.0059163\n-17.160118\n0.0000000\n\n\nmnth_Jan\n-0.1450225\n0.0067806\n-21.387732\n0.0000000\n\n\nmnth_July\n-0.3777099\n0.0049579\n-76.183572\n0.0000000\n\n\nmnth_June\n-0.1501555\n0.0046211\n-32.493432\n0.0000000\n\n\nmnth_March\n-0.0311769\n0.0053447\n-5.833195\n0.0000000\n\n\nmnth_May\n0.0507776\n0.0043437\n11.690022\n0.0000000\n\n\nmnth_Nov\n0.2845274\n0.0046053\n61.782729\n0.0000000\n\n\nmnth_Oct\n0.2667007\n0.0043237\n61.683349\n0.0000000\n\n\nmnth_Sept\n-0.0065336\n0.0044343\n-1.473415\n0.1406391\n\n\nweathersit_cloudy.misty\n-0.0308035\n0.0021642\n-14.233203\n0.0000000\n\n\nweathersit_heavy.rain.snow\n-0.6455169\n0.1667492\n-3.871185\n0.0001083\n\n\nweathersit_light.rain.snow\n-0.4727684\n0.0040430\n-116.934850\n0.0000000\n\n\n\n\n\nCode\n\n# 绘制实际值与预测值的关系图\naugment(pois_fit, new_data = df2,type=\"response\") |&gt; \n  ggplot(aes(bikers, .pred)) +\n  geom_point(alpha = 0.1) +\n  geom_abline(slope = 1, linewidth = 1, color = \"grey40\") +\n  labs(title = \"Predicting the number of bikers per hour using Poission Regression\",\n       x = \"Actual\", y = \"Predicted\")\n\n\n\n\n\n\n\n\nCodepois_fit_coef_mnths &lt;- \n  tidy(pois_fit) |&gt; \n  dplyr::filter(grepl(\"^mnth\", term)) |&gt; \n  mutate(\n    term = stringr::str_replace(term, \"mnth_\", \"\"),\n    term = forcats::fct_inorder(term)\n  ) \n\npois_fit_coef_mnths |&gt; \n  ggplot(aes(term, estimate)) +\n  geom_line(group = 1,na.rm = TRUE) +\n  geom_point(shape = 21, size = 3, stroke = 1.5, \n             fill = \"black\", color = \"white\",na.rm = TRUE) +\n  labs(title = \"Coefficient value from Poission Regression\",\n       x = \"Month\", y = \"Coefficient\")\n\n\n\n\n\n\n\n\nCodepois_acl &lt;- pois_spec |&gt; \n    fit(NChronic12_W1 ~ SelfEfficacy_W1,data = acl)\n\npois_acl |&gt; glance()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nnull.deviance\ndf.null\nlogLik\nAIC\nBIC\ndeviance\ndf.residual\nnobs\n\n\n5217.261\n3616\n-5161.259\n10326.52\n10338.9\n5113.99\n3615\n3617\n\n\n\n\nCode\npois_acl |&gt; tidy()\n\n\n\n\nterm\nestimate\nstd.error\nstatistic\np.value\n\n\n\n(Intercept)\n0.0713171\n0.0161919\n4.404498\n1.06e-05\n\n\nSelfEfficacy_W1\n-0.1495381\n0.0144411\n-10.355019\n0.00e+00\n\n\n\n\n\nCode\nAIC(pois_acl$fit)\n#&gt; [1] 10326.52\nBIC(pois_acl$fit)\n#&gt; [1] 10338.9",
    "crumbs": [
      "统计模型",
      "<span class='chapter-number'>17</span>  <span class='chapter-title'>广义线性模型</span>"
    ]
  },
  {
    "objectID": "GLM.html#负二项回归",
    "href": "GLM.html#负二项回归",
    "title": "\n17  广义线性模型\n",
    "section": "\n17.5 负二项回归",
    "text": "17.5 负二项回归\n负二项回归用于处理计数数据且存在过度离散（overdispersion）的问题。\nlog link function，z-statistic\nprobability mass function ：\n\\[\nP(X=x;\\lambda,\\nu)=\\binom{x+\\nu - 1}{ x} \\left ( \\frac{\\lambda}{\\lambda +\\nu} \\right)^x \\left ( \\frac{\\nu}{\\nu + \\lambda} \\right)^{\\nu}\n\\]\n负二项分布的均值是 \\(\\lambda\\) ，\n方差是 \\(\\lambda + \\frac{\\lambda ^2}{\\nu}\\) 。\n\nCodelibrary(MASS)\n# 负二项回归模型\nnb_spec &lt;- linear_reg() |&gt; \n  set_engine(\"glm\", family = MASS::negative.binomial(theta = 1, link = \"log\"))\n\nnb_acl &lt;- nb_spec |&gt; \n  fit(NChronic12_W1 ~ SelfEfficacy_W1, data = acl)\n\n# 查看模型结果\nnb_acl |&gt; glance()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nnull.deviance\ndf.null\nlogLik\nAIC\nBIC\ndeviance\ndf.residual\nnobs\n\n\n2945.585\n3616\n-5219.717\n10443.43\n10455.82\n2897.897\n3615\n3617\n\n\n\n\nCodenb_acl |&gt; tidy()\n\n\n\n\nterm\nestimate\nstd.error\nstatistic\np.value\n\n\n\n(Intercept)\n0.0715048\n0.0181211\n3.945943\n8.1e-05\n\n\nSelfEfficacy_W1\n-0.1480585\n0.0169183\n-8.751399\n0.0e+00\n\n\n\n\n\nCode\n\nAIC(nb_acl$fit)\n#&gt; [1] 10443.43\nBIC(nb_acl$fit)\n#&gt; [1] 10455.82\n\n# MASS::glm.nb()",
    "crumbs": [
      "统计模型",
      "<span class='chapter-number'>17</span>  <span class='chapter-title'>广义线性模型</span>"
    ]
  },
  {
    "objectID": "LME.html",
    "href": "LME.html",
    "title": "\n18  线性混合效应\n",
    "section": "",
    "text": "18.1 模型公式\n\\[\n\\eta = \\mathbf{X} \\beta + \\mathbf{Z} \\gamma + \\epsilon\n\\]\n其中：\n线性混合模型，LME的表达式如下：\n\\[\nfit=lmer (data,formual= DV ~ Fixed\\_Factor + (Random\\_intercept + Random\\_slope | Random\\_Factor))\n\\]\n截距中，1表示随机截距，0表示固定截距，默认截距为1。",
    "crumbs": [
      "统计模型",
      "<span class='chapter-number'>18</span>  <span class='chapter-title'>线性混合效应</span>"
    ]
  },
  {
    "objectID": "LME.html#模型公式",
    "href": "LME.html#模型公式",
    "title": "\n18  线性混合效应\n",
    "section": "",
    "text": "\\(\\mathbf{X}\\)是固定效应设计矩阵。\n\\(\\beta\\) 是固定效应系数。\n\\(\\mathbf{Z}\\) 是随机效应设计矩阵。\n\\(\\gamma\\) 是随机效应系数。\n\\(\\epsilon\\) 是误差项。\n\n\n\n\n\n\nLME\n表达式\n简写\n\n\n\n随机截距+随机斜率\ny~x+( 1+x | id )\ny~x+( x | id )\n\n\n随机截距+固定斜率\ny~x+( 1+1 | id )\ny~x+( 1 | id )\n\n\n固定截距+随机斜率\ny~x+( 0+x | id )\nNA\n\n\n线性模型：固定截距+固定斜率\ny~x\nNA\n\n\n\n\n18.1.1 模型选择标准\n限制最大似然法REML，赤池信息准则AIC，贝叶斯信息准则BIC\n\n\n赤池信息准则（AIC）\n\\[ kIC=−2log(\\mathcal{L})+2k\\]\n其中：\n\n\\(\\mathcal{L}\\) 是似然函数。\n\\(k\\) 是模型参数的数量。\n\n\n\n贝叶斯信息准则（BIC）\n\\[ BIC=−2log(\\mathcal{L})+klog(n) \\]\n其中：\n\n\n\\(n\\) 是样本量。",
    "crumbs": [
      "统计模型",
      "<span class='chapter-number'>18</span>  <span class='chapter-title'>线性混合效应</span>"
    ]
  },
  {
    "objectID": "LME.html#随机截距随机斜率",
    "href": "LME.html#随机截距随机斜率",
    "title": "\n18  线性混合效应\n",
    "section": "\n18.2 随机截距+随机斜率",
    "text": "18.2 随机截距+随机斜率\n\nCodedf_long &lt;- read_delim(\"data/AED/RIKZ.txt\")\ndf_long$Beach &lt;- factor(df_long$Beach)\ndf_long$Exposure &lt;- factor(df_long$Exposure)\nstr(df_long)\n#&gt; spc_tbl_ [45 × 5] (S3: spec_tbl_df/tbl_df/tbl/data.frame)\n#&gt;  $ Sample  : num [1:45] 1 2 3 4 5 6 7 8 9 10 ...\n#&gt;  $ Richness: num [1:45] 11 10 13 11 10 8 9 8 19 17 ...\n#&gt;  $ Exposure: Factor w/ 3 levels \"8\",\"10\",\"11\": 2 2 2 2 2 1 1 1 1 1 ...\n#&gt;  $ NAP     : num [1:45] 0.045 -1.036 -1.336 0.616 -0.684 ...\n#&gt;  $ Beach   : Factor w/ 9 levels \"1\",\"2\",\"3\",\"4\",..: 1 1 1 1 1 2 2 2 2 2 ...\n#&gt;  - attr(*, \"spec\")=\n#&gt;   .. cols(\n#&gt;   ..   Sample = col_double(),\n#&gt;   ..   Richness = col_double(),\n#&gt;   ..   Exposure = col_double(),\n#&gt;   ..   NAP = col_double(),\n#&gt;   ..   Beach = col_double()\n#&gt;   .. )\n#&gt;  - attr(*, \"problems\")=&lt;externalptr&gt;\n\n\n\\[\n\\eta_{(nrow \\times 1)} = \\mathbf{X}_{nrow \\times 1} \\beta_{1 \\times 1} + \\mathbf{Z}_{nrow \\times 2n_{subjects}} \\mathbf{\\gamma}_{2n_{subjects} \\times 1} + \\epsilon_i\n\\]\nZ有两倍于受试者数量的列，每个受试者的随机截距和随机斜率\n\nCodelibrary(lme4)\nlme1 &lt;- lmer(Richness ~ 1 + NAP * Exposure+ (1 +NAP |Beach) ,data = df_long)\nsummary(lme1)\n#&gt; Linear mixed model fit by REML ['lmerMod']\n#&gt; Formula: Richness ~ 1 + NAP * Exposure + (1 + NAP | Beach)\n#&gt;    Data: df_long\n#&gt; \n#&gt; REML criterion at convergence: 207.2\n#&gt; \n#&gt; Scaled residuals: \n#&gt;      Min       1Q   Median       3Q      Max \n#&gt; -1.92384 -0.36066 -0.13343  0.09819  2.84228 \n#&gt; \n#&gt; Random effects:\n#&gt;  Groups   Name        Variance Std.Dev. Corr \n#&gt;  Beach    (Intercept) 3.758    1.938         \n#&gt;           NAP         2.837    1.684    -1.00\n#&gt;  Residual             6.535    2.556         \n#&gt; Number of obs: 45, groups:  Beach, 9\n#&gt; \n#&gt; Fixed effects:\n#&gt;                Estimate Std. Error t value\n#&gt; (Intercept)     13.3457     2.2784   5.858\n#&gt; NAP             -4.1753     2.1243  -1.965\n#&gt; Exposure10      -5.3273     2.5556  -2.085\n#&gt; Exposure11      -9.7660     2.5653  -3.807\n#&gt; NAP:Exposure10   0.1646     2.3621   0.070\n#&gt; NAP:Exposure11   2.7273     2.3715   1.150\n#&gt; \n#&gt; Correlation of Fixed Effects:\n#&gt;             (Intr) NAP    Exps10 Exps11 NAP:E10\n#&gt; NAP         -0.770                             \n#&gt; Exposure10  -0.892  0.686                      \n#&gt; Exposure11  -0.888  0.683  0.792               \n#&gt; NAP:Expsr10  0.692 -0.899 -0.775 -0.615        \n#&gt; NAP:Expsr11  0.689 -0.896 -0.615 -0.779  0.806 \n#&gt; optimizer (nloptwrap) convergence code: 0 (OK)\n#&gt; boundary (singular) fit: see help('isSingular')\nAIC(lme1)\n#&gt; [1] 227.1558\nBIC(lme1)\n#&gt; [1] 245.2224\nlogLik(lme1)\n#&gt; 'log Lik.' -103.5779 (df=10)\n\n2*(1-pt(-3.914605,35,lower.tail = F))\n#&gt; [1] 0.0003993968\n\nlibrary(nlme)\n\nnlme1 &lt;- lme(Richness ~ 1 + NAP * Exposure,\n             random = ~ 1 + NAP | Beach ,\n             data = df_long,\n             control = lmeControl(opt = \"optim\", msMaxIter = 100, msMaxEval = 5000))\nsummary(nlme1)\n#&gt; Linear mixed-effects model fit by REML\n#&gt;   Data: df_long \n#&gt;        AIC      BIC    logLik\n#&gt;   227.2046 243.8402 -103.6023\n#&gt; \n#&gt; Random effects:\n#&gt;  Formula: ~1 + NAP | Beach\n#&gt;  Structure: General positive-definite, Log-Cholesky parametrization\n#&gt;             StdDev   Corr  \n#&gt; (Intercept) 1.939709 (Intr)\n#&gt; NAP         1.689580 -0.996\n#&gt; Residual    2.554676       \n#&gt; \n#&gt; Fixed effects:  Richness ~ 1 + NAP * Exposure \n#&gt;                    Value Std.Error DF   t-value p-value\n#&gt; (Intercept)    13.345694  2.278989 33  5.855970  0.0000\n#&gt; NAP            -4.175271  2.128084 33 -1.961986  0.0582\n#&gt; Exposure10     -5.323695  2.556406  6 -2.082492  0.0825\n#&gt; Exposure11     -9.765613  2.566035  6 -3.805720  0.0089\n#&gt; NAP:Exposure10  0.167146  2.366467 33  0.070631  0.9441\n#&gt; NAP:Exposure11  2.726865  2.375786 33  1.147774  0.2593\n#&gt;  Correlation: \n#&gt;                (Intr) NAP    Exps10 Exps11 NAP:E10\n#&gt; NAP            -0.767                             \n#&gt; Exposure10     -0.891  0.684                      \n#&gt; Exposure11     -0.888  0.682  0.792               \n#&gt; NAP:Exposure10  0.690 -0.899 -0.772 -0.613        \n#&gt; NAP:Exposure11  0.687 -0.896 -0.613 -0.777  0.806 \n#&gt; \n#&gt; Standardized Within-Group Residuals:\n#&gt;        Min         Q1        Med         Q3        Max \n#&gt; -1.9251786 -0.3608959 -0.1327685  0.0992999  2.8420571 \n#&gt; \n#&gt; Number of Observations: 45\n#&gt; Number of Groups: 9\n\n\n这个模型的公式可以分解为：\n\n固定效应部分：Richness 的预测由截距、NAP（数值变量）和 Exposure（分类变量，包含 Exposure10 和 Exposure11）及其交互项构成。\n随机效应部分：Beach 作为随机因子，包含随机截距和随机斜率（NAP）。\n\n\nCode# 标准化模型残差分布\nquantile(residuals(lme1,type=\"pearson\",scaled=T))\n#&gt;         0%        25%        50%        75%       100% \n#&gt; -1.9238372 -0.3606612 -0.1334336  0.0981939  2.8422803\n\n# 随机因子随机效应和显著性检验\nranef(lme1)\n#&gt; $Beach\n#&gt;     (Intercept)           NAP\n#&gt; 1 -4.274356e-02  3.713708e-02\n#&gt; 2 -2.709479e-14  2.354089e-14\n#&gt; 3  3.819348e-03 -3.318381e-03\n#&gt; 4 -2.741786e-01  2.382158e-01\n#&gt; 5  3.269522e+00 -2.840673e+00\n#&gt; 6  2.736093e-01 -2.377212e-01\n#&gt; 7 -3.250033e-03  2.823741e-03\n#&gt; 8 -2.148947e+00  1.867079e+00\n#&gt; 9 -1.077831e+00  9.364564e-01\n#&gt; \n#&gt; with conditional variances for \"Beach\"\nlmerTest::ranova(lme1)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nnpar\nlogLik\nAIC\nLRT\nDf\nPr(&gt;Chisq)\n\n\n\n\n10\n-103.5779\n227.1558\nNA\nNA\nNA\n\n\nNAP in (1 + NAP | Beach)\n8\n-105.6747\n227.3493\n4.193538\n2\n0.1228527\n\n\n\n\n\nCode\n# 查看固定效应和显著性检验\ncoef(lme1)\n#&gt; $Beach\n#&gt;   (Intercept)       NAP Exposure10 Exposure11 NAP:Exposure10 NAP:Exposure11\n#&gt; 1    13.30295 -4.138134  -5.327265  -9.766048      0.1646123       2.727307\n#&gt; 2    13.34569 -4.175271  -5.327265  -9.766048      0.1646123       2.727307\n#&gt; 3    13.34951 -4.178590  -5.327265  -9.766048      0.1646123       2.727307\n#&gt; 4    13.07152 -3.937055  -5.327265  -9.766048      0.1646123       2.727307\n#&gt; 5    16.61522 -7.015944  -5.327265  -9.766048      0.1646123       2.727307\n#&gt; 6    13.61930 -4.412992  -5.327265  -9.766048      0.1646123       2.727307\n#&gt; 7    13.34244 -4.172447  -5.327265  -9.766048      0.1646123       2.727307\n#&gt; 8    11.19675 -2.308192  -5.327265  -9.766048      0.1646123       2.727307\n#&gt; 9    12.26786 -3.238815  -5.327265  -9.766048      0.1646123       2.727307\n#&gt; \n#&gt; attr(,\"class\")\n#&gt; [1] \"coef.mer\"\nanova(lme1)\n\n\n\n\n\nnpar\nSum Sq\nMean Sq\nF value\n\n\n\nNAP\n1\n124.27890\n124.27890\n19.017821\n\n\nExposure\n2\n142.98343\n71.49172\n10.940045\n\n\nNAP:Exposure\n2\n22.30791\n11.15395\n1.706838\n\n\n\n\n\nCode\n#  查看 类和方法\nclass(lme1)\n#&gt; [1] \"lmerMod\"\n#&gt; attr(,\"package\")\n#&gt; [1] \"lme4\"\nmethods(class = \"lmerMod\")\n#&gt; [1] getL show\n#&gt; see '?methods' for accessing help and source code\n\n# confint(lme1,level = 0.95)",
    "crumbs": [
      "统计模型",
      "<span class='chapter-number'>18</span>  <span class='chapter-title'>线性混合效应</span>"
    ]
  },
  {
    "objectID": "LME.html#随机截距固定斜率",
    "href": "LME.html#随机截距固定斜率",
    "title": "\n18  线性混合效应\n",
    "section": "\n18.3 随机截距+固定斜率",
    "text": "18.3 随机截距+固定斜率\n\\[\n\\eta_{(nrow \\ \\times 1)}=\\mathbf{X_{nrow×1}}\\beta_{1\\times1} +Z_{nrow\\times n_{subjects}} \\mathbf{\\gamma}_{n_{subjects}\\times 1}+\\epsilon_i\n\\]\nZ有一倍于受试者数量的列，每个受试者的随机截距。\n\nCodelme2 &lt;- lmer(Richness ~ 1 + NAP+ (1 |Beach) ,data = df_long)\nsummary(lme2)\n#&gt; Linear mixed model fit by REML ['lmerMod']\n#&gt; Formula: Richness ~ 1 + NAP + (1 | Beach)\n#&gt;    Data: df_long\n#&gt; \n#&gt; REML criterion at convergence: 239.5\n#&gt; \n#&gt; Scaled residuals: \n#&gt;     Min      1Q  Median      3Q     Max \n#&gt; -1.4227 -0.4848 -0.1576  0.2519  3.9794 \n#&gt; \n#&gt; Random effects:\n#&gt;  Groups   Name        Variance Std.Dev.\n#&gt;  Beach    (Intercept) 8.668    2.944   \n#&gt;  Residual             9.362    3.060   \n#&gt; Number of obs: 45, groups:  Beach, 9\n#&gt; \n#&gt; Fixed effects:\n#&gt;             Estimate Std. Error t value\n#&gt; (Intercept)   6.5819     1.0958   6.007\n#&gt; NAP          -2.5684     0.4947  -5.192\n#&gt; \n#&gt; Correlation of Fixed Effects:\n#&gt;     (Intr)\n#&gt; NAP -0.157\nAIC(lme2)\n#&gt; [1] 247.4802\nBIC(lme2)\n#&gt; [1] 254.7069\nlogLik(lme2)\n#&gt; 'log Lik.' -119.7401 (df=4)\n\n2*(1-pt(6.007,35,lower.tail = T))\n#&gt; [1] 7.558855e-07\n\n\n\nnlme2 &lt;- lme(Richness ~ 1 + NAP * Exposure,random= ~ 1 |Beach ,data = df_long)\nsummary(nlme2)\n#&gt; Linear mixed-effects model fit by REML\n#&gt;   Data: df_long \n#&gt;        AIC      BIC    logLik\n#&gt;   227.3493 240.6578 -105.6747\n#&gt; \n#&gt; Random effects:\n#&gt;  Formula: ~1 | Beach\n#&gt;         (Intercept) Residual\n#&gt; StdDev:   0.5138683 2.971793\n#&gt; \n#&gt; Fixed effects:  Richness ~ 1 + NAP * Exposure \n#&gt;                    Value Std.Error DF   t-value p-value\n#&gt; (Intercept)    13.345694  1.483557 33  8.995739  0.0000\n#&gt; NAP            -4.175271  1.505110 33 -2.774063  0.0090\n#&gt; Exposure10     -5.544983  1.657659  6 -3.345069  0.0155\n#&gt; Exposure11     -9.730595  1.670518  6 -5.824898  0.0011\n#&gt; NAP:Exposure10  0.671731  1.643864 33  0.408629  0.6855\n#&gt; NAP:Exposure11  2.688806  1.656743 33  1.622947  0.1141\n#&gt;  Correlation: \n#&gt;                (Intr) NAP    Exps10 Exps11 NAP:E10\n#&gt; NAP            -0.278                             \n#&gt; Exposure10     -0.895  0.249                      \n#&gt; Exposure11     -0.888  0.247  0.795               \n#&gt; NAP:Exposure10  0.255 -0.916 -0.276 -0.226        \n#&gt; NAP:Exposure11  0.253 -0.908 -0.226 -0.296  0.832 \n#&gt; \n#&gt; Standardized Within-Group Residuals:\n#&gt;        Min         Q1        Med         Q3        Max \n#&gt; -1.5652904 -0.4386841 -0.1164805  0.1783113  4.1098230 \n#&gt; \n#&gt; Number of Observations: 45\n#&gt; Number of Groups: 9",
    "crumbs": [
      "统计模型",
      "<span class='chapter-number'>18</span>  <span class='chapter-title'>线性混合效应</span>"
    ]
  },
  {
    "objectID": "LME.html#固定截距随机斜率",
    "href": "LME.html#固定截距随机斜率",
    "title": "\n18  线性混合效应\n",
    "section": "\n18.4 固定截距+随机斜率",
    "text": "18.4 固定截距+随机斜率\n\\[\n\\eta_{(nrow \\times 1)} = \\mathbf{X}_{nrow \\times 1} \\beta_{1 \\times 1} + \\mathbf{Z}_{nrow \\times n_{subjects}} \\mathbf{\\gamma}_{n_{subjects} \\times 1} + \\epsilon_i\n\\]\nZ 有一倍于受试者数量的列，每个受试者的随机斜率。\n\nCodelme3 &lt;- lmer(Richness ~ 1 +  NAP+ (0 + NAP |Beach) ,data = df_long)\nsummary(lme3)\n#&gt; Linear mixed model fit by REML ['lmerMod']\n#&gt; Formula: Richness ~ 1 + NAP + (0 + NAP | Beach)\n#&gt;    Data: df_long\n#&gt; \n#&gt; REML criterion at convergence: 252.2\n#&gt; \n#&gt; Scaled residuals: \n#&gt;     Min      1Q  Median      3Q     Max \n#&gt; -1.2182 -0.6636 -0.1930  0.3253  3.3347 \n#&gt; \n#&gt; Random effects:\n#&gt;  Groups   Name Variance Std.Dev.\n#&gt;  Beach    NAP   0.00    0.00    \n#&gt;  Residual      17.31    4.16    \n#&gt; Number of obs: 45, groups:  Beach, 9\n#&gt; \n#&gt; Fixed effects:\n#&gt;             Estimate Std. Error t value\n#&gt; (Intercept)   6.6857     0.6578  10.164\n#&gt; NAP          -2.8669     0.6307  -4.545\n#&gt; \n#&gt; Correlation of Fixed Effects:\n#&gt;     (Intr)\n#&gt; NAP -0.333\n#&gt; optimizer (nloptwrap) convergence code: 0 (OK)\n#&gt; boundary (singular) fit: see help('isSingular')\n\nnlme3 &lt;- lme(Richness ~ 1 + NAP,random= ~ 0+NAP |Beach ,data = df_long)\nsummary(nlme3)\n#&gt; Linear mixed-effects model fit by REML\n#&gt;   Data: df_long \n#&gt;       AIC      BIC    logLik\n#&gt;   260.201 267.2458 -126.1005\n#&gt; \n#&gt; Random effects:\n#&gt;  Formula: ~0 + NAP | Beach\n#&gt;                  NAP Residual\n#&gt; StdDev: 0.0001127408 4.159929\n#&gt; \n#&gt; Fixed effects:  Richness ~ 1 + NAP \n#&gt;                 Value Std.Error DF   t-value p-value\n#&gt; (Intercept)  6.685662 0.6577579 35 10.164320   0e+00\n#&gt; NAP         -2.866853 0.6307186 35 -4.545376   1e-04\n#&gt;  Correlation: \n#&gt;     (Intr)\n#&gt; NAP -0.333\n#&gt; \n#&gt; Standardized Within-Group Residuals:\n#&gt;        Min         Q1        Med         Q3        Max \n#&gt; -1.2181663 -0.6636488 -0.1930031  0.3253447  3.3347473 \n#&gt; \n#&gt; Number of Observations: 45\n#&gt; Number of Groups: 9",
    "crumbs": [
      "统计模型",
      "<span class='chapter-number'>18</span>  <span class='chapter-title'>线性混合效应</span>"
    ]
  },
  {
    "objectID": "LME.html#随机效应模型",
    "href": "LME.html#随机效应模型",
    "title": "\n18  线性混合效应\n",
    "section": "\n18.5 随机效应模型",
    "text": "18.5 随机效应模型\n\nCode\nlme4 &lt;- lmer(Richness ~ 1 + (1|Beach) ,data = df_long)\nsummary(lme4)\n#&gt; Linear mixed model fit by REML ['lmerMod']\n#&gt; Formula: Richness ~ 1 + (1 | Beach)\n#&gt;    Data: df_long\n#&gt; \n#&gt; REML criterion at convergence: 261.1\n#&gt; \n#&gt; Scaled residuals: \n#&gt;     Min      1Q  Median      3Q     Max \n#&gt; -1.7797 -0.5070 -0.0980  0.2547  3.8063 \n#&gt; \n#&gt; Random effects:\n#&gt;  Groups   Name        Variance Std.Dev.\n#&gt;  Beach    (Intercept) 10.48    3.237   \n#&gt;  Residual             15.51    3.938   \n#&gt; Number of obs: 45, groups:  Beach, 9\n#&gt; \n#&gt; Fixed effects:\n#&gt;             Estimate Std. Error t value\n#&gt; (Intercept)    5.689      1.228   4.631\n\nnlme4 &lt;- lme(Richness ~ 1 ,random= ~ 1 |Beach ,data = df_long)\nsummary(nlme4)\n#&gt; Linear mixed-effects model fit by REML\n#&gt;   Data: df_long \n#&gt;        AIC      BIC    logLik\n#&gt;   267.1142 272.4668 -130.5571\n#&gt; \n#&gt; Random effects:\n#&gt;  Formula: ~1 | Beach\n#&gt;         (Intercept) Residual\n#&gt; StdDev:    3.237112 3.938415\n#&gt; \n#&gt; Fixed effects:  Richness ~ 1 \n#&gt;                Value Std.Error DF  t-value p-value\n#&gt; (Intercept) 5.688889  1.228419 36 4.631066       0\n#&gt; \n#&gt; Standardized Within-Group Residuals:\n#&gt;         Min          Q1         Med          Q3         Max \n#&gt; -1.77968689 -0.50704111 -0.09795286  0.25468670  3.80631705 \n#&gt; \n#&gt; Number of Observations: 45\n#&gt; Number of Groups: 9",
    "crumbs": [
      "统计模型",
      "<span class='chapter-number'>18</span>  <span class='chapter-title'>线性混合效应</span>"
    ]
  },
  {
    "objectID": "LME.html#线性模型固定截距-固定斜率",
    "href": "LME.html#线性模型固定截距-固定斜率",
    "title": "\n18  线性混合效应\n",
    "section": "\n18.6 线性模型：固定截距+ 固定斜率",
    "text": "18.6 线性模型：固定截距+ 固定斜率\n\nCodelm &lt;- lm(Richness ~ 1 + NAP ,data = df_long)\nlm\n#&gt; \n#&gt; Call:\n#&gt; lm(formula = Richness ~ 1 + NAP, data = df_long)\n#&gt; \n#&gt; Coefficients:\n#&gt; (Intercept)          NAP  \n#&gt;       6.686       -2.867",
    "crumbs": [
      "统计模型",
      "<span class='chapter-number'>18</span>  <span class='chapter-title'>线性混合效应</span>"
    ]
  },
  {
    "objectID": "LME.html#模型选择",
    "href": "LME.html#模型选择",
    "title": "\n18  线性混合效应\n",
    "section": "\n18.7 模型选择",
    "text": "18.7 模型选择\n\nCode\nplot_lme &lt;- function(model, title) {\n    ggplot(df_long, aes(NAP, Richness, group = Beach, color = Beach)) +\n        geom_point() +\n        geom_line(\n            data =  bind_cols(df_long, .pred = predict(model, df_long)),\n            mapping = aes(y = .pred),\n            linewidth = 1\n        ) +\n        labs(title = title)+\n        scale_x_continuous(expand = (mult=c(0,.1)))+\n        scale_y_continuous(expand = (mult=c(0,.1)))+\n    ggsci::scale_color_jco() +\n        ggpubr::theme_pubr() +\n        theme(legend.position = \"right\",\n              plot.title = element_text(hjust = .5))\n}\n\n\nlme_plot &lt;- map2(list(lme1,lme2,lme3,lm),list(\"随机截距+随机斜率\",\"随机截距+固定斜率\",\"固定截距+随机斜率\",\"固定截距+固定斜率\"),plot_lme)\n\n\nlme_plot\n#&gt; [[1]]\n\n\n\n\n\n\n#&gt; \n#&gt; [[2]]\n\n\n\n\n\n\n#&gt; \n#&gt; [[3]]\n\n\n\n\n\n\n#&gt; \n#&gt; [[4]]\n\n\n\n\n\n\n\n\nCodeanova(lme1,lme2,lme3)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nnpar\nAIC\nBIC\nlogLik\ndeviance\nChisq\nDf\nPr(&gt;Chisq)\n\n\n\nlme2\n4\n249.8291\n257.0557\n-120.9145\n241.8291\nNA\nNA\nNA\n\n\nlme3\n4\n261.9535\n269.1801\n-126.9767\n253.9535\n0.00000\n0\nNA\n\n\nlme1\n10\n238.1993\n256.2660\n-109.0997\n218.1993\n35.75415\n6\n3.1e-06\n\n\n\n\n\nCodeanova(lme1,lme2,lme3,lme4,lm)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nnpar\nAIC\nBIC\nlogLik\ndeviance\nChisq\nDf\nPr(&gt;Chisq)\n\n\n\nlme4\n3\n269.3035\n274.7235\n-131.6518\n263.3035\nNA\nNA\nNA\n\n\nlm\n3\n259.9535\n265.3735\n-126.9767\n253.9535\n9.350043\n0\nNA\n\n\nlme2\n4\n249.8291\n257.0557\n-120.9145\n241.8291\n12.124401\n1\n0.0004977\n\n\nlme3\n4\n261.9535\n269.1801\n-126.9767\n253.9535\n0.000000\n0\nNA\n\n\nlme1\n10\n238.1993\n256.2660\n-109.0997\n218.1993\n35.754147\n6\n0.0000031\n\n\n\n\n\nCode\n# p小于0.05,说明全模型与简化后模型存在差异，最终采用lme1,AIC最小",
    "crumbs": [
      "统计模型",
      "<span class='chapter-number'>18</span>  <span class='chapter-title'>线性混合效应</span>"
    ]
  },
  {
    "objectID": "GEE.html",
    "href": "GEE.html",
    "title": "\n19  广义估计方程\n",
    "section": "",
    "text": "19.1 数据集处理\n数据集 Analyzing ecological data\nCoderfb &lt;- read_delim(\"data/AED/RiceFieldBirds.txt\")\nrfb$richness &lt;- rowSums(rfb[, 8:56] &gt; 0)\nrfb |&gt; mutate(\n    FIELD = factor(FIELD),\n    SPTREAT = factor(SPTREAT),\n    log_AREA = log(rfb$AREA),\n    DEPTH2 = DEPTH ^ 2,\n    .after = 4\n) -&gt; rfb\n\n\nggplot(rfb, aes(Time, richness)) +\n    geom_point(pch = 21) +\n    geom_smooth(method = \"loess\", se = F) +\n    facet_wrap(vars(FIELD), labeller = \"label_both\")\nCodeowls &lt;- read_delim(\"data/AED/Owls.txt\")\n\nowls |&gt;\n    mutate(NCalls = SiblingNegotiation, log_broodsize = log(BroodSize), ) -&gt;\n    owls\nCodede &lt;- read_delim(\"data/AED/DeerEcervi.txt\")\n\nde |&gt;\n    mutate(\n        Ecervi_binary = if_else(Ecervi &gt; 0, 1, Ecervi),\n        Sex = factor(Sex),\n        Length_center = scale(Length, center = T , scale = F),\n    ) -&gt; de",
    "crumbs": [
      "统计模型",
      "<span class='chapter-number'>19</span>  <span class='chapter-title'>广义估计方程</span>"
    ]
  },
  {
    "objectID": "GEE.html#glm-连接函数",
    "href": "GEE.html#glm-连接函数",
    "title": "\n19  广义估计方程\n",
    "section": "\n19.2 GLM 连接函数",
    "text": "19.2 GLM 连接函数\nGLM的形式如下：\n\\[ g(\\mu_{ij})=\\beta_0+\\beta_1x_{ij_1}+\\beta_2x_{ij_2}+...+\\beta_px_{ij_p} \\]\n其中，g() 是一个连接函数，用于将自变量的线性组合与因变量的均值联系起来。常见的连接函数包括恒等连接函数（identity）、logistic连接函数（logit）、逆正弦连接函数（inverse sine）函数等。i 表示观测对象的索引，j 表示时间点或相关性结构的索引，uij 表示因变量的均值，β 表示待估计的系数，Xij 表示自变量。\n\\[\n\\eta = \\beta  \\mathbf{X}+ \\alpha\n\\]\n\\[\nE(y)=g^{-1}(\\eta)\n\\]\n对于计数数据：\n\\[\nE(y)=e^{\\eta}=e^{\\beta \\mathbf{X} +\\alpha}, 此时g(\\mu)=\\ln(\\mu)=\\mathbf{X}\\beta\n\\]\n\nCoderfb_glm &lt;- glm(richness ~ offset(log_AREA) +SPTREAT + DEPTH +DEPTH2,\n            family = quasipoisson(link = \"log\"),\n            data = rfb)\n\nowls_glm &lt;- glm(\n    NCalls ~ offset(log_broodsize) + SexParent * FoodTreatment + SexParent *\n        ArrivalTime,\n    family = poisson(link = \"log\"),\n    data = owls\n)\n\n\n对于二分类数据：\n\\[\nE(y)=\\frac{e^{\\beta \\mathbf{X} +\\alpha}}{1+e^{\\beta\\mathbf{X}+\\alpha}}, 此时g(\\mu)=\\ln(\\frac{\\mu}{1-\\mu})=logit(\\mu)\n\\]\n\nCodede_glm &lt;- glm(Ecervi_binary ~ Length_center *Sex,\n              family = binomial(link = \"logit\"),\n              data = de)\nsummary(de_glm)\n#&gt; \n#&gt; Call:\n#&gt; glm(formula = Ecervi_binary ~ Length_center * Sex, family = binomial(link = \"logit\"), \n#&gt;     data = de)\n#&gt; \n#&gt; Coefficients:\n#&gt;                    Estimate Std. Error z value Pr(&gt;|z|)    \n#&gt; (Intercept)        0.652409   0.109602   5.953 2.64e-09 ***\n#&gt; Length_center      0.025112   0.005576   4.504 6.68e-06 ***\n#&gt; Sex2               0.163873   0.174235   0.941   0.3469    \n#&gt; Length_center:Sex2 0.020109   0.009722   2.068   0.0386 *  \n#&gt; ---\n#&gt; Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n#&gt; \n#&gt; (Dispersion parameter for binomial family taken to be 1)\n#&gt; \n#&gt;     Null deviance: 1073.1  on 825  degrees of freedom\n#&gt; Residual deviance: 1003.7  on 822  degrees of freedom\n#&gt; AIC: 1011.7\n#&gt; \n#&gt; Number of Fisher Scoring iterations: 4",
    "crumbs": [
      "统计模型",
      "<span class='chapter-number'>19</span>  <span class='chapter-title'>广义估计方程</span>"
    ]
  },
  {
    "objectID": "GEE.html#方差",
    "href": "GEE.html#方差",
    "title": "\n19  广义估计方程\n",
    "section": "\n19.3 方差",
    "text": "19.3 方差\n\\[\nvar(Y_{is}|X_{is})=\\Phi × \\nu(\\mu_{is})\n\\]\n其中，Φ 是scale parameter （overdispersion），v() 是方差函数。",
    "crumbs": [
      "统计模型",
      "<span class='chapter-number'>19</span>  <span class='chapter-title'>广义估计方程</span>"
    ]
  },
  {
    "objectID": "GEE.html#相关性结构",
    "href": "GEE.html#相关性结构",
    "title": "\n19  广义估计方程\n",
    "section": "\n19.4 相关性结构",
    "text": "19.4 相关性结构\nR(α)\n\n非结构化相关：cor(Yis,Yit)=αst\n自回归相关：cor(Yis,Yit)=α|s-t|\nexchangeable 等相关：cor(Yis,Yit)=α\nindependence，独立，cor(Yis,Yit)=I",
    "crumbs": [
      "统计模型",
      "<span class='chapter-number'>19</span>  <span class='chapter-title'>广义估计方程</span>"
    ]
  },
  {
    "objectID": "GEE.html#gee",
    "href": "GEE.html#gee",
    "title": "\n19  广义估计方程\n",
    "section": "\n19.5 GEE",
    "text": "19.5 GEE\nGLM的期望和方差：\n\\[ E(Y_{ij})=b'(\\theta_{ij})\\\\ Var(Y_{ij})=b''(\\theta_{ij})\\ \\Phi \\]\n假定潜在的随机成分Vi ：\n\\[\nV_i=A_i^{1/2}R(\\alpha)A_i^{1/2}\\ \\Phi\n\\]\n其中，Ai =diag（b''(θi1)，...，b''(θij)） 。\nGEE的形式如下：\n\\[\nU(\\beta)=\\sum_{i=1}^{n} D'_iV_i^{-1}(y_i-\\mu_i)=0\n\\]\n其中，$U(β) $是一个包含待估计参数的函数，quasi-deviance \\(D'_i = \\left(\\frac{\\partial \\mu_i}{\\partial \\beta}\\right)'\\)，\\(V_i\\) 是方差-协方差矩阵，\\(R(\\alpha)\\) 是相关性结构矩阵，y 是观测数据，μ 是模型的均值预测值。采用迭代重复加权最小二乘法（iteratively reweighted least squares ，IWLS)），偏微分方程估计参数。",
    "crumbs": [
      "统计模型",
      "<span class='chapter-number'>19</span>  <span class='chapter-title'>广义估计方程</span>"
    ]
  },
  {
    "objectID": "GEE.html#gee-1",
    "href": "GEE.html#gee-1",
    "title": "\n19  广义估计方程\n",
    "section": "\n19.6 gee\n",
    "text": "19.6 gee\n\nhttps://www.statsmodels.org/stable//gee.html\n\nCodedata(epil,package = \"MASS\")\nOxboys |&gt; head(n=18)\n\n\n\n\nSubject\nage\nheight\nOccasion\n\n\n\n1\n-1.0000\n140.5\n1\n\n\n1\n-0.7479\n143.4\n2\n\n\n1\n-0.4630\n144.8\n3\n\n\n1\n-0.1643\n147.1\n4\n\n\n1\n-0.0027\n147.7\n5\n\n\n1\n0.2466\n150.2\n6\n\n\n1\n0.5562\n151.7\n7\n\n\n1\n0.7781\n153.3\n8\n\n\n1\n0.9945\n155.8\n9\n\n\n2\n-1.0000\n136.9\n1\n\n\n2\n-0.7479\n139.1\n2\n\n\n2\n-0.4630\n140.1\n3\n\n\n2\n-0.1643\n142.6\n4\n\n\n2\n-0.0027\n143.2\n5\n\n\n2\n0.2466\n144.0\n6\n\n\n2\n0.5562\n145.8\n7\n\n\n2\n0.7781\n146.8\n8\n\n\n2\n0.9945\n148.3\n9\n\n\n\n\n\nCode\n\ndf_long &lt;- Oxboys\n\n\n\nCodelibrary(gee)\n\ng1 &lt;- gee(height~age,data = df_long ,id = Subject,corstr = \"AR-M\",Mv = 1)\n#&gt; (Intercept)         age \n#&gt;  149.371801    6.521022\ng1\n#&gt; \n#&gt;  GEE:  GENERALIZED LINEAR MODELS FOR DEPENDENT DATA\n#&gt;  gee S-function, version 4.13 modified 98/01/27 (1998) \n#&gt; \n#&gt; Model:\n#&gt;  Link:                      Identity \n#&gt;  Variance to Mean Relation: Gaussian \n#&gt;  Correlation Structure:     AR-M , M = 1 \n#&gt; \n#&gt; Call:\n#&gt; gee(formula = height ~ age, id = Subject, data = df_long, corstr = \"AR-M\", \n#&gt;     Mv = 1)\n#&gt; \n#&gt; Number of observations :  234 \n#&gt; \n#&gt; Maximum cluster size   :  9 \n#&gt; \n#&gt; \n#&gt; Coefficients:\n#&gt; (Intercept)         age \n#&gt;  149.719096    6.547328 \n#&gt; \n#&gt; Estimated Scale Parameter:  65.41743\n#&gt; Number of Iterations:  2\n#&gt; \n#&gt; Working Correlation[1:4,1:4]\n#&gt;           [,1]      [,2]      [,3]      [,4]\n#&gt; [1,] 1.0000000 0.9892949 0.9787045 0.9682274\n#&gt; [2,] 0.9892949 1.0000000 0.9892949 0.9787045\n#&gt; [3,] 0.9787045 0.9892949 1.0000000 0.9892949\n#&gt; [4,] 0.9682274 0.9787045 0.9892949 1.0000000\n#&gt; \n#&gt; \n#&gt; Returned Error Value:\n#&gt; [1] 0\nsummary(g1)\n#&gt; \n#&gt;  GEE:  GENERALIZED LINEAR MODELS FOR DEPENDENT DATA\n#&gt;  gee S-function, version 4.13 modified 98/01/27 (1998) \n#&gt; \n#&gt; Model:\n#&gt;  Link:                      Identity \n#&gt;  Variance to Mean Relation: Gaussian \n#&gt;  Correlation Structure:     AR-M , M = 1 \n#&gt; \n#&gt; Call:\n#&gt; gee(formula = height ~ age, id = Subject, data = df_long, corstr = \"AR-M\", \n#&gt;     Mv = 1)\n#&gt; \n#&gt; Summary of Residuals:\n#&gt;         Min          1Q      Median          3Q         Max \n#&gt; -22.0304139  -5.4912438   0.1324571   4.3822174  18.5695861 \n#&gt; \n#&gt; \n#&gt; Coefficients:\n#&gt;               Estimate Naive S.E.  Naive z Robust S.E. Robust z\n#&gt; (Intercept) 149.719096  1.5531285 96.39840   1.5847569 94.47449\n#&gt; age           6.547328  0.3177873 20.60286   0.3042478 21.51972\n#&gt; \n#&gt; Estimated Scale Parameter:  65.41743\n#&gt; Number of Iterations:  2\n#&gt; \n#&gt; Working Correlation\n#&gt;            [,1]      [,2]      [,3]      [,4]      [,5]      [,6]      [,7]\n#&gt;  [1,] 1.0000000 0.9892949 0.9787045 0.9682274 0.9578625 0.9476085 0.9374643\n#&gt;  [2,] 0.9892949 1.0000000 0.9892949 0.9787045 0.9682274 0.9578625 0.9476085\n#&gt;  [3,] 0.9787045 0.9892949 1.0000000 0.9892949 0.9787045 0.9682274 0.9578625\n#&gt;  [4,] 0.9682274 0.9787045 0.9892949 1.0000000 0.9892949 0.9787045 0.9682274\n#&gt;  [5,] 0.9578625 0.9682274 0.9787045 0.9892949 1.0000000 0.9892949 0.9787045\n#&gt;  [6,] 0.9476085 0.9578625 0.9682274 0.9787045 0.9892949 1.0000000 0.9892949\n#&gt;  [7,] 0.9374643 0.9476085 0.9578625 0.9682274 0.9787045 0.9892949 1.0000000\n#&gt;  [8,] 0.9274287 0.9374643 0.9476085 0.9578625 0.9682274 0.9787045 0.9892949\n#&gt;  [9,] 0.9175005 0.9274287 0.9374643 0.9476085 0.9578625 0.9682274 0.9787045\n#&gt;            [,8]      [,9]\n#&gt;  [1,] 0.9274287 0.9175005\n#&gt;  [2,] 0.9374643 0.9274287\n#&gt;  [3,] 0.9476085 0.9374643\n#&gt;  [4,] 0.9578625 0.9476085\n#&gt;  [5,] 0.9682274 0.9578625\n#&gt;  [6,] 0.9787045 0.9682274\n#&gt;  [7,] 0.9892949 0.9787045\n#&gt;  [8,] 1.0000000 0.9892949\n#&gt;  [9,] 0.9892949 1.0000000\n\n\ngee1 &lt;- gee(y ~ age + trt + base,id=subject,data = epil,family = poisson,corstr =\"exchangeable\" )\n#&gt;  (Intercept)          age trtprogabide         base \n#&gt;   0.57304359   0.02234757  -0.15188049   0.02263524\nsummary(gee1)\n#&gt; \n#&gt;  GEE:  GENERALIZED LINEAR MODELS FOR DEPENDENT DATA\n#&gt;  gee S-function, version 4.13 modified 98/01/27 (1998) \n#&gt; \n#&gt; Model:\n#&gt;  Link:                      Logarithm \n#&gt;  Variance to Mean Relation: Poisson \n#&gt;  Correlation Structure:     Exchangeable \n#&gt; \n#&gt; Call:\n#&gt; gee(formula = y ~ age + trt + base, id = subject, data = epil, \n#&gt;     family = poisson, corstr = \"exchangeable\")\n#&gt; \n#&gt; Summary of Residuals:\n#&gt;        Min         1Q     Median         3Q        Max \n#&gt; -15.742906  -3.318756  -1.186874   1.295122  63.957902 \n#&gt; \n#&gt; \n#&gt; Coefficients:\n#&gt;                 Estimate  Naive S.E.   Naive z Robust S.E.   Robust z\n#&gt; (Intercept)   0.57304359 0.451797966  1.268362 0.360726141  1.5885835\n#&gt; age           0.02234757 0.013412798  1.666138 0.011400956  1.9601489\n#&gt; trtprogabide -0.15188049 0.159304397 -0.953398 0.171051111 -0.8879246\n#&gt; base          0.02263524 0.001696439 13.342795 0.001226748 18.4514092\n#&gt; \n#&gt; Estimated Scale Parameter:  5.087384\n#&gt; Number of Iterations:  1\n#&gt; \n#&gt; Working Correlation\n#&gt;           [,1]      [,2]      [,3]      [,4]\n#&gt; [1,] 1.0000000 0.3933815 0.3933815 0.3933815\n#&gt; [2,] 0.3933815 1.0000000 0.3933815 0.3933815\n#&gt; [3,] 0.3933815 0.3933815 1.0000000 0.3933815\n#&gt; [4,] 0.3933815 0.3933815 0.3933815 1.0000000",
    "crumbs": [
      "统计模型",
      "<span class='chapter-number'>19</span>  <span class='chapter-title'>广义估计方程</span>"
    ]
  },
  {
    "objectID": "GEE.html#geepack",
    "href": "GEE.html#geepack",
    "title": "\n19  广义估计方程\n",
    "section": "\n19.7 geepack\n",
    "text": "19.7 geepack\n\n\nCodelibrary(geepack)\n\nrfb_gee &lt;- geeglm(richness ~ offset(log_AREA) +SPTREAT + DEPTH +DEPTH2,\n            family = poisson(link = \"log\"),\n            data = rfb,\n            id=FIELD,\n            corstr = \"ar1\")\n\nsummary(rfb_gee)\n#&gt; \n#&gt; Call:\n#&gt; geeglm(formula = richness ~ offset(log_AREA) + SPTREAT + DEPTH + \n#&gt;     DEPTH2, family = poisson(link = \"log\"), data = rfb, id = FIELD, \n#&gt;     corstr = \"ar1\")\n#&gt; \n#&gt;  Coefficients:\n#&gt;                Estimate    Std.err  Wald Pr(&gt;|W|)   \n#&gt; (Intercept)  -0.6782034  0.2610088 6.752  0.00937 **\n#&gt; SPTREATrlfld -0.5223137  0.2287644 5.213  0.02242 * \n#&gt; DEPTH         0.0498238  0.0193149 6.654  0.00989 **\n#&gt; DEPTH2       -0.0011411  0.0004908 5.406  0.02007 * \n#&gt; ---\n#&gt; Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n#&gt; \n#&gt; Correlation structure = ar1 \n#&gt; Estimated Scale Parameters:\n#&gt; \n#&gt;             Estimate Std.err\n#&gt; (Intercept)    2.334  0.2927\n#&gt;   Link = identity \n#&gt; \n#&gt; Estimated Correlation Parameters:\n#&gt;       Estimate Std.err\n#&gt; alpha   0.4215 0.09034\n#&gt; Number of clusters:   11  Maximum cluster size: 10\nrfb_gee2 &lt;- geeglm(richness ~ offset(log_AREA) +SPTREAT ,\n            family = poisson(link = \"log\"),\n            data = rfb,\n            id=FIELD,\n            corstr = \"ar1\")\n\n# Wald's Test\nanova(rfb_gee,rfb_gee2)\n\n\n\n\nDf\nX2\nP(&gt;|Chi|)\n\n\n2\n6.885\n0.032\n\n\n\n\n\n\\[\nE(Y_{is})=\\mu_{is}=e^{-0.678+0.0498×DEPTH-0.001×DEPTH^2-0.522×SPTREAT_{is}}\\\\\nvar(Y_{is})= 2.33 × \\mu_{is} \\\\\ncor(Y_{is},Y_{it})=0.422^{|s-t|}\n\\]\n作业相关矩阵 corstr ，比较QIC，一般越小越好。\n\nCodeQIC(rfb_gee)\n#&gt;       QIC      QICu Quasi Lik       CIC    params      QICC \n#&gt;  -467.536  -471.921   239.961     6.193     4.000  -455.536\nQIC(rfb_gee2)\n#&gt;       QIC      QICu Quasi Lik       CIC    params      QICC \n#&gt;  -451.065  -457.436   230.718     5.185     2.000  -447.637\n\n\n\n19.7.1 示例\n\nCodedf &lt;- read_delim(\"data/麻醉诱导时相.txt\")\ndf_long &lt;- df |&gt; pivot_longer(\n    cols = starts_with(\"t\"),\n    names_to = \"time\",\n    values_to = \"SBP\"\n)\n\n\n\nCodeg3 &lt;- geeglm(SBP~ group * time,data = df_long ,id = id,corstr = \"ar1\")\n\ng3\n#&gt; \n#&gt; Call:\n#&gt; geeglm(formula = SBP ~ group * time, data = df_long, id = id, \n#&gt;     corstr = \"ar1\")\n#&gt; \n#&gt; Coefficients:\n#&gt;   (Intercept)        groupB        groupC        timet1        timet2 \n#&gt;         121.0           0.2           5.2          -8.6          -2.6 \n#&gt;        timet3        timet4 groupB:timet1 groupC:timet1 groupB:timet2 \n#&gt;           4.8          -0.2           7.2           5.4          -0.6 \n#&gt; groupC:timet2 groupB:timet3 groupC:timet3 groupB:timet4 groupC:timet4 \n#&gt;          -5.0           2.2          11.6          14.2           4.6 \n#&gt; \n#&gt; Degrees of Freedom: 75 Total (i.e. Null);  60 Residual\n#&gt; \n#&gt; Scale Link:                   identity\n#&gt; Estimated Scale Parameters:  [1] 16.13\n#&gt; \n#&gt; Correlation:  Structure = ar1    Link = identity \n#&gt; Estimated Correlation Parameters:\n#&gt;  alpha \n#&gt; 0.8464 \n#&gt; \n#&gt; Number of clusters:   15   Maximum cluster size: 5\nsummary(g3)\n#&gt; \n#&gt; Call:\n#&gt; geeglm(formula = SBP ~ group * time, data = df_long, id = id, \n#&gt;     corstr = \"ar1\")\n#&gt; \n#&gt;  Coefficients:\n#&gt;               Estimate Std.err    Wald Pr(&gt;|W|)    \n#&gt; (Intercept)    121.000   1.414 7320.50  &lt; 2e-16 ***\n#&gt; groupB           0.200   2.234    0.01  0.92867    \n#&gt; groupC           5.200   2.028    6.58  0.01034 *  \n#&gt; timet1          -8.600   0.921   87.22  &lt; 2e-16 ***\n#&gt; timet2          -2.600   1.315    3.91  0.04794 *  \n#&gt; timet3           4.800   1.180   16.55  4.7e-05 ***\n#&gt; timet4          -0.200   1.213    0.03  0.86907    \n#&gt; groupB:timet1    7.200   1.173   37.67  8.4e-10 ***\n#&gt; groupC:timet1    5.400   2.191    6.08  0.01371 *  \n#&gt; groupB:timet2   -0.600   1.470    0.17  0.68309    \n#&gt; groupC:timet2   -5.000   1.943    6.62  0.01008 *  \n#&gt; groupB:timet3    2.200   1.397    2.48  0.11534    \n#&gt; groupC:timet3   11.600   3.098   14.02  0.00018 ***\n#&gt; groupB:timet4   14.200   1.425   99.23  &lt; 2e-16 ***\n#&gt; groupC:timet4    4.600   2.498    3.39  0.06555 .  \n#&gt; ---\n#&gt; Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n#&gt; \n#&gt; Correlation structure = ar1 \n#&gt; Estimated Scale Parameters:\n#&gt; \n#&gt;             Estimate Std.err\n#&gt; (Intercept)     16.1    4.44\n#&gt;   Link = identity \n#&gt; \n#&gt; Estimated Correlation Parameters:\n#&gt;       Estimate Std.err\n#&gt; alpha    0.846  0.0661\n#&gt; Number of clusters:   15  Maximum cluster size: 5\nQIC(g3)\n#&gt;       QIC      QICu Quasi Lik       CIC    params      QICC \n#&gt;      1240      1240      -605        15        15       968",
    "crumbs": [
      "统计模型",
      "<span class='chapter-number'>19</span>  <span class='chapter-title'>广义估计方程</span>"
    ]
  },
  {
    "objectID": "SurvivalAnalysis.html",
    "href": "SurvivalAnalysis.html",
    "title": "\n20  生存分析\n",
    "section": "",
    "text": "20.1 生存函数\n\\[\nS(t)=P(T&gt;t)=1-F(t)=\\int_{t}^{+\\infty}f(x)dx\n\\]\n其中S(t)是累计生存概率或生存率，量化了生存时间大于t的概率。f(x)是密度函数，呈右偏态分布，反映了任意时间点 t 终点事件的瞬时发生率。F(t)=P(T&lt;t)是f(t)在区间[0,t]的累计形式，也称为分布函数或累积函数。",
    "crumbs": [
      "生存分析",
      "<span class='chapter-number'>20</span>  <span class='chapter-title'>生存分析</span>"
    ]
  },
  {
    "objectID": "SurvivalAnalysis.html#乘积极限法",
    "href": "SurvivalAnalysis.html#乘积极限法",
    "title": "\n20  生存分析\n",
    "section": "\n20.3 乘积极限法",
    "text": "20.3 乘积极限法\nproduct limit method 也称为Kaplan-Meier 法。\n\\(t_1&lt;t_2&lt;t_3&lt;...&lt;t_n\\)，样本量大小n，ti 代表个体i发生终点事件或右删失的时间。由于一些个体有相同的生存时间，它们被称为 tied 观测时间，生存时间的个数小于样本量n。\n\n20.3.1 点估计S(t)\n\\(n_1&gt;n_2&gt;n_3&gt;...&gt;n_n\\) ,ni d代表在时间点ti 暴露于特定事件风险的幸存者数量。\n\\(d_i\\) 代表在时间点ti 发生终点事件的数量。（如果没有 tie，di=1或0）\n生存率的KM估计计算公式：\n\\[\n\\hat S(t)=\\prod_{t_i\\le t}\\frac{n_i-d_i}{n_i}\n\\tag{20.1}\\]\nEquation 20.1 包括了删失情况，如果从ti-1 到ti 发生了删失，但没有终点事件，di =0，条件概率等于1。\n\n20.3.2 区间估计S(t)\n(1-α)×100% CI \\([\\hat S(t)-z_{1-\\alpha/2}\\sqrt{Var\\left [\\hat S(t)  \\right]},\\hat S(t)+z_{1-\\alpha/2}\\sqrt{Var\\left [\\hat S(t)  \\right]}]\\)\n其中\\(Var\\left [\\hat S(t)  \\right]=\\hat S(t)^2\\sum_{t_i\\le t}\\frac{d_i}{n_i(n_i-d_i)}\\) (Greenwood method )\n\nCodedf_raw &lt;- tibble(\n    id=1:5,\n    sex=factor(c(\"Male\",\"Male\",\"Female\",\"Male\",\"Female\")),\n    age_years=c(53,62,75,73,61),\n    outcome=c(\"Loss to follow-up\",\"Death\",\"Death\",\"Relapse\",\"Survival\"),\n    time=c(\"37.5+\",44.3,25.3,18.1,\"56.7+\")\n)\ndf &lt;- df_raw |&gt; arrange(time) |&gt; select(id,outcome,time) |&gt; \n    mutate(\n        d_i=if_else(outcome==\"Relapse\"|outcome==\"Death\",1,0),\n        time=parse_number(time),\n    )\ndf\n\n\n\n\nid\noutcome\ntime\nd_i\n\n\n\n4\nRelapse\n18.1\n1\n\n\n3\nDeath\n25.3\n1\n\n\n1\nLoss to follow-up\n37.5\n0\n\n\n2\nDeath\n44.3\n1\n\n\n5\nSurvival\n56.7\n0\n\n\n\n\n\nCode\nlibrary(survminer)\nlibrary(survival)\n\nkm_fit&lt;-survfit(Surv(time,d_i)~1,data=df)\n# t_i\nkm_fit$time\n#&gt; [1] 18.1 25.3 37.5 44.3 56.7\n# d_i\nkm_fit$n.event\n#&gt; [1] 1 1 0 1 0\n# cnesored\nkm_fit$n.censor\n#&gt; [1] 0 0 1 0 1\n# n_i\nkm_fit$n.risk\n#&gt; [1] 5 4 3 2 1\n\n# 生存率\nkm_fit$surv\n#&gt; [1] 0.8 0.6 0.6 0.3 0.3\n\nsummary(km_fit)\n#&gt; Call: survfit(formula = Surv(time, d_i) ~ 1, data = df)\n#&gt; \n#&gt;  time n.risk n.event survival std.err lower 95% CI upper 95% CI\n#&gt;  18.1      5       1      0.8   0.179       0.5161            1\n#&gt;  25.3      4       1      0.6   0.219       0.2933            1\n#&gt;  44.3      2       1      0.3   0.239       0.0631            1",
    "crumbs": [
      "生存分析",
      "<span class='chapter-number'>20</span>  <span class='chapter-title'>生存分析</span>"
    ]
  },
  {
    "objectID": "SurvivalAnalysis.html#单因素分组生存曲线的比较",
    "href": "SurvivalAnalysis.html#单因素分组生存曲线的比较",
    "title": "\n20  生存分析\n",
    "section": "\n20.4 单因素分组生存曲线的比较",
    "text": "20.4 单因素分组生存曲线的比较\n\n\n检验方法\n权重\n\n\n\nlog-rank test\n1\n\n\nWilcoxon test\nnj\n\n\n\nTarone-Ware test\n\\(\\sqrt{n_j}\\)\n\n\nPeto test\n\\(\\hat S(t_j)\\)\n\n\n\n\\[\n\\chi^2=\\frac{\\left(\\sum_jw(t_j)(m_{ij}-e_{ij})\\right)^2}{\\hat {Var}\\left(\\sum_jw(t_j)(m_{ij}-e_{ij})\\right)}\n\\]\n\n20.4.1 log-rank test\n\nH0 :两总体的生存曲线是相同的。\n\n计算当第j次发生终点事件各组终点事件的期望值（e1j ,e2j ）\n\\(e_{1j}=\\left ( \\frac{n_{1j}}{n_{1j}+n_{2j}}\\right)\\times (m_{1j}+m_{2j})\\)\n\\(e_{2j}=\\left ( \\frac{n_{2j}}{n_{1j}+n_{2j}}\\right)\\times (m_{1j}+m_{2j})\\)\n其中mij 表示在第 j 个时间点第 i 组终点事件的数量，nij 表示在第 j 个时间点第 i 组初始观测的数量\n\n\n对所有时间点对终点事件的观测值和期望值的差异求和\n\\(O_i-Ei=\\sum_j(m_{ij}-e_{ij})\\ \\ \\ (i=1,2)\\)\n计算其方差估计值\n\\(\\hat{Var}=\\sum_j\\frac{n_{1j}n_{2j}(m_{1j}+m_{2j})(n_{1j}+n_{2j}-m_{1j}-m_{2j})}{(n_{1j}+n_{2j})^2(n_{1j}+n_{2j}-1)}\\ \\ \\ (i=1,2)\\)\n\n\n计算log-rank test 的检验统计量\n\\[\n\\chi^2=\\frac{(O_1-E_1)^2}{\\hat{Var}(O_1-E_1)} \\ 或者 \\ \\chi^2=\\frac{(O_2-E_2)^2}{\\hat{Var}(O_2-E_2)}\n\\]\n也可以近似估计为\n\\[\n\\chi^2=\\sum_{i=1}^2\\frac{(O_i-E_i)^2}{E_i} \\sim \\chi^2(\\nu=1)\n\\]\n\n\n\nCodedf &lt;- read_csv(\"data/log-rank-survival.csv\")\n\n# 使用 Kaplan-Meier 方法创建一个Surv对象\nsurv_formula &lt;- Surv(Days,status)~treatment\n\nkm&lt;-survfit(surv_formula,data=df)\nsummary(km)\n#&gt; Call: survfit(formula = surv_formula, data = df)\n#&gt; \n#&gt;                 treatment=CON \n#&gt;  time n.risk n.event survival std.err lower 95% CI upper 95% CI\n#&gt;    11     14       1   0.9286  0.0688       0.8030        1.000\n#&gt;    13     13       1   0.8571  0.0935       0.6921        1.000\n#&gt;    14     12       2   0.7143  0.1207       0.5129        0.995\n#&gt;    15     10       1   0.6429  0.1281       0.4351        0.950\n#&gt;    17      9       3   0.4286  0.1323       0.2341        0.785\n#&gt;    20      6       2   0.2857  0.1207       0.1248        0.654\n#&gt;    21      4       2   0.1429  0.0935       0.0396        0.515\n#&gt;    25      2       1   0.0714  0.0688       0.0108        0.472\n#&gt;    27      1       1   0.0000     NaN           NA           NA\n#&gt; \n#&gt;                 treatment=DPVB \n#&gt;  time n.risk n.event survival std.err lower 95% CI upper 95% CI\n#&gt;    20     14       1    0.929  0.0688        0.803        1.000\n#&gt;    23     13       1    0.857  0.0935        0.692        1.000\n#&gt;    27     12       1    0.786  0.1097        0.598        1.000\n#&gt;    28     11       1    0.714  0.1207        0.513        0.995\n#&gt;    30     10       1    0.643  0.1281        0.435        0.950\n#&gt;    32      9       1    0.571  0.1323        0.363        0.899\n#&gt;    38      8       1    0.500  0.1336        0.296        0.844\n#&gt;    39      7       1    0.429  0.1323        0.234        0.785\n#&gt;    45      6       1    0.357  0.1281        0.177        0.721\n#&gt; \n#&gt;                 treatment=LDRT \n#&gt;  time n.risk n.event survival std.err lower 95% CI upper 95% CI\n#&gt;    13     14       2   0.8571  0.0935       0.6921        1.000\n#&gt;    15     12       1   0.7857  0.1097       0.5977        1.000\n#&gt;    16     11       1   0.7143  0.1207       0.5129        0.995\n#&gt;    18     10       1   0.6429  0.1281       0.4351        0.950\n#&gt;    19      9       2   0.5000  0.1336       0.2961        0.844\n#&gt;    20      7       3   0.2857  0.1207       0.1248        0.654\n#&gt;    24      4       1   0.2143  0.1097       0.0786        0.584\n#&gt;    25      3       1   0.1429  0.0935       0.0396        0.515\n#&gt;    27      2       1   0.0714  0.0688       0.0108        0.472\n#&gt;    30      1       1   0.0000     NaN           NA           NA\n#&gt; \n#&gt;                 treatment=LR_DPVB \n#&gt;  time n.risk n.event survival std.err lower 95% CI upper 95% CI\n#&gt;    30     14       1    0.929  0.0688        0.803            1\n#&gt;    40     13       1    0.857  0.0935        0.692            1\n\n# 执行Log-rank检验\nlogrank_test &lt;- survdiff(surv_formula,data = df,subset = T,na.action = \"na.omit\")\nlogrank_test$chisq\n#&gt; [1] 58.43627\nlogrank_test$pvalue\n#&gt; [1] 1.268397e-12",
    "crumbs": [
      "生存分析",
      "<span class='chapter-number'>20</span>  <span class='chapter-title'>生存分析</span>"
    ]
  },
  {
    "objectID": "SurvivalAnalysis.html#cox比例风险模型",
    "href": "SurvivalAnalysis.html#cox比例风险模型",
    "title": "\n20  生存分析\n",
    "section": "\n20.3 Cox比例风险模型",
    "text": "20.3 Cox比例风险模型\n对于有风险因子\\(x_1,x_2,...,x_k\\) 的个体在时间 t 的风险率\\(h(t|x_1,x_2,...,x_k)\\)\n\\[\nh(t|x_1,x_2,...,x_k)=h_0(t)g(x_1,x_2,...,x_k)=h_0(t)exp(\\sum_{j=1}^k\\beta_jx_j)\n\\]\n其中\n\nh0 (t) 是给定所有风险因子（协变量）为零的随时间变化的基线风险函数。\ng(X) 是k个独立风险因子的集合函数，代表变量的风险效应。\nβj 是部分回归系数，表示风险比的比例变化。\n\nCox比例风险模型是一种半参数方法\n比例风险假设（proportional hazards assumption）\n\\[\n\\frac{h(t)}{h_0(t)}=exp(\\sum_{j=1}^k\\beta_jx_j)\n\\]\n风险比（hazard ratio）\n假设有两个个体，分别具有独立变量，两个个体的风险函数之比称为风险比\n\\[\nHR=\\frac{h(t|x_1,x_2,...,x_k)}{h(t|x_1^*,x_2^*,...,x_k^*)}=exp(\\sum_{j=1}^k\\beta_j(x_j-x_j^*))\n\\]\n\nCode# 拟合Cox比例风险模型\ncox_model &lt;- coxph(surv_formula, data = df)\n\n# 查看模型结果\nsummary(cox_model)\n#&gt; Call:\n#&gt; coxph(formula = surv_formula, data = df)\n#&gt; \n#&gt;   n= 56, number of events= 39 \n#&gt; \n#&gt;                       coef exp(coef)  se(coef)      z Pr(&gt;|z|)    \n#&gt; treatmentDPVB    -2.740141  0.064561  0.580664 -4.719 2.37e-06 ***\n#&gt; treatmentLDRT    -0.383558  0.681432  0.387499 -0.990    0.322    \n#&gt; treatmentLR_DPVB -4.632850  0.009727  0.878661 -5.273 1.34e-07 ***\n#&gt; ---\n#&gt; Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n#&gt; \n#&gt;                  exp(coef) exp(-coef) lower .95 upper .95\n#&gt; treatmentDPVB     0.064561     15.489  0.020688   0.20148\n#&gt; treatmentLDRT     0.681432      1.467  0.318848   1.45634\n#&gt; treatmentLR_DPVB  0.009727    102.807  0.001738   0.05444\n#&gt; \n#&gt; Concordance= 0.822  (se = 0.025 )\n#&gt; Likelihood ratio test= 61.41  on 3 df,   p=3e-13\n#&gt; Wald test            = 36.01  on 3 df,   p=7e-08\n#&gt; Score (logrank) test = 60.47  on 3 df,   p=5e-13\n\n# 检查比例风险假设\ncox.zph(cox_model)\n#&gt;           chisq df    p\n#&gt; treatment 0.833  3 0.84\n#&gt; GLOBAL    0.833  3 0.84\n\n\n\n20.3.1 模型系数的估计\n条件死亡概率和局部似然函数方法\n\\[\n\\ln L_p(\\beta)=\\sum_{i=1}^{d}\\left[ \\sum_{j=1}^k\\beta_jx_{ij}-\\ln\\sum_{m\\in R_i}exp( \\sum_{j=1}^k\\beta_jx_{mj})         \\right]\n\\]\nNewton-Raphson iterative method\n\\[\n\\begin{cases}\n\\frac{\\partial \\ln L_p(\\beta)}{\\partial \\beta_1}=0\\\\\n\\frac{\\partial \\ln L_p(\\beta)}{\\partial \\beta_2}=0\\\\\n\\vdots\\\\\n\\frac{\\partial \\ln L_p(\\beta)}{\\partial \\beta_k}=0\\\\\n\\end{cases}\n\\]\n\n20.3.2 模型系数的假设检验\n\n\nWald‘s test\n检验是否有独立变量需要被消除，统计量\\(Z=b_j/S_{b_j}\\)\n当样本量足够大时，Z服从标准正态分布，Z2 服从自由度为1 的\\(\\chi^2\\) 分布\n\\[\n\\chi^2_W=(b_j/S_{b_j})^2\\sim \\chi^2(1)\n\\]\n\n\nPartial likelihood Ratio test\n主要用于非显著性变量的消除，新变量的引入和模型的比较。\n\\[\n\\chi^2_{LR}=2\\left[ \\ln L_p(\\beta_k)-\\ln L_p(\\beta_{k-1}) \\right]\\sim\\chi^2(1)\n\\]\n其中分别是包含 k 个和 k-1 个（不包含要检验的第 j 个变量）独立变量的对数局部似然函数",
    "crumbs": [
      "生存分析",
      "<span class='chapter-number'>20</span>  <span class='chapter-title'>生存分析</span>"
    ]
  },
  {
    "objectID": "PropensityScore.html",
    "href": "PropensityScore.html",
    "title": "\n21  倾向性评分\n",
    "section": "",
    "text": "21.1 分层（Stratification）",
    "crumbs": [
      "倾向性评分",
      "<span class='chapter-number'>21</span>  <span class='chapter-title'>倾向性评分</span>"
    ]
  },
  {
    "objectID": "PropensityScore.html#分层stratification",
    "href": "PropensityScore.html#分层stratification",
    "title": "\n21  倾向性评分\n",
    "section": "",
    "text": "21.1.1 估计倾向得分（逻辑回归）\n\nCodedata(lalonde, package = 'Matching')\n\n\nlalonde_formu &lt;- treat ~ age + I(age^2) + educ + I(educ^2) + black +\n    hisp + married + nodegr + re74  + I(re74^2) + re75 + I(re75^2) + u74 + u75\nlr_out &lt;- glm(formula = lalonde_formu,\n              data = lalonde,\n              family = binomial(link = 'logit'))\n\nsummary(lr_out)\n#&gt; \n#&gt; Call:\n#&gt; glm(formula = lalonde_formu, family = binomial(link = \"logit\"), \n#&gt;     data = lalonde)\n#&gt; \n#&gt; Coefficients:\n#&gt;               Estimate Std. Error z value Pr(&gt;|z|)  \n#&gt; (Intercept)  4.269e+00  2.173e+00   1.965   0.0494 *\n#&gt; age          2.143e-02  9.037e-02   0.237   0.8126  \n#&gt; I(age^2)    -3.448e-04  1.484e-03  -0.232   0.8163  \n#&gt; educ        -8.713e-01  4.150e-01  -2.099   0.0358 *\n#&gt; I(educ^2)    4.499e-02  2.330e-02   1.931   0.0535 .\n#&gt; black       -2.613e-01  3.708e-01  -0.705   0.4809  \n#&gt; hisp        -8.974e-01  5.184e-01  -1.731   0.0835 .\n#&gt; married      1.829e-01  2.831e-01   0.646   0.5183  \n#&gt; nodegr      -4.285e-01  3.930e-01  -1.090   0.2756  \n#&gt; re74        -2.168e-05  7.739e-05  -0.280   0.7793  \n#&gt; I(re74^2)   -8.553e-10  2.424e-09  -0.353   0.7242  \n#&gt; re75         6.577e-05  1.025e-04   0.642   0.5210  \n#&gt; I(re75^2)   -1.968e-09  5.042e-09  -0.390   0.6963  \n#&gt; u74         -8.315e-02  4.521e-01  -0.184   0.8541  \n#&gt; u75         -3.060e-01  3.591e-01  -0.852   0.3942  \n#&gt; ---\n#&gt; Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n#&gt; \n#&gt; (Dispersion parameter for binomial family taken to be 1)\n#&gt; \n#&gt;     Null deviance: 604.20  on 444  degrees of freedom\n#&gt; Residual deviance: 580.02  on 430  degrees of freedom\n#&gt; AIC: 610.02\n#&gt; \n#&gt; Number of Fisher Scoring iterations: 4\n\n\n倾向性得分就是模型的拟合值，查看得分的分布\n\nCodelalonde$lr_ps &lt;- fitted(lr_out)\n\nggplot(lalonde, aes(x = lr_ps, color = as.logical(treat))) + \n    geom_density() +\n    xlab('Propensity Score')\n\n\n\n\n\n\n\n\n21.1.1.1 分层\n使用五分位数进行分层\n\nCodebreaks5 &lt;- psa::get_strata_breaks(lalonde$lr_ps)\nbreaks5\n#&gt; $breaks\n#&gt;        0%       20%       40%       60%       80%      100% \n#&gt; 0.1127949 0.3299797 0.3502632 0.4295841 0.5060112 0.8175245 \n#&gt; \n#&gt; $labels\n#&gt;     strata      xmin      xmax      xmid\n#&gt; 0%       A 0.1127949 0.3299797 0.2213873\n#&gt; 20%      B 0.3299797 0.3502632 0.3401214\n#&gt; 40%      C 0.3502632 0.4295841 0.3899236\n#&gt; 60%      D 0.4295841 0.5060112 0.4677976\n#&gt; 80%      E 0.5060112 0.8175245 0.6617678\n\nlalonde$lr_strata5 &lt;- cut(x = lalonde$lr_ps, \n                          breaks = breaks5$breaks, \n                          include.lowest = TRUE, \n                          labels = breaks5$labels$strata)\ntable(lalonde$treat, lalonde$lr_strata5)\n#&gt;    \n#&gt;      A  B  C  D  E\n#&gt;   0 65 58 56 43 38\n#&gt;   1 25 30 33 46 51\n\n\n\nCodeggplot(lalonde, aes(x = lr_ps, color = as.logical(treat))) + \n    geom_density(aes(fill = as.logical(treat)), alpha = 0.2) +\n    geom_vline(xintercept = breaks5$breaks, alpha = 0.5) +\n    geom_text(data = breaks5$labels, \n              aes(x = xmid, y = 0, label = strata),\n              color = 'black', vjust = 1) +\n    xlab('Propensity Score') + ylab('Density') +\n    xlim(c(0, 1))\n\n\n\n\n\n\n\n\nCodeggplot() +\n    geom_vline(xintercept = breaks5$breaks) +\n    geom_point(data = lalonde, aes(x = lr_ps, y = log(re78 + 1), color = as.logical(treat)), alpha = 0.5) +\n    geom_text(data = breaks5$labels, aes(x = xmid, y = 0, label = strata), color = 'black', vjust = 1) +\n    xlab('Propensity Score')\n\n\n\n\n\n\n\n\n21.1.1.2 查看平衡混杂效应\n\nCodecovars &lt;- all.vars(lalonde_formu)\ncovars &lt;- lalonde[,covars[-1]]\nPSAgraphics::cv.bal.psa(covariates = covars, \n                        treatment = lalonde$treat,\n                        propensity = lalonde$lr_ps,\n                        strata = lalonde$lr_strata)\n\n\n\n\n\n\n\n数值变量的协变量平衡图\n\nCodePSAgraphics::box.psa(continuous = lalonde$age, \n                     treatment = lalonde$treat, \n                     strata = lalonde$lr_strata,\n                     xlab = \"Strata\", \n                     balance = FALSE,\n                     main = 'Covariate: age')\n\n\n\n\n\n\n\n分类变量的协变量平衡图\n\nCodePSAgraphics::cat.psa(categorical = lalonde$nodegr, \n                     treatment = lalonde$treat, \n                     strata = lalonde$lr_strata, \n                     xlab = 'Strata',\n                     balance = FALSE,\n                     main = 'Covariate: nodegr')\n\n\n\n\n\n\n#&gt; $`treatment:stratum.proportions`\n#&gt;   0:A 1:A 0:B 1:B   0:C  1:C   0:D  1:D   0:E   1:E\n#&gt; 0   0   0   0   0 0.036 0.03 0.302 0.37 0.737 0.706\n#&gt; 1   1   1   1   1 0.964 0.97 0.698 0.63 0.263 0.294\n\n\n21.1.2 估计因果效应\n个体处理效应：\n\\[\nITE=\\tau_i=y_i^1-y_i^0\n\\]\n因果推断的基本难题：Y=ZY1 +(1-Z)Y0 , Z=0 或 1，2个实际结果，2个反事实结果\n平均处理效应\n\\[\n\\widehat {ATE} =E(\\tau)=E(Y^1-Y^0)=E(Y^1)-E(Y^0)\n\\]\n实验组平均处理效应ATT\n对照组平均处理效应ATC\n\nCodePSAgraphics::loess.psa(response = log(lalonde$re78 + 1),\n                       treatment = lalonde$treat,\n                       propensity = lalonde$lr_ps)\n\n\n\n\n\n\n#&gt; $ATE\n#&gt; [1] 0.832516\n#&gt; \n#&gt; $se.wtd\n#&gt; [1] 0.3992742\n#&gt; \n#&gt; $CI95\n#&gt; [1] 0.03396767 1.63106435\n#&gt; \n#&gt; $summary.strata\n#&gt;    counts.0 counts.1  means.0  means.1  diff.means\n#&gt; 1        33       13 6.355024 6.090923 -0.26410149\n#&gt; 2        32       12 5.568504 5.490818 -0.07768589\n#&gt; 3        33       11 5.509654 5.537747  0.02809323\n#&gt; 4        25       19 5.449248 5.571249  0.12200105\n#&gt; 5        29       16 5.407022 5.912038  0.50501592\n#&gt; 6        27       17 5.280991 6.401716  1.12072425\n#&gt; 7        22       22 5.265440 6.791844  1.52640379\n#&gt; 8        21       24 5.241780 6.882596  1.64081539\n#&gt; 9        19       25 5.223695 7.051758  1.82806315\n#&gt; 10       19       26 5.660499 7.570755  1.91025558\n\npsa::loess_plot(ps = lalonde$lr_ps,\n                outcome = log(lalonde$re78 + 1),\n                treatment = lalonde$treat == 1,\n                responseTitle = 'log(re78)',\n                \n                plot.strata = 5,\n                points.treat.alpha = 0.5,\n                points.control.alpha = 0.5,\n                percentPoints.treat = 1,\n                percentPoints.control = 1,\n                se = FALSE, \n                method = 'loess')\n\n\n\n\n\n\n\n\nCodePSAgraphics::circ.psa(response = log(lalonde$re78 + 1), \n                      treatment = lalonde$treat == 1, \n                      strata = lalonde$lr_strata5)\n\n\n\n\n\n\n#&gt; $summary.strata\n#&gt;   n.FALSE n.TRUE means.FALSE means.TRUE\n#&gt; A      65     25    5.965231   5.813530\n#&gt; B      58     30    5.159507   5.017170\n#&gt; C      56     33    5.884181   7.170466\n#&gt; D      43     46    4.831869   6.300722\n#&gt; E      38     51    5.397140   7.479826\n#&gt; \n#&gt; $wtd.Mn.FALSE\n#&gt; [1] 5.449396\n#&gt; \n#&gt; $wtd.Mn.TRUE\n#&gt; [1] 6.358132\n#&gt; \n#&gt; $ATE\n#&gt; [1] 0.9087362\n#&gt; \n#&gt; $se.wtd\n#&gt; [1] 0.3965889\n#&gt; \n#&gt; $approx.t\n#&gt; [1] 2.291381\n#&gt; \n#&gt; $df\n#&gt; [1] 435\n#&gt; \n#&gt; $CI.95\n#&gt; [1] 0.1292676 1.6882048\n\n\n21.1.3 敏感性分析\n\n21.1.3.1 估计倾向得分（分类树）\n\nCodelibrary(tree)\ntree_out &lt;- tree::tree(lalonde_formu,\n                       data = lalonde)\nplot(tree_out); text(tree_out)\n\n\n\n\n\n\nCodelalonde$tree_ps &lt;- predict(tree_out)\ntable(lalonde$tree_ps, lalonde$treat, useNA = 'ifany')\n#&gt;                    \n#&gt;                       0   1\n#&gt;   0.332             167  83\n#&gt;   0.344827586206897  19  10\n#&gt;   0.351851851851852  35  19\n#&gt;   0.612903225806452  24  38\n#&gt;   0.659090909090909  15  29\n#&gt;   1                   0   6\nlalonde$tree_strata &lt;- predict(tree_out, type = 'where')\ntable(lalonde$tree_strata, lalonde$treat, useNA = 'ifany')\n#&gt;     \n#&gt;        0   1\n#&gt;   3  167  83\n#&gt;   5   15  29\n#&gt;   6   35  19\n#&gt;   9   24  38\n#&gt;   10  19  10\n#&gt;   11   0   6",
    "crumbs": [
      "倾向性评分",
      "<span class='chapter-number'>21</span>  <span class='chapter-title'>倾向性评分</span>"
    ]
  },
  {
    "objectID": "PropensityScore.html#匹配matching",
    "href": "PropensityScore.html#匹配matching",
    "title": "\n21  倾向性评分\n",
    "section": "\n21.2 匹配（Matching）",
    "text": "21.2 匹配（Matching）\n倾向评分匹配根据他们的倾向评分将治疗组中的每个人与对照组中的个体相匹配。对于每个人来说，倾向得分可以直观地视为从一系列协变量（和潜在混杂因素）计算出来的最近治疗的概率。两个人，一个来自治疗组，一个来自对照组，如果他们的倾向评分之间的差异很小，则被认为是匹配的。不匹配的参与者将被丢弃。\n\nCodelibrary(Matching)\n\n\n\nCodelalonde_match &lt;- Match(\n    Y = lalonde$re78,\n    Tr = lalonde$treat,\n    X = lalonde$lr_ps,\n    M = 1,\n    caliper = 0.1,\n    replace = TRUE,\n    estimand = 'ATE'\n)\n\nsummary(lalonde_match)\n#&gt; \n#&gt; Estimate...  2053.1 \n#&gt; AI SE......  803.05 \n#&gt; T-stat.....  2.5566 \n#&gt; p.val......  0.010569 \n#&gt; \n#&gt; Original number of observations..............  445 \n#&gt; Original number of treated obs...............  185 \n#&gt; Matched number of observations...............  433 \n#&gt; Matched number of observations  (unweighted).  744 \n#&gt; \n#&gt; Caliper (SDs)........................................   0.1 \n#&gt; Number of obs dropped by 'exact' or 'caliper'  12\n\nlalonde_match_df &lt;- data.frame(\n    treated.ps = lalonde[lalonde_match$index.treated, ]$lr_ps,\n    control.ps = lalonde[lalonde_match$index.control, ]$lr_ps,\n    treated.y = 1,\n    control.y = 0\n)\nlalonde_match_df &lt;- lalonde_match_df[order(lalonde_match_df$control.ps), ]\n\n\nrows &lt;- (1:nrow(lalonde_match_df) - 1) %% floor(nrow(lalonde_match_df) / 5) == 0\n\nggplot(lalonde, aes(x = lr_ps, y = treat)) +\n    geom_point(alpha = 0.5) +\n    geom_smooth(\n        method = glm,\n        formula = y ~ x,\n        method.args = list(family = binomial(link = 'logit')),\n        se = FALSE\n    ) +\n    xlim(c(0, 1)) +\n    xlab('Propensity Score') + ylab('Treatment') +\n    geom_segment(\n        data = lalonde_match_df,\n        aes(\n            x = treated.ps,\n            xend = control.ps,\n            y = treated.y,\n            yend = control.y\n        ),\n        color = 'purple',\n        alpha = 0.1\n    )\n\n\n\n\n\n\n\n匹配后，治疗组和对照组应具有非常相似的特征。可以使用简单的回归模型来估计治疗对结果的影响。\n\n21.2.1 一对一匹配ATT\n\nCoderr_att &lt;- Match(Y = lalonde$re78, \n                Tr = lalonde$treat, \n                X = lalonde$lr_ps,\n                M = 1,\n                estimand='ATT')\nsummary(rr_att) # The default estimate is ATT here\n#&gt; \n#&gt; Estimate...  2153.3 \n#&gt; AI SE......  825.4 \n#&gt; T-stat.....  2.6088 \n#&gt; p.val......  0.0090858 \n#&gt; \n#&gt; Original number of observations..............  445 \n#&gt; Original number of treated obs...............  185 \n#&gt; Matched number of observations...............  185 \n#&gt; Matched number of observations  (unweighted).  346\n\nrr_att_mb &lt;- psa::MatchBalance(\n    df = lalonde,\n    formu = lalonde_formu,\n    formu.Y = update.formula(lalonde_formu, re78 ~ .),\n    index.treated = rr_att$index.treated,\n    index.control = rr_att$index.control,\n    tolerance = 0.25,\n    M = 1,\n    estimand = 'ATT')\nplot(rr_att_mb)\n\n\n\n\n\n\nCodesummary(rr_att_mb)\n#&gt; Sample sizes and number of matches:\n#&gt;    Group   n n.matched n.percent.matched\n#&gt;  Treated 185       185         1.0000000\n#&gt;  Control 260       173         0.6653846\n#&gt;    Total 445       358         0.8044944\n#&gt; \n#&gt; Covariate importance and t-tests for matched pairs:\n#&gt;           Import.Treat Import.Y Import.Total std.estimate       t p.value\n#&gt; I(educ^2)        1.931   1.5228        3.453     -0.04903 -0.8916  0.3732\n#&gt; educ             2.099   1.2121        3.311     -0.05483 -0.9577  0.3389\n#&gt; black            0.705   1.8424        2.547     -0.02326 -0.5383  0.5907\n#&gt; I(re74^2)        0.353   1.6415        1.994      0.07581  2.0955  0.0369\n#&gt; u75              0.852   0.9435        1.796     -0.06655 -1.8144  0.0705\n#&gt; hisp             1.731   0.0404        1.771      0.02042  0.8161  0.4150\n#&gt; nodegr           1.090   0.5011        1.591      0.03496  1.0914  0.2759\n#&gt; re74             0.280   1.1019        1.382      0.07979  1.7483  0.0813\n#&gt; re75             0.642   0.5903        1.232      0.06147  1.3171  0.1887\n#&gt; age              0.237   0.6729        0.910      0.00896  0.1374  0.8908\n#&gt; married          0.646   0.1406        0.787      0.04627  1.0000  0.3180\n#&gt; I(re75^2)        0.390   0.3817        0.772      0.05125  1.0364  0.3007\n#&gt; I(age^2)         0.232   0.5096        0.742      0.00297  0.0438  0.9651\n#&gt; u74              0.184   0.0702        0.254      0.03913  0.7495  0.4541\n#&gt;             ci.min  ci.max PercentMatched\n#&gt; I(educ^2) -0.15719 0.05913           60.4\n#&gt; educ      -0.16744 0.05778           60.1\n#&gt; black     -0.10826 0.06173           91.0\n#&gt; I(re74^2)  0.00465 0.14696           86.7\n#&gt; u75       -0.13870 0.00559           89.3\n#&gt; hisp      -0.02879 0.06963           98.3\n#&gt; nodegr    -0.02804 0.09797           93.9\n#&gt; re74      -0.00998 0.16956           77.2\n#&gt; re75      -0.03032 0.15326           78.0\n#&gt; age       -0.11922 0.13713           44.8\n#&gt; married   -0.04474 0.13728           89.6\n#&gt; I(re75^2) -0.04602 0.14852           88.7\n#&gt; I(age^2)  -0.13062 0.13656           49.7\n#&gt; u74       -0.06356 0.14183           81.5\n\n\n\n21.2.2 一对一匹配ATE\n\nCoderr.ate &lt;- Match(Y = lalonde$re78, \n                Tr = lalonde$treat, \n                X = lalonde$lr_ps,\n                M = 1,\n                estimand = 'ATE')\nsummary(rr.ate)\n#&gt; \n#&gt; Estimate...  2013.3 \n#&gt; AI SE......  817.76 \n#&gt; T-stat.....  2.4619 \n#&gt; p.val......  0.013819 \n#&gt; \n#&gt; Original number of observations..............  445 \n#&gt; Original number of treated obs...............  185 \n#&gt; Matched number of observations...............  445 \n#&gt; Matched number of observations  (unweighted).  756\n\n\n\n21.2.3 一对多匹配 （ATT）\n\nCoderr2 &lt;- Match(Y = lalonde$re78,      \n             Tr = lalonde$treat, \n             X = lalonde$lr_ps,\n             M = 1, \n             ties = TRUE, \n             replace = TRUE,\n             estimand = 'ATT')\nsummary(rr2) # The default estimate is ATT here\n#&gt; \n#&gt; Estimate...  2153.3 \n#&gt; AI SE......  825.4 \n#&gt; T-stat.....  2.6088 \n#&gt; p.val......  0.0090858 \n#&gt; \n#&gt; Original number of observations..............  445 \n#&gt; Original number of treated obs...............  185 \n#&gt; Matched number of observations...............  185 \n#&gt; Matched number of observations  (unweighted).  346\n\n\n\n21.2.4 MachIt套件类型\n\nCodematchit.out &lt;- MatchIt::matchit(lalonde_formu, data = lalonde)\nsummary(matchit.out)\n#&gt; \n#&gt; Call:\n#&gt; MatchIt::matchit(formula = lalonde_formu, data = lalonde)\n#&gt; \n#&gt; Summary of Balance for All Data:\n#&gt;           Means Treated Means Control Std. Mean Diff. Var. Ratio eCDF Mean\n#&gt; distance         0.4468        0.3936          0.4533     1.2101    0.1340\n#&gt; age             25.8162       25.0538          0.1066     1.0278    0.0254\n#&gt; I(age^2)       717.3946      677.3154          0.0929     1.0115    0.0254\n#&gt; educ            10.3459       10.0885          0.1281     1.5513    0.0287\n#&gt; I(educ^2)      111.0595      104.3731          0.1701     1.6625    0.0287\n#&gt; black            0.8432        0.8269          0.0449          .    0.0163\n#&gt; hisp             0.0595        0.1077         -0.2040          .    0.0482\n#&gt; married          0.1892        0.1538          0.0902          .    0.0353\n#&gt; nodegr           0.7081        0.8346         -0.2783          .    0.1265\n#&gt; re74          2095.5740     2107.0268         -0.0023     0.7381    0.0192\n#&gt; I(re74^2) 28141433.9907 36667413.1577         -0.0747     0.5038    0.0192\n#&gt; re75          1532.0556     1266.9092          0.0824     1.0763    0.0508\n#&gt; I(re75^2) 12654752.6909 11196530.0057          0.0260     1.4609    0.0508\n#&gt; u74              0.7081        0.7500         -0.0921          .    0.0419\n#&gt; u75              0.6000        0.6846         -0.1727          .    0.0846\n#&gt;           eCDF Max\n#&gt; distance    0.2244\n#&gt; age         0.0652\n#&gt; I(age^2)    0.0652\n#&gt; educ        0.1265\n#&gt; I(educ^2)   0.1265\n#&gt; black       0.0163\n#&gt; hisp        0.0482\n#&gt; married     0.0353\n#&gt; nodegr      0.1265\n#&gt; re74        0.0471\n#&gt; I(re74^2)   0.0471\n#&gt; re75        0.1075\n#&gt; I(re75^2)   0.1075\n#&gt; u74         0.0419\n#&gt; u75         0.0846\n#&gt; \n#&gt; Summary of Balance for Matched Data:\n#&gt;           Means Treated Means Control Std. Mean Diff. Var. Ratio eCDF Mean\n#&gt; distance         0.4468        0.4284          0.1571     1.3077    0.0387\n#&gt; age             25.8162       25.1351          0.0952     1.1734    0.0243\n#&gt; I(age^2)       717.3946      675.1676          0.0979     1.1512    0.0243\n#&gt; educ            10.3459       10.2649          0.0403     1.2869    0.0174\n#&gt; I(educ^2)      111.0595      108.4919          0.0653     1.3938    0.0174\n#&gt; black            0.8432        0.8486         -0.0149          .    0.0054\n#&gt; hisp             0.0595        0.0703         -0.0457          .    0.0108\n#&gt; married          0.1892        0.1892          0.0000          .    0.0000\n#&gt; nodegr           0.7081        0.7676         -0.1308          .    0.0595\n#&gt; re74          2095.5740     1741.2109          0.0725     1.5797    0.0146\n#&gt; I(re74^2) 28141433.9907 18066538.6428          0.0883     3.5436    0.0146\n#&gt; re75          1532.0556     1314.8073          0.0675     1.3933    0.0264\n#&gt; I(re75^2) 12654752.6909  9126579.7979          0.0630     3.4873    0.0264\n#&gt; u74              0.7081        0.7243         -0.0357          .    0.0162\n#&gt; u75              0.6000        0.6108         -0.0221          .    0.0108\n#&gt;           eCDF Max Std. Pair Dist.\n#&gt; distance    0.1189          0.1585\n#&gt; age         0.0541          0.8159\n#&gt; I(age^2)    0.0541          0.7701\n#&gt; educ        0.0595          0.7662\n#&gt; I(educ^2)   0.0595          0.7604\n#&gt; black       0.0054          0.5798\n#&gt; hisp        0.0108          0.2286\n#&gt; married     0.0000          0.2378\n#&gt; nodegr      0.0595          0.5588\n#&gt; re74        0.0432          0.6080\n#&gt; I(re74^2)   0.0432          0.3620\n#&gt; re75        0.0649          0.7292\n#&gt; I(re75^2)   0.0649          0.3690\n#&gt; u74         0.0162          0.7728\n#&gt; u75         0.0108          0.7282\n#&gt; \n#&gt; Sample Sizes:\n#&gt;           Control Treated\n#&gt; All           260     185\n#&gt; Matched       185     185\n#&gt; Unmatched      75       0\n#&gt; Discarded       0       0\n\n\n\nCode# Same as above but calculate average treatment effect\nrr.ate &lt;- Match(Y = lalonde$re78, \n                Tr = lalonde$treat, \n                X = lalonde$lr_ps,\n                M = 1,\n                ties = FALSE, \n                replace = FALSE, \n                estimand='ATE')\nsummary(rr.ate) # Here the estimate is ATE\n#&gt; \n#&gt; Estimate...  2053.1 \n#&gt; SE.........  496.05 \n#&gt; T-stat.....  4.1389 \n#&gt; p.val......  3.4902e-05 \n#&gt; \n#&gt; Original number of observations..............  445 \n#&gt; Original number of treated obs...............  185 \n#&gt; Matched number of observations...............  370 \n#&gt; Matched number of observations  (unweighted).  370\n\n\n\nCode## Genetic Matching\nrr.gen &lt;- GenMatch(Tr = lalonde$treat, \n                   X = lalonde$lr_ps, \n                   BalanceMatrix = lalonde[,all.vars(lalonde_formu)[-1]],\n                   estimand = 'ATE', \n                   M = 1, \n                   pop.size = 16,\n                   print.level = 0)\nrr.gen.mout &lt;- Match(Y = lalonde$re78, \n                     Tr = lalonde$treat, \n                     X = lalonde$lr_ps,\n                     estimand = 'ATE',\n                     Weight.matrix = rr.gen)\nsummary(rr.gen.mout)\n#&gt; \n#&gt; Estimate...  2158.2 \n#&gt; AI SE......  814.93 \n#&gt; T-stat.....  2.6483 \n#&gt; p.val......  0.0080897 \n#&gt; \n#&gt; Original number of observations..............  445 \n#&gt; Original number of treated obs...............  185 \n#&gt; Matched number of observations...............  445 \n#&gt; Matched number of observations  (unweighted).  651\n\n\n\nCode## Partial exact matching\nrr2 &lt;- Matchby(Y = lalonde$re78, \n               Tr = lalonde$treat, \n               X = lalonde$lr_ps, \n               by = factor(lalonde$nodegr),\n               print.level = 0)\nsummary(rr2)\n#&gt; \n#&gt; Estimate...  2252.2 \n#&gt; SE.........  675.04 \n#&gt; T-stat.....  3.3363 \n#&gt; p.val......  0.00084896 \n#&gt; \n#&gt; Original number of observations..............  445 \n#&gt; Original number of treated obs...............  185 \n#&gt; Matched number of observations...............  185 \n#&gt; Matched number of observations  (unweighted).  185\n\n\n\nCode## Partial exact matching on two covariates\nrr3 &lt;- Matchby(Y = lalonde$re78, \n               Tr = lalonde$treat, \n               X = lalonde$lr_ps, \n               by = lalonde[,c('nodegr','married')],\n               print.level = 0)\nsummary(rr3)\n#&gt; \n#&gt; Estimate...  1668.8 \n#&gt; SE.........  715.87 \n#&gt; T-stat.....  2.3311 \n#&gt; p.val......  0.019747 \n#&gt; \n#&gt; Original number of observations..............  445 \n#&gt; Original number of treated obs...............  185 \n#&gt; Matched number of observations...............  185 \n#&gt; Matched number of observations  (unweighted).  185",
    "crumbs": [
      "倾向性评分",
      "<span class='chapter-number'>21</span>  <span class='chapter-title'>倾向性评分</span>"
    ]
  },
  {
    "objectID": "PropensityScore.html#倾向值匹配法的概述与应用-r实现",
    "href": "PropensityScore.html#倾向值匹配法的概述与应用-r实现",
    "title": "\n21  倾向性评分\n",
    "section": "\n21.3 倾向值匹配法的概述与应用 R实现",
    "text": "21.3 倾向值匹配法的概述与应用 R实现\n\nCodelibrary(Matching)\ndata(lalonde, package = 'Matching')\n\n\n\n\n变量名\n描述\n\n\n\nage\n年龄\n\n\neduc\n受教育年限\n\n\nblack\n分类变量，1为黑人\n\n\nhisp\n分类变量，1为西班牙裔\n\n\nmarried\n分类变量，1为已婚\n\n\nnodegr\n分类变量，1为有高中学历证书\n\n\nre74\n1974年的收入\n\n\nre75\n1975年的收入\n\n\nre78\n1978年的收入\n\n\nu74\n分类变量，1为1974年收入为零\n\n\nu75\n分类变量，1为1975年收入为零\n\n\ntreat\n分类变量，1为实验组\n\n\n\n\n21.3.1 估计倾向值分数\n\nCodeattach(lalonde)\nglm_ps &lt;- glm(\n    formula = treat ~ age + educ + black + hisp + married + nodegr + re74  + re75,\n    family = binomial(link = 'logit')\n)\n\npsm1 &lt;- Match(Y=re78,\n             Tr = treat,\n             X=glm_ps$fitted.values,\n             estimand = \"ATT\",\n             M=1,\n             replace = TRUE)\nsummary(psm1)\n#&gt; \n#&gt; Estimate...  2624.3 \n#&gt; AI SE......  802.19 \n#&gt; T-stat.....  3.2714 \n#&gt; p.val......  0.0010702 \n#&gt; \n#&gt; Original number of observations..............  445 \n#&gt; Original number of treated obs...............  185 \n#&gt; Matched number of observations...............  185 \n#&gt; Matched number of observations  (unweighted).  344\n\n\n如上所示，使用1对1样本可替代匹配法，实验组平均效应为2624.3，因果效应的标准误为803.19，t值为3.2714，p值为0.0010702&lt;0.05，表明估计的实验组平均处理效应有统计学差异。\n\nCodepsm2 &lt;- Match(Y=re78,\n             Tr = treat,\n             X=glm_ps$fitted.values,\n             estimand = \"ATT\",\n             M=1,\n             replace = FALSE)\nsummary(psm2)\n#&gt; \n#&gt; Estimate...  1912.9 \n#&gt; SE.........  644.47 \n#&gt; T-stat.....  2.9682 \n#&gt; p.val......  0.0029958 \n#&gt; \n#&gt; Original number of observations..............  445 \n#&gt; Original number of treated obs...............  185 \n#&gt; Matched number of observations...............  185 \n#&gt; Matched number of observations  (unweighted).  185\n\n\n\n21.3.2 检验\n受试者个体同质性，是否随机分配\n协变量分布是否平衡，是否重合：\n以age 为例，实验组匹配前25.816匹配后25.816，对照组匹配前25.054匹配后25.692 ，匹配后实验组与对照组更接近了；T-test p-value &gt; 0.05 ，表示匹配前后age 均值无统计学差异；KS Bootstrap p-value &gt; 0.05 ，表示匹配前后age 分布无统计学差异\n***** (V1) age *****                Before Matching          After Matching mean   treatment........          25.816             25.816  \nmean control..........     25.054            25.692 \nstd mean diff.........     10.655            1.7342 \n\nmean raw eQQ diff.....    0.94054           0.73837  \nmed  raw eQQ diff.....          1                 0  \nmax  raw eQQ diff.....          7                 9   \n\nmean eCDF diff........   0.025364          0.021893  \nmed  eCDF diff........   0.022193          0.020349  \nmax  eCDF diff........   0.065177          0.061047   \n\nvar ratio (Tr/Co).....     1.0278             1.083  \nT-test p-value........    0.26594           0.84975  \nKS Bootstrap p-value..      0.526             0.355  \nKS Naive p-value......     0.7481           0.54314  \nKS Statistic..........   0.065177          0.061047 \n\nCodecheck_balance &lt;- MatchBalance(\n    formul = treat ~ age + educ + black + hisp + married + nodegr + re74  + re75,\n    match.out = psm1,\n    nboots = 1000,data = lalonde\n)\n#&gt; \n#&gt; ***** (V1) age *****\n#&gt;                        Before Matching        After Matching\n#&gt; mean treatment........     25.816             25.816 \n#&gt; mean control..........     25.054             25.692 \n#&gt; std mean diff.........     10.655             1.7342 \n#&gt; \n#&gt; mean raw eQQ diff.....    0.94054            0.73837 \n#&gt; med  raw eQQ diff.....          1                  0 \n#&gt; max  raw eQQ diff.....          7                  9 \n#&gt; \n#&gt; mean eCDF diff........   0.025364           0.021893 \n#&gt; med  eCDF diff........   0.022193           0.020349 \n#&gt; max  eCDF diff........   0.065177           0.061047 \n#&gt; \n#&gt; var ratio (Tr/Co).....     1.0278              1.083 \n#&gt; T-test p-value........    0.26594            0.84975 \n#&gt; KS Bootstrap p-value..      0.528              0.354 \n#&gt; KS Naive p-value......     0.7481            0.54314 \n#&gt; KS Statistic..........   0.065177           0.061047 \n#&gt; \n#&gt; \n#&gt; ***** (V2) educ *****\n#&gt;                        Before Matching        After Matching\n#&gt; mean treatment........     10.346             10.346 \n#&gt; mean control..........     10.088             10.146 \n#&gt; std mean diff.........     12.806             9.9664 \n#&gt; \n#&gt; mean raw eQQ diff.....    0.40541            0.23256 \n#&gt; med  raw eQQ diff.....          0                  0 \n#&gt; max  raw eQQ diff.....          2                  2 \n#&gt; \n#&gt; mean eCDF diff........   0.028698           0.016611 \n#&gt; med  eCDF diff........   0.012682           0.010174 \n#&gt; max  eCDF diff........    0.12651           0.061047 \n#&gt; \n#&gt; var ratio (Tr/Co).....     1.5513             1.2344 \n#&gt; T-test p-value........    0.15017             0.1842 \n#&gt; KS Bootstrap p-value..      0.006              0.223 \n#&gt; KS Naive p-value......   0.062873            0.54314 \n#&gt; KS Statistic..........    0.12651           0.061047 \n#&gt; \n#&gt; \n#&gt; ***** (V3) black *****\n#&gt;                        Before Matching        After Matching\n#&gt; mean treatment........    0.84324            0.84324 \n#&gt; mean control..........    0.82692            0.86847 \n#&gt; std mean diff.........     4.4767            -6.9194 \n#&gt; \n#&gt; mean raw eQQ diff.....   0.016216           0.026163 \n#&gt; med  raw eQQ diff.....          0                  0 \n#&gt; max  raw eQQ diff.....          1                  1 \n#&gt; \n#&gt; mean eCDF diff........  0.0081601           0.013081 \n#&gt; med  eCDF diff........  0.0081601           0.013081 \n#&gt; max  eCDF diff........    0.01632           0.026163 \n#&gt; \n#&gt; var ratio (Tr/Co).....    0.92503             1.1572 \n#&gt; T-test p-value........    0.64736            0.40214 \n#&gt; \n#&gt; \n#&gt; ***** (V4) hisp *****\n#&gt;                        Before Matching        After Matching\n#&gt; mean treatment........   0.059459           0.059459 \n#&gt; mean control..........    0.10769            0.04955 \n#&gt; std mean diff.........    -20.341             4.1792 \n#&gt; \n#&gt; mean raw eQQ diff.....   0.048649           0.011628 \n#&gt; med  raw eQQ diff.....          0                  0 \n#&gt; max  raw eQQ diff.....          1                  1 \n#&gt; \n#&gt; mean eCDF diff........   0.024116           0.005814 \n#&gt; med  eCDF diff........   0.024116           0.005814 \n#&gt; max  eCDF diff........   0.048233           0.011628 \n#&gt; \n#&gt; var ratio (Tr/Co).....    0.58288             1.1875 \n#&gt; T-test p-value........   0.064043            0.46063 \n#&gt; \n#&gt; \n#&gt; ***** (V5) married *****\n#&gt;                        Before Matching        After Matching\n#&gt; mean treatment........    0.18919            0.18919 \n#&gt; mean control..........    0.15385            0.18423 \n#&gt; std mean diff.........     8.9995             1.2617 \n#&gt; \n#&gt; mean raw eQQ diff.....   0.037838           0.026163 \n#&gt; med  raw eQQ diff.....          0                  0 \n#&gt; max  raw eQQ diff.....          1                  1 \n#&gt; \n#&gt; mean eCDF diff........   0.017672           0.013081 \n#&gt; med  eCDF diff........   0.017672           0.013081 \n#&gt; max  eCDF diff........   0.035343           0.026163 \n#&gt; \n#&gt; var ratio (Tr/Co).....     1.1802             1.0207 \n#&gt; T-test p-value........    0.33425            0.89497 \n#&gt; \n#&gt; \n#&gt; ***** (V6) nodegr *****\n#&gt;                        Before Matching        After Matching\n#&gt; mean treatment........    0.70811            0.70811 \n#&gt; mean control..........    0.83462            0.76757 \n#&gt; std mean diff.........    -27.751            -13.043 \n#&gt; \n#&gt; mean raw eQQ diff.....    0.12432           0.043605 \n#&gt; med  raw eQQ diff.....          0                  0 \n#&gt; max  raw eQQ diff.....          1                  1 \n#&gt; \n#&gt; mean eCDF diff........   0.063254           0.021802 \n#&gt; med  eCDF diff........   0.063254           0.021802 \n#&gt; max  eCDF diff........    0.12651           0.043605 \n#&gt; \n#&gt; var ratio (Tr/Co).....     1.4998             1.1585 \n#&gt; T-test p-value........  0.0020368          0.0071385 \n#&gt; \n#&gt; \n#&gt; ***** (V7) re74 *****\n#&gt;                        Before Matching        After Matching\n#&gt; mean treatment........     2095.6             2095.6 \n#&gt; mean control..........       2107             2193.3 \n#&gt; std mean diff.........   -0.23437            -2.0004 \n#&gt; \n#&gt; mean raw eQQ diff.....     487.98             869.16 \n#&gt; med  raw eQQ diff.....          0                  0 \n#&gt; max  raw eQQ diff.....       8413              10305 \n#&gt; \n#&gt; mean eCDF diff........   0.019223           0.054701 \n#&gt; med  eCDF diff........     0.0158           0.050872 \n#&gt; max  eCDF diff........   0.047089            0.12209 \n#&gt; \n#&gt; var ratio (Tr/Co).....     0.7381            0.75054 \n#&gt; T-test p-value........    0.98186            0.84996 \n#&gt; KS Bootstrap p-value..      0.547              0.001 \n#&gt; KS Naive p-value......    0.97023           0.011858 \n#&gt; KS Statistic..........   0.047089            0.12209 \n#&gt; \n#&gt; \n#&gt; ***** (V8) re75 *****\n#&gt;                        Before Matching        After Matching\n#&gt; mean treatment........     1532.1             1532.1 \n#&gt; mean control..........     1266.9             2179.9 \n#&gt; std mean diff.........     8.2363            -20.125 \n#&gt; \n#&gt; mean raw eQQ diff.....     367.61             590.34 \n#&gt; med  raw eQQ diff.....          0                  0 \n#&gt; max  raw eQQ diff.....     2110.2             8092.9 \n#&gt; \n#&gt; mean eCDF diff........   0.050834           0.050338 \n#&gt; med  eCDF diff........   0.061954           0.049419 \n#&gt; max  eCDF diff........    0.10748           0.098837 \n#&gt; \n#&gt; var ratio (Tr/Co).....     1.0763            0.56563 \n#&gt; T-test p-value........    0.38527           0.079002 \n#&gt; KS Bootstrap p-value..      0.031              0.012 \n#&gt; KS Naive p-value......    0.16449           0.069435 \n#&gt; KS Statistic..........    0.10748           0.098837 \n#&gt; \n#&gt; \n#&gt; Before Matching Minimum p.value: 0.0020368 \n#&gt; Variable Name(s): nodegr  Number(s): 6 \n#&gt; \n#&gt; After Matching Minimum p.value: 0.001 \n#&gt; Variable Name(s): re74  Number(s): 7\n\n\n\nCode# age 变平衡了\nqqplot(lalonde$age[psm1$index.control],lalonde$age[psm1$index.treated])\nabline(a=0,b=1)\n\n\n\n\n\n\nCode\n# re74 更不平衡了\nqqplot(lalonde$re74[psm1$index.control],lalonde$re74[psm1$index.treated])\nabline(a=0,b=1)\n\n\n\n\n\n\n\n\nCode# # The covariates we want to match on\nx &lt;- cbind(age , educ , black , hisp , married , nodegr , re74  , re75)\n\n# The covariates we want to obtain balance on\nBalanceMatrix = x\nset.seed(100)\n\n\n\n# Genetic Matching 自动适配平衡\ngen_match &lt;- GenMatch(Tr=treat,\n                      X=glm_ps$fitted.values,\n                      BalanceMatrix = x,\n                      estimand = \"ATT\")\n#&gt; \n#&gt; \n#&gt; Thu Jul  4 18:04:49 2024\n#&gt; Domains:\n#&gt;  0.000000e+00   &lt;=  X1   &lt;=    1.000000e+03 \n#&gt; \n#&gt; Data Type: Floating Point\n#&gt; Operators (code number, name, population) \n#&gt;  (1) Cloning...........................  15\n#&gt;  (2) Uniform Mutation..................  12\n#&gt;  (3) Boundary Mutation.................  12\n#&gt;  (4) Non-Uniform Mutation..............  12\n#&gt;  (5) Polytope Crossover................  12\n#&gt;  (6) Simple Crossover..................  12\n#&gt;  (7) Whole Non-Uniform Mutation........  12\n#&gt;  (8) Heuristic Crossover...............  12\n#&gt;  (9) Local-Minimum Crossover...........  0\n#&gt; \n#&gt; SOFT Maximum Number of Generations: 100\n#&gt; Maximum Nonchanging Generations: 4\n#&gt; Population size       : 100\n#&gt; Convergence Tolerance: 1.000000e-03\n#&gt; \n#&gt; Not Using the BFGS Derivative Based Optimizer on the Best Individual Each Generation.\n#&gt; Not Checking Gradients before Stopping.\n#&gt; Using Out of Bounds Individuals.\n#&gt; \n#&gt; Maximization Problem.\n#&gt; GENERATION: 0 (initializing the population)\n#&gt; Lexical Fit..... 1.180299e-02  1.180299e-02  1.155612e-01  1.186261e-01  1.822343e-01  3.842491e-01  3.842491e-01  4.144313e-01  4.144313e-01  4.610718e-01  5.977650e-01  7.731052e-01  7.731052e-01  8.523060e-01  9.184104e-01  9.749549e-01  \n#&gt; #unique......... 100, #Total UniqueCount: 100\n#&gt; var 1:\n#&gt; best............ 3.729259e+01\n#&gt; mean............ 4.810920e+02\n#&gt; variance........ 7.636997e+04\n#&gt; \n#&gt; GENERATION: 1\n#&gt; Lexical Fit..... 1.180299e-02  1.180299e-02  1.155612e-01  1.186261e-01  1.822343e-01  3.842491e-01  3.842491e-01  4.144313e-01  4.144313e-01  4.610718e-01  5.977650e-01  7.731052e-01  7.731052e-01  8.523060e-01  9.184104e-01  9.749549e-01  \n#&gt; #unique......... 61, #Total UniqueCount: 161\n#&gt; var 1:\n#&gt; best............ 3.729259e+01\n#&gt; mean............ 2.015230e+02\n#&gt; variance........ 6.039634e+04\n#&gt; \n#&gt; GENERATION: 2\n#&gt; Lexical Fit..... 1.180299e-02  1.180299e-02  1.155612e-01  1.186261e-01  1.822343e-01  3.842491e-01  3.842491e-01  4.144313e-01  4.144313e-01  4.610718e-01  5.977650e-01  7.731052e-01  7.731052e-01  8.523060e-01  9.184104e-01  9.749549e-01  \n#&gt; #unique......... 56, #Total UniqueCount: 217\n#&gt; var 1:\n#&gt; best............ 3.729259e+01\n#&gt; mean............ 9.873041e+01\n#&gt; variance........ 3.291501e+04\n#&gt; \n#&gt; GENERATION: 3\n#&gt; Lexical Fit..... 1.180299e-02  1.180299e-02  1.155612e-01  1.186261e-01  1.822343e-01  3.842491e-01  3.842491e-01  4.144313e-01  4.144313e-01  4.610718e-01  5.977650e-01  7.731052e-01  7.731052e-01  8.523060e-01  9.184104e-01  9.749549e-01  \n#&gt; #unique......... 56, #Total UniqueCount: 273\n#&gt; var 1:\n#&gt; best............ 3.729259e+01\n#&gt; mean............ 1.042351e+02\n#&gt; variance........ 2.899583e+04\n#&gt; \n#&gt; GENERATION: 4\n#&gt; Lexical Fit..... 1.180299e-02  1.180299e-02  1.155612e-01  1.186261e-01  1.822343e-01  3.842491e-01  3.842491e-01  4.144313e-01  4.144313e-01  4.610718e-01  5.977650e-01  7.731052e-01  7.731052e-01  8.523060e-01  9.184104e-01  9.749549e-01  \n#&gt; #unique......... 58, #Total UniqueCount: 331\n#&gt; var 1:\n#&gt; best............ 3.729259e+01\n#&gt; mean............ 1.050645e+02\n#&gt; variance........ 2.721152e+04\n#&gt; \n#&gt; GENERATION: 5\n#&gt; Lexical Fit..... 1.541148e-02  2.397991e-02  2.418950e-02  2.418950e-02  1.729273e-01  1.956942e-01  3.942807e-01  3.942807e-01  6.059370e-01  6.059370e-01  6.074259e-01  6.137460e-01  8.414918e-01  8.538318e-01  9.621995e-01  9.621995e-01  \n#&gt; #unique......... 58, #Total UniqueCount: 389\n#&gt; var 1:\n#&gt; best............ 2.941808e-01\n#&gt; mean............ 8.418536e+01\n#&gt; variance........ 1.578216e+04\n#&gt; \n#&gt; GENERATION: 6\n#&gt; Lexical Fit..... 4.145421e-02  4.145421e-02  4.499068e-02  4.499068e-02  1.608408e-01  1.806532e-01  2.764640e-01  4.729068e-01  4.729068e-01  6.940013e-01  6.940013e-01  7.762162e-01  8.635587e-01  8.667712e-01  8.667712e-01  9.507460e-01  \n#&gt; #unique......... 62, #Total UniqueCount: 451\n#&gt; var 1:\n#&gt; best............ 7.310932e-02\n#&gt; mean............ 9.403781e+01\n#&gt; variance........ 2.447312e+04\n#&gt; \n#&gt; GENERATION: 7\n#&gt; Lexical Fit..... 4.177047e-02  4.177047e-02  4.419097e-02  6.248288e-02  1.198352e-01  2.880778e-01  3.513309e-01  4.150287e-01  4.150287e-01  8.316757e-01  8.316757e-01  8.667712e-01  8.667712e-01  8.836843e-01  8.920699e-01  8.920699e-01  \n#&gt; #unique......... 61, #Total UniqueCount: 512\n#&gt; var 1:\n#&gt; best............ 8.760968e-02\n#&gt; mean............ 1.016562e+02\n#&gt; variance........ 4.437002e+04\n#&gt; \n#&gt; GENERATION: 8\n#&gt; Lexical Fit..... 4.177047e-02  4.177047e-02  4.559074e-02  6.427954e-02  1.215371e-01  2.846955e-01  3.519026e-01  4.150287e-01  4.150287e-01  8.316757e-01  8.316757e-01  8.667712e-01  8.667712e-01  8.794500e-01  8.948772e-01  8.948772e-01  \n#&gt; #unique......... 60, #Total UniqueCount: 572\n#&gt; var 1:\n#&gt; best............ 8.627748e-02\n#&gt; mean............ 7.473970e+01\n#&gt; variance........ 2.676016e+04\n#&gt; \n#&gt; GENERATION: 9\n#&gt; Lexical Fit..... 4.177047e-02  4.177047e-02  4.559074e-02  6.427954e-02  1.215371e-01  2.846955e-01  3.519026e-01  4.150287e-01  4.150287e-01  8.316757e-01  8.316757e-01  8.667712e-01  8.667712e-01  8.794500e-01  8.948772e-01  8.948772e-01  \n#&gt; #unique......... 55, #Total UniqueCount: 627\n#&gt; var 1:\n#&gt; best............ 8.627748e-02\n#&gt; mean............ 4.192386e+01\n#&gt; variance........ 1.737331e+04\n#&gt; \n#&gt; GENERATION: 10\n#&gt; Lexical Fit..... 4.177047e-02  4.177047e-02  4.559074e-02  6.427954e-02  1.215371e-01  2.846955e-01  3.519026e-01  4.150287e-01  4.150287e-01  8.316757e-01  8.316757e-01  8.667712e-01  8.667712e-01  8.794500e-01  8.948772e-01  8.948772e-01  \n#&gt; #unique......... 51, #Total UniqueCount: 678\n#&gt; var 1:\n#&gt; best............ 8.627748e-02\n#&gt; mean............ 6.242257e+01\n#&gt; variance........ 2.722981e+04\n#&gt; \n#&gt; GENERATION: 11\n#&gt; Lexical Fit..... 4.177047e-02  4.177047e-02  4.559074e-02  6.427954e-02  1.215371e-01  2.846955e-01  3.519026e-01  4.150287e-01  4.150287e-01  8.316757e-01  8.316757e-01  8.667712e-01  8.667712e-01  8.794500e-01  8.948772e-01  8.948772e-01  \n#&gt; #unique......... 49, #Total UniqueCount: 727\n#&gt; var 1:\n#&gt; best............ 8.627748e-02\n#&gt; mean............ 5.280735e+01\n#&gt; variance........ 1.784927e+04\n#&gt; \n#&gt; GENERATION: 12\n#&gt; Lexical Fit..... 4.177047e-02  4.177047e-02  4.559074e-02  6.427954e-02  1.215371e-01  2.846955e-01  3.519026e-01  4.150287e-01  4.150287e-01  8.316757e-01  8.316757e-01  8.667712e-01  8.667712e-01  8.794500e-01  8.948772e-01  8.948772e-01  \n#&gt; #unique......... 50, #Total UniqueCount: 777\n#&gt; var 1:\n#&gt; best............ 8.627748e-02\n#&gt; mean............ 5.682777e+01\n#&gt; variance........ 2.131922e+04\n#&gt; \n#&gt; GENERATION: 13\n#&gt; Lexical Fit..... 4.177047e-02  4.177047e-02  4.559074e-02  6.427954e-02  1.215371e-01  2.846955e-01  3.519026e-01  4.150287e-01  4.150287e-01  8.316757e-01  8.316757e-01  8.667712e-01  8.667712e-01  8.794500e-01  8.948772e-01  8.948772e-01  \n#&gt; #unique......... 53, #Total UniqueCount: 830\n#&gt; var 1:\n#&gt; best............ 8.627748e-02\n#&gt; mean............ 3.877940e+01\n#&gt; variance........ 1.599211e+04\n#&gt; \n#&gt; 'wait.generations' limit reached.\n#&gt; No significant improvement in 4 generations.\n#&gt; \n#&gt; Solution Lexical Fitness Value:\n#&gt; 4.177047e-02  4.177047e-02  4.559074e-02  6.427954e-02  1.215371e-01  2.846955e-01  3.519026e-01  4.150287e-01  4.150287e-01  8.316757e-01  8.316757e-01  8.667712e-01  8.667712e-01  8.794500e-01  8.948772e-01  8.948772e-01  \n#&gt; \n#&gt; Parameters at the Solution:\n#&gt; \n#&gt;  X[ 1] : 8.627748e-02\n#&gt; \n#&gt; Solution Found Generation 8\n#&gt; Number of Generations Run 13\n#&gt; \n#&gt; Thu Jul  4 18:04:55 2024\n#&gt; Total run time : 0 hours 0 minutes and 6 seconds\n\nPSM &lt;-  Match(Y=re78,\n             Tr = treat,\n             X=glm_ps$fitted.values,\n             estimand = \"ATT\",\n             Weight.matrix = gen_match,\n             replace = TRUE,)\nsummary(PSM)\n#&gt; \n#&gt; Estimate...  2439.3 \n#&gt; AI SE......  813.4 \n#&gt; T-stat.....  2.9989 \n#&gt; p.val......  0.0027099 \n#&gt; \n#&gt; Original number of observations..............  445 \n#&gt; Original number of treated obs...............  185 \n#&gt; Matched number of observations...............  185 \n#&gt; Matched number of observations  (unweighted).  489\n\ncheck_balance2 &lt;- MatchBalance(\n    formul = treat ~ age + educ + black + hisp + married + nodegr + re74  + re75,\n    match.out = PSM,\n    nboots = 1000,data = lalonde\n)\n#&gt; \n#&gt; ***** (V1) age *****\n#&gt;                        Before Matching        After Matching\n#&gt; mean treatment........     25.816             25.816 \n#&gt; mean control..........     25.054             25.217 \n#&gt; std mean diff.........     10.655             8.3769 \n#&gt; \n#&gt; mean raw eQQ diff.....    0.94054            0.46217 \n#&gt; med  raw eQQ diff.....          1                  0 \n#&gt; max  raw eQQ diff.....          7                  9 \n#&gt; \n#&gt; mean eCDF diff........   0.025364           0.012952 \n#&gt; med  eCDF diff........   0.022193           0.010225 \n#&gt; max  eCDF diff........   0.065177            0.03681 \n#&gt; \n#&gt; var ratio (Tr/Co).....     1.0278             1.2224 \n#&gt; T-test p-value........    0.26594             0.3519 \n#&gt; KS Bootstrap p-value..      0.503              0.734 \n#&gt; KS Naive p-value......     0.7481            0.89488 \n#&gt; KS Statistic..........   0.065177            0.03681 \n#&gt; \n#&gt; \n#&gt; ***** (V2) educ *****\n#&gt;                        Before Matching        After Matching\n#&gt; mean treatment........     10.346             10.346 \n#&gt; mean control..........     10.088             10.188 \n#&gt; std mean diff.........     12.806             7.8605 \n#&gt; \n#&gt; mean raw eQQ diff.....    0.40541            0.17587 \n#&gt; med  raw eQQ diff.....          0                  0 \n#&gt; max  raw eQQ diff.....          2                  2 \n#&gt; \n#&gt; mean eCDF diff........   0.028698           0.012562 \n#&gt; med  eCDF diff........   0.012682           0.010225 \n#&gt; max  eCDF diff........    0.12651            0.03681 \n#&gt; \n#&gt; var ratio (Tr/Co).....     1.5513             1.2791 \n#&gt; T-test p-value........    0.15017             0.2847 \n#&gt; KS Bootstrap p-value..      0.011              0.456 \n#&gt; KS Naive p-value......   0.062873            0.89488 \n#&gt; KS Statistic..........    0.12651            0.03681 \n#&gt; \n#&gt; \n#&gt; ***** (V3) black *****\n#&gt;                        Before Matching        After Matching\n#&gt; mean treatment........    0.84324            0.84324 \n#&gt; mean control..........    0.82692              0.868 \n#&gt; std mean diff.........     4.4767            -6.7917 \n#&gt; \n#&gt; mean raw eQQ diff.....   0.016216           0.034765 \n#&gt; med  raw eQQ diff.....          0                  0 \n#&gt; max  raw eQQ diff.....          1                  1 \n#&gt; \n#&gt; mean eCDF diff........  0.0081601           0.017382 \n#&gt; med  eCDF diff........  0.0081601           0.017382 \n#&gt; max  eCDF diff........    0.01632           0.034765 \n#&gt; \n#&gt; var ratio (Tr/Co).....    0.92503             1.1537 \n#&gt; T-test p-value........    0.64736            0.41503 \n#&gt; \n#&gt; \n#&gt; ***** (V4) hisp *****\n#&gt;                        Before Matching        After Matching\n#&gt; mean treatment........   0.059459           0.059459 \n#&gt; mean control..........    0.10769           0.057132 \n#&gt; std mean diff.........    -20.341            0.98148 \n#&gt; \n#&gt; mean raw eQQ diff.....   0.048649            0.00818 \n#&gt; med  raw eQQ diff.....          0                  0 \n#&gt; max  raw eQQ diff.....          1                  1 \n#&gt; \n#&gt; mean eCDF diff........   0.024116            0.00409 \n#&gt; med  eCDF diff........   0.024116            0.00409 \n#&gt; max  eCDF diff........   0.048233            0.00818 \n#&gt; \n#&gt; var ratio (Tr/Co).....    0.58288             1.0382 \n#&gt; T-test p-value........   0.064043            0.86677 \n#&gt; \n#&gt; \n#&gt; ***** (V5) married *****\n#&gt;                        Before Matching        After Matching\n#&gt; mean treatment........    0.18919            0.18919 \n#&gt; mean control..........    0.15385            0.18101 \n#&gt; std mean diff.........     8.9995             2.0837 \n#&gt; \n#&gt; mean raw eQQ diff.....   0.037838           0.018405 \n#&gt; med  raw eQQ diff.....          0                  0 \n#&gt; max  raw eQQ diff.....          1                  1 \n#&gt; \n#&gt; mean eCDF diff........   0.017672          0.0092025 \n#&gt; med  eCDF diff........   0.017672          0.0092025 \n#&gt; max  eCDF diff........   0.035343           0.018405 \n#&gt; \n#&gt; var ratio (Tr/Co).....     1.1802             1.0348 \n#&gt; T-test p-value........    0.33425            0.83168 \n#&gt; \n#&gt; \n#&gt; ***** (V6) nodegr *****\n#&gt;                        Before Matching        After Matching\n#&gt; mean treatment........    0.70811            0.70811 \n#&gt; mean control..........    0.83462            0.75333 \n#&gt; std mean diff.........    -27.751            -9.9207 \n#&gt; \n#&gt; mean raw eQQ diff.....    0.12432           0.034765 \n#&gt; med  raw eQQ diff.....          0                  0 \n#&gt; max  raw eQQ diff.....          1                  1 \n#&gt; \n#&gt; mean eCDF diff........   0.063254           0.017382 \n#&gt; med  eCDF diff........   0.063254           0.017382 \n#&gt; max  eCDF diff........    0.12651           0.034765 \n#&gt; \n#&gt; var ratio (Tr/Co).....     1.4998             1.1123 \n#&gt; T-test p-value........  0.0020368            0.04177 \n#&gt; \n#&gt; \n#&gt; ***** (V7) re74 *****\n#&gt;                        Before Matching        After Matching\n#&gt; mean treatment........     2095.6             2095.6 \n#&gt; mean control..........       2107             2018.1 \n#&gt; std mean diff.........   -0.23437             1.5857 \n#&gt; \n#&gt; mean raw eQQ diff.....     487.98             648.91 \n#&gt; med  raw eQQ diff.....          0                  0 \n#&gt; max  raw eQQ diff.....       8413              10305 \n#&gt; \n#&gt; mean eCDF diff........   0.019223           0.037077 \n#&gt; med  eCDF diff........     0.0158           0.033742 \n#&gt; max  eCDF diff........   0.047089           0.087935 \n#&gt; \n#&gt; var ratio (Tr/Co).....     0.7381            0.86668 \n#&gt; T-test p-value........    0.98186            0.87945 \n#&gt; KS Bootstrap p-value..      0.555              0.002 \n#&gt; KS Naive p-value......    0.97023           0.045591 \n#&gt; KS Statistic..........   0.047089           0.087935 \n#&gt; \n#&gt; \n#&gt; ***** (V8) re75 *****\n#&gt;                        Before Matching        After Matching\n#&gt; mean treatment........     1532.1             1532.1 \n#&gt; mean control..........     1266.9             2079.5 \n#&gt; std mean diff.........     8.2363            -17.005 \n#&gt; \n#&gt; mean raw eQQ diff.....     367.61             532.46 \n#&gt; med  raw eQQ diff.....          0                  0 \n#&gt; max  raw eQQ diff.....     2110.2             8092.9 \n#&gt; \n#&gt; mean eCDF diff........   0.050834           0.040137 \n#&gt; med  eCDF diff........   0.061954             0.0409 \n#&gt; max  eCDF diff........    0.10748           0.083845 \n#&gt; \n#&gt; var ratio (Tr/Co).....     1.0763            0.64518 \n#&gt; T-test p-value........    0.38527            0.12154 \n#&gt; KS Bootstrap p-value..      0.038               0.02 \n#&gt; KS Naive p-value......    0.16449            0.06428 \n#&gt; KS Statistic..........    0.10748           0.083845 \n#&gt; \n#&gt; \n#&gt; Before Matching Minimum p.value: 0.0020368 \n#&gt; Variable Name(s): nodegr  Number(s): 6 \n#&gt; \n#&gt; After Matching Minimum p.value: 0.002 \n#&gt; Variable Name(s): re74  Number(s): 7\n\n# age 变平衡了\nqqplot(lalonde$age[PSM$index.control],lalonde$age[PSM$index.treated])\nabline(a=0,b=1)\n\n\n\n\n\n\nCode\n# re74 也变平衡了\nqqplot(lalonde$re74[PSM$index.control],lalonde$re74[PSM$index.treated])\nabline(a=0,b=1)\n\n\n\n\n\n\n\n敏感性分析\n\nCodelibrary(rbounds)\npsens(x =lalonde[PSM$index.treated,\"re78\"],\n      y =lalonde[PSM$index.control,\"re78\"] ,Gamma = 2,GammaInc = 0.1)\n#&gt; \n#&gt;  Rosenbaum Sensitivity Test for Wilcoxon Signed Rank P-Value \n#&gt;  \n#&gt; Unconfounded estimate ....  1e-04 \n#&gt; \n#&gt;  Gamma Lower bound Upper bound\n#&gt;    1.0       1e-04      0.0001\n#&gt;    1.1       0e+00      0.0015\n#&gt;    1.2       0e+00      0.0142\n#&gt;    1.3       0e+00      0.0693\n#&gt;    1.4       0e+00      0.2048\n#&gt;    1.5       0e+00      0.4152\n#&gt;    1.6       0e+00      0.6393\n#&gt;    1.7       0e+00      0.8140\n#&gt;    1.8       0e+00      0.9191\n#&gt;    1.9       0e+00      0.9699\n#&gt;    2.0       0e+00      0.9903\n#&gt; \n#&gt;  Note: Gamma is Odds of Differential Assignment To\n#&gt;  Treatment Due to Unobserved Factors \n#&gt; \npsens\n#&gt; function (x, y, Gamma = 6, GammaInc = 1) \n#&gt; {\n#&gt;     trt &lt;- x\n#&gt;     ctrl &lt;- y\n#&gt;     gamma &lt;- seq(1, Gamma, by = GammaInc)\n#&gt;     m &lt;- length(gamma)\n#&gt;     pvals &lt;- matrix(NA, m, 2)\n#&gt;     diff &lt;- trt - ctrl\n#&gt;     S &lt;- length(diff)\n#&gt;     diff &lt;- diff[diff != 0]\n#&gt;     ranks &lt;- rank(abs(diff), ties.method = \"average\")\n#&gt;     psi &lt;- as.numeric(diff &gt; 0)\n#&gt;     T &lt;- sum(psi * ranks)\n#&gt;     for (i in 1:m) {\n#&gt;         p.plus &lt;- gamma[i]/(1 + gamma[i])\n#&gt;         p.minus &lt;- 1/(1 + gamma[i])\n#&gt;         E.T.plus &lt;- sum(ranks * p.plus)\n#&gt;         V.T &lt;- sum(ranks^2 * p.plus * (1 - p.plus))\n#&gt;         E.T.minus &lt;- sum(ranks * p.minus)\n#&gt;         z.plus &lt;- (T - E.T.plus)/sqrt(V.T)\n#&gt;         z.minus &lt;- (T - E.T.minus)/sqrt(V.T)\n#&gt;         p.val.up &lt;- 1 - pnorm(z.plus)\n#&gt;         p.val.low &lt;- 1 - pnorm(z.minus)\n#&gt;         pvals[i, 1] &lt;- round(p.val.low, digits = 4)\n#&gt;         pvals[i, 2] &lt;- round(p.val.up, digits = 4)\n#&gt;     }\n#&gt;     pval &lt;- pvals[1, 1]\n#&gt;     bounds &lt;- data.frame(gamma, pvals)\n#&gt;     names(bounds) &lt;- c(\"Gamma\", \"Lower bound\", \"Upper bound\")\n#&gt;     msg &lt;- \"Rosenbaum Sensitivity Test for Wilcoxon Signed Rank P-Value \\n\"\n#&gt;     note &lt;- \"Note: Gamma is Odds of Differential Assignment To\\n Treatment Due to Unobserved Factors \\n\"\n#&gt;     Obj &lt;- list(Gamma = Gamma, GammaInc = GammaInc, pval = pval, \n#&gt;         msg = msg, bounds = bounds, note = note)\n#&gt;     class(Obj) &lt;- c(\"rbounds\", class(Obj))\n#&gt;     Obj\n#&gt; }\n#&gt; &lt;bytecode: 0x0000021cdb998080&gt;\n#&gt; &lt;environment: namespace:rbounds&gt;\n\n\n对PSM（Y=re78）使用psens()进行Wilcoxon 符合秩检验，当τ=1.3，p值就大于0.05了，说明处理发生比为1.3时，就可以改变原先对于处理效应的结论，也就是说，这个隐藏性偏差不必太大就可以改变原来的结论，因此分析结果对隐藏性排除的影响非常敏感，结论不可靠。\n对 PSM（Y=re78）使用Hodges-Lehmann点估计检验法 hlsens() ，当τ=1.5，其95%置信区间包含零，说明此时处理效应是无效的。说明处理发生比为1.5时，隐藏性偏差就可以改变原来的结论，因此匹配后的结论不可靠。\n\nCodex = lalonde[PSM$index.treated, \"re78\"]\ny = lalonde[PSM$index.control, \"re78\"]\nhlsens(x, y,Gamma = 2,GammaInc = 0.1)\n#&gt; \n#&gt;  Rosenbaum Sensitivity Test for Hodges-Lehmann Point Estimate \n#&gt;  \n#&gt; Unconfounded estimate ....  1527.95 \n#&gt; \n#&gt;  Gamma Lower bound Upper bound\n#&gt;    1.0 1527.900000      1527.9\n#&gt;    1.1  917.250000      1580.2\n#&gt;    1.2  608.050000      1918.7\n#&gt;    1.3  338.450000      2141.0\n#&gt;    1.4  114.850000      2407.3\n#&gt;    1.5   -0.050046      2631.4\n#&gt;    1.6 -154.050000      2850.3\n#&gt;    1.7 -378.150000      3072.7\n#&gt;    1.8 -545.350000      3258.1\n#&gt;    1.9 -706.350000      3474.2\n#&gt;    2.0 -867.650000      3678.9\n#&gt; \n#&gt;  Note: Gamma is Odds of Differential Assignment To\n#&gt;  Treatment Due to Unobserved Factors \n#&gt; \n\n\n共同支持域的查验\n\nCodesum(glm_ps$fitted.values[lalonde$treat==1]&gt; \n        max(glm_ps$fitted.values[lalonde$treat==0]))\n#&gt; [1] 4\n\nsum(glm_ps$fitted.values[lalonde$treat==1]&lt; \n        min(glm_ps$fitted.values[lalonde$treat==0]))\n#&gt; [1] 0\n\n\n丢弃的实验组样本共有4个。185-181\n\nCodeattach(lalonde)\nsummary(PSM)\n#&gt; \n#&gt; Estimate...  2439.3 \n#&gt; AI SE......  813.4 \n#&gt; T-stat.....  2.9989 \n#&gt; p.val......  0.0027099 \n#&gt; \n#&gt; Original number of observations..............  445 \n#&gt; Original number of treated obs...............  185 \n#&gt; Matched number of observations...............  185 \n#&gt; Matched number of observations  (unweighted).  489\nPSM_CS &lt;-  Match(Y=re78,\n             Tr = treat,\n             X=glm_ps$fitted.values,\n             estimand = \"ATT\",\n             Weight.matrix = gen_match,\n             replace = TRUE,\n             CommonSupport = TRUE)\nsummary(PSM_CS)\n#&gt; \n#&gt; Estimate...  2330 \n#&gt; AI SE......  821.6 \n#&gt; T-stat.....  2.836 \n#&gt; p.val......  0.0045684 \n#&gt; \n#&gt; Original number of observations..............  430 \n#&gt; Original number of treated obs...............  181 \n#&gt; Matched number of observations...............  181 \n#&gt; Matched number of observations  (unweighted).  468\ndetach(lalonde)\n\n\n有查验共同支持域的ATT（2330），与无查验共同支持域（2439.3）存在差异，因此必须重新改进倾向值分析。\n\n21.3.3 MatchIt\n\n21.3.3.1 匹配数据\n\nCodelibrary(MatchIt)\nNM &lt;- MatchIt::matchit(\n    formula = treat ~ age + educ + black + hisp + married + nodegr + re74  + re75,\n    data = lalonde,\n    method = \"nearest\", # 最近邻匹配\n    ratio = 1, # 1:1\n    replace = FALSE\n)\nsummary(NM)\n#&gt; \n#&gt; Call:\n#&gt; MatchIt::matchit(formula = treat ~ age + educ + black + hisp + \n#&gt;     married + nodegr + re74 + re75, data = lalonde, method = \"nearest\", \n#&gt;     replace = FALSE, ratio = 1)\n#&gt; \n#&gt; Summary of Balance for All Data:\n#&gt;          Means Treated Means Control Std. Mean Diff. Var. Ratio eCDF Mean\n#&gt; distance        0.4377        0.4001          0.3935     1.0471    0.1117\n#&gt; age            25.8162       25.0538          0.1066     1.0278    0.0254\n#&gt; educ           10.3459       10.0885          0.1281     1.5513    0.0287\n#&gt; black           0.8432        0.8269          0.0449          .    0.0163\n#&gt; hisp            0.0595        0.1077         -0.2040          .    0.0482\n#&gt; married         0.1892        0.1538          0.0902          .    0.0353\n#&gt; nodegr          0.7081        0.8346         -0.2783          .    0.1265\n#&gt; re74         2095.5740     2107.0268         -0.0023     0.7381    0.0192\n#&gt; re75         1532.0556     1266.9092          0.0824     1.0763    0.0508\n#&gt;          eCDF Max\n#&gt; distance   0.2140\n#&gt; age        0.0652\n#&gt; educ       0.1265\n#&gt; black      0.0163\n#&gt; hisp       0.0482\n#&gt; married    0.0353\n#&gt; nodegr     0.1265\n#&gt; re74       0.0471\n#&gt; re75       0.1075\n#&gt; \n#&gt; Summary of Balance for Matched Data:\n#&gt;          Means Treated Means Control Std. Mean Diff. Var. Ratio eCDF Mean\n#&gt; distance        0.4377        0.4267          0.1152     1.0987    0.0298\n#&gt; age            25.8162       25.8757         -0.0083     0.9551    0.0121\n#&gt; educ           10.3459       10.1459          0.0995     1.3748    0.0220\n#&gt; black           0.8432        0.8486         -0.0149          .    0.0054\n#&gt; hisp            0.0595        0.0649         -0.0229          .    0.0054\n#&gt; married         0.1892        0.2000         -0.0276          .    0.0108\n#&gt; nodegr          0.7081        0.7730         -0.1427          .    0.0649\n#&gt; re74         2095.5740     1659.5326          0.0892     1.1752    0.0351\n#&gt; re75         1532.0556     1359.6980          0.0535     0.9270    0.0502\n#&gt;          eCDF Max Std. Pair Dist.\n#&gt; distance   0.1027          0.1302\n#&gt; age        0.0432          0.8711\n#&gt; educ       0.0757          0.6533\n#&gt; black      0.0054          0.4906\n#&gt; hisp       0.0054          0.2057\n#&gt; married    0.0108          0.7177\n#&gt; nodegr     0.0649          0.2378\n#&gt; re74       0.0865          0.6297\n#&gt; re75       0.1081          0.7019\n#&gt; \n#&gt; Sample Sizes:\n#&gt;           Control Treated\n#&gt; All           260     185\n#&gt; Matched       185     185\n#&gt; Unmatched      75       0\n#&gt; Discarded       0       0\n\n\n\n21.3.3.2 评估质量\n\nCode# 散点图展示了匹配后实验组和对照组样本倾向值的分布，凸显了分布平衡与不平衡，分布缺乏重合\nplot(NM,type = \"jitter\")\n\n\n\n\n\n\n#&gt; To identify the units, use first mouse button; to stop, use second.\n\n\nCode# QQ图 展示了 匹配前（All）匹配后（Matched）的平衡情况\nplot(NM,type = \"QQ\")\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCode\n# 直方图展示了匹配前后倾向值的分布\nplot(NM,type = \"hist\")\n\n\n\n\n\n\n\n\nCode# 标准化平衡统计值，Std. Mean Diff.\nsummary(NM,standardize = TRUE)\n#&gt; \n#&gt; Call:\n#&gt; MatchIt::matchit(formula = treat ~ age + educ + black + hisp + \n#&gt;     married + nodegr + re74 + re75, data = lalonde, method = \"nearest\", \n#&gt;     replace = FALSE, ratio = 1)\n#&gt; \n#&gt; Summary of Balance for All Data:\n#&gt;          Means Treated Means Control Std. Mean Diff. Var. Ratio eCDF Mean\n#&gt; distance        0.4377        0.4001          0.3935     1.0471    0.1117\n#&gt; age            25.8162       25.0538          0.1066     1.0278    0.0254\n#&gt; educ           10.3459       10.0885          0.1281     1.5513    0.0287\n#&gt; black           0.8432        0.8269          0.0449          .    0.0163\n#&gt; hisp            0.0595        0.1077         -0.2040          .    0.0482\n#&gt; married         0.1892        0.1538          0.0902          .    0.0353\n#&gt; nodegr          0.7081        0.8346         -0.2783          .    0.1265\n#&gt; re74         2095.5740     2107.0268         -0.0023     0.7381    0.0192\n#&gt; re75         1532.0556     1266.9092          0.0824     1.0763    0.0508\n#&gt;          eCDF Max\n#&gt; distance   0.2140\n#&gt; age        0.0652\n#&gt; educ       0.1265\n#&gt; black      0.0163\n#&gt; hisp       0.0482\n#&gt; married    0.0353\n#&gt; nodegr     0.1265\n#&gt; re74       0.0471\n#&gt; re75       0.1075\n#&gt; \n#&gt; Summary of Balance for Matched Data:\n#&gt;          Means Treated Means Control Std. Mean Diff. Var. Ratio eCDF Mean\n#&gt; distance        0.4377        0.4267          0.1152     1.0987    0.0298\n#&gt; age            25.8162       25.8757         -0.0083     0.9551    0.0121\n#&gt; educ           10.3459       10.1459          0.0995     1.3748    0.0220\n#&gt; black           0.8432        0.8486         -0.0149          .    0.0054\n#&gt; hisp            0.0595        0.0649         -0.0229          .    0.0054\n#&gt; married         0.1892        0.2000         -0.0276          .    0.0108\n#&gt; nodegr          0.7081        0.7730         -0.1427          .    0.0649\n#&gt; re74         2095.5740     1659.5326          0.0892     1.1752    0.0351\n#&gt; re75         1532.0556     1359.6980          0.0535     0.9270    0.0502\n#&gt;          eCDF Max Std. Pair Dist.\n#&gt; distance   0.1027          0.1302\n#&gt; age        0.0432          0.8711\n#&gt; educ       0.0757          0.6533\n#&gt; black      0.0054          0.4906\n#&gt; hisp       0.0054          0.2057\n#&gt; married    0.0108          0.7177\n#&gt; nodegr     0.0649          0.2378\n#&gt; re74       0.0865          0.6297\n#&gt; re75       0.1081          0.7019\n#&gt; \n#&gt; Sample Sizes:\n#&gt;           Control Treated\n#&gt; All           260     185\n#&gt; Matched       185     185\n#&gt; Unmatched      75       0\n#&gt; Discarded       0       0\n\n\n继续改进，调整模型和协变量\n\n21.3.3.3 计算平均处理效应\n为了简化步骤，以当前的结果进行匹配后分析。\n\nCode\n# 提取匹配后的样本\nmData &lt;- match.data(NM,group = \"all\")\nmData_trt &lt;- match.data(NM,group = \"treat\")\nmData_ctrl &lt;- match.data(NM,group = \"control\")\n \n# 包从CRAN剔除了\n\n\n\nCodelibrary(rbounds)\npsens(x =mData_trt$re78,\n      y =mData_ctrl$re78 ,Gamma = 2,GammaInc = 0.1)\n#&gt; \n#&gt;  Rosenbaum Sensitivity Test for Wilcoxon Signed Rank P-Value \n#&gt;  \n#&gt; Unconfounded estimate ....  0.0199 \n#&gt; \n#&gt;  Gamma Lower bound Upper bound\n#&gt;    1.0      0.0199      0.0199\n#&gt;    1.1      0.0048      0.0639\n#&gt;    1.2      0.0010      0.1491\n#&gt;    1.3      0.0002      0.2749\n#&gt;    1.4      0.0000      0.4248\n#&gt;    1.5      0.0000      0.5755\n#&gt;    1.6      0.0000      0.7076\n#&gt;    1.7      0.0000      0.8108\n#&gt;    1.8      0.0000      0.8844\n#&gt;    1.9      0.0000      0.9328\n#&gt;    2.0      0.0000      0.9627\n#&gt; \n#&gt;  Note: Gamma is Odds of Differential Assignment To\n#&gt;  Treatment Due to Unobserved Factors \n#&gt; \n\nhlsens(x =mData_trt$re78,\n      y =mData_ctrl$re78 ,Gamma = 2,GammaInc = 0.1)\n#&gt; \n#&gt;  Rosenbaum Sensitivity Test for Hodges-Lehmann Point Estimate \n#&gt;  \n#&gt; Unconfounded estimate ....  1435.08 \n#&gt; \n#&gt;  Gamma Lower bound Upper bound\n#&gt;    1.0  1.4351e+03      1435.1\n#&gt;    1.1  8.0828e+02      1515.9\n#&gt;    1.2  4.6298e+02      1809.0\n#&gt;    1.3  1.8238e+02      2178.1\n#&gt;    1.4 -2.0266e-02      2439.4\n#&gt;    1.5 -2.4892e+02      2678.5\n#&gt;    1.6 -4.5162e+02      2937.5\n#&gt;    1.7 -6.7212e+02      3184.0\n#&gt;    1.8 -8.9732e+02      3462.6\n#&gt;    1.9 -1.1328e+03      3651.1\n#&gt;    2.0 -1.3022e+03      3848.9\n#&gt; \n#&gt;  Note: Gamma is Odds of Differential Assignment To\n#&gt;  Treatment Due to Unobserved Factors \n#&gt;",
    "crumbs": [
      "倾向性评分",
      "<span class='chapter-number'>21</span>  <span class='chapter-title'>倾向性评分</span>"
    ]
  },
  {
    "objectID": "PropensityScore.html#加权weighting",
    "href": "PropensityScore.html#加权weighting",
    "title": "\n21  倾向性评分\n",
    "section": "\n21.4 加权（Weighting）",
    "text": "21.4 加权（Weighting）\n……",
    "crumbs": [
      "倾向性评分",
      "<span class='chapter-number'>21</span>  <span class='chapter-title'>倾向性评分</span>"
    ]
  },
  {
    "objectID": "PropensityScore.html#回归",
    "href": "PropensityScore.html#回归",
    "title": "\n21  倾向性评分\n",
    "section": "\n21.5 回归",
    "text": "21.5 回归\n……",
    "crumbs": [
      "倾向性评分",
      "<span class='chapter-number'>21</span>  <span class='chapter-title'>倾向性评分</span>"
    ]
  },
  {
    "objectID": "PropensityScore.html#psapsa_shiny",
    "href": "PropensityScore.html#psapsa_shiny",
    "title": "\n21  倾向性评分\n",
    "section": "\n21.6 psa::psa_shiny()",
    "text": "21.6 psa::psa_shiny()\n\nCodepsa::psa_shiny()",
    "crumbs": [
      "倾向性评分",
      "<span class='chapter-number'>21</span>  <span class='chapter-title'>倾向性评分</span>"
    ]
  },
  {
    "objectID": "diagnostic_test.html",
    "href": "diagnostic_test.html",
    "title": "\n22  诊断性测试\n",
    "section": "",
    "text": "22.1 基本特征",
    "crumbs": [
      "研究设计",
      "<span class='chapter-number'>22</span>  <span class='chapter-title'>诊断性测试</span>"
    ]
  },
  {
    "objectID": "diagnostic_test.html#基本特征",
    "href": "diagnostic_test.html#基本特征",
    "title": "\n22  诊断性测试\n",
    "section": "",
    "text": "22.1.1 灵敏度（Sensitivity）\n真阳性率：指在所有真实状况为阳性的样本中，被正确识别出阳性的比例。\n\\[\nSe=\\frac{TP}{TP+FN}\n\\]\n其中TP 是真阳性的数量，FN 是假阴性的数量。\n假阴性率(FNR) /漏诊率\n\\[\nFNR=1-Se\n\\]\n\n22.1.2 特异度（Specificity）\n真阴性率：指在所有真实状况为阴性的样本中，被正确识别出阴性的比例。\n\\[\nSp=\\frac{TN}{TN+FP}\n\\]\n其中 TN 是真阴性的数量，FP 是假阳性的数量。\n假阳性率(FPR) /误诊率\n\\[ FPR=1-Sp \\]\n\n22.1.3 Youden’s Index\n\\[\nJ=Se-FPR =Se+Sp-1,J[1,-1]\n\\]\n\nJ 越大诊断有效性越高\nJ=1 表示完美的诊断性能，因为Se，Sp都是1。\nJ≤0 表示没有诊断价值\n\n22.1.4 Likelihood Ratio\n正似然比\n\\[\nLR+=\\frac{Se}{FPR}=\\frac{Se}{1-Sp}\n\\]\n\nLR+越大表示患病测出阳性结果的优势越大\nLR+=1表示诊断无效\n\n负似然比\n\\[\nLR-=\\frac{FNR}{Sp}=\\frac{1-Sp}{Sp}\n\\]\n\nLR-越小表示患病测出阴性结果的优势越小\nLR-=1表示诊断无效\n\n22.1.5 预测值\n\nCodem\n#&gt;        truth\n#&gt; predict +    -   \n#&gt;       + \"TP\" \"FP\"\n#&gt;       - \"FN\" \"TN\"\n\n\n阳性预测值（Positive Predictive Value, PPV）：在所有被测试为阳性的样本中，真正的阳性比例。\n\\[\nPPV=\\frac{TP}{TP+NP}\n\\]\n阴性预测值（Negative Predictive Value, NPV）：在所有被测试为阴性的样本中，真正的阴性比例。\n\\[\nPPV=\\frac{TN}{TN+FN}\n\\]\n配对样本设计\n\\(\\chi^2\\)配对检验\n完全随机设计\n\\(\\chi^2\\)检验",
    "crumbs": [
      "研究设计",
      "<span class='chapter-number'>22</span>  <span class='chapter-title'>诊断性测试</span>"
    ]
  },
  {
    "objectID": "diagnostic_test.html#一致性agreement",
    "href": "diagnostic_test.html#一致性agreement",
    "title": "\n22  诊断性测试\n",
    "section": "\n22.2 一致性agreement",
    "text": "22.2 一致性agreement\n准确度（Accuracy）：指测试正确地分类（阳性或阴性）的样本占总样本的比例。\n\\[\nAccuracy=\\frac{TP+TN}{N}\n\\]\nkappa 系数\n\\[\n\\kappa =\\frac{Accuracy-[(a+b)(a+c)+(c+d)(b+d)]/N^2}{1-[(a+b)(a+c)+(c+d)(b+d)]/N^2}\n\\]\n\nκ=1表示完全一致\nκ=-1表示完全不一致\nκ=0表示一致性与偶然一致性Pe相同\n\n通常κ＞0.7即可以认为两种诊断方法有较好的一致性",
    "crumbs": [
      "研究设计",
      "<span class='chapter-number'>22</span>  <span class='chapter-title'>诊断性测试</span>"
    ]
  },
  {
    "objectID": "diagnostic_test.html#roc曲线receiver-operating-characteristic-curve",
    "href": "diagnostic_test.html#roc曲线receiver-operating-characteristic-curve",
    "title": "\n22  诊断性测试\n",
    "section": "\n22.3 ROC曲线（Receiver Operating Characteristic Curve）",
    "text": "22.3 ROC曲线（Receiver Operating Characteristic Curve）\nROC曲线（Receiver Operating Characteristic Curve）：是一个图形工具，用于展示不同阈值下灵敏度和特异度之间的关系。曲线下面积（AUC）越接近1，表示测试的性能越好。\n\nCodelibrary(pROC)\n\nroc_data &lt;- aSAH %&gt;%\n    dplyr::filter(gender == \"Female\") %&gt;%\n    roc(outcome, s100b)\n\n\n\n# 绘制ROC曲线\nplot(roc_data, print.thres = \"best\", print.thres.pattern = \"Best cutoff: %.2f\", main = \"ROC Curve\")\n\n\n\n\n\n\nCode\n\n# 计算AUC\nauc_value &lt;- auc(roc_data)\nprint(paste(\"AUC:\", auc_value))\n#&gt; [1] \"AUC: 0.72\"\n\n\n\n22.3.1 AUC\n$ A=P(X&gt;Y) $\n\\[\nS(X,Y)=\n\\begin{cases}\n1,\\ \\ \\ \\  X&gt;Y\\\\\n1/2,X=Y\\\\\n0,\\ \\ \\ \\ X&lt;Y\\\\\n\\end{cases}\n\\]\n$ A=_1^{n_1}_1^{n_0}S(X,Y) $\n\n22.3.2 分组AUC的比较\n完全随机设计\n\\[\nZ=\\frac{\\hat A_1-\\hat A_2}{\\sqrt{Var(\\hat A_1)+Var(\\hat A_2)}}\n\\]\n配对样本设计\n\\[\nZ=\\frac{\\hat A_1-\\hat A_2}{\\sqrt{Var(\\hat A_1)+Var(\\hat A_2)-2Cov(\\hat A_1,\\hat A_2)}}\n\\]",
    "crumbs": [
      "研究设计",
      "<span class='chapter-number'>22</span>  <span class='chapter-title'>诊断性测试</span>"
    ]
  },
  {
    "objectID": "SurvivalAnalysis.html#风险函数",
    "href": "SurvivalAnalysis.html#风险函数",
    "title": "\n20  生存分析\n",
    "section": "\n20.2 风险函数",
    "text": "20.2 风险函数\n\\[\n\\begin{aligned}\nh(t)=&\\lim_{\\Delta t\\to 0}\\frac{P(t\\le T&lt;t+\\Delta t|T\\ge t)}{\\Delta t}\\\\\n=&\\lim_{\\Delta t\\to 0}\\frac{P(t\\le T&lt;t+\\Delta t\\ \\&\\ T\\ge t)}{\\Delta t·P(T\\ge t) }\\\\\n=&\\lim_{\\Delta t\\to 0}\\frac{S(t)- S(t+\\Delta t)}{\\Delta t·S(t)}\\\\\n=&-\\frac{d(\\ln S(t))}{dt}\n\\end{aligned}\n\\]\n\\[S(t)=e^{-\\int_0^t h(u)du} \\]\n\\[\n\\begin{aligned}\nh(t)\\Delta t=&P(t\\le T&lt;t+\\Delta t|T\\ge t)\n=\\frac{P(t\\le T&lt;t+\\Delta t\\ \\&\\ T\\ge t)}{P(T\\ge t) }\\\\\n=&\\frac{P(t\\le T&lt;t+\\Delta t)}{P(T\\ge t) }\\\\\n=&\\frac{f(t)\\Delta t}{S(t)}\n\\end{aligned}\n\\]\n\\(f(t)=h(t)S(t)\\)",
    "crumbs": [
      "生存分析",
      "<span class='chapter-number'>20</span>  <span class='chapter-title'>生存分析</span>"
    ]
  },
  {
    "objectID": "CoxProportionalHazardsModel.html",
    "href": "CoxProportionalHazardsModel.html",
    "title": "\n21  Cox比例风险模型\n",
    "section": "",
    "text": "21.1 风险函数\n\\[\n\\begin{aligned} h(t)=&\\lim_{\\Delta t\\to 0}\\frac{P(t\\le T&lt;t+\\Delta t|T\\ge t)}{\\Delta t}\\\\ =&\\lim_{\\Delta t\\to 0}\\frac{P(t\\le T&lt;t+\\Delta t\\ \\&\\ T\\ge t)}{\\Delta t·P(T\\ge t) }\\\\ =&\\lim_{\\Delta t\\to 0}\\frac{S(t)- S(t+\\Delta t)}{\\Delta t·S(t)}\\\\ =&-\\frac{d(\\ln S(t))}{dt} \\end{aligned}\n\\]",
    "crumbs": [
      "生存分析",
      "<span class='chapter-number'>21</span>  <span class='chapter-title'>Cox比例风险模型</span>"
    ]
  },
  {
    "objectID": "CoxProportionalHazardsModel.html#风险率",
    "href": "CoxProportionalHazardsModel.html#风险率",
    "title": "\n21  Cox比例风险模型\n",
    "section": "\n21.2 风险率",
    "text": "21.2 风险率\n对于有风险因子\\(x_1,x_2,...,x_k\\) 的个体在时间 t 的风险率\\(h(t|x_1,x_2,...,x_k)\\)\n\\[ h(t|x_1,x_2,...,x_k)=h_0(t)g(x_1,x_2,...,x_k)=h_0(t)exp(\\sum_{j=1}^k\\beta_jx_j) \\]\n其中\n\n\\(h0 (t)\\)是给定所有风险因子（协变量）为零的随时间变化的基线风险函数。\n\\(g(X)\\)是k个独立风险因子的集合函数，代表变量的风险效应。\n\\(β_j\\)是部分回归系数，表示风险比的比例变化。",
    "crumbs": [
      "生存分析",
      "<span class='chapter-number'>21</span>  <span class='chapter-title'>Cox比例风险模型</span>"
    ]
  },
  {
    "objectID": "CoxProportionalHazardsModel.html#比例风险假设",
    "href": "CoxProportionalHazardsModel.html#比例风险假设",
    "title": "\n21  Cox比例风险模型\n",
    "section": "\n21.3 比例风险假设",
    "text": "21.3 比例风险假设\n（proportional hazards assumption）\n\\[ \\frac{h(t)}{h_0(t)}=exp(\\sum_{j=1}^k\\beta_jx_j) \\]",
    "crumbs": [
      "生存分析",
      "<span class='chapter-number'>21</span>  <span class='chapter-title'>Cox比例风险模型</span>"
    ]
  },
  {
    "objectID": "CoxProportionalHazardsModel.html#风险比hazard-ratio",
    "href": "CoxProportionalHazardsModel.html#风险比hazard-ratio",
    "title": "\n21  Cox比例风险模型\n",
    "section": "\n21.4 风险比（hazard ratio）",
    "text": "21.4 风险比（hazard ratio）\n假设有两个个体，分别具有独立变量，两个个体的风险函数之比称为风险比\n\\[ HR=\\frac{h(t|x_1,x_2,...,x_k)}{h(t|x_1^*,x_2^*,...,x_k^*)}=exp(\\sum_{j=1}^k\\beta_j(x_j-x_j^*)) \\]\n\nCodedf &lt;- read_csv(\"data/log-rank-survival.csv\")\n\n\nlibrary(survminer)\nlibrary(survival)\n# 使用 Kaplan-Meier 方法创建一个Surv对象\nsurv_formula &lt;- Surv(Days,status)~treatment\n\n# 拟合Cox比例风险模型 \ncox_model &lt;- coxph(surv_formula, data = df)  \n# 查看模型结果 \nsummary(cox_model)  \n#&gt; Call:\n#&gt; coxph(formula = surv_formula, data = df)\n#&gt; \n#&gt;   n= 56, number of events= 39 \n#&gt; \n#&gt;                       coef exp(coef)  se(coef)      z Pr(&gt;|z|)    \n#&gt; treatmentDPVB    -2.740141  0.064561  0.580664 -4.719 2.37e-06 ***\n#&gt; treatmentLDRT    -0.383558  0.681432  0.387499 -0.990    0.322    \n#&gt; treatmentLR_DPVB -4.632850  0.009727  0.878661 -5.273 1.34e-07 ***\n#&gt; ---\n#&gt; Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n#&gt; \n#&gt;                  exp(coef) exp(-coef) lower .95 upper .95\n#&gt; treatmentDPVB     0.064561     15.489  0.020688   0.20148\n#&gt; treatmentLDRT     0.681432      1.467  0.318848   1.45634\n#&gt; treatmentLR_DPVB  0.009727    102.807  0.001738   0.05444\n#&gt; \n#&gt; Concordance= 0.822  (se = 0.025 )\n#&gt; Likelihood ratio test= 61.41  on 3 df,   p=3e-13\n#&gt; Wald test            = 36.01  on 3 df,   p=7e-08\n#&gt; Score (logrank) test = 60.47  on 3 df,   p=5e-13\n# 检查比例风险假设 \ncox.zph(cox_model)\n#&gt;           chisq df    p\n#&gt; treatment 0.833  3 0.84\n#&gt; GLOBAL    0.833  3 0.84\n\n\n\n21.4.1 模型系数的估计\n条件死亡概率和局部似然函数方法\n\\[ \\ln L_p(\\beta)=\\sum_{i=1}^{d}\\left[ \\sum_{j=1}^k\\beta_jx_{ij}-\\ln\\sum_{m\\in R_i}exp( \\sum_{j=1}^k\\beta_jx_{mj})         \\right] \\]\nNewton-Raphson iterative method\n\\[  \\begin{cases}  \\frac{\\partial \\ln L_p(\\beta)}{\\partial \\beta_1}=0\\\\ \\frac{\\partial \\ln L_p(\\beta)}{\\partial \\beta_2}=0\\\\ \\vdots\\\\ \\frac{\\partial \\ln L_p(\\beta)}{\\partial \\beta_k}=0\\\\ \\end{cases} \\]\n\n21.4.2 模型系数的假设检验\n\n\nWald‘s test\n检验是否有独立变量需要被消除，统计量\\(Z=b_j/S_{b_j}\\)\n当样本量足够大时，Z服从标准正态分布，Z2 服从自由度为1 的\\(\\chi^2\\) 分布\n\\[ \\chi^2_W=(b_j/S_{b_j})^2\\sim \\chi^2(1) \\]\n\n\nPartial likelihood Ratio test\n主要用于非显著性变量的消除，新变量的引入和模型的比较。\n\\[ \\chi^2_{LR}=2\\left[ \\ln L_p(\\beta_k)-\\ln L_p(\\beta_{k-1}) \\right]\\sim\\chi^2(1) \\]\n其中分别是包含 k 个和 k-1 个（不包含要检验的第 j 个变量）独立变量的对数局部似然函数",
    "crumbs": [
      "生存分析",
      "<span class='chapter-number'>21</span>  <span class='chapter-title'>Cox比例风险模型</span>"
    ]
  }
]