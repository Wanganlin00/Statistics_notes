# 线性回归

一般线性模型中，其自变量全部为固定效应自变量，3点假设：

1.  正态性，因变量y服从正态分布。
2.  独立性，各例观测值Y~i~ 之间相互独立。
3.  方差齐性，Y方差相等或 残差e 服从N（0，σ^2^）

```{r}
library(tidymodels)
library(patchwork)
```

[数据下载网站](https://www.statlearning.com/resources-second-edition)

```{r}
advertising<-read_csv("data/Advertising.csv")
income1<-read_csv("data/Income1.csv")
income2<-read_csv("data/Income2.csv")
```

## 一元线性回归

### lm

```{r}
#linear model specification 线性模型规范
lm_spec <-linear_reg() |>
  set_mode("regression") |>
  set_engine("lm")  
lm_spec
```

linear regression model：

$$
Y_i=\beta_0+ \beta_1 X_i+\epsilon_i,其中\epsilon_i\sim N(0,\sigma^2)
$$

```{r}
p_sales<-function(x){
  ggplot(advertising,aes({{x}},sales))+
           geom_point(shape=21,color="red")+
           geom_smooth(formula = 'y ~ x',method = "lm",se=FALSE)
}
p_sales(TV)|p_sales(radio)|p_sales(newspaper)
```

```{r}
lm_sales_tv <- lm_spec |>  fit(sales ~ TV, data = advertising)
# 模型摘要
lm_sales_tv  # lm_sales_tv |>  pluck("fit")
summary(lm_sales_tv$fit)  # lm_sales_tv |>pluck("fit") |>summary()


# 参数估计值、标准误、统计量、p值
broom::tidy(lm_sales_tv)
# 模型统计信息
broom::glance(lm_sales_tv) 
```

### 预测

```{r}
# 预测
stats::predict(lm_sales_tv, new_data = advertising)
predict(lm_sales_tv, new_data = advertising, type = "conf_int")



# 比较观测值与预测值
bind_cols( predict(lm_sales_tv, new_data = advertising), advertising)
    
bind_cols( predict(lm_sales_tv, new_data = advertising), advertising) |> 
  select(sales, .pred)

augment(lm_sales_tv, new_data = advertising) |>   
  select(sales, .pred)
```

### 最小二乘法

保证各实测点到回归直线的纵向距离的平方和最小，即使得残差平方和

$$
Q=\sum (Y-\hat Y)^2
$$

最小。

```{r}
# 可视化
bind_cols(predict(lm_sales_tv, new_data = advertising), advertising) |>
    ggplot(aes(x = TV)) +
    geom_linerange(aes(ymin = sales, ymax = .pred)) +
    geom_point(aes(y = sales), color = "red") +
    geom_abline(
        intercept = coef(lm_sales_tv$fit)[1],
        slope = coef(lm_sales_tv$fit)[2],
        color = "blue",
        size = 1
    )
```

### 回归诊断

#### 残差图

```{r}
plot(lm_sales_tv$fit,1)  
```

```{r}
# 检查线性回归模型的残差是否与拟合值无关，即残差的分布是否随机。
# 残差应该随机分布在0附近
tibble(
    `Fitted values`=lm_sales_tv$fit$fitted.values,
    Residuals = lm_sales_tv$fit$residuals
) |> ggplot(aes(x = `Fitted values` , y = Residuals)) +
  geom_point(pch=21) +
    geom_smooth(formula = "y~x",color="red",lwd=0.5)+
  geom_hline(yintercept = 0,lty=2) +
  labs(x = "Fitted Values", y = "Residuals")
```

```{r}
# 检查线性回归模型的残差是否与观测值无关，即残差的分布是否随机。
tibble(Sales = lm_sales_tv$fit$model$sales,
       Residuals = lm_sales_tv$fit$residuals,) |> 
    ggplot(aes(x = Sales , y = Residuals)) +
    geom_point(pch=21) +
    geom_smooth(,color="red",lwd=0.5) +
    labs(x = "Observed Values", y = "Residuals")
```

```{r}
plot(lm_sales_tv$fit,3)  
```

```{r}
tibble(
    fitted_values=lm_sales_tv$fit$fitted.values,
    StandardizedResiduals = rstudent(lm_sales_tv$fit) ,
) |>
    ggplot(aes(x = fitted_values, y = sqrt(abs(StandardizedResiduals)))) +
    geom_point(pch=21) +
    geom_smooth(color="red",lwd=0.5)+
    labs(x = "Fitted Values", y = "√|Standardized residuals|")
```

#### Q-Q图

```{r}
plot(lm_sales_tv$fit,2)  
```

```{r}
tibble(
       StandardizedResiduals =rstandard(lm_sales_tv$fit) ) |> 
    ggplot(aes(sample=StandardizedResiduals)) +
    stat_qq(pch=21)+
    stat_qq_line(color="red",lty=2)+
    labs(x = "Theoretical Quantiles", y = "Standardized residuals")

```

#### Cook's距离

```{r}
plot(lm_sales_tv$fit,4)  
```

```{r}
threshold <- 4 / (nrow(lm_sales_tv$fit$model) - length(coef(lm_sales_tv$fit)) - 2)

tibble(x = 1:nrow(advertising),
       CooksD = cooks.distance(lm_sales_tv$fit),
       Threshold = CooksD > threshold)|>
    ggplot() +
    geom_segment(aes(x=x,xend=x,y=0,yend=CooksD,color=Threshold)) +
    geom_text(aes(x=x,y=CooksD,label=if_else(Threshold,x,NA)),vjust=-0.2)+
    labs(x = "Observation Index", y = "Cook's Distance")
```

#### 杠杆值图

```{r}
plot(lm_sales_tv$fit,5)  
```

```{r}
tibble(
    leverage = hatvalues(lm_sales_tv$fit),
    StandardizedResiduals = rstandard(lm_sales_tv$fit) ,
) |>
    ggplot(aes(x = leverage, y = StandardizedResiduals)) +
    geom_point(pch=21) +
    geom_smooth(color="red",lwd=0.5)+
    scale_x_continuous(limits = c(0, NA)) +
    geom_vline(xintercept = 0, lty = 2) +
    geom_hline(yintercept = 0, lty = 2) +
    labs(x = "Leverage Values", y = "Standardized residuals")
```

```{r}
plot(lm_sales_tv$fit,6)  
```

```{r}


threshold <- 4 / (nrow(lm_sales_tv$fit$model) - length(coef(lm_sales_tv$fit)) - 2)

df <- tibble(
    x = 1:nrow(advertising),
    leverage = hatvalues(lm_sales_tv$fit),
    CooksD = cooks.distance(lm_sales_tv$fit),
    Threshold = CooksD > threshold,
) 

    ggplot(df,aes(leverage, CooksD)) +
    geom_point(pch=21) +
    xlim(c(0,NA))+
    geom_text(aes(label=if_else(Threshold,as.character(x),NA)),vjust=-0.5)+
    geom_abline(intercept = 0, slope = seq(0,6,by=1), 
                linetype = "dotted", color = "black")+
    geom_abline(intercept = 0, slope = 0.5, 
                linetype = 1, color = "red")+
    labs(x = "Leverage", y = "Cook's Distance")
```

## 逐步回归

逐步回归是筛选变量，有向前、向后和两个方向同时进行三个方法。

-   `direction = "both"`双向

-   `direction = "backward"`向后

-   `direction = "forward"`向前

```{r}

fit_lm <- lm(sales~.,data = advertising[-1])

fit_step <- stats::step(fit_lm, direction = "both")
summary(fit_step)
```

## 多元线性回归

$$
Y_i=\beta_0+\sum_{i=1}^p \beta_p X_{pi}+\epsilon_i,其中\epsilon_i\sim N(0,\sigma^2)
$$

### `rms::ols()`

```{r}
acl <- read_rds("data/icpsr/advanced_acl_data.rds")
ols_mlm <- rms::ols(SWL_W1 ~ Sex + AGE_W1 + SESCategory ,data = acl)

texreg::texreg(ols_mlm)

car::vif(ols_mlm)
anova(ols_mlm)
```

### `lm()`

```{r}
lm_mlm <- lm_spec |> 
    fit(SWL_W1 ~ Sex + AGE_W1 + SESCategory ,data = acl)

lm_mlm |> glance()
lm_mlm |> tidy()


logLik(lm_mlm$fit)
car::vif(lm_mlm$fit)
```

### `glm()`

```{r}
glm_mlm <- linear_reg() %>%
    set_engine('glm',family=gaussian(link = "identity")) |> 
    fit(SWL_W1 ~ Sex + AGE_W1 + SESCategory ,data = acl)

glm_mlm |> glance()
glm_mlm |> tidy()

summary(glm_mlm$fit)
```

```{r}
#第一步，检测变量相关关系
ad <- advertising |> select(-1)
cor(ad)

#第二步，多元线性回归
lm_sales_multi<- lm_spec |> fit(sales~TV+radio+newspaper,data = advertising)
summary(lm_sales_multi$fit)

tidy(lm_sales_multi)
glance(lm_sales_multi)
```

## 交互项

```{r}
lm_sales_tv_radio <- lm_spec |>  fit(sales ~ TV*radio, data = advertising)

lm_sales_tv_radio
```

```{r}
# pre-processing specification

rec_spec_interact <- recipe(sales ~ TV+radio, data = advertising) |>  
  step_interact(~ TV:radio) 

rec_spec_interact

# combine the linear regression model specification with the pre-processing specification
lm_sales_tv_radio_interact <- workflow() |>  
  add_model(lm_spec) |>  
  add_recipe(rec_spec_interact)  

lm_sales_tv_radio_interact

lm <- lm_sales_tv_radio_interact |> fit(advertising)
tidy(lm)
glance(lm)
```

## 变换

### 非线性变换

```{r}

rec_spec_square <- recipe(sales ~ TV, data = advertising) |>  
  step_mutate(`TV^2` = TV^2)  
rec_spec_square

lm_wf_square <- workflow() |>  
  add_model(lm_spec) |>  
  add_recipe(rec_spec_square)  

lm_wf_square |>
  fit(advertising)

```

### 对数变换

```{r}
rec_spec_log <- recipe(sales ~ TV, data = advertising) |>  
  step_log(TV)  

lm_wf_log <- workflow() |> 
  add_model(lm_spec) |>  
  add_recipe(rec_spec_log) 

lm_wf_log |>
  fit(advertising)
```

## 回归诊断

<https://www.statmethods.net/stats/rdiagnostics.html>

```{r}
library(car)
#回归检验
car::scatterplotMatrix(ad)  # 多重共线性
confint(lm_sales_multi$fit)  # 95%置信区间
plot(lm_sales_multi$fit) #回归诊断图
```

#### 线性假设

残差图

```{r}
plot(lm_sales_multi$fit,1)  
crPlots(lm_sales_multi$fit)
```

#### 正态性假设Q-Q图

Standardized Residuals

```{r}
plot(lm_sales_multi$fit,2) 
summary(powerTransform(lm_sales_multi$fit))  
```

```{r}
plot(lm_sales_tv$fit,3)
```

#### 误差相关性

```{r}
durbinWatsonTest(lm_sales_multi$fit)      #结果表明rho=0
```

#### 误差项的方差齐性

```{r}
ncvTest(lm_sales_multi$fit)
spreadLevelPlot(lm_sales_multi$fit)
```

```{r}
tibble(
    abs_studentized_residuals=abs(rstudent(lm_sales_multi$fit)),
    fitted_values=lm_sales_multi$fit$model$sales
) |> ggplot(aes(fitted_values,abs_studentized_residuals))+
    geom_point(pch=21)+
    geom_smooth()
```

#### 异常观测点

```{r}
# studentized residual Plot
residplot<-function(fit,nbreaks=10){
  z<-rstudent(fit)
  hist(z,breaks=nbreaks,freq=FALSE)     #密度直方图
  title(xlab="Studentized Residual")
  rug(z,col="brown")                    #轴须图
  curve(dnorm(x,mean=mean(z),sd=sd(z)),add=TRUE,col="blue",lwd=2) #正态密度曲线
  lines(density(z)$x,density(z)$y,col="red",lwd=2)       #样本密度曲线
  legend("topright",c("Normal Curve","Kernel Density Curve"),#图例
  lty = c(3,2),pch = c(21,22),col=c("blue","red"),cex=.7)
}
residplot(lm_sales_tv$fit)
```

```{r eval=FALSE}
#######################################################################
library(car)
outlierTest(lm_sales_tv$fit)            #离群点
#高杠杆值点
hat.plot<-function(fit){
  p<-length(coefficients(fit)) #模型估计的参数数目（包含截距项）
  n<-length(fitted(fit))       #样本量
  plot(hatvalues(fit),main="Index Plot of Hat Values")#帽子值
  abline(h=c(2,3)*p/n,col="red",lty=2)  #大于帽子均值p/n的2或3倍被认为是高杠杆值
  identity(1:n,hatvalues(fit),names(hatvalues(fit)))
}
hat.plot(lm_sales_tv$fit)
####强影响点
#Cook's D图形    大于4/(n-k-1)  k为预测变量数目
cutoff<-4/(nrow(advertising)-length(lm_sales_tv$fit$coefficients)-2)
{plot(lm_sales_tv$fit,which=4,cook.levels=cutoff)
abline(h=cutoff,lty=2,col="red")}
#变量添加图
avPlots(lm_sales_tv$fit,ask=FALSE,id.method="identity")

###
influencePlot(lm_sales_tv$fit,id.method="identity",main="Influence Plot")
```

##### Cook's distance

```{r}
plot(lm_sales_tv$fit,4)
```

##### Leverage

```{r}
plot(lm_sales_tv$fit,5)
```

```{r}
plot(lm_sales_tv$fit,6)
```

#### 多重共线性

```{r}
vif(lm_sales_multi$fit)

sqrt(vif(lm_sales_multi$fit))>=2       #vif平方根 ≥2 存在
```

## 模型选择和优化

```{r}
########################两模型比较
lm1 <- lm_spec |> fit(sales~TV+radio+newspaper,data = advertising)
lm2 <- lm_spec |> fit(sales~TV*radio*newspaper,data = advertising[-1])

anova(lm2$fit,lm1$fit) #anova() 嵌套模型


##########################################            AIC 
AIC(lm2$fit,lm1$fit)  # 赤池信息准则  AIC值小的优先选择
#BIC


####################################相对重要性##################################
ad <- scale(advertising[-1])
ad
#R平方贡献率  #相对权重 
relweights<-function(fit,...){
  R<-cor(fit$model)
  nvar<-ncol(R)
  rxx<-R[2:nvar,2:nvar]
  rxy<-R[2:nvar,1]
  svd<-eigen(rxx)
  evec<-svd$vectors
  ev<-svd$values
  delta<-diag(sqrt(ev))
  lambda<-evec %*%delta %*% t(evec)
  lambdaasq<-lambda^2
  beta<-solve(lambda) %*% rxy
  r2<-colSums(beta^2)
  rawwgt<-lambdaasq%*%beta^2
  import<-(rawwgt/r2)*100            #计算相对权重
  import<-data.frame(Weights=import)  #数据框化
  row.names(import)<-names(fit$model[2:nvar])
  import<-import[order(import$Weights),1,drop=FALSE] #升序排序
  dotchart(import$Weights,labels=row.names(import),   #点图
           xlab = "% of R-Square",pch=19,
           main="Relative Importiance of Predictor Variables ",
           sub=paste("Total R-Square =",round(r2,digits = 3)),
  ...)
return(import)
}
relweights(lm1$fit,col="blue")
```

## 线性可加模型

additive model

$$
Y_i=\beta_0+ \beta_1 X_i+  \beta_2 X_i^2+\epsilon_i
$$

$$
Y_i=\beta_0+ \beta_1\times \log(X_i)+\epsilon_i
$$

$$
Y_i=\beta_0+ \beta_1 (X_i\times W_i)+\epsilon_i
$$

$$
Y_i=\beta_0+ \beta_1\times \exp(X_i)+\epsilon_i
$$

$$
Y_i=\beta_0+ \beta_1\times \sin(X_i)+\epsilon_i
$$
