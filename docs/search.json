[
  {
    "objectID": "qualitative_data.html",
    "href": "qualitative_data.html",
    "title": "\n2  定性数据的统计描述\n",
    "section": "",
    "text": "2.1 率\n率（rate）表示在一定空间或时间范围内某现象的发生数与可能发生的总数之比，说明某现象出现的频率。\n标准化率（standardized rate）",
    "crumbs": [
      "描述性统计学",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>定性数据的统计描述</span>"
    ]
  },
  {
    "objectID": "qualitative_data.html#构成比",
    "href": "qualitative_data.html#构成比",
    "title": "\n2  定性数据的统计描述\n",
    "section": "\n2.2 构成比",
    "text": "2.2 构成比\n构成比（proportion）",
    "crumbs": [
      "描述性统计学",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>定性数据的统计描述</span>"
    ]
  },
  {
    "objectID": "qualitative_data.html#相对比",
    "href": "qualitative_data.html#相对比",
    "title": "\n2  定性数据的统计描述\n",
    "section": "\n2.3 相对比",
    "text": "2.3 相对比\n相对比（relative ratio）是A和B两个有关联指标值之比。\n\n2.3.1 RR\nUsing R for Biomedical Statistics\n\n\n相对危险度 （Relative Risk，RR），是指暴露组人群的发病率与非暴露组人群的发病率之比。RR 用于反映暴露因素与结局事件的关联程度， 其 取值范围为 0 到无穷大。数值为 1 时，表明暴露因素与结局事件无关联；小于 1 时，表 明暴露因素导致结局事件的发生率降低；大于 1 时，表明暴露因素导致结局事件的发生率增加。相对风险适用于前瞻性队列研究。\n\nShow the codex &lt;- matrix(c(156,9421,1531,14797),nrow=2,byrow=TRUE,\n             dimnames = list(c(\"Exposed\",\"Unexposed\"),c(\"Disease\",\"Control\")))\n\nx\n#&gt;           Disease Control\n#&gt; Exposed       156    9421\n#&gt; Unexposed    1531   14797\n# RR\n156/(156+9421)*(1531+14797)/1531\n#&gt; [1] 0.1737212\nsource(\"function/calcRelativeRisk.R\")\ncalcRelativeRisk(x,alpha=0.05)\n#&gt; [1] \"category = Exposed , relative risk =  0.173721236521721\"\n#&gt; [1] \"category = Exposed ,  95 % confidence interval = [ 0.147624440337197 , 0.204431379720742 ]\"\n\n# OR\n156/9421/(1531/14797)\n#&gt; [1] 0.1600391\nsource(\"function/calcOddsRatio.R\")\ncalcOddsRatio(x,alpha = 0.05)\n#&gt; [1] \"category = Exposed , odds ratio =  0.160039091621751\"\n#&gt; [1] \"category = Exposed ,  95 % confidence interval = [ 0.135460641900536 , 0.189077140693912 ]\"\n\n\n\n2.3.2 OR\n\n\n优势比（Odds Ratio，OR），是指暴露组中病例与非病例人数的比值除以非暴露组中病例与非病例人数的比值。　　OR 的取值范围也为 0 到无穷大。如果 OR 值大于 1 ，说明该暴露因素更 容易导致结果事件发生，或者说该因素是一个危险因素；小于 1 ，则说明该暴露因素更不 容易导致结果事件发生，或者说该因素是一个保护因素。比值比适用于队列研究和病例对照研究。\n\nShow the codey &lt;- matrix(c(30,24,76,241,82,509),nrow=3,byrow=TRUE,\n            dimnames = list(c(\"Exposure1\",\"Exposure2\",\"Unexposed\"),\n                            c(\"Disease\",\"Control\")))\ny\n#&gt;           Disease Control\n#&gt; Exposure1      30      24\n#&gt; Exposure2      76     241\n#&gt; Unexposed      82     509\ncalcOddsRatio(y, referencerow=3)\n#&gt; [1] \"category = Exposure1 , odds ratio =  7.75914634146342\"\n#&gt; [1] \"category = Exposure1 ,  95 % confidence interval = [ 4.32163714854064 , 13.9309131884372 ]\"\n#&gt; [1] \"category = Exposure2 , odds ratio =  1.95749418075094\"\n#&gt; [1] \"category = Exposure2 ,  95 % confidence interval = [ 1.38263094540732 , 2.77137111707344 ]\"\ncalcRelativeRisk(y, referencerow=3)\n#&gt; [1] \"category = Exposure1 , relative risk =  4.00406504065041\"\n#&gt; [1] \"category = Exposure1 ,  95 % confidence interval = [ 2.93130744422409 , 5.46941498113737 ]\"\n#&gt; [1] \"category = Exposure2 , relative risk =  1.72793721628068\"\n#&gt; [1] \"category = Exposure2 ,  95 % confidence interval = [ 1.30507489771431 , 2.2878127750653 ]\"",
    "crumbs": [
      "描述性统计学",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>定性数据的统计描述</span>"
    ]
  },
  {
    "objectID": "qualitative_data.html#列联表",
    "href": "qualitative_data.html#列联表",
    "title": "\n2  定性数据的统计描述\n",
    "section": "\n2.4 列联表",
    "text": "2.4 列联表\n\nShow the codeeg &lt;- matrix(c(156,9421,1531,14797),nrow=2,byrow=TRUE)\ncolnames(eg) &lt;- c(\"Disease\",\"Control\")\nrownames(eg) &lt;- c(\"Exposed\",\"Unexposed\")\nprint(eg)\n#&gt;           Disease Control\n#&gt; Exposed       156    9421\n#&gt; Unexposed    1531   14797\nprop.table(eg)          #各单元格比例\n#&gt;               Disease   Control\n#&gt; Exposed   0.006022003 0.3636750\n#&gt; Unexposed 0.059100560 0.5712025\nprop.table(eg,margin = 1)        #行比例和=1\n#&gt;              Disease   Control\n#&gt; Exposed   0.01628903 0.9837110\n#&gt; Unexposed 0.09376531 0.9062347",
    "crumbs": [
      "描述性统计学",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>定性数据的统计描述</span>"
    ]
  },
  {
    "objectID": "qualitative_data.html#边际列联表",
    "href": "qualitative_data.html#边际列联表",
    "title": "\n2  定性数据的统计描述\n",
    "section": "\n2.5 边际列联表",
    "text": "2.5 边际列联表\n\nShow the code# 边际\nmargin.table(x=eg,margin = 2)      #列和\n#&gt; Disease Control \n#&gt;    1687   24218\naddmargins(eg)          #添加行和、列和\n#&gt;           Disease Control   Sum\n#&gt; Exposed       156    9421  9577\n#&gt; Unexposed    1531   14797 16328\n#&gt; Sum          1687   24218 25905\naddmargins(eg,1)        #添加列和\n#&gt;           Disease Control\n#&gt; Exposed       156    9421\n#&gt; Unexposed    1531   14797\n#&gt; Sum          1687   24218\naddmargins(eg,2)        #添加行和\n#&gt;           Disease Control   Sum\n#&gt; Exposed       156    9421  9577\n#&gt; Unexposed    1531   14797 16328\naddmargins(prop.table(eg,1))\n#&gt;              Disease   Control Sum\n#&gt; Exposed   0.01628903 0.9837110   1\n#&gt; Unexposed 0.09376531 0.9062347   1\n#&gt; Sum       0.11005434 1.8899457   2\n\nftable(eg)   # \"平铺式\"列联表\n#&gt;            Disease Control\n#&gt;                           \n#&gt; Exposed        156    9421\n#&gt; Unexposed     1531   14797",
    "crumbs": [
      "描述性统计学",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>定性数据的统计描述</span>"
    ]
  },
  {
    "objectID": "qualitative_data.html#关联度量",
    "href": "qualitative_data.html#关联度量",
    "title": "\n2  定性数据的统计描述\n",
    "section": "\n2.6 关联度量",
    "text": "2.6 关联度量\n\n2.6.1 卡方系数\n\nShow the codechisq.test(eg)\n#&gt; \n#&gt;  Pearson's Chi-squared test with Yates' continuity correction\n#&gt; \n#&gt; data:  eg\n#&gt; X-squared = 593.88, df = 1, p-value &lt; 2.2e-16\n\n\n\n2.6.2 列联系数\n\n\nShow the codeContingency &lt;- function(x) {\n    chi &lt;- chisq.test(x)\n    unname(sqrt(chi$statistic / (chi$statistic + sum(x))))\n}\nContingency(eg)\n#&gt; [1] 0.1497052\n\n\n\nShow the codelibrary(DescTools)\n\nContCoef(eg)\n#&gt; [1] 0.1498618\n\n\n\n2.6.3 Phi and Cramer’s V 系数\n\n\n\nShow the code# Phi coefficient\nPhiCoef &lt;- function(x){\n    unname(sqrt(chisq.test(x)$statistic / sum(x)))\n}\n\n# Cramer's V coefficient\nV &lt;- function(x) {\n    unname(sqrt(chisq.test(x)$statistic / (sum(x) * (min(dim(x)) - 1))))\n}\n\n\n\nShow the codePhiCoef(eg) \n#&gt; [1] 0.1514115\nV(eg) \n#&gt; [1] 0.1514115\n\n\n\nShow the codelibrary(DescTools)\nPhi(eg)\n#&gt; [1] 0.1515735\nCramerV(eg)\n#&gt; [1] 0.1515735\n\n\n\nShow the codelibrary(vcd)\n\nassocstats(eg)\n#&gt;                     X^2 df P(&gt; X^2)\n#&gt; Likelihood Ratio 722.30  1        0\n#&gt; Pearson          595.16  1        0\n#&gt; \n#&gt; Phi-Coefficient   : 0.152 \n#&gt; Contingency Coeff.: 0.15 \n#&gt; Cramer's V        : 0.152",
    "crumbs": [
      "描述性统计学",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>定性数据的统计描述</span>"
    ]
  },
  {
    "objectID": "qualitative_data.html#马赛克图",
    "href": "qualitative_data.html#马赛克图",
    "title": "\n2  定性数据的统计描述\n",
    "section": "\n2.7 马赛克图",
    "text": "2.7 马赛克图\n\nShow the codemosaicplot(eg)",
    "crumbs": [
      "描述性统计学",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>定性数据的统计描述</span>"
    ]
  },
  {
    "objectID": "correlation.html",
    "href": "correlation.html",
    "title": "\n3  相关性\n",
    "section": "",
    "text": "3.1 分类变量\nhttps://corrr.tidymodels.org/articles/using-corrr.html\nhttps://easystats.github.io/correlation/\n相关性：判断两个变量之间的相关关系强度和方向，无论是否独立。\n如果独立性检验的结果表明两个变量之间不独立，那么如何量化它们之间相关性的强弱?",
    "crumbs": [
      "描述性统计学",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>相关性</span>"
    ]
  },
  {
    "objectID": "correlation.html#分类变量",
    "href": "correlation.html#分类变量",
    "title": "\n3  相关性\n",
    "section": "",
    "text": "3.1.1 列联系数、Phi 系数和 Cramer’s V 系数\nvcd 包里的函数 assocstats( )可以用来计算列联表的 Phi 系数、列联系数和 Cramer’s V 系数。其中， Phi 系数只适用于四格表。 　　\n\nShow the codelibrary(vcd)\nmytable &lt;- table(Arthritis$Sex, Arthritis$Treatment)\nassocstats(mytable)\n#&gt;                      X^2 df P(&gt; X^2)\n#&gt; Likelihood Ratio 0.73748  1  0.39047\n#&gt; Pearson          0.73653  1  0.39078\n#&gt; \n#&gt; Phi-Coefficient   : 0.094 \n#&gt; Contingency Coeff.: 0.093 \n#&gt; Cramer's V        : 0.094\n\n\n\n3.1.2 Kappa 统计量\n对于配对列联表，可以计算一致性指标 Kappa 统计量。 epiDisplay 包里的函数 kap( )可以用于计算一致性的比例以及 Kappa 统计量的值 　　 　　\n\nShow the codemy.matrix &lt;- matrix(c(11, 2, 12, 33), nrow = 2)\nsum(my.matrix)\n#&gt; [1] 58\nvcd::Kappa(my.matrix)\n#&gt;            value    ASE     z Pr(&gt;|z|)\n#&gt; Unweighted 0.455 0.1153 3.945 7.97e-05\n#&gt; Weighted   0.455 0.1153 3.945 7.97e-05\nepiDisplay::kap(my.matrix)\n#&gt; \n#&gt;  Table for calculation of kappa\n#&gt;    A  B\n#&gt; A 11 12\n#&gt; B  2 33\n#&gt; \n#&gt; Observed agreement = 75.86 % \n#&gt; Expected agreement = 55.71 % \n#&gt; Kappa = 0.455 \n#&gt; Standard error = 0.121 , Z = 3.762 , P value = &lt; 0.001 \n#&gt; \n\n\n　　共 58 个对象，每一对象用两种检测方法检测，其中11 个对象的两种检测结果都为阳性， 33 个对象的两种检测结果都是阴性，所以总一致性为 (11 + 33)/58 ≈ 75.86% 。\n\nShow the codechisq.test(my.matrix)$expected\n#&gt;          [,1]     [,2]\n#&gt; [1,] 5.155172 17.84483\n#&gt; [2,] 7.844828 27.15517\n\n\n　为了解释期望一致性和 Kappa 值的含义，先计算各个单元格的期望频数。 对角线上的这两个单元格对应的期望频数分别约为5.155172 和27.15517 ，因此期望一致性为 (5.155172+27.15517)/58≈ 55.71% 。期望一致性是假定两种方法的检测结果都是完全随机的情况下的 一致性。也就是说，即使两种检测方法都毫无作用，平均也能达到 55.71% 的一致性。 Kappa 统计量是超出随机的一致性的部分占最大可能超出随机的一致性的比例。在本例中，前者为 75.86% − 55.71% ， 后者为 100% − 55.71% 。 因此， Kappa 值为 (75.86 - 55.71)/(100 - 55.71) ≈ 0.455\n\n3.1.3 马赛克图\n　　马赛克图中的矩形面积正比于多维列联表中单元格的频率 　　\n\nShow the codemosaicplot(mytable,xlab =\"Sex\",ylab =  \"Treatment\",las = 1)\n\n\n\n\n\n\nShow the codemosaicplot(my.matrix)",
    "crumbs": [
      "描述性统计学",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>相关性</span>"
    ]
  },
  {
    "objectID": "correlation.html#连续变量",
    "href": "correlation.html#连续变量",
    "title": "\n3  相关性\n",
    "section": "\n3.2 连续变量",
    "text": "3.2 连续变量\n如果两个连续变量不相互独立时，使用协方差（covariance）来描述两个变量的关系。\n协方差（或相关系数）为零，不相关，不存在线性关系，但可能存在非线性关系。\n\nShow the codedf &lt;- mpg[,c(3,8,9)]\ncov(df)    # 协方差矩阵\n#&gt;           displ      cty       hwy\n#&gt; displ  1.669158 -4.39069 -5.893111\n#&gt; cty   -4.390690 18.11307 24.225432\n#&gt; hwy   -5.893111 24.22543 35.457779\n\n\n\n3.2.0.1 相关系数\n相关系数的取值范围： \\([-1,1]\\)\n\\[\nr(X,Y)=\\frac {\\sum_{i=1}^n (x_i-\\bar x)(y_i-\\bar y)}{\\sqrt{\\sum_{i=1}^n (x_i-\\bar x)^2 \\sum_{i=1}^n (y_i-\\bar y)^2}}\n\\]\n\nShow the code# Pearson's 积差相关系数 　　一般要求两个连续变量都服从正态分布\ncor(df,use = \"everything\",method=\"pearson\") # default\n#&gt;           displ        cty        hwy\n#&gt; displ  1.000000 -0.7985240 -0.7660200\n#&gt; cty   -0.798524  1.0000000  0.9559159\n#&gt; hwy   -0.766020  0.9559159  1.0000000\n\ncorrelation::correlation(df,method = \"pearson\",p_adjust = \"holm\")\n#&gt; # Correlation Matrix (pearson-method)\n#&gt; \n#&gt; Parameter1 | Parameter2 |     r |         95% CI | t(232) |         p\n#&gt; ---------------------------------------------------------------------\n#&gt; displ      |        cty | -0.80 | [-0.84, -0.75] | -20.21 | &lt; .001***\n#&gt; displ      |        hwy | -0.77 | [-0.81, -0.71] | -18.15 | &lt; .001***\n#&gt; cty        |        hwy |  0.96 | [ 0.94,  0.97] |  49.58 | &lt; .001***\n#&gt; \n#&gt; p-value adjustment method: Holm (1979)\n#&gt; Observations: 234\n\n# Spearman's rank相关系数  　　非参数\ncor(df,method = \"spearman\")\n#&gt;            displ        cty        hwy\n#&gt; displ  1.0000000 -0.8809049 -0.8266576\n#&gt; cty   -0.8809049  1.0000000  0.9542104\n#&gt; hwy   -0.8266576  0.9542104  1.0000000\n\ncorrelation::correlation(df,method = \"spearman\",p_adjust = \"holm\")\n#&gt; # Correlation Matrix (spearman-method)\n#&gt; \n#&gt; Parameter1 | Parameter2 |   rho |         95% CI |        S |         p\n#&gt; -----------------------------------------------------------------------\n#&gt; displ      |        cty | -0.88 | [-0.91, -0.85] | 4.02e+06 | &lt; .001***\n#&gt; displ      |        hwy | -0.83 | [-0.86, -0.78] | 3.90e+06 | &lt; .001***\n#&gt; cty        |        hwy |  0.95 | [ 0.94,  0.96] | 97781.21 | &lt; .001***\n#&gt; \n#&gt; p-value adjustment method: Holm (1979)\n#&gt; Observations: 234\n\n# Kendall's tau相关系数  　　非参数\ncor(df,method = \"kendall\")\n#&gt;            displ        cty        hwy\n#&gt; displ  1.0000000 -0.7210828 -0.6536974\n#&gt; cty   -0.7210828  1.0000000  0.8628045\n#&gt; hwy   -0.6536974  0.8628045  1.0000000\ncorrelation::correlation(df,method = \"kendall\",p_adjust = \"holm\")\n#&gt; # Correlation Matrix (kendall-method)\n#&gt; \n#&gt; Parameter1 | Parameter2 |   tau |         95% CI |      z |         p\n#&gt; ---------------------------------------------------------------------\n#&gt; displ      |        cty | -0.72 | [-0.76, -0.68] | -15.54 | &lt; .001***\n#&gt; displ      |        hwy | -0.65 | [-0.70, -0.60] | -14.14 | &lt; .001***\n#&gt; cty        |        hwy |  0.86 | [ 0.84,  0.88] |  18.40 | &lt; .001***\n#&gt; \n#&gt; p-value adjustment method: Holm (1979)\n#&gt; Observations: 234\n\n\n\n3.2.0.2 相关图（correlogram）\n\nShow the codeggcorrplot::ggcorrplot(\n    corr = cor(df,use = \"everything\",method=\"pearson\") ,\n    lab = T\n)\n\n\n\n\n\n\n\n\n3.2.0.3 显著性检验\n　　零假设为变量之间不相关（即两个总体的相关系数为 0 ） 。函数 cor.test( ) 可用于对相关系数进行显著性检 验。\n统计量\n\\[\nt=\\frac{r\\sqrt{n-2}}{\\sqrt{1-r^2}}\n\\]\n\nShow the codecor.test(df$displ,df$hwy)\n#&gt; \n#&gt;  Pearson's product-moment correlation\n#&gt; \n#&gt; data:  df$displ and df$hwy\n#&gt; t = -18.151, df = 232, p-value &lt; 2.2e-16\n#&gt; alternative hypothesis: true correlation is not equal to 0\n#&gt; 95 percent confidence interval:\n#&gt;  -0.8142727 -0.7072539\n#&gt; sample estimates:\n#&gt;      cor \n#&gt; -0.76602\n\n\npsych包corr.test() 计算相关系数矩阵和显著性检验\n\nShow the codepsych::corr.test(df)\n#&gt; Call:psych::corr.test(x = df)\n#&gt; Correlation matrix \n#&gt;       displ   cty   hwy\n#&gt; displ  1.00 -0.80 -0.77\n#&gt; cty   -0.80  1.00  0.96\n#&gt; hwy   -0.77  0.96  1.00\n#&gt; Sample Size \n#&gt; [1] 234\n#&gt; Probability values (Entries above the diagonal are adjusted for multiple tests.) \n#&gt;       displ cty hwy\n#&gt; displ     0   0   0\n#&gt; cty       0   0   0\n#&gt; hwy       0   0   0\n#&gt; \n#&gt;  To see confidence intervals of the correlations, print with the short=FALSE option\n\nprint(psych::corr.test(df), short = FALSE)\n#&gt; Call:psych::corr.test(x = df)\n#&gt; Correlation matrix \n#&gt;       displ   cty   hwy\n#&gt; displ  1.00 -0.80 -0.77\n#&gt; cty   -0.80  1.00  0.96\n#&gt; hwy   -0.77  0.96  1.00\n#&gt; Sample Size \n#&gt; [1] 234\n#&gt; Probability values (Entries above the diagonal are adjusted for multiple tests.) \n#&gt;       displ cty hwy\n#&gt; displ     0   0   0\n#&gt; cty       0   0   0\n#&gt; hwy       0   0   0\n#&gt; \n#&gt;  Confidence intervals based upon normal theory.  To get bootstrapped values, try cor.ci\n#&gt;           raw.lower raw.r raw.upper raw.p lower.adj upper.adj\n#&gt; displ-cty     -0.84 -0.80     -0.75     0     -0.85     -0.74\n#&gt; displ-hwy     -0.81 -0.77     -0.71     0     -0.81     -0.71\n#&gt; cty-hwy        0.94  0.96      0.97     0      0.94      0.97",
    "crumbs": [
      "描述性统计学",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>相关性</span>"
    ]
  },
  {
    "objectID": "normality_test.html",
    "href": "normality_test.html",
    "title": "\n4  正态性检验\n",
    "section": "",
    "text": "4.1 描述性统计方法\n统计检验与假设",
    "crumbs": [
      "假设检验",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>正态性检验</span>"
    ]
  },
  {
    "objectID": "normality_test.html#描述性统计方法",
    "href": "normality_test.html#描述性统计方法",
    "title": "\n4  正态性检验\n",
    "section": "",
    "text": "4.1.1 密度图\n密度图提供了关于分布是否为钟形的视觉判断\n\nShow the codeggdensity(df$ctrl, fill = \"lightgray\") +\n   #  stat_overlay_normal_density(color = \"red\", linetype = \"dashed\")+\n    xlim(c(mean(df$ctrl) - 3 * sd(df$ctrl), \n           mean(df$ctrl) + 3 * sd(df$ctrl)))\n\n\n\n\n\n\n\n\n4.1.2 Q-Q图\nQ-Q图（或分位数-分位数图）绘制给定样本与正态分布之间的相关性。还绘制了一条 45 度参考线。在 QQ 图中，每个观测值都绘制为一个点。如果数据是正常的，则点应形成一条直线。\n\nShow the codeggqqplot(df$ctrl)\n\n\n\n\n\n\n\n\nShow the codenorm &lt;- rnorm(1000,10,3)\nggqqplot(norm)\n\n\n\n\n\n\nShow the codeunif &lt;- runif(1000,5,15)\nggqqplot(unif)\n\n\n\n\n\n\nShow the code\nexp &lt;- rexp(1000,1)\nggqqplot(exp)",
    "crumbs": [
      "假设检验",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>正态性检验</span>"
    ]
  },
  {
    "objectID": "normality_test.html#基于卡方分布",
    "href": "normality_test.html#基于卡方分布",
    "title": "\n4  正态性检验\n",
    "section": "\n4.2 基于卡方分布",
    "text": "4.2 基于卡方分布\n\n4.2.1 D’Agostino-Pearson Omnibus Test\nD’Agostino-Pearson test\nD’Agostino-Pearson 综合检验 是基于数据的偏度和峰度来评估数据是否接近正态分布的。\n\n首先计算偏斜度和峰度，以量化分布在不对称性和形状方面与高斯分布的差距。然后，其计算这些值中的每一个与高斯分布的预期值之间的差异，并基于这些差异的总和，计算各P值。这是一种通用和强大的正态性检验，通常推荐使用。但值得注意的是，该建议也有例外。具体而言，当该分布的偏度和峰度非常接近正态分布的偏度和峰度，但肯定是非正态分布时，该检验将无法将该分布确定为非正态分布。\n\n\n\n\n在R语言中，可以使用 moments 包中的 agostino.test() 函数来执行此检验。此检验的原假设是数据来自正态分布，如果检验的p值小于显著性水平（通常是0.05），则可以拒绝原假设，认为数据不服从正态分布。\n\nShow the code# 样本偏度和峰度\nskewness &lt;- moments::skewness(df$ctrl,na.rm = T)\nkurtosis &lt;- moments::kurtosis(df$ctrl,na.rm = T)\n\n# 偏度检验\nmoments::agostino.test(df$ctrl)\n#&gt; \n#&gt;  D'Agostino skewness test\n#&gt; \n#&gt; data:  df$ctrl\n#&gt; skew = -0.20140, z = -0.41707, p-value = 0.6766\n#&gt; alternative hypothesis: data have a skewness\n\n# 峰度检验\nmoments::anscombe.test(df$ctrl)\n#&gt; \n#&gt;  Anscombe-Glynn kurtosis test\n#&gt; \n#&gt; data:  df$ctrl\n#&gt; kurt = 1.96325, z = -0.99736, p-value = 0.3186\n#&gt; alternative hypothesis: kurtosis is not equal to 3\n\n\n# D'Agostino's K² 检验\nK2 &lt;- length(df$ctrl) * (skewness^2 / 6 + (kurtosis - 3)^2 / 24)\np_value &lt;- 1 - pchisq(K2, df = 2)\n\nK2\n#&gt; [1] 0.8247351\np_value\n#&gt; [1] 0.6620809\n\n\n\n4.2.2 Jarque-Bera 正态性检验\nJarque-Bera检验也是一种基于样本偏度和峰度的正态性检验方法。\n\n\n\n\n\nShow the codeif(!require(tseries)){install.packages('tseries')}\ntseries::jarque.bera.test(df$ctrl)\n#&gt; \n#&gt;  Jarque Bera Test\n#&gt; \n#&gt; data:  df$ctrl\n#&gt; X-squared = 0.82474, df = 2, p-value = 0.6621\ntseries::jarque.bera.test(df$trt)\n#&gt; \n#&gt;  Jarque Bera Test\n#&gt; \n#&gt; data:  df$trt\n#&gt; X-squared = 0.69681, df = 2, p-value = 0.7058\n\n\n\n4.2.3 Pearson’s X2 test\n\nShow the code\n\nnortest::pearson.test(df$ctrl)\n#&gt; \n#&gt;  Pearson chi-square normality test\n#&gt; \n#&gt; data:  df$ctrl\n#&gt; P = 2.375, p-value = 0.6671\nnortest::pearson.test(df$trt)\n#&gt; \n#&gt;  Pearson chi-square normality test\n#&gt; \n#&gt; data:  df$trt\n#&gt; P = 3.25, p-value = 0.5169",
    "crumbs": [
      "假设检验",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>正态性检验</span>"
    ]
  },
  {
    "objectID": "normality_test.html#基于回归和相关",
    "href": "normality_test.html#基于回归和相关",
    "title": "\n4  正态性检验\n",
    "section": "\n4.3 基于回归和相关",
    "text": "4.3 基于回归和相关\n\n4.3.1 Shapiro-Wilk’s test\nShapiro-Wilk检验而是将数据的实际SD与根据数据的QQ图斜率计算的SD进行比较，并计算其比率。如果数据从高斯分布中采样，则两个值将相似，因此比率将接近1.0，而比率与1相差很大则表明为非正态分布。如果每个值均唯一，则Shapiro-Wilk检验非常有效，但如果几个值均相同，则不那么有效。推荐样本量 7~2000。\n这些检验的原假设是“样本分布是正态的”。如果检验显著，则分布为非正态分布。Shapiro-Wilk 方法被广泛推荐用于正态性检验，它提供了比 K-S 更好的功率。 它基于数据与相应的正常分数之间的相关性。\n\n\n\n\n\n\nNote\n\n\n\n正态性检验对样本量很敏感。小样本通常通过正态性检验。因此，为了做出正确的决定，将图示法和显著性检验结合起来是很重要的。如果样本数量大于 50，则首选正态 QQ 图，因为在较大的样本量下，Shapiro-Wilk 检验变得非常敏感，即使与正态的微小偏差也是如此。\n\n\n\nShow the codemap_df(df,~ shapiro.test(.x)[c(\"statistic\",\"p.value\")])\n#&gt; # A tibble: 2 × 2\n#&gt;   statistic p.value\n#&gt;       &lt;dbl&gt;   &lt;dbl&gt;\n#&gt; 1     0.961   0.676\n#&gt; 2     0.966   0.763\ndf %&gt;% shapiro_test(ctrl,trt)\n#&gt; # A tibble: 2 × 3\n#&gt;   variable statistic     p\n#&gt;   &lt;chr&gt;        &lt;dbl&gt; &lt;dbl&gt;\n#&gt; 1 ctrl         0.961 0.676\n#&gt; 2 trt          0.966 0.763\n\n\n\nShow the codeToothGrowth %&gt;%\n  group_by(dose) %&gt;%\n  shapiro_test(len)\n#&gt; # A tibble: 3 × 4\n#&gt;    dose variable statistic     p\n#&gt;   &lt;dbl&gt; &lt;chr&gt;        &lt;dbl&gt; &lt;dbl&gt;\n#&gt; 1   0.5 len          0.941 0.247\n#&gt; 2   1   len          0.931 0.164\n#&gt; 3   2   len          0.978 0.902\n\n\n\nShow the code# Shapiro Wilk normality test for two variables\niris %&gt;% shapiro_test(Sepal.Length, Petal.Width)\n#&gt; # A tibble: 2 × 3\n#&gt;   variable     statistic            p\n#&gt;   &lt;chr&gt;            &lt;dbl&gt;        &lt;dbl&gt;\n#&gt; 1 Petal.Width      0.902 0.0000000168\n#&gt; 2 Sepal.Length     0.976 0.0102\n\n\n\nShow the code# Multivariate normality test\nmshapiro_test(iris[, 1:3])\n#&gt; # A tibble: 1 × 2\n#&gt;   statistic p.value\n#&gt;       &lt;dbl&gt;   &lt;dbl&gt;\n#&gt; 1     0.991   0.443",
    "crumbs": [
      "假设检验",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>正态性检验</span>"
    ]
  },
  {
    "objectID": "normality_test.html#基于经验分布函数empirical-distribution-function",
    "href": "normality_test.html#基于经验分布函数empirical-distribution-function",
    "title": "\n4  正态性检验\n",
    "section": "\n4.4 基于经验分布函数（empirical distribution function）",
    "text": "4.4 基于经验分布函数（empirical distribution function）\n\n4.4.1 Kolmogorov-Smirnov (K-S) test\nKolmogorov-Smirnov检验（K-S检验），这是一种非参数检验方法，用于比较一个样本的累积分布函数（CDF）与某个理论CDF的差异。需要指定总体的均值和方差\n不建议使用Kolmogorov-Smirnov检验。但在大样本（&gt;2000）实用\n\nShow the codeks.test(df$ctrl,\"pnorm\",mean=mean(df$ctrl),sd=sd(df$ctrl))\n#&gt; Warning in ks.test.default(df$ctrl, \"pnorm\", mean = mean(df$ctrl), sd =\n#&gt; sd(df$ctrl)): ties should not be present for the one-sample Kolmogorov-Smirnov\n#&gt; test\n#&gt; \n#&gt;  Asymptotic one-sample Kolmogorov-Smirnov test\n#&gt; \n#&gt; data:  df$ctrl\n#&gt; D = 0.13004, p-value = 0.9496\n#&gt; alternative hypothesis: two-sided\n\n\n在执行单样本Kolmogorov-Smirnov检验时，数据中不应该存在“ties”，即不应该有重复的数值。如果存在重复的数值，它会影响检验的有效性，因为K-S检验对数据中的“ties”敏感。此时，可以考虑使用其他对“ties”不敏感的检验方法，例如Shapiro-Wilk检验或Lilliefors检验。\n\n4.4.2 Lilliefors test\nLilliefors test 是一个修改版的K-S检验，它使用样本均值和标准差来标准化数据，然后与标准正态分布进行比较\n\nShow the codenortest::lillie.test(df$ctrl)\n#&gt; \n#&gt;  Lilliefors (Kolmogorov-Smirnov) normality test\n#&gt; \n#&gt; data:  df$ctrl\n#&gt; D = 0.13004, p-value = 0.6656\nnortest::lillie.test(df$trt)\n#&gt; \n#&gt;  Lilliefors (Kolmogorov-Smirnov) normality test\n#&gt; \n#&gt; data:  df$trt\n#&gt; D = 0.11011, p-value = 0.87\n\n\n\n4.4.3 Anderson-Darling test\nAnderson-Darling test 是基于累积分布函数（CDF）的比较，通过计算观测值与理论分布之间的差异程度来评估数据的拟合程度。在R语言中，可以使用 nortest 包中的 ad.test() 函数来执行此检验291011。此检验的原假设同样是数据服从正态分布，如果p值小于显著性水平，则拒绝原假设，认为数据不服从正态分布。对尾部敏感，适用于中等样本量的数据\n\nShow the codenortest::ad.test(df$ctrl)\n#&gt; \n#&gt;  Anderson-Darling normality test\n#&gt; \n#&gt; data:  df$ctrl\n#&gt; A = 0.24254, p-value = 0.7247\nnortest::ad.test(df$trt)\n#&gt; \n#&gt;  Anderson-Darling normality test\n#&gt; \n#&gt; data:  df$trt\n#&gt; A = 0.24294, p-value = 0.7233",
    "crumbs": [
      "假设检验",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>正态性检验</span>"
    ]
  },
  {
    "objectID": "normality_test.html#数据变换",
    "href": "normality_test.html#数据变换",
    "title": "\n4  正态性检验\n",
    "section": "\n4.5 数据变换",
    "text": "4.5 数据变换\n\n4.5.1 中度偏度-平方根变换\n\nShow the codelibrary(moments)\nskewness(iris$Sepal.Length, na.rm = TRUE)\n#&gt; [1] 0.3117531\ne1071::skewness(iris$Sepal.Length, na.rm = TRUE)\n#&gt; [1] 0.3086407\n\n\n\nsqrt(x)对于正偏态数据，\nsqrt(max(x+1) - x)对于负偏态数据\n\n4.5.2 更偏态-对数变换\n\nlog10(x)对于正偏态数据，\nlog10(max(x+1) - x)对于负偏态数据\n\n4.5.3 非常偏态-倒数\n\n1/x对于正偏态数据\n1/(max(x+1) - x)对于负偏态数据\n\n4.5.4 线性度和异方差性\nLinearity and heteroscedasticity\n\n首先，在因变量随着自变量值的增加而开始更快地增加的情况下尝试log 变换\n如果数据与此相反（因变量值随着自变量值的增加而减少得更快）可以考虑square变换\n\n\nShow the codelibrary(ggpubr)\nlibrary(moments)\ndata(\"USJudgeRatings\")\ndf &lt;- USJudgeRatings\nhead(df)\n#&gt;                CONT INTG DMNR DILG CFMG DECI PREP FAMI ORAL WRIT PHYS RTEN\n#&gt; AARONSON,L.H.   5.7  7.9  7.7  7.3  7.1  7.4  7.1  7.1  7.1  7.0  8.3  7.8\n#&gt; ALEXANDER,J.M.  6.8  8.9  8.8  8.5  7.8  8.1  8.0  8.0  7.8  7.9  8.5  8.7\n#&gt; ARMENTANO,A.J.  7.2  8.1  7.8  7.8  7.5  7.6  7.5  7.5  7.3  7.4  7.9  7.8\n#&gt; BERDON,R.I.     6.8  8.8  8.5  8.8  8.3  8.5  8.7  8.7  8.4  8.5  8.8  8.7\n#&gt; BRACKEN,J.J.    7.3  6.4  4.3  6.5  6.0  6.2  5.7  5.7  5.1  5.3  5.5  4.8\n#&gt; BURNS,E.B.      6.2  8.8  8.7  8.5  7.9  8.0  8.1  8.0  8.0  8.0  8.6  8.6\n\n\n\nShow the code# Distribution of CONT variable\nggdensity(df, x = \"CONT\", fill = \"lightgray\", title = \"CONT\") +\n  scale_x_continuous(limits = c(3, 12)) +\n  stat_overlay_normal_density(color = \"red\", linetype = \"dashed\")\n\n\n\n\n\n\nShow the code\n# Distribution of PHYS variable\nggdensity(df, x = \"PHYS\", fill = \"lightgray\", title = \"PHYS\") +\n  scale_x_continuous(limits = c(3, 12)) +\n  stat_overlay_normal_density(color = \"red\", linetype = \"dashed\")\n\n\n\n\n\n\n\n\nShow the codeskewness(df$CONT, na.rm = TRUE)\n#&gt; [1] 1.085972\nskewness(df$PHYS, na.rm = TRUE)\n#&gt; [1] -1.558215\n\n\n\n4.5.5 Box-Cox 幂次变换\n\nShow the codebc &lt;- car::powerTransform(df)\n\nbc\n#&gt; Estimated transformation parameters \n#&gt;       CONT       INTG       DMNR       DILG       CFMG       DECI       PREP \n#&gt; -0.9819079  3.8646573  3.1866054  3.0071768  3.2197291  2.8949756  2.2797376 \n#&gt;       FAMI       ORAL       WRIT       PHYS       RTEN \n#&gt;  2.0508085  2.4118066  2.2521739  4.9918792  3.3428550\nsummary(bc)\n#&gt; bcPower Transformations to Multinormality \n#&gt;      Est Power Rounded Pwr Wald Lwr Bnd Wald Upr Bnd\n#&gt; CONT   -0.9819        0.00      -2.7096       0.7458\n#&gt; INTG    3.8647        3.86       2.3656       5.3637\n#&gt; DMNR    3.1866        3.19       2.1669       4.2063\n#&gt; DILG    3.0072        2.00       1.9536       4.0607\n#&gt; CFMG    3.2197        3.22       2.1068       4.3326\n#&gt; DECI    2.8950        2.00       1.6568       4.1332\n#&gt; PREP    2.2797        2.00       1.5568       3.0026\n#&gt; FAMI    2.0508        2.00       1.1463       2.9553\n#&gt; ORAL    2.4118        2.00       1.8057       3.0180\n#&gt; WRIT    2.2522        2.00       1.5698       2.9346\n#&gt; PHYS    4.9919        4.99       3.1346       6.8491\n#&gt; RTEN    3.3429        3.34       2.5902       4.0955\n#&gt; \n#&gt; Likelihood ratio test that transformation parameters are equal to 0\n#&gt;  (all log transformations)\n#&gt;                                                  LRT df       pval\n#&gt; LR test, lambda = (0 0 0 0 0 0 0 0 0 0 0 0) 121.8881 12 &lt; 2.22e-16\n#&gt; \n#&gt; Likelihood ratio test that no transformations are needed\n#&gt;                                                  LRT df       pval\n#&gt; LR test, lambda = (1 1 1 1 1 1 1 1 1 1 1 1) 61.75316 12 1.0794e-08",
    "crumbs": [
      "假设检验",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>正态性检验</span>"
    ]
  },
  {
    "objectID": "variance_homogeneity_test.html",
    "href": "variance_homogeneity_test.html",
    "title": "\n5  方差齐性检验\n",
    "section": "",
    "text": "5.1 两样本",
    "crumbs": [
      "假设检验",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>方差齐性检验</span>"
    ]
  },
  {
    "objectID": "variance_homogeneity_test.html#两样本",
    "href": "variance_homogeneity_test.html#两样本",
    "title": "\n5  方差齐性检验\n",
    "section": "",
    "text": "5.1.1 F 检验\nF 检验：比较两组的方差。数据必须呈正态分布。\n步骤：\n\n检查数据是否呈正态分布（例如使用 Shapiro-Wilk 检验）。\n进行 F 检验以比较两组的方差。\n\n\nShow the codedf &lt;- tibble(\n    ctrl=c(2,6,13,5,8,9,12,11,8,10,12,14,13,6,7,4),\n    trt=c(8,6,8,9,12,12,14,15,16,17,14,12,11,8,10,10)\n)\ndf %&gt;% \n    DT::datatable()\n\n\n\n\nShow the codevar.test(df$ctrl,df$trt)\n#&gt; \n#&gt;  F test to compare two variances\n#&gt; \n#&gt; data:  df$ctrl and df$trt\n#&gt; F = 1.2553, num df = 15, denom df = 15, p-value = 0.6653\n#&gt; alternative hypothesis: true ratio of variances is not equal to 1\n#&gt; 95 percent confidence interval:\n#&gt;  0.4385898 3.5927405\n#&gt; sample estimates:\n#&gt; ratio of variances \n#&gt;           1.255285\n\nres &lt;- var.test(len ~ supp, data = ToothGrowth)\nres\n#&gt; \n#&gt;  F test to compare two variances\n#&gt; \n#&gt; data:  len by supp\n#&gt; F = 0.6386, num df = 29, denom df = 29, p-value = 0.2331\n#&gt; alternative hypothesis: true ratio of variances is not equal to 1\n#&gt; 95 percent confidence interval:\n#&gt;  0.3039488 1.3416857\n#&gt; sample estimates:\n#&gt; ratio of variances \n#&gt;          0.6385951\n\n\np 值为 p = 0.2，大于显著性水平 0.05，可以认为两个方差之间没有显著差异。",
    "crumbs": [
      "假设检验",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>方差齐性检验</span>"
    ]
  },
  {
    "objectID": "variance_homogeneity_test.html#多样本",
    "href": "variance_homogeneity_test.html#多样本",
    "title": "\n5  方差齐性检验\n",
    "section": "\n5.2 多样本",
    "text": "5.2 多样本\n\n5.2.1 Bartlett 检验\nBartlett 检验：比较两组或多组的方差。数据必须呈正态分布。\n具有一个自变量的 Bartlett 检验\n\nShow the coderes &lt;- bartlett.test(weight ~ group, data = PlantGrowth)\nres\n#&gt; \n#&gt;  Bartlett test of homogeneity of variances\n#&gt; \n#&gt; data:  weight by group\n#&gt; Bartlett's K-squared = 2.8786, df = 2, p-value = 0.2371\n\n\n具有多个自变量的 Bartlett 检验：必须使用interaction（） 函数将多个因子折叠成一个包含因子所有组合的变量\n\nShow the code\nwith(ToothGrowth,interaction(supp,dose)) |&gt; levels()\n#&gt; [1] \"OJ.0.5\" \"VC.0.5\" \"OJ.1\"   \"VC.1\"   \"OJ.2\"   \"VC.2\"\n\n\n\nbartlett.test(len ~ interaction(supp,dose), data=ToothGrowth)\n#&gt; \n#&gt;  Bartlett test of homogeneity of variances\n#&gt; \n#&gt; data:  len by interaction(supp, dose)\n#&gt; Bartlett's K-squared = 6.9273, df = 5, p-value = 0.2261\n\n\n\n5.2.2 Levene’s 检验\nLevene’s 检验：Bartlett 检验的可靠替代方案，对偏离正态不太敏感。\n\n\nLevene 检验有三个版本：\n\n使用平均值（原始）\n使用中位数（Brown-Forsythe扩展）\n10% trimmed mean（Brown-Forsythe扩展）\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nLevene 检验是文献中最常用的检验。\n\n\n\nShow the codelibrary(car)\n# Levene's test with one independent variable\nleveneTest(weight ~ group, data = PlantGrowth,center=mean)\n#&gt; Levene's Test for Homogeneity of Variance (center = mean)\n#&gt;       Df F value Pr(&gt;F)\n#&gt; group  2   1.237 0.3062\n#&gt;       27\nleveneTest(weight ~ group, data = PlantGrowth,center=mean,trim=0.1)\n#&gt; Levene's Test for Homogeneity of Variance (center = mean: 0.1)\n#&gt;       Df F value Pr(&gt;F)\n#&gt; group  2  1.2777  0.295\n#&gt;       27\nleveneTest(weight ~ group, data = PlantGrowth,center=median)\n#&gt; Levene's Test for Homogeneity of Variance (center = median)\n#&gt;       Df F value Pr(&gt;F)\n#&gt; group  2  1.1192 0.3412\n#&gt;       27\n\nrstatix::levene_test(PlantGrowth,weight ~ group,center = mean)\n#&gt; # A tibble: 1 × 4\n#&gt;     df1   df2 statistic     p\n#&gt;   &lt;int&gt; &lt;int&gt;     &lt;dbl&gt; &lt;dbl&gt;\n#&gt; 1     2    27      1.24 0.306\n\n\n\nShow the code# Levene's test with multiple independent variables\nToothGrowth$dose &lt;- factor(ToothGrowth$dose)\nleveneTest(len ~ supp*dose, data = ToothGrowth)\n#&gt; Levene's Test for Homogeneity of Variance (center = median)\n#&gt;       Df F value Pr(&gt;F)\n#&gt; group  5  1.7086 0.1484\n#&gt;       54\n\n\n\nBrown-Forsythe 检验 作为 Levene 检验的扩展，特别适用于处理非正态数据。\n\n\nShow the codeleveneTest(weight ~ group, data = PlantGrowth,center=median)\n#&gt; Levene's Test for Homogeneity of Variance (center = median)\n#&gt;       Df F value Pr(&gt;F)\n#&gt; group  2  1.1192 0.3412\n#&gt;       27\nHH::hov(weight ~ group, data = PlantGrowth)\n#&gt; \n#&gt;  hov: Brown-Forsyth\n#&gt; \n#&gt; data:  weight\n#&gt; F = 1.1192, df:group = 2, df:Residuals = 27, p-value = 0.3412\n#&gt; alternative hypothesis: variances are not identical\n\n\n\n5.2.3 Fligner-Killeen 检验\nFligner-Killeen 检验：一种非参数检验，对偏离正态非常稳健。\n\nShow the codefligner.test(weight ~ group, data = PlantGrowth)\n#&gt; \n#&gt;  Fligner-Killeen test of homogeneity of variances\n#&gt; \n#&gt; data:  weight by group\n#&gt; Fligner-Killeen:med chi-squared = 2.3499, df = 2, p-value = 0.3088",
    "crumbs": [
      "假设检验",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>方差齐性检验</span>"
    ]
  },
  {
    "objectID": "repeated_measures_anova.html",
    "href": "repeated_measures_anova.html",
    "title": "\n8  重复测量方差分析\n",
    "section": "",
    "text": "8.1 假设\n重复测量方差分析用于分析重复测量数据中组间和组内自变量对因变量的影响。模型形式为：\n\\[\nY_{ijk}=\\mu +\\alpha_i +\\beta_j +(\\alpha\\beta)_{ij}+S_k+(\\beta S)_{jk}+\\epsilon_{ijk}\n\\] 其中，\\(Y_{ijk}\\) 是第i 个组、第j 个时间点或条件下、第k 个受试者的测量值，\\(\\alpha_i\\) 是组间效应，\\(\\beta_j\\) 时间效应或条件效应，\\((\\alpha\\beta)_{ij}\\) 是组效应与时间效应的交互效应，\\(S_k\\) 是第 k 个受试者的效应（通常被视为随机效应），\\((\\beta S)_{jk}\\) 是时间效应与受试者效应的交互作用（也通常被视为随机效应）， \\(\\epsilon_{ijk}\\) 是误差项。",
    "crumbs": [
      "假设检验",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>重复测量方差分析</span>"
    ]
  },
  {
    "objectID": "repeated_measures_anova.html#假设",
    "href": "repeated_measures_anova.html#假设",
    "title": "\n8  重复测量方差分析\n",
    "section": "",
    "text": "独立性，即不同受试者之间的观测值是独立的。\n正态性，观测值在每个时间点或条件下的正态分布。\n各组内的方差齐性（sphericity），即组内相关性结构是已知的，通常假设为复合对称（compound symmetry）。协方差矩阵的球形检验（W=1）\n\n\n\n\n\n\n\nNote\n\n\n\n\n复合对称假设：RM-ANOVA假设误差项具有复合对称性，即组内相关性和方差齐性。如果复合对称假设不成立，结果可能不准确，可以使用更为灵活的线性混合模型（LMM）或广义估计方程（GEE）进行分析。\n检验方法：RM-ANOVA的主要检验方法包括F检验，用于检验组效应、时间效应和交互作用是否显著。",
    "crumbs": [
      "假设检验",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>重复测量方差分析</span>"
    ]
  },
  {
    "objectID": "repeated_measures_anova.html#单因素重复测量方差分析",
    "href": "repeated_measures_anova.html#单因素重复测量方差分析",
    "title": "\n8  重复测量方差分析\n",
    "section": "\n8.2 单因素重复测量方差分析",
    "text": "8.2 单因素重复测量方差分析\n\n8.2.1 公式\n\\[\nSS_T=\\sum_{j=1}^{t}\\sum_{i=1}^{n}X_{ij}^2-\\frac{(\\sum_{j=1}^{t}\\sum_{i=1}^{n}X_{ij})^2}{nt}=SS_{受试者间}+SS_{不同时间点}+SS_{E\\ \\ 随机误差}，\\nu_T=nt-1\n\\]\n\\[\nSS_{受试者间}=\\frac{\\sum_{i}(\\sum_{j}X_{ij})^2}{t}-C，\\nu_{受试者}=n-1\n\\]反映了在受试者间的变异。\n\\[\nSS_{不同时间点}=\\frac{\\sum_{j}(\\sum_{i}X_{ij})^2}{n}-C ，\\nu_{时间点}=t-1\n\\]反映了在每个受试者内不同时间点的重复测量变异。\n\\[\nSS_E=SS_T-SS_{受试者间}-SS_{不同时间点}，\\nu_E=(n-1)(t-1)\n\\]\n\\(H_0:\\mu_1=\\mu_2=...=\\mu_t\\)，检验统计量\n\\[\nF=\\frac{MS_{不同时间点}}{MS_E}=\\frac{SS_{不同时间点}/(t-1)}{SS_E/((n-1)(t-1))}\n\\]\n\nShow the codeALT &lt;- tribble(\n    ~id,~zero,~ten,~twenty,~thirty,\n    1,186,122,134,110,\n    2,345,312,268,176,\n    3,98,84,52,61,\n    4,288,98,91,85,\n    5,176,86,130,99,\n    6,210,188,143,120,\n    7,271,322,86,65,\n    8,415,332,265,186,\n    9,171,126,130,135,\n    10,243,330,95,64,\n)\nALT_long &lt;-\n    ALT |&gt; pivot_longer(cols = -1,\n                       names_to = \"week\",\n                       values_to = \"ALT\") |&gt; \n    mutate(week = factor(week, levels = c(\"zero\",\"ten\", \"twenty\", \"thirty\")))\n\n\n# 假设检验\nALT_long %&gt;% \n    group_by(week) %&gt;% \n    rstatix::shapiro_test(ALT)\n#&gt; # A tibble: 4 × 4\n#&gt;   week   variable statistic      p\n#&gt;   &lt;fct&gt;  &lt;chr&gt;        &lt;dbl&gt;  &lt;dbl&gt;\n#&gt; 1 zero   ALT          0.972 0.906 \n#&gt; 2 ten    ALT          0.796 0.0131\n#&gt; 3 twenty ALT          0.834 0.0378\n#&gt; 4 thirty ALT          0.907 0.262\n\n\n\nShow the code# 总变异\nxij_sum &lt;- sum(ALT_long$ALT)\nxij_square_sum &lt;- sum(ALT_long$ALT^2)\nC &lt;- xij_sum^2/40\nSS_T &lt;- xij_square_sum-C\n\n# 受试者间  \nxi._sum &lt;- rowSums(ALT[,-1])\nxi._sum\n#&gt;  [1]  552 1101  295  562  491  661  744 1198  562  732\nSS_B &lt;- sum(xi._sum^2)/4-C #行和平方和\nMS_B &lt;- SS_B/9\n\n# 不同时间点\nx.j_sum &lt;- colSums(ALT[,-1])\nx.j_sum\n#&gt;   zero    ten twenty thirty \n#&gt;   2403   2000   1394   1101\nSS_W &lt;- sum(x.j_sum^2)/10-C #列和平方和\nMS_W &lt;- SS_W/3\n\n\n\nSS_E &lt;- SS_T-SS_B-SS_W\nMS_E &lt;- SS_E/(9*3)\n\nF_stat &lt;- MS_W/MS_E\nF_stat\n#&gt; [1] 11.13855\n\nv1 = 4-1\nv2 = (4-1)*(10-1)\n\npf(F_stat, df1 = v1, df2 = v2, lower.tail = F)\n#&gt; [1] 6.170758e-05\n\ncat(\"F统计量：\", F_stat, \"\\n\",\n    \"p值：\",pf(F_stat, df1 = v1, df2 = v2, lower.tail = F))\n#&gt; F统计量： 11.13855 \n#&gt;  p值： 6.170758e-05\n\n\n\n8.2.2 nlme::lme()\n\n\nShow the codelibrary(nlme)\nALT_lme &lt;- lme(fixed=ALT ~ week, random = ~1| id/week, data = ALT_long)\n\nALT_aov &lt;- anova.lme(ALT_lme)\nALT_aov \n#&gt;             numDF denDF  F-value p-value\n#&gt; (Intercept)     1    27 62.98194  &lt;.0001\n#&gt; week            3    27 11.13855   1e-04\nALT_aov$`p-value`\n#&gt; [1] 1.569667e-08 6.170758e-05\n\n\n事后检验\n\nShow the code#成对比较\nlibrary(emmeans)\nemmeans(ALT_lme, pairwise ~week, adjust = \"bonferroni\") \n#&gt; $emmeans\n#&gt;  week   emmean   SE df lower.CL upper.CL\n#&gt;  zero      240 26.5  9    180.3      300\n#&gt;  ten       200 26.5  9    140.0      260\n#&gt;  twenty    139 26.5  9     79.4      199\n#&gt;  thirty    110 26.5  9     50.1      170\n#&gt; \n#&gt; Degrees-of-freedom method: containment \n#&gt; Confidence level used: 0.95 \n#&gt; \n#&gt; $contrasts\n#&gt;  contrast        estimate   SE df t.ratio p.value\n#&gt;  zero - ten          40.3 24.9 27   1.620  0.7014\n#&gt;  zero - twenty      100.9 24.9 27   4.055  0.0023\n#&gt;  zero - thirty      130.2 24.9 27   5.233  0.0001\n#&gt;  ten - twenty        60.6 24.9 27   2.436  0.1305\n#&gt;  ten - thirty        89.9 24.9 27   3.613  0.0073\n#&gt;  twenty - thirty     29.3 24.9 27   1.178  1.0000\n#&gt; \n#&gt; Degrees-of-freedom method: containment \n#&gt; P value adjustment: bonferroni method for 6 tests\nemmeans(ALT_lme,  ~week) %&gt;% pairs(., adjust = \"bonferroni\")\n#&gt;  contrast        estimate   SE df t.ratio p.value\n#&gt;  zero - ten          40.3 24.9 27   1.620  0.7014\n#&gt;  zero - twenty      100.9 24.9 27   4.055  0.0023\n#&gt;  zero - thirty      130.2 24.9 27   5.233  0.0001\n#&gt;  ten - twenty        60.6 24.9 27   2.436  0.1305\n#&gt;  ten - thirty        89.9 24.9 27   3.613  0.0073\n#&gt;  twenty - thirty     29.3 24.9 27   1.178  1.0000\n#&gt; \n#&gt; Degrees-of-freedom method: containment \n#&gt; P value adjustment: bonferroni method for 6 tests\n\n\n\nShow the codelibrary(multcomp)\nALT_posthoc &lt;-glht(ALT_lme, linfct = mcp(week =c(\"zero - ten = 0 \",\n                                               \"twenty - zero == 0\",\n                                               \"thirty - zero = 0 \")))\nsummary(ALT_posthoc) %&gt;% broom::tidy()\n#&gt; # A tibble: 3 × 7\n#&gt;   term  contrast      null.value estimate std.error statistic adj.p.value\n#&gt;   &lt;chr&gt; &lt;chr&gt;              &lt;dbl&gt;    &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;       &lt;dbl&gt;\n#&gt; 1 week  zero - ten             0     40.3      24.9      1.62 0.248      \n#&gt; 2 week  twenty - zero          0   -101.       24.9     -4.06 0.000136   \n#&gt; 3 week  thirty - zero          0   -130.       24.9     -5.23 0.000000482",
    "crumbs": [
      "假设检验",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>重复测量方差分析</span>"
    ]
  },
  {
    "objectID": "repeated_measures_anova.html#含组间因子的重复测量方差分析",
    "href": "repeated_measures_anova.html#含组间因子的重复测量方差分析",
    "title": "\n8  重复测量方差分析\n",
    "section": "\n8.3 含组间因子的重复测量方差分析",
    "text": "8.3 含组间因子的重复测量方差分析\n\n8.3.1 公式\n\\[\n\\begin{aligned}\nSS_总&= SS_{受试对象间}+SS_{受试对象内}  \\\\\n&=（SS_{处理方法}+SS_{个体间差异}）+（SS_{时间}+SS_{处理与时间交互}+SS_{个体内差异}）\n\\end{aligned}\n\\]\nhttps://personality-project.org/r/r.guide/r.anova.html#oneway\n\n8.3.2 案例\n孙振球（医学统计学第四版 人卫版，例12-3，P193）\n\nShow the code# 医学统计学 人卫版 第7版\nSBP &lt;- read_tsv(\"data/麻醉诱导时相.tsv\")\nSBP\n#&gt; # A tibble: 15 × 7\n#&gt;       id group    t0    t1    t2    t3    t4\n#&gt;    &lt;dbl&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n#&gt;  1     1 A       120   108   112   120   117\n#&gt;  2     2 A       118   109   115   126   123\n#&gt;  3     3 A       119   112   119   124   118\n#&gt;  4     4 A       121   112   119   126   120\n#&gt;  5     5 A       127   121   127   133   126\n#&gt;  6     6 B       121   120   118   131   137\n#&gt;  7     7 B       122   121   119   129   133\n#&gt;  8     8 B       128   129   126   135   142\n#&gt;  9     9 B       117   115   111   123   131\n#&gt; 10    10 B       118   114   116   123   133\n#&gt; 11    11 C       131   119   118   135   129\n#&gt; 12    12 C       129   128   121   148   132\n#&gt; 13    13 C       123   123   120   143   136\n#&gt; 14    14 C       123   121   116   145   126\n#&gt; 15    15 C       125   124   118   142   130\n\n\n\nShow the codeSBP_long &lt;- SBP |&gt; pivot_longer(cols = starts_with(\"t\"),\n                              names_to = \"time\",\n                              values_to = \"SBP\") |&gt; \n    mutate(\n        id=factor(id),\n        group=factor(group),\n        time=factor(time)\n    )\n\nSBP_long %&gt;% head()\n#&gt; # A tibble: 6 × 4\n#&gt;   id    group time    SBP\n#&gt;   &lt;fct&gt; &lt;fct&gt; &lt;fct&gt; &lt;dbl&gt;\n#&gt; 1 1     A     t0      120\n#&gt; 2 1     A     t1      108\n#&gt; 3 1     A     t2      112\n#&gt; 4 1     A     t3      120\n#&gt; 5 1     A     t4      117\n#&gt; 6 2     A     t0      118\n\n\n\nShow the code# 正态性检验\nlibrary(rstatix)\nSBP_long %&gt;% group_by(time,group) %&gt;% \n    shapiro_test(SBP)\n#&gt; # A tibble: 15 × 5\n#&gt;    group time  variable statistic     p\n#&gt;    &lt;fct&gt; &lt;fct&gt; &lt;chr&gt;        &lt;dbl&gt; &lt;dbl&gt;\n#&gt;  1 A     t0    SBP          0.836 0.154\n#&gt;  2 B     t0    SBP          0.916 0.503\n#&gt;  3 C     t0    SBP          0.867 0.254\n#&gt;  4 A     t1    SBP          0.834 0.148\n#&gt;  5 B     t1    SBP          0.913 0.485\n#&gt;  6 C     t1    SBP          0.978 0.921\n#&gt;  7 A     t2    SBP          0.940 0.666\n#&gt;  8 B     t2    SBP          0.969 0.869\n#&gt;  9 C     t2    SBP          0.953 0.758\n#&gt; 10 A     t3    SBP          0.937 0.647\n#&gt; 11 B     t3    SBP          0.902 0.421\n#&gt; 12 C     t3    SBP          0.941 0.672\n#&gt; 13 A     t4    SBP          0.943 0.687\n#&gt; 14 B     t4    SBP          0.892 0.367\n#&gt; 15 C     t4    SBP          0.984 0.955\n\n\n\n8.3.2.1 nlme::lme()\n\n\nShow the code# 第一种方法\nlibrary(nlme)\nSBP_lme &lt;- lme(SBP ~ group*time, random = ~ 1 |id/time, data = SBP_long)\n# summary(SBP_lme)\nanova(SBP_lme)\n#&gt;             numDF denDF   F-value p-value\n#&gt; (Intercept)     1    48 14649.223  &lt;.0001\n#&gt; group           2    12     5.783  0.0174\n#&gt; time            4    48   106.558  &lt;.0001\n#&gt; group:time      8    48    19.101  &lt;.0001\n# 看不到球形检验\n\n\n# 事后检验 成对比较\nlibrary(emmeans)\n# 如果交互效应不显著\n\n## 时间点事后检验\nSBP_long %&gt;%\n  pairwise_t_test(SBP ~ time, p.adjust.method = \"none\", detailed = TRUE)\n#&gt; # A tibble: 10 × 10\n#&gt;    .y.   group1 group2    n1    n2        p method   p.adj p.signif p.adj.signif\n#&gt;  * &lt;chr&gt; &lt;chr&gt;  &lt;chr&gt;  &lt;int&gt; &lt;int&gt;    &lt;dbl&gt; &lt;chr&gt;    &lt;dbl&gt; &lt;chr&gt;    &lt;chr&gt;       \n#&gt;  1 SBP   t0     t1        15    15  6.81e-2 T-test 6.81e-2 ns       ns          \n#&gt;  2 SBP   t0     t2        15    15  6.41e-2 T-test 6.41e-2 ns       ns          \n#&gt;  3 SBP   t1     t2        15    15  9.78e-1 T-test 9.78e-1 ns       ns          \n#&gt;  4 SBP   t0     t3        15    15  1.78e-4 T-test 1.78e-4 ***      ***         \n#&gt;  5 SBP   t1     t3        15    15  1.67e-7 T-test 1.67e-7 ****     ****        \n#&gt;  6 SBP   t2     t3        15    15  1.49e-7 T-test 1.49e-7 ****     ****        \n#&gt;  7 SBP   t0     t4        15    15  1.28e-2 T-test 1.28e-2 *        *           \n#&gt;  8 SBP   t1     t4        15    15  3.68e-5 T-test 3.68e-5 ****     ****        \n#&gt;  9 SBP   t2     t4        15    15  3.32e-5 T-test 3.32e-5 ****     ****        \n#&gt; 10 SBP   t3     t4        15    15  1.65e-1 T-test 1.65e-1 ns       ns\n\nemmeans(SBP_lme,pairwise ~time, adjust = \"none\")  \n#&gt; $emmeans\n#&gt;  time emmean   SE df lower.CL upper.CL\n#&gt;  t0      123 1.16 12      120      125\n#&gt;  t1      118 1.16 12      116      121\n#&gt;  t2      118 1.16 12      116      121\n#&gt;  t3      132 1.16 12      130      135\n#&gt;  t4      129 1.16 12      126      131\n#&gt; \n#&gt; Results are averaged over the levels of: group \n#&gt; Degrees-of-freedom method: containment \n#&gt; Confidence level used: 0.95 \n#&gt; \n#&gt; $contrasts\n#&gt;  contrast estimate    SE df t.ratio p.value\n#&gt;  t0 - t1    4.4000 0.855 48   5.147  &lt;.0001\n#&gt;  t0 - t2    4.4667 0.855 48   5.225  &lt;.0001\n#&gt;  t0 - t3   -9.4000 0.855 48 -10.995  &lt;.0001\n#&gt;  t0 - t4   -6.0667 0.855 48  -7.096  &lt;.0001\n#&gt;  t1 - t2    0.0667 0.855 48   0.078  0.9382\n#&gt;  t1 - t3  -13.8000 0.855 48 -16.142  &lt;.0001\n#&gt;  t1 - t4  -10.4667 0.855 48 -12.243  &lt;.0001\n#&gt;  t2 - t3  -13.8667 0.855 48 -16.220  &lt;.0001\n#&gt;  t2 - t4  -10.5333 0.855 48 -12.321  &lt;.0001\n#&gt;  t3 - t4    3.3333 0.855 48   3.899  0.0003\n#&gt; \n#&gt; Results are averaged over the levels of: group \n#&gt; Degrees-of-freedom method: containment\n\n## 组间事后检验\nemmeans(SBP_lme,pairwise ~group, adjust = \"none\")  # 与spss一样\n#&gt; $emmeans\n#&gt;  group emmean   SE df lower.CL upper.CL\n#&gt;  A        120 1.78 14      116      123\n#&gt;  B        124 1.78 12      121      128\n#&gt;  C        128 1.78 12      124      132\n#&gt; \n#&gt; Results are averaged over the levels of: time \n#&gt; Degrees-of-freedom method: containment \n#&gt; Confidence level used: 0.95 \n#&gt; \n#&gt; $contrasts\n#&gt;  contrast estimate   SE df t.ratio p.value\n#&gt;  A - B       -4.80 2.51 12  -1.911  0.0802\n#&gt;  A - C       -8.52 2.51 12  -3.392  0.0054\n#&gt;  B - C       -3.72 2.51 12  -1.481  0.1644\n#&gt; \n#&gt; Results are averaged over the levels of: time \n#&gt; Degrees-of-freedom method: containment\n\n# 此处交互效应显著\n# 1. 简单组别效应 与SPSS一样\nSBP_long %&gt;% group_by(time) %&gt;% anova_test(SBP~group)\n#&gt; # A tibble: 5 × 8\n#&gt;   time  Effect   DFn   DFd      F        p `p&lt;.05`   ges\n#&gt; * &lt;fct&gt; &lt;chr&gt;  &lt;dbl&gt; &lt;dbl&gt;  &lt;dbl&gt;    &lt;dbl&gt; &lt;chr&gt;   &lt;dbl&gt;\n#&gt; 1 t0    group      2    12  2.93  0.092    \"\"      0.328\n#&gt; 2 t1    group      2    12  6.03  0.015    \"*\"     0.501\n#&gt; 3 t2    group      2    12  0.022 0.979    \"\"      0.004\n#&gt; 4 t3    group      2    12 17.0   0.000312 \"*\"     0.74 \n#&gt; 5 t4    group      2    12 17.4   0.000286 \"*\"     0.743\n\n# 2. 各时间点处理组成对比较  用的是未调整的p值，无法观察到标准误\nSBP_long %&gt;%\n  group_by(time) %&gt;%\n  pairwise_t_test(SBP ~ group, \n                  p.adjust.method = \"bonferroni\", detailed = TRUE)\n#&gt; # A tibble: 15 × 11\n#&gt;    time  .y.   group1 group2    n1    n2         p method    p.adj p.signif\n#&gt;  * &lt;fct&gt; &lt;chr&gt; &lt;chr&gt;  &lt;chr&gt;  &lt;int&gt; &lt;int&gt;     &lt;dbl&gt; &lt;chr&gt;     &lt;dbl&gt; &lt;chr&gt;   \n#&gt;  1 t0    SBP   A      B          5     5 0.936     T-test 1        ns      \n#&gt;  2 t0    SBP   A      C          5     5 0.0539    T-test 0.162    ns      \n#&gt;  3 t0    SBP   B      C          5     5 0.0623    T-test 0.187    ns      \n#&gt;  4 t1    SBP   A      B          5     5 0.0358    T-test 0.107    *       \n#&gt;  5 t1    SBP   A      C          5     5 0.00541   T-test 0.0162   **      \n#&gt;  6 t1    SBP   B      C          5     5 0.327     T-test 0.981    ns      \n#&gt;  7 t2    SBP   A      B          5     5 0.894     T-test 1        ns      \n#&gt;  8 t2    SBP   A      C          5     5 0.947     T-test 1        ns      \n#&gt;  9 t2    SBP   B      C          5     5 0.842     T-test 1        ns      \n#&gt; 10 t3    SBP   A      B          5     5 0.456     T-test 1        ns      \n#&gt; 11 t3    SBP   A      C          5     5 0.000161  T-test 0.000483 ***     \n#&gt; 12 t3    SBP   B      C          5     5 0.000585  T-test 0.00175  ***     \n#&gt; 13 t4    SBP   A      B          5     5 0.0000887 T-test 0.000266 ****    \n#&gt; 14 t4    SBP   A      C          5     5 0.00201   T-test 0.00602  **      \n#&gt; 15 t4    SBP   B      C          5     5 0.0901    T-test 0.27     ns      \n#&gt; # ℹ 1 more variable: p.adj.signif &lt;chr&gt;\n\n\n\n8.3.2.2 rstatix::anova_test() 看球形检验 W统计量\n\nShow the codelibrary(rstatix)\naov_SBP &lt;- anova_test(data = SBP_long,\n           dv = SBP,\n           wid = id,\n           within = time,\n           between = group,\n           type = \"3\"\n           )\n\naov_SBP\n#&gt; ANOVA Table (type III tests)\n#&gt; \n#&gt; $ANOVA\n#&gt;       Effect DFn DFd       F        p p&lt;.05   ges\n#&gt; 1      group   2  12   5.783 1.70e-02     * 0.430\n#&gt; 2       time   4  48 106.558 3.02e-23     * 0.659\n#&gt; 3 group:time   8  48  19.101 1.62e-12     * 0.409\n#&gt; \n#&gt; $`Mauchly's Test for Sphericity`\n#&gt;       Effect     W     p p&lt;.05\n#&gt; 1       time 0.293 0.178      \n#&gt; 2 group:time 0.293 0.178      \n#&gt; \n#&gt; $`Sphericity Corrections`\n#&gt;       Effect   GGe      DF[GG]    p[GG] p[GG]&lt;.05   HFe      DF[HF]    p[HF]\n#&gt; 1       time 0.679 2.71, 32.58 1.87e-16         * 0.896 3.59, 43.03 4.65e-21\n#&gt; 2 group:time 0.679 5.43, 32.58 4.26e-09         * 0.896 7.17, 43.03 2.04e-11\n#&gt;   p[HF]&lt;.05\n#&gt; 1         *\n#&gt; 2         *\n\n# 进行事后检验，若交互效应不显著\n\nSBP_long %&gt;%\n  group_by(time) %&gt;%\n  pairwise_t_test(SBP ~ group, p.adjust.method = \"bonferroni\", detailed = TRUE)\n#&gt; # A tibble: 15 × 11\n#&gt;    time  .y.   group1 group2    n1    n2         p method    p.adj p.signif\n#&gt;  * &lt;fct&gt; &lt;chr&gt; &lt;chr&gt;  &lt;chr&gt;  &lt;int&gt; &lt;int&gt;     &lt;dbl&gt; &lt;chr&gt;     &lt;dbl&gt; &lt;chr&gt;   \n#&gt;  1 t0    SBP   A      B          5     5 0.936     T-test 1        ns      \n#&gt;  2 t0    SBP   A      C          5     5 0.0539    T-test 0.162    ns      \n#&gt;  3 t0    SBP   B      C          5     5 0.0623    T-test 0.187    ns      \n#&gt;  4 t1    SBP   A      B          5     5 0.0358    T-test 0.107    *       \n#&gt;  5 t1    SBP   A      C          5     5 0.00541   T-test 0.0162   **      \n#&gt;  6 t1    SBP   B      C          5     5 0.327     T-test 0.981    ns      \n#&gt;  7 t2    SBP   A      B          5     5 0.894     T-test 1        ns      \n#&gt;  8 t2    SBP   A      C          5     5 0.947     T-test 1        ns      \n#&gt;  9 t2    SBP   B      C          5     5 0.842     T-test 1        ns      \n#&gt; 10 t3    SBP   A      B          5     5 0.456     T-test 1        ns      \n#&gt; 11 t3    SBP   A      C          5     5 0.000161  T-test 0.000483 ***     \n#&gt; 12 t3    SBP   B      C          5     5 0.000585  T-test 0.00175  ***     \n#&gt; 13 t4    SBP   A      B          5     5 0.0000887 T-test 0.000266 ****    \n#&gt; 14 t4    SBP   A      C          5     5 0.00201   T-test 0.00602  **      \n#&gt; 15 t4    SBP   B      C          5     5 0.0901    T-test 0.27     ns      \n#&gt; # ℹ 1 more variable: p.adj.signif &lt;chr&gt;\n\n\n\n8.3.2.3 afex::aov_*()看各时间点处理组成对比较和各处理组时间点成对比较\nhttps://cran.r-project.org/web/packages/afex/vignettes/afex_anova_example.html\n\nShow the codelibrary(\"afex\")     \nlibrary(\"emmeans\") \n# aov_car(SBP ~ group + Error(id/time), data = SBP_long)\n# aov_4(SBP ~ group + (time|id), data = SBP_long)\n\nSBP_aovez &lt;- aov_ez(id = \"id\",\n                    dv =  \"SBP\",\n                    data =  SBP_long, \n                    between =\"group\" , \n                    within = c(\"time\")\n                    )\nSBP_aovez\n#&gt; Anova Table (Type 3 tests)\n#&gt; \n#&gt; Response: SBP\n#&gt;       Effect          df   MSE          F  ges p.value\n#&gt; 1      group       2, 12 78.87     5.78 * .430    .017\n#&gt; 2       time 2.71, 32.58  8.08 106.56 *** .659   &lt;.001\n#&gt; 3 group:time 5.43, 32.58  8.08  19.10 *** .409   &lt;.001\n#&gt; ---\n#&gt; Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '+' 0.1 ' ' 1\n#&gt; \n#&gt; Sphericity correction method: GG\n\nSBP_aovez %&gt;% summary()\n#&gt; \n#&gt; Univariate Type III Repeated-Measures ANOVA Assuming Sphericity\n#&gt; \n#&gt;              Sum Sq num Df Error SS den Df    F value    Pr(&gt;F)    \n#&gt; (Intercept) 1155433      1   946.48     12 14649.2234 &lt; 2.2e-16 ***\n#&gt; group           912      2   946.48     12     5.7829   0.01743 *  \n#&gt; time           2336      4   263.12     48   106.5576 &lt; 2.2e-16 ***\n#&gt; group:time      838      8   263.12     48    19.1006 1.621e-12 ***\n#&gt; ---\n#&gt; Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n#&gt; \n#&gt; \n#&gt; Mauchly Tests for Sphericity\n#&gt; \n#&gt;            Test statistic p-value\n#&gt; time              0.29307 0.17766\n#&gt; group:time        0.29307 0.17766\n#&gt; \n#&gt; \n#&gt; Greenhouse-Geisser and Huynh-Feldt Corrections\n#&gt;  for Departure from Sphericity\n#&gt; \n#&gt;             GG eps Pr(&gt;F[GG])    \n#&gt; time       0.67869  &lt; 2.2e-16 ***\n#&gt; group:time 0.67869  4.263e-09 ***\n#&gt; ---\n#&gt; Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n#&gt; \n#&gt;              HF eps   Pr(&gt;F[HF])\n#&gt; time       0.896371 4.649080e-21\n#&gt; group:time 0.896371 2.041727e-11\n\n# 多变量检验\nsummary(SBP_aovez$Anova)\n#&gt; \n#&gt; Type III Repeated Measures MANOVA Tests:\n#&gt; \n#&gt; ------------------------------------------\n#&gt;  \n#&gt; Term: (Intercept) \n#&gt; \n#&gt;  Response transformation matrix:\n#&gt;    (Intercept)\n#&gt; t0           1\n#&gt; t1           1\n#&gt; t2           1\n#&gt; t3           1\n#&gt; t4           1\n#&gt; \n#&gt; Sum of squares and products for the hypothesis:\n#&gt;             (Intercept)\n#&gt; (Intercept)     5777165\n#&gt; \n#&gt; Multivariate Tests: (Intercept)\n#&gt;                  Df test stat approx F num Df den Df     Pr(&gt;F)    \n#&gt; Pillai            1    0.9992 14649.22      1     12 &lt; 2.22e-16 ***\n#&gt; Wilks             1    0.0008 14649.22      1     12 &lt; 2.22e-16 ***\n#&gt; Hotelling-Lawley  1 1220.7686 14649.22      1     12 &lt; 2.22e-16 ***\n#&gt; Roy               1 1220.7686 14649.22      1     12 &lt; 2.22e-16 ***\n#&gt; ---\n#&gt; Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n#&gt; \n#&gt; ------------------------------------------\n#&gt;  \n#&gt; Term: group \n#&gt; \n#&gt;  Response transformation matrix:\n#&gt;    (Intercept)\n#&gt; t0           1\n#&gt; t1           1\n#&gt; t2           1\n#&gt; t3           1\n#&gt; t4           1\n#&gt; \n#&gt; Sum of squares and products for the hypothesis:\n#&gt;             (Intercept)\n#&gt; (Intercept)      4561.2\n#&gt; \n#&gt; Multivariate Tests: group\n#&gt;                  Df test stat approx F num Df den Df   Pr(&gt;F)  \n#&gt; Pillai            2 0.4907894 5.782943      2     12 0.017434 *\n#&gt; Wilks             2 0.5092106 5.782943      2     12 0.017434 *\n#&gt; Hotelling-Lawley  2 0.9638239 5.782943      2     12 0.017434 *\n#&gt; Roy               2 0.9638239 5.782943      2     12 0.017434 *\n#&gt; ---\n#&gt; Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n#&gt; \n#&gt; ------------------------------------------\n#&gt;  \n#&gt; Term: time \n#&gt; \n#&gt;  Response transformation matrix:\n#&gt;    time1 time2 time3 time4\n#&gt; t0     1     0     0     0\n#&gt; t1     0     1     0     0\n#&gt; t2     0     0     1     0\n#&gt; t3     0     0     0     1\n#&gt; t4    -1    -1    -1    -1\n#&gt; \n#&gt; Sum of squares and products for the hypothesis:\n#&gt;           time1     time2     time3     time4\n#&gt; time1  552.0667  952.4667  958.5333 -303.3333\n#&gt; time2  952.4667 1643.2667 1653.7333 -523.3333\n#&gt; time3  958.5333 1653.7333 1664.2667 -526.6667\n#&gt; time4 -303.3333 -523.3333 -526.6667  166.6667\n#&gt; \n#&gt; Multivariate Tests: time\n#&gt;                  Df test stat approx F num Df den Df     Pr(&gt;F)    \n#&gt; Pillai            1   0.98255 126.6592      4      9 6.6475e-08 ***\n#&gt; Wilks             1   0.01745 126.6592      4      9 6.6475e-08 ***\n#&gt; Hotelling-Lawley  1  56.29299 126.6592      4      9 6.6475e-08 ***\n#&gt; Roy               1  56.29299 126.6592      4      9 6.6475e-08 ***\n#&gt; ---\n#&gt; Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n#&gt; \n#&gt; ------------------------------------------\n#&gt;  \n#&gt; Term: group:time \n#&gt; \n#&gt;  Response transformation matrix:\n#&gt;    time1 time2 time3 time4\n#&gt; t0     1     0     0     0\n#&gt; t1     0     1     0     0\n#&gt; t2     0     0     1     0\n#&gt; t3     0     0     0     1\n#&gt; t4    -1    -1    -1    -1\n#&gt; \n#&gt; Sum of squares and products for the hypothesis:\n#&gt;          time1    time2    time3    time4\n#&gt; time1 524.9333 284.3333 507.0667 534.3333\n#&gt; time2 284.3333 184.1333 227.4667 396.3333\n#&gt; time3 507.0667 227.4667 563.7333 348.6667\n#&gt; time4 534.3333 396.3333 348.6667 923.3333\n#&gt; \n#&gt; Multivariate Tests: group:time\n#&gt;                  Df test stat approx F num Df den Df     Pr(&gt;F)    \n#&gt; Pillai            2  1.808841 23.65627      8     20 1.3857e-08 ***\n#&gt; Wilks             2  0.008458 22.21451      8     18 7.9942e-08 ***\n#&gt; Hotelling-Lawley  2 20.599670 20.59967      8     16 4.8560e-07 ***\n#&gt; Roy               2 13.375814 33.43953      4     10 9.2057e-06 ***\n#&gt; ---\n#&gt; Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n#&gt; \n#&gt; Univariate Type III Repeated-Measures ANOVA Assuming Sphericity\n#&gt; \n#&gt;              Sum Sq num Df Error SS den Df    F value    Pr(&gt;F)    \n#&gt; (Intercept) 1155433      1   946.48     12 14649.2234 &lt; 2.2e-16 ***\n#&gt; group           912      2   946.48     12     5.7829   0.01743 *  \n#&gt; time           2336      4   263.12     48   106.5576 &lt; 2.2e-16 ***\n#&gt; group:time      838      8   263.12     48    19.1006 1.621e-12 ***\n#&gt; ---\n#&gt; Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n#&gt; \n#&gt; \n#&gt; Mauchly Tests for Sphericity\n#&gt; \n#&gt;            Test statistic p-value\n#&gt; time              0.29307 0.17766\n#&gt; group:time        0.29307 0.17766\n#&gt; \n#&gt; \n#&gt; Greenhouse-Geisser and Huynh-Feldt Corrections\n#&gt;  for Departure from Sphericity\n#&gt; \n#&gt;             GG eps Pr(&gt;F[GG])    \n#&gt; time       0.67869  &lt; 2.2e-16 ***\n#&gt; group:time 0.67869  4.263e-09 ***\n#&gt; ---\n#&gt; Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n#&gt; \n#&gt;              HF eps   Pr(&gt;F[HF])\n#&gt; time       0.896371 4.649080e-21\n#&gt; group:time 0.896371 2.041727e-11\n# 事后检验 不调整与SPSS一样\n\n## 看各时间点处理组成对比较\nemmeans::emmeans(SBP_aovez ,  ~ group|time, adjust = \"none\") %&gt;% pairs()\n#&gt; time = t0:\n#&gt;  contrast estimate   SE df t.ratio p.value\n#&gt;  A - B        -0.2 2.43 12  -0.082  0.9963\n#&gt;  A - C        -5.2 2.43 12  -2.137  0.1238\n#&gt;  B - C        -5.0 2.43 12  -2.055  0.1415\n#&gt; \n#&gt; time = t1:\n#&gt;  contrast estimate   SE df t.ratio p.value\n#&gt;  A - B        -7.4 3.13 12  -2.364  0.0847\n#&gt;  A - C       -10.6 3.13 12  -3.386  0.0139\n#&gt;  B - C        -3.2 3.13 12  -1.022  0.5776\n#&gt; \n#&gt; time = t2:\n#&gt;  contrast estimate   SE df t.ratio p.value\n#&gt;  A - B         0.4 2.95 12   0.136  0.9899\n#&gt;  A - C        -0.2 2.95 12  -0.068  0.9975\n#&gt;  B - C        -0.6 2.95 12  -0.204  0.9774\n#&gt; \n#&gt; time = t3:\n#&gt;  contrast estimate   SE df t.ratio p.value\n#&gt;  A - B        -2.4 3.11 12  -0.771  0.7272\n#&gt;  A - C       -16.8 3.11 12  -5.396  0.0004\n#&gt;  B - C       -14.4 3.11 12  -4.625  0.0016\n#&gt; \n#&gt; time = t4:\n#&gt;  contrast estimate   SE df t.ratio p.value\n#&gt;  A - B       -14.4 2.50 12  -5.771  0.0002\n#&gt;  A - C        -9.8 2.50 12  -3.927  0.0053\n#&gt;  B - C         4.6 2.50 12   1.843  0.1975\n#&gt; \n#&gt; P value adjustment: tukey method for comparing a family of 3 estimates\n\n\n\n## 看各处理组时间点成对比较\nemmeans::emmeans(SBP_aovez , pairwise ~ time| group, adjust = \"none\")\n#&gt; $emmeans\n#&gt; group = A:\n#&gt;  time emmean   SE df lower.CL upper.CL\n#&gt;  t0      121 1.72 12      117      125\n#&gt;  t1      112 2.21 12      108      117\n#&gt;  t2      118 2.08 12      114      123\n#&gt;  t3      126 2.20 12      121      131\n#&gt;  t4      121 1.76 12      117      125\n#&gt; \n#&gt; group = B:\n#&gt;  time emmean   SE df lower.CL upper.CL\n#&gt;  t0      121 1.72 12      117      125\n#&gt;  t1      120 2.21 12      115      125\n#&gt;  t2      118 2.08 12      113      123\n#&gt;  t3      128 2.20 12      123      133\n#&gt;  t4      135 1.76 12      131      139\n#&gt; \n#&gt; group = C:\n#&gt;  time emmean   SE df lower.CL upper.CL\n#&gt;  t0      126 1.72 12      122      130\n#&gt;  t1      123 2.21 12      118      128\n#&gt;  t2      119 2.08 12      114      123\n#&gt;  t3      143 2.20 12      138      147\n#&gt;  t4      131 1.76 12      127      134\n#&gt; \n#&gt; Confidence level used: 0.95 \n#&gt; \n#&gt; $contrasts\n#&gt; group = A:\n#&gt;  contrast estimate    SE df t.ratio p.value\n#&gt;  t0 - t1       8.6 1.490 12   5.772  0.0001\n#&gt;  t0 - t2       2.6 1.320 12   1.964  0.0732\n#&gt;  t0 - t3      -4.8 2.060 12  -2.333  0.0379\n#&gt;  t0 - t4       0.2 1.680 12   0.119  0.9074\n#&gt;  t1 - t2      -6.0 0.913 12  -6.573  &lt;.0001\n#&gt;  t1 - t3     -13.4 1.060 12 -12.624  &lt;.0001\n#&gt;  t1 - t4      -8.4 1.530 12  -5.507  0.0001\n#&gt;  t2 - t3      -7.4 1.460 12  -5.066  0.0003\n#&gt;  t2 - t4      -2.4 1.340 12  -1.789  0.0989\n#&gt;  t3 - t4       5.0 1.630 12   3.062  0.0099\n#&gt; \n#&gt; group = B:\n#&gt;  contrast estimate    SE df t.ratio p.value\n#&gt;  t0 - t1       1.4 1.490 12   0.940  0.3659\n#&gt;  t0 - t2       3.2 1.320 12   2.417  0.0325\n#&gt;  t0 - t3      -7.0 2.060 12  -3.402  0.0052\n#&gt;  t0 - t4     -14.0 1.680 12  -8.317  &lt;.0001\n#&gt;  t1 - t2       1.8 0.913 12   1.972  0.0721\n#&gt;  t1 - t3      -8.4 1.060 12  -7.914  &lt;.0001\n#&gt;  t1 - t4     -15.4 1.530 12 -10.096  &lt;.0001\n#&gt;  t2 - t3     -10.2 1.460 12  -6.983  &lt;.0001\n#&gt;  t2 - t4     -17.2 1.340 12 -12.820  &lt;.0001\n#&gt;  t3 - t4      -7.0 1.630 12  -4.287  0.0011\n#&gt; \n#&gt; group = C:\n#&gt;  contrast estimate    SE df t.ratio p.value\n#&gt;  t0 - t1       3.2 1.490 12   2.148  0.0529\n#&gt;  t0 - t2       7.6 1.320 12   5.740  0.0001\n#&gt;  t0 - t3     -16.4 2.060 12  -7.971  &lt;.0001\n#&gt;  t0 - t4      -4.4 1.680 12  -2.614  0.0226\n#&gt;  t1 - t2       4.4 0.913 12   4.820  0.0004\n#&gt;  t1 - t3     -19.6 1.060 12 -18.465  &lt;.0001\n#&gt;  t1 - t4      -7.6 1.530 12  -4.982  0.0003\n#&gt;  t2 - t3     -24.0 1.460 12 -16.432  &lt;.0001\n#&gt;  t2 - t4     -12.0 1.340 12  -8.944  &lt;.0001\n#&gt;  t3 - t4      12.0 1.630 12   7.348  &lt;.0001\n\n\n\n8.3.3 分部计算\n\\[\n\\begin{aligned}\nSS_总&= SS_{受试对象间}+SS_{受试对象内}  \\\\\n&=（SS_{处理方法}+SS_{个体间差异}）+（SS_{时间}+SS_{处理与时间交互}+SS_{个体内差异}）\n\\end{aligned}\n\\]\n\\[\n\\begin{aligned}\n\\nu_总&= \\nu_{受试对象间}+\\nu_{受试对象内}  \\\\\n&=（\\nu_{处理方法}+\\nu_{个体差异}）+（\\nu_{时间}+\\nu_{处理与时间交互}+\\nu_{个体差异}）\n\\end{aligned}\n\\]\n\n\n\n\n\n\n\n\n\n\n\nPage 86-87\n变异\nSS\nv\nMS\nF\nCP\n\n\n\n受试对象间\n处理\n912.24\n2\n456.12\n5.78\n0.0174\n\n\n\n个体差异\n946.48\n12\n78.87\n\n\n\n\n\n\n1858.72\n\n\n\n\n\n\n受试对象内\n时间\n2336.45\n4\n584.11\n106.56\n&lt;0.0001\n\n\n\n处理与时间交互\n837.63\n8\n104.70\n19.10\n&lt;0.0001\n\n\n\n个体差异\n263.12\n48\n5.48\n\n\n\n\n\n\n3437.2\n\n\n\n\n\n\n总\n\n5295.92\n3×15-1=74\n\n\n\n\n\n\n\n8.3.3.1 SS总\n\n\\[\nSS_总=\\sum_i^n{（X_i-\\bar X）^2}\n\\]\n其中，n是观测值的总数，Xi 为每个观测值，\\(\\bar X\\) 是所有观测值的均值。\n\nShow the code\nSBP_data &lt;- c(SBP$t0,SBP$t1,SBP$t2,SBP$t3,SBP$t4)\n\nSBP_mean &lt;- mean(SBP_data)\n\nSS_total &lt;- sum((SBP_data-SBP_mean)^2)\n\nSS_total    \n#&gt; [1] 5295.92\n\n\n\n8.3.3.2 SS受试对象间\n\n\\[\nSS_{受试对象间}=\\sum_{j=1}^m n_{.j}(\\bar X_{.j}-\\bar X)^2\n\\]\n其中，m是受试者数量（15），n.j 是第j 个受试对象的观测值数量，\\(\\bar X.j\\)是第j 个受试对象的观测值的均值，\\(\\bar X\\) 是所有观测值的均值。\n\nShow the codeid_mean &lt;- SBP |&gt; dplyr::select(c(-1,-2)) |&gt; rowMeans()\n\nSS_between &lt;- 0\nfor (i in 1:nrow(SBP)) {\n    SS_between &lt;- SS_between + 5*(id_mean[i]-SBP_mean)^2\n}\nSS_between\n#&gt; [1] 1858.72\n\n\n\nShow the codegroup__summary &lt;- SBP_long |&gt; group_by(group) |&gt; \n    summarise(n=n(),mean=mean(SBP),sum=sum(SBP))\ngroup__summary \n#&gt; # A tibble: 3 × 4\n#&gt;   group     n  mean   sum\n#&gt;   &lt;fct&gt; &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt;\n#&gt; 1 A        25  120.  2992\n#&gt; 2 B        25  124.  3112\n#&gt; 3 C        25  128.  3205\n\n\nSS处理\n\n\\[\nSS_{处理}= \\sum_i^k n_k (\\bar X_k - \\bar X)^2\n\\]\n其中，k为不同处理组的组数，nk 为第 k 处理组观测值的总数，\\(\\bar  X_k\\) 为第k 处理组观测值的均数，\\(\\bar X\\) 是所有观测值的均值。\n\nShow the codeSS_处理 &lt;- 25*( (group__summary$mean[1] - SBP_mean )^2 + \n                       (group__summary$mean[2] - SBP_mean )^2 +\n                       (group__summary$mean[3] - SBP_mean )^2) \nSS_处理\n#&gt; [1] 912.24\n\n\n\nShow the codeSS_between_error &lt;- SS_between-SS_处理\n\nSS_between_error\n#&gt; [1] 946.48\n\n\n\n8.3.3.3 SS受试对象内\n\n\\[\nSS_{受试对象内}=SS_总-SS_{受试对象间}\n\\]\n\nShow the codeSS_within &lt;- SS_total-SS_between\nSS_within\n#&gt; [1] 3437.2\n\n\nSS时间\n\n\\[\nSS_{时间}=\\sum _{t=1}^T n_t （\\bar X_{.t}-\\bar X）^2\n\\]\n其中，T是时间点的数量，nt 是在时间点t的观测值数量，\\bar X.t 是在时间点 t 的均值。\n\nShow the codet_mean &lt;- SBP |&gt; dplyr::select(c(-1,-2)) |&gt; colMeans()\n\nSS_time &lt;- 0\nfor (i in seq_along(t_mean)) {\n    \n    SS_time &lt;- SS_time + 15*(t_mean[i]-SBP_mean)^2\n    \n}\nnames(SS_time) &lt;- \"SS_time\"\nSS_time\n#&gt;  SS_time \n#&gt; 2336.453\n\n\nSS处理与时间交互\n\n\\[\nSS_{处理与时间交互}=\\sum_{i=1}^{k}\\sum_{j=1}^{T}n_{ij}\\left (\\bar X_{ij.} -\\bar X_{i..}-\\bar X_{.j.} + \\bar X_{...} \\right )^2\n\\]\n其中，\n\nk 是处理方法的数量，3\nT 是时间点的数量，5\nnij 是第 i 个处理方法和第 j 个时间点的观测次数，25/5=5\nXij . 是第 i 个处理方法、第 j 个时间点的观测值的平均值\nXi . . 是第 i 个处理方法观测值的平均值，不考虑时间点\nX. j . 是第 j 个时间点观测值的平均值，不考虑处理方法\nX. . . 是所有观测值的平均值，不考虑处理方法和时间点\n\n\nShow the codeinteraction_effect_summary &lt;- SBP_long |&gt;\n    summarise(\n        #n = n(),\n        mean = mean(SBP),\n       # sum = sum(SBP),\n        .by = c(group , time)\n    )\ninteraction_effect_mean &lt;- interaction_effect_summary |&gt; pivot_wider(names_from = c(\"time\"),values_from = \"mean\")\n\n\n\nSS_interaction_effect &lt;- 0\nfor (i in 1:3) {\n    for (j in 1:5) {\n        SS_interaction_effect &lt;- SS_interaction_effect + 5 * (interaction_effect_mean[i, j + 1] -group__summary$mean[i] - t_mean[j] + SBP_mean) ^ 2\n    }\n    \n}\nnames(SS_interaction_effect) &lt;- \"SS_interaction_effect\"\nSS_interaction_effect\n#&gt;   SS_interaction_effect\n#&gt; 1              837.6267\n\n\n\nShow the codeSS_within_error &lt;- SS_within-SS_time-SS_interaction_effect\n\nnames(SS_within_error) &lt;- \"SS_within_error\"\nSS_within_error \n#&gt;   SS_within_error\n#&gt; 1          263.12",
    "crumbs": [
      "假设检验",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>重复测量方差分析</span>"
    ]
  },
  {
    "objectID": "repeated_measures_anova.html#球形度检验-sphericity",
    "href": "repeated_measures_anova.html#球形度检验-sphericity",
    "title": "\n8  重复测量方差分析\n",
    "section": "\n8.4 球形度检验 sphericity",
    "text": "8.4 球形度检验 sphericity\n重复测量方差分析假设相关条件（或组水平）的所有组合之间的差异方差相等。这被称为球形度假设。\nR中球形度检验\n球度仅针对具有两个以上水平的变量进行评估，因为球形度必然适用于只有两个水平的条件。\n违反球形度假设可能会扭曲方差计算，从而导致更宽松的重复测量方差分析检验（即 I 类错误率增加）。在这种情况下，必须根据违反球形度的程度适当校正重复测量方差分析。文献中使用了两种常见的校正：Greenhouse-Geisser epsilon （GGe） 和 Huynh-Feldt epsilon （HFe）。\n球形度的 Mauchly 检验用于评估是否满足球形度的假设。使用rstatix::anova_test() 时，会自动报告此问题。尽管该方法受到严厉批评，通常无法检测到小样本中的球形偏离，而在大样本中则过度检测到它们，但它仍然是一种常用的方法。\n\n8.4.1 计算步骤\n具体操作步骤如下：\n\n计算相关组的每个组合之间的差异\n计算每个组差的方差\n\n\n\n8.4.2 案例\n\n8.4.2.1 rstatix::anova_test()\n\n\nShow the code\naov_SBP &lt;- rstatix::anova_test(data = SBP_long,\n           dv = SBP,\n           wid = id,\n           within = time,\n           between = group\n           )\n\naov_SBP\n#&gt; ANOVA Table (type II tests)\n#&gt; \n#&gt; $ANOVA\n#&gt;       Effect DFn DFd       F        p p&lt;.05   ges\n#&gt; 1      group   2  12   5.783 1.70e-02     * 0.430\n#&gt; 2       time   4  48 106.558 3.02e-23     * 0.659\n#&gt; 3 group:time   8  48  19.101 1.62e-12     * 0.409\n#&gt; \n#&gt; $`Mauchly's Test for Sphericity`\n#&gt;       Effect     W     p p&lt;.05\n#&gt; 1       time 0.293 0.178      \n#&gt; 2 group:time 0.293 0.178      \n#&gt; \n#&gt; $`Sphericity Corrections`\n#&gt;       Effect   GGe      DF[GG]    p[GG] p[GG]&lt;.05   HFe      DF[HF]    p[HF]\n#&gt; 1       time 0.679 2.71, 32.58 1.87e-16         * 0.896 3.59, 43.03 4.65e-21\n#&gt; 2 group:time 0.679 5.43, 32.58 4.26e-09         * 0.896 7.17, 43.03 2.04e-11\n#&gt;   p[HF]&lt;.05\n#&gt; 1         *\n#&gt; 2         *\n\n\n输出是一个包含三个表的列表：\n\n方差分析结果显示标有（generalized eta squared，ges）的列上的 p 值和效应大小;效应大小本质上是由于受试者内因素而忽略受试者效应而导致的变异量。\nMauchly Sphericity检验。仅报告具有 &gt;2 水平的变量或效应，因为球形度必然适用于只有 2 个水平的效应。原假设是组差的方差相等。因此，显著的 p 值 （p &lt; 0.05） 表示组差的方差不相等。\n球度校正结果，以防我们无法维持球形度假设。提供了文献中使用的两种常见校正：Greenhouse-Geisser epsilon （GGe） 和 Huynh-Feldt epsilon （HFe） 及其相应的 p 值\n\n8.4.2.2 ez::ezANOVA()\n\n\nShow the codelibrary(ez)\n\n# 进行重复测量方差分析\naov_ez &lt;- ezANOVA(data = SBP_long,\n                   dv = SBP,\n                   wid = id,\n                   within = time,\n                   between = group,\n                   detailed = TRUE)\n\n# 查看球形检验结果\nprint(aov_ez)\n#&gt; $ANOVA\n#&gt;        Effect DFn DFd          SSn    SSd            F            p p&lt;.05\n#&gt; 1 (Intercept)   1  12 1155433.0800 946.48 14649.223396 6.784700e-20     *\n#&gt; 2       group   2  12     912.2400 946.48     5.782943 1.743351e-02     *\n#&gt; 3        time   4  48    2336.4533 263.12   106.557616 3.017101e-23     *\n#&gt; 4  group:time   8  48     837.6267 263.12    19.100638 1.621310e-12     *\n#&gt;         ges\n#&gt; 1 0.9989542\n#&gt; 2 0.4299287\n#&gt; 3 0.6588884\n#&gt; 4 0.4091519\n#&gt; \n#&gt; $`Mauchly's Test for Sphericity`\n#&gt;       Effect         W         p p&lt;.05\n#&gt; 3       time 0.2930746 0.1776608      \n#&gt; 4 group:time 0.2930746 0.1776608      \n#&gt; \n#&gt; $`Sphericity Corrections`\n#&gt;       Effect      GGe        p[GG] p[GG]&lt;.05      HFe        p[HF] p[HF]&lt;.05\n#&gt; 3       time 0.678693 1.867336e-16         * 0.896371 4.649080e-21         *\n#&gt; 4 group:time 0.678693 4.262529e-09         * 0.896371 2.041727e-11         *\n\n\n\n8.4.3 当满足球形度假设时\n\n球形度的 Mauchly 检验不显著 （p &gt; 0.05）;这表明，受试者内因素水平之间的差异方差是相等的。因此，我们可以假设协方差矩阵的球形度，并解释方差分析表中可用的标准输出。\n\nShow the code# Display ANOVA table\naov_SBP$ANOVA\n#&gt;       Effect DFn DFd       F        p p&lt;.05   ges\n#&gt; 1      group   2  12   5.783 1.70e-02     * 0.430\n#&gt; 2       time   4  48 106.558 3.02e-23     * 0.659\n#&gt; 3 group:time   8  48  19.101 1.62e-12     * 0.409\n\n\n\nF表示我们正在与 F 分布（F 检验）进行比较; 分别表示 time 和 Error（time） 的自由度; 表示得到的 F 统计量值(2, 18)81.8\np指定 p 值\nges（广义 eta 平方，etaov_SBP[g]）是效应大小（由于受试者内因素引起的变异量）\n\n8.4.4 当违反球形度假设时\n\n如果数据违反了球形度假设（即 Mauchly 检验，p &lt;= 0.05），则应解释表sphericity corrections中的结果，其中对自由度进行了调整，这会影响检验的统计显著性（即 p 值）。校正通过乘法和校正估计值（Greenhouse-Geisser （GG） 和 Huynh-Feldt （HF） ε 值）来应用。\n\n\n\n\n\n\nNote\n\n\n\nepsilon 提供了球形度被侵犯的程度的度量。值为 1 表示不偏离球形度（组差的所有方差均相等）。违反球形度会导致 epsilon 值低于 1。epsilon 离 1 越远，违规越严重。\n\n\n可以看出，即使在球形度校正（p[GG] &lt; 0.001，p[HF] &lt; 0.001）之后，平均自尊得分在不同时间点仍存在统计学差异。\n在两种球形度校正方法中，Huynh-Feldt 校正被认为是最不保守的（高估了 epsilon），而 Greenhouse-Geisser 被认为是更保守的（当 epsilon 接近 1 时低估了 epsilon）。\n一般建议使用 Greenhouse-Geisser 校正，特别是当 epsilon &lt; 0.75 时。在 epsilon 大于 0.75 的情况下，一些统计学家建议使用 Huynh-Feldt 校正 （Girden 1992）。",
    "crumbs": [
      "假设检验",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>重复测量方差分析</span>"
    ]
  },
  {
    "objectID": "nonparametric_test.html",
    "href": "nonparametric_test.html",
    "title": "\n11  非参数检验\n",
    "section": "",
    "text": "11.1 秩\n\\[\nF(Median)=P(X\\le Median)=0.5\n\\]\nShow the codex &lt;- c(1,4,2,2,6,9,5)\nrank(x)\n#&gt; [1] 1.0 4.0 2.5 2.5 6.0 7.0 5.0",
    "crumbs": [
      "假设检验",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>非参数检验</span>"
    ]
  },
  {
    "objectID": "nonparametric_test.html#二项分布bn0.5",
    "href": "nonparametric_test.html#二项分布bn0.5",
    "title": "\n11  非参数检验\n",
    "section": "\n11.2 二项分布B(n，0.5)",
    "text": "11.2 二项分布B(n，0.5)\n\nShow the codetibble(\n    x = -5:15,\n    y_binom = dbinom(x, size = 10,prob = 0.5),\n) %&gt;% \nggplot()+\n    geom_col(aes(x=x,y=y_binom,color=\"binomal Distribution\"),fill=NA)+\n    geom_function(mapping = aes(color=\"normal Distribution\"),\n                  fun = dnorm, args = list(mean = 5, sd = 1),\n                   )+\n    scale_color_manual(values = c(\"normal Distribution\" = \"red\",\n                                  \"binomal Distribution\" = \"blue\"))+\n    labs(color = \"Distribution\")",
    "crumbs": [
      "假设检验",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>非参数检验</span>"
    ]
  },
  {
    "objectID": "nonparametric_test.html#单样本-wilcoxon-signed-rank-exact-test",
    "href": "nonparametric_test.html#单样本-wilcoxon-signed-rank-exact-test",
    "title": "\n11  非参数检验\n",
    "section": "\n11.3 单样本 Wilcoxon Signed-Rank exact test",
    "text": "11.3 单样本 Wilcoxon Signed-Rank exact test\n如果样本数据没有通过正态分布检验就要采用单样本wilcoxon符号秩检验进行计算。使用该检验需要满足的条件是样本值均匀地分布在均值两侧。\n\nShow the codeset.seed(123)\nx &lt;- runif(n = 100,min = 6,max = 8)\nhist(x)\n\n\n\n\n\n\nShow the codeshapiro.test(x)\n#&gt; \n#&gt;  Shapiro-Wilk normality test\n#&gt; \n#&gt; data:  x\n#&gt; W = 0.95237, p-value = 0.001192\nwilcox.test(x, mu=7) \n#&gt; \n#&gt;  Wilcoxon signed rank test with continuity correction\n#&gt; \n#&gt; data:  x\n#&gt; V = 2518, p-value = 0.9822\n#&gt; alternative hypothesis: true location is not equal to 7",
    "crumbs": [
      "假设检验",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>非参数检验</span>"
    ]
  },
  {
    "objectID": "nonparametric_test.html#双样本",
    "href": "nonparametric_test.html#双样本",
    "title": "\n11  非参数检验\n",
    "section": "\n11.4 双样本",
    "text": "11.4 双样本\n\n11.4.1 配对 Wilcoxon’s signed-rank test\n\\[\nT_++T_-=\\frac{n(n+1)}{2},n为非零配对差值的数量\n\\]\n\\[\nT=min{(T_+,T_-)}\n\\]\n5 ≤ n ≤30，附表T0\nn＞16，正态近似法\n\nShow the code\ndf &lt;- tibble(\n    low=c(958.5,838.4,612.2,812.9,739.0,899.4,758.5,695.0,749.7,815.5),\n    high=c(958.5,866.5,788.9,815.2,783.2,910.9,760.8,870.8,862.3,799.9),\n)\n\nshapiro.test(df$high-df$low)\n#&gt; \n#&gt;  Shapiro-Wilk normality test\n#&gt; \n#&gt; data:  df$high - df$low\n#&gt; W = 0.79689, p-value = 0.01329\n\n# 忽略  差异绝对值为“0”的数剔除；\nwilcox.test(df$low[-1],df$high[-1],exact = T,paired = T)\n#&gt; \n#&gt;  Wilcoxon signed rank exact test\n#&gt; \n#&gt; data:  df$low[-1] and df$high[-1]\n#&gt; V = 4, p-value = 0.02734\n#&gt; alternative hypothesis: true location shift is not equal to 0\n\n\n\n11.4.2 独立 Wilcoxon’s Rank-Sum 检验 (Mann-Whitney U 检验)\n当两个样本不满足正态分布时，使用Wilcoxon秩和检验进行非参数检验\n用于比较两个独立样本的中位数是否相等。\n\\[\nWilxoxon秩和\\ T=min\\{T_1,T_2\\}\n\\]\n\nShow the codeMVR = c(38, 29, 35, 33, 38, 41, 31)\nMVP = c(32, 43, 44, 81, 35, 46, 37, 45, 44)\nshapiro.test(c(MVR,MVP))\n#&gt; \n#&gt;  Shapiro-Wilk normality test\n#&gt; \n#&gt; data:  c(MVR, MVP)\n#&gt; W = 0.70443, p-value = 0.0001889\n\ncombined_data &lt;- c(MVR, MVP)\nranked_data &lt;- rank(combined_data)\nranked_data \n#&gt;  [1]  8.5  1.0  5.5  4.0  8.5 10.0  2.0  3.0 11.0 12.5 16.0  5.5 15.0  7.0 14.0\n#&gt; [16] 12.5\n\nMVR_ranks &lt;- ranked_data[1:length(MVR)]\nMVP_ranks &lt;- ranked_data[(length(MVR)+1):length(combined_data)]\n\nT1 &lt;- sum(MVR_ranks)\nT2 &lt;- sum(MVP_ranks)\n\nT1-length(MVR)*(length(MVR)+1)/2\n#&gt; [1] 11.5\nwilcox.test(MVR,MVP,exact = F,correct = F)\n#&gt; \n#&gt;  Wilcoxon rank sum test\n#&gt; \n#&gt; data:  MVR and MVP\n#&gt; W = 11.5, p-value = 0.03386\n#&gt; alternative hypothesis: true location shift is not equal to 0\n\n\n\n11.4.2.1 W统计量\nn1&lt;10,n2-n1&lt;10，附录\nn1&gt;10,n2&gt;10，正态近似法\n\nShow the codex &lt;- c(17, 12, 13, 16, 9, 19, 21, 12, 18, 17)\ny &lt;- c(10, 6, 15, 9, 8, 11, 8, 16, 13, 7, 5, 14)\nwilcox.test(x, y, correct = F)\n#&gt; \n#&gt;  Wilcoxon rank sum test\n#&gt; \n#&gt; data:  x and y\n#&gt; W = 101.5, p-value = 0.006124\n#&gt; alternative hypothesis: true location shift is not equal to 0\n\nrank(c(x,y))[1:10] %&gt;% sum()\n#&gt; [1] 156.5\nrank(c(x,y))[11:22] %&gt;% sum()\n#&gt; [1] 96.5\n\n156.5-10*11/2\n#&gt; [1] 101.5\n\na &lt;- wilcox.test(x,y,correct=FALSE)\nstr(a) \n#&gt; List of 7\n#&gt;  $ statistic  : Named num 102\n#&gt;   ..- attr(*, \"names\")= chr \"W\"\n#&gt;  $ parameter  : NULL\n#&gt;  $ p.value    : num 0.00612\n#&gt;  $ null.value : Named num 0\n#&gt;   ..- attr(*, \"names\")= chr \"location shift\"\n#&gt;  $ alternative: chr \"two.sided\"\n#&gt;  $ method     : chr \"Wilcoxon rank sum test\"\n#&gt;  $ data.name  : chr \"x and y\"\n#&gt;  - attr(*, \"class\")= chr \"htest\"\nn1 &lt;- length(x)\na$statistic &lt;- a$statistic + n1*(n1+1)/2\nnames(a$statistic) &lt;- \"T.W\"\na\n#&gt; \n#&gt;  Wilcoxon rank sum test\n#&gt; \n#&gt; data:  x and y\n#&gt; T.W = 156.5, p-value = 0.006124\n#&gt; alternative hypothesis: true location shift is not equal to 0\n\n\n\n11.4.2.2 曼-惠特尼 U 统计量\n\\[\n曼-惠特尼U统计量= 威尔科克森W(较小秩和)-\\frac{n_{T_{min}}(n_{T_{min}}+1)}{2}\n\\]\n\n11.4.2.3 Z 统计量 coin::wilcox_test()\n\n\nShow the codelibrary(coin)\ndf &lt;- read_excel(\"data/coin-wilcox_test.xlsx\") %&gt;% \n    mutate(group=as.factor(group))\ndf\n#&gt; # A tibble: 240 × 2\n#&gt;    HADS得分 group\n#&gt;       &lt;dbl&gt; &lt;fct&gt;\n#&gt;  1       14 1    \n#&gt;  2       14 1    \n#&gt;  3        7 1    \n#&gt;  4       22 1    \n#&gt;  5        7 1    \n#&gt;  6       12 1    \n#&gt;  7       15 1    \n#&gt;  8       17 1    \n#&gt;  9        8 1    \n#&gt; 10       14 1    \n#&gt; # ℹ 230 more rows\n\nrank &lt;- rank(df$HADS得分)\n\ng1rankSum &lt;- sum(rank[1:120])\ng2rankSum &lt;- sum(rank[121:240])\n\n\nSPSS_威尔科克森W &lt;- min(g1rankSum,g2rankSum)\nSPSS_威尔科克森W \n#&gt; [1] 13965.5\nSPSS_曼惠特尼U &lt;-  SPSS_威尔科克森W -120*121/2\nSPSS_曼惠特尼U\n#&gt; [1] 6705.5\n\nwilcox.test(HADS得分 ~ group,data=df,correct=F)\n#&gt; \n#&gt;  Wilcoxon rank sum test\n#&gt; \n#&gt; data:  HADS得分 by group\n#&gt; W = 7694.5, p-value = 0.3572\n#&gt; alternative hypothesis: true location shift is not equal to 0\n# SPSS  z统计量\ncoin::wilcox_test( HADS得分 ~ group,data=df, distribution = \"asymptotic\") #   exact   asymptotic    approximate\n#&gt; \n#&gt;  Asymptotic Wilcoxon-Mann-Whitney Test\n#&gt; \n#&gt; data:  HADS得分 by group (1, 2)\n#&gt; Z = 0.92062, p-value = 0.3572\n#&gt; alternative hypothesis: true mu is not equal to 0\ncoin::wilcox_test( HADS得分 ~ group,data=df, distribution = \"approximate\")\n#&gt; \n#&gt;  Approximative Wilcoxon-Mann-Whitney Test\n#&gt; \n#&gt; data:  HADS得分 by group (1, 2)\n#&gt; Z = 0.92062, p-value = 0.3589\n#&gt; alternative hypothesis: true mu is not equal to 0\n\n\nSPSS 用较小秩和减去对应 n(n+1)/2\nR有时用较小秩和减去对应 n(n+1)/2，有时用较大秩和减去对应 n(n+1)/2\n\nShow the codewilcox.test(HADS得分 ~ group,data=df,exact = F,correct = F)\n#&gt; \n#&gt;  Wilcoxon rank sum test\n#&gt; \n#&gt; data:  HADS得分 by group\n#&gt; W = 7694.5, p-value = 0.3572\n#&gt; alternative hypothesis: true location shift is not equal to 0\n\n# SPSS_曼惠特尼U\ng2rankSum-120*121/2\n#&gt; [1] 6705.5\n\n\n# R中W\ng1rankSum-120*121/2\n#&gt; [1] 7694.5\n\n\n\nn1&gt;20\n\n11.4.3 Wilcoxon Distribution\n\nShow the code\ntibble(\n    x = 0:100,\n    y =dwilcox(x,m = 7,n = 9)\n) %&gt;% \n    ggplot() +\n    geom_col(aes(x,y),fill=\"lightblue\",color=\"black\")+\n    ggtitle(\"Wilcoxon Distribution\")",
    "crumbs": [
      "假设检验",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>非参数检验</span>"
    ]
  },
  {
    "objectID": "nonparametric_test.html#多样本",
    "href": "nonparametric_test.html#多样本",
    "title": "\n11  非参数检验\n",
    "section": "\n11.5 多样本",
    "text": "11.5 多样本\n\n11.5.1 独立 Kruskal-Wallis 检验\n用于比较三个或更多独立样本的中位数是否相等。\n假设：\n\n随机，独立\n每个样本至少5个观测\n能够计算秩次\n\n\nShow the codekruskal.test(weight~group,data = PlantGrowth)\n#&gt; \n#&gt;  Kruskal-Wallis rank sum test\n#&gt; \n#&gt; data:  weight by group\n#&gt; Kruskal-Wallis chi-squared = 7.9882, df = 2, p-value = 0.01842\n\n\n\n11.5.1.1 事后多重比较\n\nShow the codepairwise.wilcox.test(PlantGrowth$weight,PlantGrowth$group,p.adjust.method = \"fdr\",exact=F)\n#&gt; \n#&gt;  Pairwise comparisons using Wilcoxon rank sum test with continuity correction \n#&gt; \n#&gt; data:  PlantGrowth$weight and PlantGrowth$group \n#&gt; \n#&gt;      ctrl  trt1 \n#&gt; trt1 0.199 -    \n#&gt; trt2 0.096 0.034\n#&gt; \n#&gt; P value adjustment method: fdr\n\n\n\n11.5.2 相关 Friedman 检验\n用于比较三个或更多相关样本的中位数是否相等。\n\nShow the code# 假设有三个相关样本 x, y, z\nx &lt;- c(14, 17, 20, 23, 25)\ny &lt;- c(15, 18, 21, 24, 26)\nz &lt;- c(16, 19, 22, 25, 27)\n\n# 将样本合并成一个数据框，并指定组别和受试者\ndata &lt;- data.frame(\n  value = c(x, y, z),\n  group = factor(rep(c(\"x\", \"y\", \"z\"), each = 5)),\n  subject = factor(rep(1:5, 3))\n)\n\n# 使用 friedman.test() 函数进行检验\nresult &lt;- friedman.test(value ~ group | subject, data = data)\n\n# 输出检验结果\nprint(result)\n#&gt; \n#&gt;  Friedman rank sum test\n#&gt; \n#&gt; data:  value and group and subject\n#&gt; Friedman chi-squared = 10, df = 2, p-value = 0.006738",
    "crumbs": [
      "假设检验",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>非参数检验</span>"
    ]
  },
  {
    "objectID": "nonparametric_test.html#kendalls-tau-检验",
    "href": "nonparametric_test.html#kendalls-tau-检验",
    "title": "\n11  非参数检验\n",
    "section": "\n11.6 Kendall’s Tau 检验",
    "text": "11.6 Kendall’s Tau 检验\n用途：用于检验两个变量之间的相关性。\n\nShow the code# 假设有两个变量 x 和 y\nx &lt;- c(14, 17, 20, 23, 25)\ny &lt;- c(15, 18, 21, 24, 26)\n\n# 使用 cor.test() 函数进行 Kendall's Tau 检验\nresult &lt;- cor.test(x, y, method = \"kendall\")\n\n# 输出检验结果\nprint(result)\n#&gt; \n#&gt;  Kendall's rank correlation tau\n#&gt; \n#&gt; data:  x and y\n#&gt; T = 10, p-value = 0.01667\n#&gt; alternative hypothesis: true tau is not equal to 0\n#&gt; sample estimates:\n#&gt; tau \n#&gt;   1",
    "crumbs": [
      "假设检验",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>非参数检验</span>"
    ]
  },
  {
    "objectID": "nonparametric_test.html#spearmans-rank-correlation-检验",
    "href": "nonparametric_test.html#spearmans-rank-correlation-检验",
    "title": "\n11  非参数检验\n",
    "section": "\n11.7 Spearman’s Rank Correlation 检验",
    "text": "11.7 Spearman’s Rank Correlation 检验\n用途：用于检验两个变量之间的相关性，适用于数据非线性关系。\n\nShow the code# 假设有两个变量 x 和 y\nx &lt;- c(14, 17, 20, 23, 25)\ny &lt;- c(15, 18, 21, 24, 26)\n\n# 使用 cor.test() 函数进行 Spearman's Rank Correlation 检验\nresult &lt;- cor.test(x, y, method = \"spearman\")\n\n# 输出检验结果\nprint(result)\n#&gt; \n#&gt;  Spearman's rank correlation rho\n#&gt; \n#&gt; data:  x and y\n#&gt; S = 4.4409e-15, p-value = 0.01667\n#&gt; alternative hypothesis: true rho is not equal to 0\n#&gt; sample estimates:\n#&gt; rho \n#&gt;   1",
    "crumbs": [
      "假设检验",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>非参数检验</span>"
    ]
  },
  {
    "objectID": "simple_linear_regression.html",
    "href": "simple_linear_regression.html",
    "title": "\n12  线性回归\n",
    "section": "",
    "text": "12.1 一元线性回归\n线性模型用于解释一个连续因变量和一个或多个自变量之间的线性关系。模型形式一般为：\n\\[\nY=X\\beta + \\epsilon\n\\]\n其中， Y 是因变量，X 是自变量矩阵，β 是回归系数，ϵ 是误差项。\n数据下载网站\nlinear regression model：\n\\[\nY_i=\\beta_0+ \\beta_1 X_i+\\epsilon_i,其中\\epsilon_i\\sim N(0,\\sigma^2)\n\\]\nShow the code#linear model specification 线性模型规范\nlm_spec &lt;-linear_reg() %&gt;%\n  set_mode(\"regression\") %&gt;%\n  set_engine(\"lm\")  \nlm_spec\n#&gt; Linear Regression Model Specification (regression)\n#&gt; \n#&gt; Computational engine: lm\nShow the codelm_tv &lt;- lm_spec %&gt;%  fit(sales ~ TV, data = advertising)\n# 模型摘要\nsummary(lm_tv$fit)\n#&gt; \n#&gt; Call:\n#&gt; stats::lm(formula = sales ~ TV, data = data)\n#&gt; \n#&gt; Residuals:\n#&gt;     Min      1Q  Median      3Q     Max \n#&gt; -8.3860 -1.9545 -0.1913  2.0671  7.2124 \n#&gt; \n#&gt; Coefficients:\n#&gt;             Estimate Std. Error t value Pr(&gt;|t|)    \n#&gt; (Intercept) 7.032594   0.457843   15.36   &lt;2e-16 ***\n#&gt; TV          0.047537   0.002691   17.67   &lt;2e-16 ***\n#&gt; ---\n#&gt; Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n#&gt; \n#&gt; Residual standard error: 3.259 on 198 degrees of freedom\n#&gt; Multiple R-squared:  0.6119, Adjusted R-squared:  0.6099 \n#&gt; F-statistic: 312.1 on 1 and 198 DF,  p-value: &lt; 2.2e-16\n\n# 参数估计值、标准误、统计量、p值\nbroom::tidy(lm_tv, conf.int=T)\n#&gt; # A tibble: 2 × 7\n#&gt;   term        estimate std.error statistic  p.value conf.low conf.high\n#&gt;   &lt;chr&gt;          &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt;    &lt;dbl&gt;     &lt;dbl&gt;\n#&gt; 1 (Intercept)   7.03     0.458        15.4 1.41e-35   6.13      7.94  \n#&gt; 2 TV            0.0475   0.00269      17.7 1.47e-42   0.0422    0.0528\n# 模型统计信息\nbroom::glance(lm_tv) \n#&gt; # A tibble: 1 × 12\n#&gt;   r.squared adj.r.squared sigma statistic  p.value    df logLik   AIC   BIC\n#&gt;       &lt;dbl&gt;         &lt;dbl&gt; &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt; &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n#&gt; 1     0.612         0.610  3.26      312. 1.47e-42     1  -519. 1044. 1054.\n#&gt; # ℹ 3 more variables: deviance &lt;dbl&gt;, df.residual &lt;int&gt;, nobs &lt;int&gt;",
    "crumbs": [
      "统计模型",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>线性回归</span>"
    ]
  },
  {
    "objectID": "simple_linear_regression.html#一元线性回归",
    "href": "simple_linear_regression.html#一元线性回归",
    "title": "\n12  线性回归\n",
    "section": "",
    "text": "12.1.1 点须图\n\nShow the code\n# 整理回归模型结果\ntidy_lm &lt;- tidy(lm_tv, conf.int=T) %&gt;% dplyr::filter(term !='(Intercept)' )\n# 绘制点须图\nggplot(tidy_lm, aes(x = estimate, y = term)) +\n  geom_point(size = 2, color = \"black\") + # 绘制点\n  geom_errorbarh(aes(xmin = conf.low, \n                     xmax = conf.high), \n                 height = 0, color = \"black\") + # 绘制误差线\n  geom_vline(xintercept = 0, colour = \"grey50\", linetype = 2) + # 绘制参考线\n  labs(x = NULL, y = NULL) \n\n\n\n\n\n\n\n\n12.1.2 预测\n\nShow the code# 预测\nstats::predict(lm_tv, new_data = advertising) %&gt;% \n    head(n = 10)\n#&gt; # A tibble: 10 × 1\n#&gt;    .pred\n#&gt;    &lt;dbl&gt;\n#&gt;  1 18.0 \n#&gt;  2  9.15\n#&gt;  3  7.85\n#&gt;  4 14.2 \n#&gt;  5 15.6 \n#&gt;  6  7.45\n#&gt;  7  9.77\n#&gt;  8 12.7 \n#&gt;  9  7.44\n#&gt; 10 16.5\n\n# 置信区间 平均响应值       取决于方差和样本量     随样本量增加收缩\npredict(lm_tv, new_data = advertising, type = \"conf_int\") %&gt;% \n    head(n = 10)\n#&gt; # A tibble: 10 × 2\n#&gt;    .pred_lower .pred_upper\n#&gt;          &lt;dbl&gt;       &lt;dbl&gt;\n#&gt;  1       17.3        18.6 \n#&gt;  2        8.44        9.86\n#&gt;  3        7.02        8.68\n#&gt;  4       13.8        14.7 \n#&gt;  5       15.1        16.1 \n#&gt;  6        6.58        8.31\n#&gt;  7        9.11       10.4 \n#&gt;  8       12.3        13.2 \n#&gt;  9        6.58        8.31\n#&gt; 10       16.0        17.1\n\n# 单个新观测值         主要取决于方差\npredict(lm_tv, new_data = advertising, type = \"pred_int\") %&gt;% \n    head(n = 10)\n#&gt; # A tibble: 10 × 2\n#&gt;    .pred_lower .pred_upper\n#&gt;          &lt;dbl&gt;       &lt;dbl&gt;\n#&gt;  1      11.5          24.4\n#&gt;  2       2.68         15.6\n#&gt;  3       1.37         14.3\n#&gt;  4       7.79         20.7\n#&gt;  5       9.18         22.1\n#&gt;  6       0.962        13.9\n#&gt;  7       3.31         16.2\n#&gt;  8       6.30         19.2\n#&gt;  9       0.957        13.9\n#&gt; 10      10.1          23.0\n\n\n# 比较观测值与预测值\naugment(lm_tv, new_data = advertising) %&gt;%\n    select(sales, .pred) %&gt;%\n    head(n = 10)\n#&gt; # A tibble: 10 × 2\n#&gt;    sales .pred\n#&gt;    &lt;dbl&gt; &lt;dbl&gt;\n#&gt;  1  22.1 18.0 \n#&gt;  2  10.4  9.15\n#&gt;  3   9.3  7.85\n#&gt;  4  18.5 14.2 \n#&gt;  5  12.9 15.6 \n#&gt;  6   7.2  7.45\n#&gt;  7  11.8  9.77\n#&gt;  8  13.2 12.7 \n#&gt;  9   4.8  7.44\n#&gt; 10  10.6 16.5\n\n\npredict(lm_tv$fit, new_data = advertising, interval = \"confidence\") %&gt;% \n    head(n = 10)\npredict(lm_tv$fit, new_data = advertising, interval = \"prediction\") %&gt;% \n    head(n = 10)",
    "crumbs": [
      "统计模型",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>线性回归</span>"
    ]
  },
  {
    "objectID": "simple_linear_regression.html#线性回归假设",
    "href": "simple_linear_regression.html#线性回归假设",
    "title": "\n12  线性回归\n",
    "section": "\n12.2 线性回归假设",
    "text": "12.2 线性回归假设\n一般线性模型中，其自变量全部为固定效应自变量，3点假设：\n\n线性度\n\n保证各实测点到回归直线的纵向距离的平方和最小，即使得残差平方和最小。\n\\[\nQ=\\sum (Y-\\hat Y)^2\n\\]\n\nShow the code# 可视化\naugment(lm_tv, new_data = advertising) %&gt;%\n    ggplot(aes(x = TV)) +\n    geom_linerange(aes(ymin = sales, ymax = .pred)) +\n    geom_point(aes(y = sales), color = \"red\") +\n    geom_abline(\n        intercept = coef(lm_tv$fit)[1],\n        slope = coef(lm_tv$fit)[2],\n        color = \"blue\",\n        linewidth = 1\n    )\n\n\n\n\n\n\n\n\n同方差性：残差具有常数方差\n残差的正态性\n观测的独立性：通常通过审查研究设计来调查",
    "crumbs": [
      "统计模型",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>线性回归</span>"
    ]
  },
  {
    "objectID": "simple_linear_regression.html#模型诊断",
    "href": "simple_linear_regression.html#模型诊断",
    "title": "\n12  线性回归\n",
    "section": "\n12.3 模型诊断",
    "text": "12.3 模型诊断\n\nShow the codeautoplot(lm_tv, which = 1:6, ncol = 2, label.size = 3)\n\n\n\n\n\n\n\n\n12.3.1 残差图\n预测值与残差的关系，线性度，同方差\n\nShow the code# 检查线性回归模型的残差是否与预测值无关，即残差的分布是否随机。\n# 残差应该随机分布在0附近\ntibble(\n    `Fitted values`=fitted(lm_tv$fit),\n    Residuals = residuals(lm_tv$fit)\n) %&gt;% ggplot(aes(x = `Fitted values` , y = Residuals)) +\n  geom_point(pch=21) +\n    geom_smooth(formula = \"y~x\",color=\"red\",lwd=0.5)+\n  geom_hline(yintercept = 0,lty=2) +\n  labs(x = \"Fitted Values\", y = \"Residuals\")\n\n\n\n\n\n\n\n\n12.3.2 Q-Q图\n标准化残差正态性\n\nShow the codetibble(\n       StandardizedResiduals =rstandard(lm_tv$fit) ) %&gt;% \n    ggplot(aes(sample=StandardizedResiduals)) +\n    stat_qq(pch=21)+\n    stat_qq_line(color=\"red\",lty=2)+\n    labs(x = \"Theoretical Quantiles\", y = \"Sample quantiles\")\n\n\n\n\n\n\n\n\n12.3.3 Scale-Location 图\n检查同方差性，如果看到漏斗形（残差随着拟合值增大而增大），则可能存在异方差性问题。\n标准化残差平方根图\n检查残差的正态性，如果看到残差的分布围绕 0 随机散布，没有明显的模式，模型拟合是理想的。\n\nShow the codeplot(lm_tv$fit, which = 3)\n\n\n\n\n\n\n\n\nShow the code# 绘制 Scale-Location 图\ntibble(\n    fitted_values=fitted(lm_tv$fit),\n    StandardizedResiduals = rstudent(lm_tv$fit) ,\n) %&gt;%\n    ggplot(aes(x = fitted_values, y = sqrt(abs(StandardizedResiduals)))) +\n    geom_point(pch=21) +\n    geom_smooth(color=\"red\",lwd=0.5)+\n    labs(title = \"Scale-Location Plot\",x = \"Fitted Values\", y = \"√|Standardized residuals|\")\n\n\n\n\n\n\n\n\n12.3.4 Cook’s距离\n\n\nShow the codeset.seed(1011)\nx&lt;-rnorm(9)               #random 9 values\nx[10]&lt;-5                  #value far from the others\ny&lt;-rnorm(10,0.5+2*x,1)   #generate y\n\n#plot the data\nlmodel&lt;-lm(y~x)           #fit the model\nplot(x,y)                 #plot the data\nabline(line(x,y))        # add the regression line\n\n\n\n\n\n\nShow the codeinfluence.measures(lmodel)   \n#&gt; Influence measures of\n#&gt;   lm(formula = y ~ x) :\n#&gt; \n#&gt;     dfb.1_   dfb.x   dffit cov.r  cook.d   hat inf\n#&gt; 1  -0.0724 -0.0137 -0.0837 1.431 0.00397 0.103    \n#&gt; 2  -0.2607  0.1637 -0.2717 1.388 0.03993 0.157    \n#&gt; 3   0.0822 -0.0555  0.0869 1.554 0.00430 0.169    \n#&gt; 4   0.2679  0.0174  0.2935 1.178 0.04433 0.100    \n#&gt; 5   0.1102  0.0548  0.1490 1.408 0.01238 0.116    \n#&gt; 6  -0.5785  0.1207 -0.5854 0.724 0.13792 0.104    \n#&gt; 7   0.4851 -0.1676  0.4851 0.925 0.10651 0.114    \n#&gt; 8  -0.6059  0.3277 -0.6179 0.848 0.16313 0.139    \n#&gt; 9   0.4957 -0.2572  0.5034 0.996 0.11760 0.135    \n#&gt; 10  0.0157 -1.0428 -1.1090 9.033 0.68380 0.863   *\n\n\n\nShow the codeplot(lm_tv$fit,4)  \n\n\n\n\n\n\n\n\nShow the codethreshold &lt;- 4 / (nrow(advertising)-length(lm_tv$fit$coefficients)-2)\n                  \n                 \ntibble(\n    x = 1:nrow(advertising),\n    cooks_distance = cooks.distance(lm_tv$fit),\n    label = factor(if_else(cooks_distance&gt;threshold,x,NA))\n) %&gt;% \n    ggplot() +\n    geom_segment(aes(\n        x = x,\n        xend = x,\n        y = 0,\n        yend = cooks_distance ,\n    )) +\n    geom_text(aes(\n        x = x,\n        y =cooks_distance ,\n        label =label,\n    ), vjust = -0.2) +\n    labs(x = \"Observation Index\", y = \"Cook's Distance\")\n\n\n\n\n\n\n\n\n12.3.5 残差-杠杆值图\n\n\nShow the code\ninfluence(lmodel)$hat     #leverage\n#&gt;         1         2         3         4         5         6         7         8 \n#&gt; 0.1027407 0.1570337 0.1686229 0.1003533 0.1156210 0.1044403 0.1135604 0.1391403 \n#&gt;         9        10 \n#&gt; 0.1353478 0.8631394\n\n\n1/10 + (x-mean(x))^2/(var(x)*9)  #leverage manually computed \n#&gt;  [1] 0.1027407 0.1570337 0.1686229 0.1003533 0.1156210 0.1044403 0.1135604\n#&gt;  [8] 0.1391403 0.1353478 0.8631394\n\n\n\n\nShow the codeinfluence(lmodel)$coefficients     #DFBETA\n#&gt;     (Intercept)            x\n#&gt; 1  -0.015131790 -0.001678535\n#&gt; 2  -0.053246101  0.019647712\n#&gt; 3   0.017216660 -0.006821716\n#&gt; 4   0.053369207  0.002038393\n#&gt; 5   0.022861311  0.006672433\n#&gt; 6  -0.101915091  0.012493753\n#&gt; 7   0.090627673 -0.018400391\n#&gt; 8  -0.109982670  0.034951829\n#&gt; 9   0.093779788 -0.028593745\n#&gt; 10  0.003248704 -0.126864091\n\ndfbeta(lmodel)  \n#&gt;     (Intercept)            x\n#&gt; 1  -0.015131790 -0.001678535\n#&gt; 2  -0.053246101  0.019647712\n#&gt; 3   0.017216660 -0.006821716\n#&gt; 4   0.053369207  0.002038393\n#&gt; 5   0.022861311  0.006672433\n#&gt; 6  -0.101915091  0.012493753\n#&gt; 7   0.090627673 -0.018400391\n#&gt; 8  -0.109982670  0.034951829\n#&gt; 9   0.093779788 -0.028593745\n#&gt; 10  0.003248704 -0.126864091\n#computing the DFBETA manually for the 10th observation\ncoef(lm(y~x)) - coef(lm(y[-10]~x[-10]))\n#&gt;  (Intercept)            x \n#&gt;  0.003248704 -0.126864091\n\n\n\nShow the codeplot(lm_tv$fit,5)  \n\n\n\n\n\n\n\nhat 统计量\n\nShow the codetibble(\n    x = 1:nrow(advertising),\n    leverage = hatvalues(lm_tv$fit),\n    StandardizedResiduals = rstandard(lm_tv$fit) ,\n    cooks_distance = cooks.distance(lm_tv$fit),\n    label = factor(if_else(cooks_distance&gt;threshold,x,NA))\n) %&gt;%\n    ggplot(aes(x = leverage, y = StandardizedResiduals)) +\n    geom_point(pch=21) +\n    geom_smooth(color=\"red\",lwd=0.5)+\n    scale_x_continuous(limits = c(0, NA)) +\n    geom_vline(xintercept = 0, lty = 2) +\n    geom_hline(yintercept = 0, lty = 2) +\n    ggrepel::geom_text_repel(mapping = aes(label = label))+\n    labs(x = \"Leverage Values\", y = \"Standardized residuals\")\n\n\n\n\n\n\n\n\n12.3.6 Cook‘s距离和杠杆值\n\nShow the codeplot(lm_tv$fit,6)",
    "crumbs": [
      "统计模型",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>线性回归</span>"
    ]
  },
  {
    "objectID": "multiple_linear_regression.html",
    "href": "multiple_linear_regression.html",
    "title": "\n13  多元线性回归\n",
    "section": "",
    "text": "13.1 多元回归\n\\[\nY_i=\\beta_0+\\sum_{i=1}^p \\beta_p X_{pi}+\\epsilon_i,其中\\epsilon_i\\sim N(0,\\sigma^2)\n\\]\nY=Xβ+ε\n在矩阵表示法中，因变量是一个向量 Y，每个样本都有一行。自变量组合成一个矩阵X，其中每个特征有一列，另外还有一列 1值用于截距。每列每个示例都有一行。回归系数β和残差ε也是向量。\n向量β的最佳估计值计算为：\n\\[\n\\hat{\\mathbf{\\beta}}=  (X^TX)^{-1}X^TY\n\\]\nShow the codelibrary(tidymodels)\nlibrary(patchwork)\nlibrary(ggfortify)\nlibrary(rms)\n\n# 检测变量相关关系\nad &lt;- advertising %&gt;% select(-1)\ncor(ad)\n#&gt;                   TV      radio  newspaper     sales\n#&gt; TV        1.00000000 0.05480866 0.05664787 0.7822244\n#&gt; radio     0.05480866 1.00000000 0.35410375 0.5762226\n#&gt; newspaper 0.05664787 0.35410375 1.00000000 0.2282990\n#&gt; sales     0.78222442 0.57622257 0.22829903 1.0000000",
    "crumbs": [
      "统计模型",
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>多元线性回归</span>"
    ]
  },
  {
    "objectID": "multiple_linear_regression.html#多元回归",
    "href": "multiple_linear_regression.html#多元回归",
    "title": "\n13  多元线性回归\n",
    "section": "",
    "text": "13.1.1 rms::ols()\n\n\nShow the code\nmlm_ols &lt;- rms::ols(sales~ TV+radio+newspaper,data = advertising)\nmlm_ols \n#&gt; Linear Regression Model\n#&gt; \n#&gt; rms::ols(formula = sales ~ TV + radio + newspaper, data = advertising)\n#&gt; \n#&gt;                 Model Likelihood    Discrimination    \n#&gt;                       Ratio Test           Indexes    \n#&gt; Obs     200    LR chi2    455.01    R2       0.897    \n#&gt; sigma1.6855    d.f.            3    R2 adj   0.896    \n#&gt; d.f.    196    Pr(&gt; chi2) 0.0000    g        5.685    \n#&gt; \n#&gt; Residuals\n#&gt; \n#&gt;     Min      1Q  Median      3Q     Max \n#&gt; -8.8277 -0.8908  0.2418  1.1893  2.8292 \n#&gt; \n#&gt; \n#&gt;           Coef    S.E.   t     Pr(&gt;|t|)\n#&gt; Intercept  2.9389 0.3119  9.42 &lt;0.0001 \n#&gt; TV         0.0458 0.0014 32.81 &lt;0.0001 \n#&gt; radio      0.1885 0.0086 21.89 &lt;0.0001 \n#&gt; newspaper -0.0010 0.0059 -0.18 0.8599\n# texreg::texreg(mlm_ols)\n\ncar::vif(mlm_ols)\n#&gt;        TV     radio newspaper \n#&gt;  3.966283  3.970266  3.410504\nanova(mlm_ols)\n#&gt;                 Analysis of Variance          Response: sales \n#&gt; \n#&gt;  Factor     d.f. Partial SS   MS           F       P     \n#&gt;  TV           1  3.058010e+03 3.058010e+03 1076.41 &lt;.0001\n#&gt;  radio        1  1.361737e+03 1.361737e+03  479.33 &lt;.0001\n#&gt;  newspaper    1  8.871717e-02 8.871717e-02    0.03 0.8599\n#&gt;  REGRESSION   3  4.860323e+03 1.620108e+03  570.27 &lt;.0001\n#&gt;  ERROR      196  5.568253e+02 2.840945e+00\n\n\n\n13.1.2 lm()\n\n\nShow the codemlm_lm&lt;- lm(sales~TV+radio+newspaper,data = advertising)\nsummary(mlm_lm)\n#&gt; \n#&gt; Call:\n#&gt; lm(formula = sales ~ TV + radio + newspaper, data = advertising)\n#&gt; \n#&gt; Residuals:\n#&gt;     Min      1Q  Median      3Q     Max \n#&gt; -8.8277 -0.8908  0.2418  1.1893  2.8292 \n#&gt; \n#&gt; Coefficients:\n#&gt;              Estimate Std. Error t value Pr(&gt;|t|)    \n#&gt; (Intercept)  2.938889   0.311908   9.422   &lt;2e-16 ***\n#&gt; TV           0.045765   0.001395  32.809   &lt;2e-16 ***\n#&gt; radio        0.188530   0.008611  21.893   &lt;2e-16 ***\n#&gt; newspaper   -0.001037   0.005871  -0.177     0.86    \n#&gt; ---\n#&gt; Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n#&gt; \n#&gt; Residual standard error: 1.686 on 196 degrees of freedom\n#&gt; Multiple R-squared:  0.8972, Adjusted R-squared:  0.8956 \n#&gt; F-statistic: 570.3 on 3 and 196 DF,  p-value: &lt; 2.2e-16\n\nbroom::tidy(mlm_lm)\n#&gt; # A tibble: 4 × 5\n#&gt;   term        estimate std.error statistic  p.value\n#&gt;   &lt;chr&gt;          &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt;\n#&gt; 1 (Intercept)  2.94      0.312       9.42  1.27e-17\n#&gt; 2 TV           0.0458    0.00139    32.8   1.51e-81\n#&gt; 3 radio        0.189     0.00861    21.9   1.51e-54\n#&gt; 4 newspaper   -0.00104   0.00587    -0.177 8.60e- 1\nbroom::glance(mlm_lm)\n#&gt; # A tibble: 1 × 12\n#&gt;   r.squared adj.r.squared sigma statistic  p.value    df logLik   AIC   BIC\n#&gt;       &lt;dbl&gt;         &lt;dbl&gt; &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt; &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n#&gt; 1     0.897         0.896  1.69      570. 1.58e-96     3  -386.  782.  799.\n#&gt; # ℹ 3 more variables: deviance &lt;dbl&gt;, df.residual &lt;int&gt;, nobs &lt;int&gt;\n\nlogLik(mlm_lm)\n#&gt; 'log Lik.' -386.1811 (df=5)\ncar::vif(mlm_lm)\n#&gt;        TV     radio newspaper \n#&gt;  1.004611  1.144952  1.145187\n\n\n\n13.1.3 线性组合\n我们经常希望对回归系数的线性组合进行推断，特别是对于多个类别的分类变量。例如，对于分类变量，回归系数表示其中一个组与参考类别之间的平均差异\n\nShow the codelibrary(multcomp, quietly = T)\nconfint(mlm_lm)\n#&gt;                   2.5 %     97.5 %\n#&gt; (Intercept)  2.32376228 3.55401646\n#&gt; TV           0.04301371 0.04851558\n#&gt; radio        0.17154745 0.20551259\n#&gt; newspaper   -0.01261595 0.01054097\n# 在 R 中，我们通过首先指定一个矩阵来执行此计算，该矩阵指定要进行的比较。此处的矩阵必须具有与回归方程中的回归系数相同的列数\ncomparison &lt;- matrix(c(0,3,1,1), nrow=1)\n\nlincom &lt;- glht(mlm_lm, linfct = comparison)\nsummary(lincom)\n#&gt; \n#&gt;   Simultaneous Tests for General Linear Hypotheses\n#&gt; \n#&gt; Fit: lm(formula = sales ~ TV + radio + newspaper, data = advertising)\n#&gt; \n#&gt; Linear Hypotheses:\n#&gt;        Estimate Std. Error t value Pr(&gt;|t|)    \n#&gt; 1 == 0 0.324786   0.009268   35.05   &lt;2e-16 ***\n#&gt; ---\n#&gt; Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n#&gt; (Adjusted p values reported -- single-step method)\nconfint(lincom)\n#&gt; \n#&gt;   Simultaneous Confidence Intervals\n#&gt; \n#&gt; Fit: lm(formula = sales ~ TV + radio + newspaper, data = advertising)\n#&gt; \n#&gt; Quantile = 1.9721\n#&gt; 95% family-wise confidence level\n#&gt;  \n#&gt; \n#&gt; Linear Hypotheses:\n#&gt;        Estimate lwr    upr   \n#&gt; 1 == 0 0.3248   0.3065 0.3431",
    "crumbs": [
      "统计模型",
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>多元线性回归</span>"
    ]
  },
  {
    "objectID": "multiple_linear_regression.html#交互项",
    "href": "multiple_linear_regression.html#交互项",
    "title": "\n13  多元线性回归\n",
    "section": "\n13.2 交互项",
    "text": "13.2 交互项\n\nShow the codelm_interact&lt;- lm(sales ~ .+ TV:radio, data = advertising)\n\nlm_interact\n#&gt; \n#&gt; Call:\n#&gt; lm(formula = sales ~ . + TV:radio, data = advertising)\n#&gt; \n#&gt; Coefficients:\n#&gt; (Intercept)           id           TV        radio    newspaper     TV:radio  \n#&gt;   6.7912439   -0.0005502    0.0190783    0.0278567    0.0012488    0.0010873",
    "crumbs": [
      "统计模型",
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>多元线性回归</span>"
    ]
  },
  {
    "objectID": "multiple_linear_regression.html#变换",
    "href": "multiple_linear_regression.html#变换",
    "title": "\n13  多元线性回归\n",
    "section": "\n13.3 变换",
    "text": "13.3 变换\n\n13.3.1 多项式\n\nShow the codelm(sales ~ TV+ I(TV^2),data = advertising)\n#&gt; \n#&gt; Call:\n#&gt; lm(formula = sales ~ TV + I(TV^2), data = advertising)\n#&gt; \n#&gt; Coefficients:\n#&gt; (Intercept)           TV      I(TV^2)  \n#&gt;   6.114e+00    6.727e-02   -6.847e-05\n\n\n\n13.3.2 对数变换\n\nShow the codelm(sales ~ log(TV),data = advertising)\n#&gt; \n#&gt; Call:\n#&gt; lm(formula = sales ~ log(TV), data = advertising)\n#&gt; \n#&gt; Coefficients:\n#&gt; (Intercept)      log(TV)  \n#&gt;      -4.203        3.901",
    "crumbs": [
      "统计模型",
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>多元线性回归</span>"
    ]
  },
  {
    "objectID": "multiple_linear_regression.html#回归诊断",
    "href": "multiple_linear_regression.html#回归诊断",
    "title": "\n13  多元线性回归\n",
    "section": "\n13.4 回归诊断",
    "text": "13.4 回归诊断\nhttps://www.statmethods.net/stats/rdiagnostics.html\n\nShow the codelibrary(car)\ncar::scatterplotMatrix(ad)  # 多重共线性\n\n\n\n\n\n\nShow the codeconfint(mlm_lm)  # 95%置信区间\n#&gt;                   2.5 %     97.5 %\n#&gt; (Intercept)  2.32376228 3.55401646\n#&gt; TV           0.04301371 0.04851558\n#&gt; radio        0.17154745 0.20551259\n#&gt; newspaper   -0.01261595 0.01054097\nplot(mlm_lm)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nShow the codeautoplot(mlm_lm) #回归诊断图\n\n\n\n\n\n\n\n\n13.4.1 线性假设\n残差图， 成分残差图\n\nShow the codeplot(mlm_lm,1)  \n\n\n\n\n\n\nShow the codecrPlots(mlm_lm)\n\n\n\n\n\n\n\n\n13.4.2 正态性假设Q-Q图\nStandardized Residuals\n\nShow the codeplot(mlm_lm,2) \n\n\n\n\n\n\nShow the codesummary(powerTransform(mlm_lm))  \n#&gt; bcPower Transformation to Normality \n#&gt;    Est Power Rounded Pwr Wald Lwr Bnd Wald Upr Bnd\n#&gt; Y1    0.9074           1       0.7569       1.0578\n#&gt; \n#&gt; Likelihood ratio test that transformation parameter is equal to 0\n#&gt;  (log transformation)\n#&gt;                            LRT df       pval\n#&gt; LR test, lambda = (0) 147.1578  1 &lt; 2.22e-16\n#&gt; \n#&gt; Likelihood ratio test that no transformation is needed\n#&gt;                           LRT df    pval\n#&gt; LR test, lambda = (1) 1.41991  1 0.23342\n\n\n\nShow the codeplot(mlm_lm,3)\n\n\n\n\n\n\n\n\n13.4.3 误差相关性\n\nShow the codedurbinWatsonTest(mlm_lm)      #结果表明rho=0\n#&gt;  lag Autocorrelation D-W Statistic p-value\n#&gt;    1     -0.04687792      2.083648   0.542\n#&gt;  Alternative hypothesis: rho != 0\n\n\n\n13.4.4 误差项的方差齐性\n\nShow the codencvTest(mlm_lm)\n#&gt; Non-constant Variance Score Test \n#&gt; Variance formula: ~ fitted.values \n#&gt; Chisquare = 5.355982, Df = 1, p = 0.020651\nspreadLevelPlot(mlm_lm)\n\n\n\n\n\n\n#&gt; \n#&gt; Suggested power transformation:  1.499852\n\n\nShow the codetibble(\n    abs_studentized_residuals=abs(rstudent(mlm_lm)),\n    fitted_values=mlm_lm$model$sales\n) %&gt;% ggplot(aes(fitted_values,abs_studentized_residuals))+\n    geom_point(pch=21)+\n    geom_smooth()\n\n\n\n\n\n\n\n\n13.4.5 异常观测点\n\nShow the code# studentized residual Plot\nresidplot&lt;-function(fit,nbreaks=10){\n  z&lt;-rstudent(fit)\n  hist(z,breaks=nbreaks,freq=FALSE)     #密度直方图\n  title(xlab=\"Studentized Residual\")\n  rug(z,col=\"brown\")                    #轴须图\n  curve(dnorm(x,mean=mean(z),sd=sd(z)),add=TRUE,col=\"blue\",lwd=2) #正态密度曲线\n  lines(density(z)$x,density(z)$y,col=\"red\",lwd=2)       #样本密度曲线\n  legend(\"topright\",c(\"Normal Curve\",\"Kernel Density Curve\"),#图例\n  lty = c(3,2),pch = c(21,22),col=c(\"blue\",\"red\"),cex=.7)\n}\nresidplot(mlm_lm)\n\n\n\n\n\n\n\n\nShow the code#######################################################################\nlibrary(car)\noutlierTest(mlm_lm)            #离群点\n#高杠杆值点\nhat.plot&lt;-function(fit){\n  p&lt;-length(coefficients(fit)) #模型估计的参数数目（包含截距项）\n  n&lt;-length(fitted(fit))       #样本量\n  plot(hatvalues(fit),main=\"Index Plot of Hat Values\")#帽子值\n  abline(h=c(2,3)*p/n,col=\"red\",lty=2)  #大于帽子均值p/n的2或3倍被认为是高杠杆值\n  identity(1:n,hatvalues(fit),names(hatvalues(fit)))\n}\nhat.plot(mlm_lm)\n####强影响点\n#Cook's D图形    大于4/(n-k-1)  k为预测变量数目\ncutoff&lt;-4/(nrow(advertising)-length(mlm_lm$coefficients)-2)\n{plot(mlm_lm,which=4,cook.levels=cutoff)\nabline(h=cutoff,lty=2,col=\"red\")}\n#变量添加图\navPlots(mlm_lm,ask=FALSE,id.method=\"identity\")\n\n###\ninfluencePlot(mlm_lm,id.method=\"identity\",main=\"Influence Plot\")\n\n\n\n13.4.6 多重共线性\n\nShow the codecar::vif(mlm_lm)\n#&gt;        TV     radio newspaper \n#&gt;  1.004611  1.144952  1.145187\n\nsqrt(car::vif(mlm_lm))&gt;=2       #vif平方根 ≥2 存在\n#&gt;        TV     radio newspaper \n#&gt;     FALSE     FALSE     FALSE",
    "crumbs": [
      "统计模型",
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>多元线性回归</span>"
    ]
  },
  {
    "objectID": "multiple_linear_regression.html#逐步回归",
    "href": "multiple_linear_regression.html#逐步回归",
    "title": "\n13  多元线性回归\n",
    "section": "\n13.5 逐步回归",
    "text": "13.5 逐步回归\n逐步回归是筛选变量，有向前、向后和两个方向同时进行三个方法。\n\ndirection = \"both\"双向\ndirection = \"backward\"向后\ndirection = \"forward\"向前\n\n\nShow the codestep_full &lt;- lm(sales~ . ,data = advertising[-1])\nstep_lm_0 &lt;- lm(sales~ 1 ,data = advertising[-1])\n\nstep_forward &lt;- stats::step(step_lm_0,scope =formula(step_full),  \n                            direction = \"forward\")\n#&gt; Start:  AIC=661.8\n#&gt; sales ~ 1\n#&gt; \n#&gt;             Df Sum of Sq    RSS    AIC\n#&gt; + TV         1    3314.6 2102.5 474.52\n#&gt; + radio      1    1798.7 3618.5 583.10\n#&gt; + newspaper  1     282.3 5134.8 653.10\n#&gt; &lt;none&gt;                   5417.1 661.80\n#&gt; \n#&gt; Step:  AIC=474.52\n#&gt; sales ~ TV\n#&gt; \n#&gt;             Df Sum of Sq     RSS    AIC\n#&gt; + radio      1   1545.62  556.91 210.82\n#&gt; + newspaper  1    183.97 1918.56 458.20\n#&gt; &lt;none&gt;                   2102.53 474.52\n#&gt; \n#&gt; Step:  AIC=210.82\n#&gt; sales ~ TV + radio\n#&gt; \n#&gt;             Df Sum of Sq    RSS    AIC\n#&gt; &lt;none&gt;                   556.91 210.82\n#&gt; + newspaper  1  0.088717 556.83 212.79\nsummary(step_forward)\n#&gt; \n#&gt; Call:\n#&gt; lm(formula = sales ~ TV + radio, data = advertising[-1])\n#&gt; \n#&gt; Residuals:\n#&gt;     Min      1Q  Median      3Q     Max \n#&gt; -8.7977 -0.8752  0.2422  1.1708  2.8328 \n#&gt; \n#&gt; Coefficients:\n#&gt;             Estimate Std. Error t value Pr(&gt;|t|)    \n#&gt; (Intercept)  2.92110    0.29449   9.919   &lt;2e-16 ***\n#&gt; TV           0.04575    0.00139  32.909   &lt;2e-16 ***\n#&gt; radio        0.18799    0.00804  23.382   &lt;2e-16 ***\n#&gt; ---\n#&gt; Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n#&gt; \n#&gt; Residual standard error: 1.681 on 197 degrees of freedom\n#&gt; Multiple R-squared:  0.8972, Adjusted R-squared:  0.8962 \n#&gt; F-statistic: 859.6 on 2 and 197 DF,  p-value: &lt; 2.2e-16\n\n\n\nstep_backward &lt;- stats::step(object = step_full,#scope = formula(step_lm_0) ,\n                         direction = \"backward\")\n#&gt; Start:  AIC=212.79\n#&gt; sales ~ TV + radio + newspaper\n#&gt; \n#&gt;             Df Sum of Sq    RSS    AIC\n#&gt; - newspaper  1      0.09  556.9 210.82\n#&gt; &lt;none&gt;                    556.8 212.79\n#&gt; - radio      1   1361.74 1918.6 458.20\n#&gt; - TV         1   3058.01 3614.8 584.90\n#&gt; \n#&gt; Step:  AIC=210.82\n#&gt; sales ~ TV + radio\n#&gt; \n#&gt;         Df Sum of Sq    RSS    AIC\n#&gt; &lt;none&gt;                556.9 210.82\n#&gt; - radio  1    1545.6 2102.5 474.52\n#&gt; - TV     1    3061.6 3618.5 583.10\nsummary(step_backward )\n#&gt; \n#&gt; Call:\n#&gt; lm(formula = sales ~ TV + radio, data = advertising[-1])\n#&gt; \n#&gt; Residuals:\n#&gt;     Min      1Q  Median      3Q     Max \n#&gt; -8.7977 -0.8752  0.2422  1.1708  2.8328 \n#&gt; \n#&gt; Coefficients:\n#&gt;             Estimate Std. Error t value Pr(&gt;|t|)    \n#&gt; (Intercept)  2.92110    0.29449   9.919   &lt;2e-16 ***\n#&gt; TV           0.04575    0.00139  32.909   &lt;2e-16 ***\n#&gt; radio        0.18799    0.00804  23.382   &lt;2e-16 ***\n#&gt; ---\n#&gt; Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n#&gt; \n#&gt; Residual standard error: 1.681 on 197 degrees of freedom\n#&gt; Multiple R-squared:  0.8972, Adjusted R-squared:  0.8962 \n#&gt; F-statistic: 859.6 on 2 and 197 DF,  p-value: &lt; 2.2e-16\n\nstep_both&lt;- stats::step(object = step_lm_0, scope = formula(step_full) ,\n                         direction = \"both\")\n#&gt; Start:  AIC=661.8\n#&gt; sales ~ 1\n#&gt; \n#&gt;             Df Sum of Sq    RSS    AIC\n#&gt; + TV         1    3314.6 2102.5 474.52\n#&gt; + radio      1    1798.7 3618.5 583.10\n#&gt; + newspaper  1     282.3 5134.8 653.10\n#&gt; &lt;none&gt;                   5417.1 661.80\n#&gt; \n#&gt; Step:  AIC=474.52\n#&gt; sales ~ TV\n#&gt; \n#&gt;             Df Sum of Sq    RSS    AIC\n#&gt; + radio      1    1545.6  556.9 210.82\n#&gt; + newspaper  1     184.0 1918.6 458.20\n#&gt; &lt;none&gt;                   2102.5 474.52\n#&gt; - TV         1    3314.6 5417.1 661.80\n#&gt; \n#&gt; Step:  AIC=210.82\n#&gt; sales ~ TV + radio\n#&gt; \n#&gt;             Df Sum of Sq    RSS    AIC\n#&gt; &lt;none&gt;                    556.9 210.82\n#&gt; + newspaper  1      0.09  556.8 212.79\n#&gt; - radio      1   1545.62 2102.5 474.52\n#&gt; - TV         1   3061.57 3618.5 583.10\nsummary(step_both)\n#&gt; \n#&gt; Call:\n#&gt; lm(formula = sales ~ TV + radio, data = advertising[-1])\n#&gt; \n#&gt; Residuals:\n#&gt;     Min      1Q  Median      3Q     Max \n#&gt; -8.7977 -0.8752  0.2422  1.1708  2.8328 \n#&gt; \n#&gt; Coefficients:\n#&gt;             Estimate Std. Error t value Pr(&gt;|t|)    \n#&gt; (Intercept)  2.92110    0.29449   9.919   &lt;2e-16 ***\n#&gt; TV           0.04575    0.00139  32.909   &lt;2e-16 ***\n#&gt; radio        0.18799    0.00804  23.382   &lt;2e-16 ***\n#&gt; ---\n#&gt; Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n#&gt; \n#&gt; Residual standard error: 1.681 on 197 degrees of freedom\n#&gt; Multiple R-squared:  0.8972, Adjusted R-squared:  0.8962 \n#&gt; F-statistic: 859.6 on 2 and 197 DF,  p-value: &lt; 2.2e-16",
    "crumbs": [
      "统计模型",
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>多元线性回归</span>"
    ]
  },
  {
    "objectID": "multiple_linear_regression.html#模型选择和优化",
    "href": "multiple_linear_regression.html#模型选择和优化",
    "title": "\n13  多元线性回归\n",
    "section": "\n13.6 模型选择和优化",
    "text": "13.6 模型选择和优化\n\n\nn是观测值的数量，p是模型的参数数（等于回归系数的数量）\n\n\n\\(\\mathcal{L}\\)是模型拟合的最大似然值\n\nShow the code########################两模型比较\nlm1 &lt;- lm(sales~TV+radio+newspaper,data = advertising)\nlm2 &lt;- lm(sales~TV*radio*newspaper,data = advertising)\n\nanova(lm2,lm1) #anova() 嵌套模型\n#&gt; Analysis of Variance Table\n#&gt; \n#&gt; Model 1: sales ~ TV * radio * newspaper\n#&gt; Model 2: sales ~ TV + radio + newspaper\n#&gt;   Res.Df    RSS Df Sum of Sq      F    Pr(&gt;F)    \n#&gt; 1    192 169.86                                  \n#&gt; 2    196 556.83 -4   -386.97 109.35 &lt; 2.2e-16 ***\n#&gt; ---\n#&gt; Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\n##########################################            AIC \nAIC(lm2,lm1)  # 赤池信息准则  AIC值小的优先选择\n#&gt;     df      AIC\n#&gt; lm2  9 552.9065\n#&gt; lm1  5 782.3622\n#BIC\n\n\n####################################相对重要性##################################\nad &lt;- scale(advertising[-1])\nad\n#&gt;                 TV        radio    newspaper        sales\n#&gt;   [1,]  0.96742460  0.979065591  1.774492530  1.548168135\n#&gt;   [2,] -1.19437904  1.080097401  0.667902716 -0.694303815\n#&gt;   [3,] -1.51235985  1.524637364  1.779084189 -0.905134512\n#&gt;   [4,]  0.05191939  1.214806480  1.283185019  0.858176766\n#&gt;   [5,]  0.39319551 -0.839506984  1.278593360 -0.215143142\n#&gt;   [6,] -1.61136487  1.726700983  2.040808751 -1.307629477\n#&gt;   [7,] -1.04295960  0.642292892 -0.323895625 -0.425973838\n#&gt;   [8,] -0.31265202 -0.246787034 -0.870303044 -0.157643861\n#&gt;   [9,] -1.61252963 -1.425491481 -1.357018896 -1.767623723\n#&gt;  [10,]  0.61450084 -1.391814211 -0.429503781 -0.655970962\n#&gt;  [11,] -0.94278982 -1.176279684 -0.291754012 -1.039299500\n#&gt;  [12,]  0.78805080  0.049572941 -1.219269126  0.647346069\n#&gt;  [13,] -1.43548537  0.797208333  1.622967784 -0.924300938\n#&gt;  [14,] -0.57705364 -1.055041512 -1.072336039 -0.828468804\n#&gt;  [15,]  0.66458573  0.649028346  0.709227646  0.954008900\n#&gt;  [16,]  0.56325118  1.645875535  1.026052116  1.605667416\n#&gt;  [17,] -0.92298882  0.898240143  3.831555755 -0.291808850\n#&gt;  [18,]  1.56494899  1.100303763  1.159210227  1.988995954\n#&gt;  [19,] -0.90668211 -0.186167948 -0.562661892 -0.521805973\n#&gt;  [20,]  0.00299927  0.042837487 -0.525928620  0.110686115\n#&gt;  [21,]  0.83114711  0.298784739  1.049010411  0.762344631\n#&gt;  [22,]  1.05245243 -1.223427861 -0.323895625 -0.291808850\n#&gt;  [23,] -1.55895045 -0.495998831  0.874527370 -1.614292308\n#&gt;  [24,]  0.94645883 -0.428644291 -0.199920832  0.283183958\n#&gt;  [25,] -0.98705089 -0.718268813 -0.562661892 -0.828468804\n#&gt;  [26,]  1.34946748 -1.331195125 -0.507561984 -0.387640985\n#&gt;  [27,] -0.04825039  0.406552002 -0.824386454  0.187351823\n#&gt;  [28,]  1.08390109 -0.442115199 -0.351445579  0.359849666\n#&gt;  [29,]  1.18523563  0.258372015 -0.351445579  0.934842473\n#&gt;  [30,] -0.89037540 -0.489263377  0.470461379 -0.675137388\n#&gt;  [31,]  1.69889695  0.339197463  0.580661195  1.414003146\n#&gt;  [32,] -0.39767985 -0.394967022  0.369444882 -0.406807411\n#&gt;  [33,] -0.58054794 -1.465904205 -0.025437791 -0.847635231\n#&gt;  [34,]  1.38091613 -0.219845218 -1.389160509  0.647346069\n#&gt;  [35,] -0.59801941 -1.472639659 -1.063152721 -0.866801658\n#&gt;  [36,]  1.67327212 -1.290782401 -1.012644472 -0.234309569\n#&gt;  [37,]  1.39605808  1.383192830 -1.173352536  2.180660223\n#&gt;  [38,] -0.84262004  1.760378253  0.695452669  0.129852542\n#&gt;  [39,] -1.21068574  0.231430199  0.208736817 -0.751803096\n#&gt;  [40,]  0.94296453  0.972330137  0.066395389  1.433169573\n#&gt;  [41,]  0.64594949 -0.064929776  0.048028753  0.494014654\n#&gt;  [42,]  0.34893444  0.682705616  0.374036541  0.589846789\n#&gt;  [43,]  1.70705030  0.298784739 -1.320285624  1.279838158\n#&gt;  [44,]  0.69719914 -1.001157880 -0.190737514 -0.215143142\n#&gt;  [45,] -1.42034342  0.164075659  0.585252854 -1.058465927\n#&gt;  [46,]  0.32680391 -0.051458868  0.043437094  0.168185396\n#&gt;  [47,] -0.66790531 -0.900126070  0.236286771 -0.655970962\n#&gt;  [48,]  1.08157156  1.228277388 -0.553478574  1.758998831\n#&gt;  [49,]  0.93364642 -0.502734285  0.888302347  0.149018969\n#&gt;  [50,] -0.93347170 -0.778887899  0.286795020 -0.828468804\n#&gt;  [51,]  0.61450084 -1.358136941  0.185778522 -0.502639546\n#&gt;  [52,] -0.54327546 -0.920332432 -1.237635762 -0.636804535\n#&gt;  [53,]  0.80785181  1.241748296  0.415361472  1.644000269\n#&gt;  [54,]  0.41416128  1.544843726  1.292368337  1.375670293\n#&gt;  [55,]  1.34713795  0.372874732 -0.672861707  1.184006023\n#&gt;  [56,]  0.60401795  1.760378253  1.352059904  1.854830966\n#&gt;  [57,] -1.62767157  0.325726555  0.498011333 -1.633458735\n#&gt;  [58,] -0.12628963 -0.273728850 -0.640720094 -0.157643861\n#&gt;  [59,]  0.74262497  1.773849161  0.328119951  1.873997393\n#&gt;  [60,]  0.74146021  0.420022910 -0.975911200  0.839010339\n#&gt;  [61,] -1.08955020 -1.432226935 -0.420320463 -1.135131635\n#&gt;  [62,]  1.33083124  1.309102836  1.108701978  1.950663100\n#&gt;  [63,]  1.07458297 -0.522940647 -0.149412583  0.321516812\n#&gt;  [64,] -0.51648587  0.426758364 -1.017236131 -0.004312446\n#&gt;  [65,] -0.18569264  1.315838290 -0.075946040  0.762344631\n#&gt;  [66,] -0.90901164 -0.940538794 -1.361610555 -0.905134512\n#&gt;  [67,] -1.34579847  0.089985665 -1.301918988 -0.866801658\n#&gt;  [68,] -0.09018192 -0.590295187 -0.934586269 -0.119311008\n#&gt;  [69,]  1.05245243  0.285313831 -0.897852997  0.934842473\n#&gt;  [70,]  0.81251087  1.389928284 -0.154004242  1.586500989\n#&gt;  [71,]  0.60634748  0.494112904  0.374036541  0.819843912\n#&gt;  [72,] -0.43378756 -0.603766095  0.052620412 -0.310975277\n#&gt;  [73,] -1.40054242  0.655763800 -0.516745302 -1.000966646\n#&gt;  [74,] -0.20549365 -1.183015138  0.034253776 -0.579305254\n#&gt;  [75,]  0.77290886  0.089985665 -0.801428159  0.570680362\n#&gt;  [76,] -1.51585415  1.376457376  2.702007645 -1.020133073\n#&gt;  [77,] -1.39238907 -1.459168751 -0.452462076 -1.365128758\n#&gt;  [78,] -0.30915772  0.352668371 -0.750919910  0.034020408\n#&gt;  [79,] -1.64980211  0.446964726 -0.971319541 -1.671791589\n#&gt;  [80,] -0.36157214 -1.048306058 -0.342262261 -0.579305254\n#&gt;  [81,] -0.82281904  0.231430199 -0.378995532 -0.425973838\n#&gt;  [82,]  1.08040679 -1.290782401  0.291386679 -0.330141704\n#&gt;  [83,] -0.83563145 -0.199638856  0.089353684 -0.521805973\n#&gt;  [84,] -0.91600023  1.430341008  0.231695112 -0.080978154\n#&gt;  [85,]  0.77407363  1.329309198  0.149045251  1.471502427\n#&gt;  [86,]  0.53762635 -0.327612482  1.613784466  0.225684677\n#&gt;  [87,] -0.82398380  0.285313831 -0.668270048 -0.387640985\n#&gt;  [88,] -0.42330468  1.167658302  1.498992991  0.379016092\n#&gt;  [89,] -0.68421201  0.150604751  1.967342208 -0.215143142\n#&gt;  [90,] -0.43378756  1.652610989  0.957177231  0.513181081\n#&gt;  [91,] -0.14842017 -1.236898769 -0.975911200 -0.540972400\n#&gt;  [92,] -1.37957665 -1.465904205  0.112311979 -1.288463050\n#&gt;  [93,]  0.82299375  0.689441070  1.306143314  1.030674608\n#&gt;  [94,]  1.20969569  0.891504689  1.916833959  1.567334562\n#&gt;  [95,] -0.46174192 -0.623972457 -0.902444656 -0.483473119\n#&gt;  [96,]  0.18936165  0.561467444  1.026052116  0.551513935\n#&gt;  [97,]  0.58887601 -1.331195125 -1.132027606 -0.445140265\n#&gt;  [98,]  0.44095087 -0.152490678 -0.392770509  0.283183958\n#&gt;  [99,]  1.66162447  1.282161020  0.947993914  2.180660223\n#&gt; [100,] -0.13793728  1.241748296  0.704635987  0.609013216\n#&gt; [101,]  0.87773770 -1.277311493  0.883710688 -0.445140265\n#&gt; [102,]  1.73966372  0.878033781  3.230048428  1.873997393\n#&gt; [103,]  1.55097181 -0.886655162 -0.420320463  0.149018969\n#&gt; [104,]  0.47589381 -0.408437930 -0.581028528  0.129852542\n#&gt; [105,]  1.06177055  0.743324702 -1.159577559  1.279838158\n#&gt; [106,] -0.10648863  1.558314633  1.306143314  0.992341754\n#&gt; [107,] -1.42150819 -0.826036076 -0.039212768 -1.307629477\n#&gt; [108,] -0.65975195 -1.546729653 -0.337670602 -1.020133073\n#&gt; [109,] -1.56011521 -1.539994199 -0.227470786 -1.671791589\n#&gt; [110,]  1.26211011  0.244901107 -1.150394241  1.107340316\n#&gt; [111,]  0.91733971 -1.014628788  1.191351840 -0.119311008\n#&gt; [112,]  1.10253732  0.992536499 -0.337670602  1.490668854\n#&gt; [113,]  0.33379250 -0.529676101 -1.292735670  0.014853981\n#&gt; [114,]  0.72864780 -0.179432494 -0.911627974  0.359849666\n#&gt; [115,] -0.80185327  1.585256449  0.181186863  0.110686115\n#&gt; [116,] -0.83796098  0.790472879  1.016868798 -0.272642423\n#&gt; [117,] -0.09134669 -0.603766095 -0.227470786 -0.349308131\n#&gt; [118,] -0.82281904 -1.513052383 -0.723369956 -0.885968085\n#&gt; [119,] -0.24858995  0.918446505  2.233658429  0.359849666\n#&gt; [120,] -1.48673502 -0.489263377 -0.378995532 -1.422628038\n#&gt; [121,] -0.06688662  0.238165653  0.718410964  0.283183958\n#&gt; [122,] -1.49372361 -0.105342500  0.911260642 -1.345962331\n#&gt; [123,]  0.89637394 -1.405285119 -0.686636684 -0.464306692\n#&gt; [124,] -0.27887383  0.763531064 -0.833569772  0.225684677\n#&gt; [125,]  0.96043601  0.608615622  2.004075480  1.088173889\n#&gt; [126,] -0.69702443 -0.772152445 -0.213695809 -0.655970962\n#&gt; [127,] -1.62184775  1.053155585  0.920443960 -1.422628038\n#&gt; [128,] -0.77855797 -1.566936015 -0.980502859 -1.000966646\n#&gt; [129,]  0.85327764  1.733436437 -1.256002398  2.046495235\n#&gt; [130,] -1.01849954 -0.758681537  0.576069536 -0.828468804\n#&gt; [131,] -1.70454606  1.100303763 -1.003461154 -2.380949385\n#&gt; [132,]  1.37625707 -1.371607849  0.571477877 -0.253475996\n#&gt; [133,] -1.61485916  0.265107469 -1.306510647 -1.595125881\n#&gt; [134,]  0.84745381  0.689441070  0.667902716  1.069007462\n#&gt; [135,] -1.28290117  1.032949223  1.609192807 -0.617638108\n#&gt; [136,] -1.15011797  1.598727357 -1.012644472 -0.464306692\n#&gt; [137,] -1.41451960  1.059891039 -0.975911200 -0.866801658\n#&gt; [138,]  1.47526209  0.379610186  1.338284927  1.299004585\n#&gt; [139,] -1.21185051  0.177546567 -0.461645394 -0.847635231\n#&gt; [140,]  0.44095087  1.389928284 -1.324877283  1.279838158\n#&gt; [141,] -0.85776198 -0.421908837 -0.810611477 -0.598471681\n#&gt; [142,]  0.54345018  0.817414695  2.068358705  0.992341754\n#&gt; [143,]  0.85560717  0.669234708  0.337303269  1.164839596\n#&gt; [144,] -0.49435534 -1.183015138  0.176595204 -0.694303815\n#&gt; [145,] -0.59219559 -0.570088825  0.383219859 -0.502639546\n#&gt; [146,] -0.07853427 -1.438962389 -0.989686177 -0.713470242\n#&gt; [147,]  1.08390109 -1.075247874 -1.003461154 -0.157643861\n#&gt; [148,]  1.12000880  1.733436437  0.631169444  2.180660223\n#&gt; [149,] -1.27008875  1.147451941 -0.856528067 -0.598471681\n#&gt; [150,] -1.19204951  0.170811113 -0.457053735 -0.751803096\n#&gt; [151,]  1.55679563 -0.630707911  0.295978338  0.398182519\n#&gt; [152,] -0.30333390 -1.001157880  0.833202439 -0.464306692\n#&gt; [153,]  0.58887601  0.002424763 -0.750919910  0.494014654\n#&gt; [154,]  0.28254284  1.107039217  0.328119951  0.954008900\n#&gt; [155,]  0.47472905 -0.145755224 -0.966727882  0.302350385\n#&gt; [156,] -1.66494405 -0.785623353 -1.141210924 -2.074286554\n#&gt; [157,] -0.61898518  1.362986468  0.915852301  0.244851104\n#&gt; [158,]  0.03211839 -1.479375113 -0.287162353 -0.751803096\n#&gt; [159,] -1.57642192  0.918446505  0.672494375 -1.288463050\n#&gt; [160,] -0.17870405 -0.327612482  0.185778522 -0.215143142\n#&gt; [161,]  0.29652002 -0.347818844  0.006703822  0.072353262\n#&gt; [162,] -0.71449590  0.844356511  0.860752393 -0.138477435\n#&gt; [163,]  0.48171764 -0.347818844 -0.227470786  0.168185396\n#&gt; [164,]  0.19169118  0.911711051 -1.063152721  0.762344631\n#&gt; [165,] -0.34759496 -0.576824279 -1.154985900 -0.406807411\n#&gt; [166,]  1.01867425 -1.337930579  2.490791332 -0.406807411\n#&gt; [167,] -1.50420650  0.965594683 -0.411137145 -1.154298062\n#&gt; [168,]  0.69603438 -1.216692407 -0.512153643 -0.349308131\n#&gt; [169,]  0.79620416  0.022631125  1.241860088  0.589846789\n#&gt; [170,]  1.59872717 -0.852977892 -1.109069311  0.187351823\n#&gt; [171,] -1.13031697 -0.785623353 -0.558070233 -1.077632354\n#&gt; [172,]  0.20333883 -0.159226132  0.773510872  0.091519689\n#&gt; [173,] -1.48440549 -0.213109764 -0.622353458 -1.230963769\n#&gt; [174,]  0.24876466 -1.088718782 -0.815203136 -0.445140265\n#&gt; [175,]  0.87773770 -1.337930579 -0.801428159 -0.483473119\n#&gt; [176,]  1.51253457  1.726700983  0.516377969  2.487323054\n#&gt; [177,]  1.18057657  0.467171088 -0.470828712  1.184006023\n#&gt; [178,]  0.26973043 -1.041570604  0.213328476 -0.445140265\n#&gt; [179,]  1.51020504 -1.412020573 -0.314712307 -0.425973838\n#&gt; [180,]  0.21615124 -0.893390616 -0.594803505 -0.272642423\n#&gt; [181,]  0.11132240 -1.391814211 -1.021827790 -0.675137388\n#&gt; [182,]  0.83231187 -1.203221500 -0.144820924 -0.349308131\n#&gt; [183,] -1.05810154 -1.183015138 -0.039212768 -1.020133073\n#&gt; [184,]  1.63716441  1.329309198  1.893875664  2.333991639\n#&gt; [185,]  1.24347388 -0.132284316 -0.025437791  0.685678923\n#&gt; [186,]  0.67506861  1.470753732 -0.502970325  1.644000269\n#&gt; [187,] -0.08785239 -1.425491481 -0.181554196 -0.713470242\n#&gt; [188,]  0.51316629  0.366139279 -0.567253551  0.628179642\n#&gt; [189,]  1.61852817 -0.630707911 -1.233044103  0.359849666\n#&gt; [190,] -1.49488838 -0.751946083 -0.328487284 -1.403461612\n#&gt; [191,] -1.25261728  1.201335572 -1.136619265 -0.617638108\n#&gt; [192,] -0.83330192 -0.839506984 -1.127435947 -0.790135950\n#&gt; [193,] -1.51235985 -1.290782401  0.048028753 -1.556793027\n#&gt; [194,]  0.23012842  1.261954658 -1.237635762  1.069007462\n#&gt; [195,]  0.03095363  0.830885603 -1.127435947  0.628179642\n#&gt; [196,] -1.26775922 -1.317724217 -0.769286546 -1.230963769\n#&gt; [197,] -0.61549089 -1.236898769 -1.031011108 -0.828468804\n#&gt; [198,]  0.34893444 -0.940538794 -1.109069311 -0.234309569\n#&gt; [199,]  1.59057381  1.261954658  1.636742761  2.199826650\n#&gt; [200,]  0.99071990 -0.987686972 -1.003461154 -0.119311008\n#&gt; attr(,\"scaled:center\")\n#&gt;        TV     radio newspaper     sales \n#&gt;  147.0425   23.2640   30.5540   14.0225 \n#&gt; attr(,\"scaled:scale\")\n#&gt;        TV     radio newspaper     sales \n#&gt; 85.854236 14.846809 21.778621  5.217457\n#R平方贡献率  #相对权重 \nrelweights&lt;-function(fit,...){\n  R&lt;-cor(fit$model)\n  nvar&lt;-ncol(R)\n  rxx&lt;-R[2:nvar,2:nvar]\n  rxy&lt;-R[2:nvar,1]\n  svd&lt;-eigen(rxx)\n  evec&lt;-svd$vectors\n  ev&lt;-svd$values\n  delta&lt;-diag(sqrt(ev))\n  lambda&lt;-evec %*%delta %*% t(evec)\n  lambdaasq&lt;-lambda^2\n  beta&lt;-solve(lambda) %*% rxy\n  r2&lt;-colSums(beta^2)\n  rawwgt&lt;-lambdaasq%*%beta^2\n  import&lt;-(rawwgt/r2)*100            #计算相对权重\n  import&lt;-data.frame(Weights=import)  #数据框化\n  row.names(import)&lt;-names(fit$model[2:nvar])\n  import&lt;-import[order(import$Weights),1,drop=FALSE] #升序排序\n  dotchart(import$Weights,labels=row.names(import),   #点图\n           xlab = \"% of R-Square\",pch=19,\n           main=\"Relative Importiance of Predictor Variables \",\n           sub=paste(\"Total R-Square =\",round(r2,digits = 3)),\n  ...)\nreturn(import)\n}\nrelweights(lm1,col=\"blue\")\n\n\n\n\n\n\n#&gt;             Weights\n#&gt; newspaper  2.468097\n#&gt; radio     32.198236\n#&gt; TV        65.333667",
    "crumbs": [
      "统计模型",
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>多元线性回归</span>"
    ]
  },
  {
    "objectID": "multiple_linear_regression.html#线性可加模型",
    "href": "multiple_linear_regression.html#线性可加模型",
    "title": "\n13  多元线性回归\n",
    "section": "\n13.7 线性可加模型",
    "text": "13.7 线性可加模型\nadditive model\n\\[\nY_i=\\beta_0+ \\beta_1 X_i+  \\beta_2 X_i^2+\\epsilon_i\n\\]\n\\[\nY_i=\\beta_0+ \\beta_1\\times \\log(X_i)+\\epsilon_i\n\\]\n\\[\nY_i=\\beta_0+ \\beta_1 (X_i\\times W_i)+\\epsilon_i\n\\]\n\\[\nY_i=\\beta_0+ \\beta_1\\times \\exp(X_i)+\\epsilon_i\n\\]\n\\[\nY_i=\\beta_0+ \\beta_1\\times \\sin(X_i)+\\epsilon_i\n\\]",
    "crumbs": [
      "统计模型",
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>多元线性回归</span>"
    ]
  },
  {
    "objectID": "LME.html",
    "href": "LME.html",
    "title": "\n14  线性混合模型\n",
    "section": "",
    "text": "14.1 lme4::lmer()\n线性混合效应模型 （Linear Mixed-effect Model, LMM）用于分析具有固定效应和随机效应的数据结构。它能够处理数据中的组内相关性和个体差异，广泛应用于生态学、心理学等领域的统计分析。如果数据满足正态分布但有组内相关性，使用线性混合模型（LMM）。\nMixed Effects Models and Extensions in Ecology with R 第5章\n线性混合模型的一般表达形式：\n\\[\nY = \\mathbf{X} \\beta + \\mathbf{Z} \\gamma + \\epsilon\n\\]\n其中：\nlmer() 的表达式如下：\n\\[\nlmer (data,formual= DV \\sim Fixed\\_Factor + (Random\\_intercept + Random\\_slope | Random\\_Factor))\n\\]\n截距中，1表示随机截距，0表示固定截距，默认截距为1。",
    "crumbs": [
      "统计模型",
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>线性混合模型</span>"
    ]
  },
  {
    "objectID": "LME.html#lme4lmer",
    "href": "LME.html#lme4lmer",
    "title": "\n14  线性混合模型\n",
    "section": "",
    "text": "LME\n表达式\n简写\n\n\n\n随机截距+随机斜率\ny~x+( 1+x | id )\ny~x+( x | id )\n\n\n随机截距+固定斜率\ny~x+( 1+1 | id )\ny~x+( 1 | id )\n\n\n固定截距+随机斜率\ny~x+( 0+x | id )\nNA\n\n\n线性模型：固定截距+固定斜率\ny~x\nNA",
    "crumbs": [
      "统计模型",
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>线性混合模型</span>"
    ]
  },
  {
    "objectID": "LME.html#nlmelme",
    "href": "LME.html#nlmelme",
    "title": "\n14  线性混合模型\n",
    "section": "\n14.2 nlme::lme()\n",
    "text": "14.2 nlme::lme()",
    "crumbs": [
      "统计模型",
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>线性混合模型</span>"
    ]
  },
  {
    "objectID": "LME.html#随机截距随机斜率",
    "href": "LME.html#随机截距随机斜率",
    "title": "\n14  线性混合模型\n",
    "section": "\n14.3 随机截距+随机斜率",
    "text": "14.3 随机截距+随机斜率\n\nShow the codedf_long &lt;- read_delim(\"data/AED/RIKZ.txt\")\ndf_long$Beach &lt;- factor(df_long$Beach)\ndf_long$Exposure &lt;- factor(df_long$Exposure)\nhead(df_long)\n#&gt; # A tibble: 6 × 5\n#&gt;   Sample Richness Exposure    NAP Beach\n#&gt;    &lt;dbl&gt;    &lt;dbl&gt; &lt;fct&gt;     &lt;dbl&gt; &lt;fct&gt;\n#&gt; 1      1       11 10        0.045 1    \n#&gt; 2      2       10 10       -1.04  1    \n#&gt; 3      3       13 10       -1.34  1    \n#&gt; 4      4       11 10        0.616 1    \n#&gt; 5      5       10 10       -0.684 1    \n#&gt; 6      6        8 8         1.19  2\n\n\n\\[\n\\eta_{(nrow \\times 1)} = \\mathbf{X}_{nrow \\times 1} \\beta_{1 \\times 1} + \\mathbf{Z}_{nrow \\times 2n_{subjects}} \\mathbf{\\gamma}_{2n_{subjects} \\times 1} + \\epsilon_i\n\\]\nZ有两倍于受试者数量的列，每个受试者的随机截距和随机斜率\n\nShow the codelibrary(lme4)\nlme1 &lt;- lmer(Richness ~ 1 + NAP * Exposure+ (1 + NAP |Beach) ,data = df_long)\nsummary(lme1)\n#&gt; Linear mixed model fit by REML ['lmerMod']\n#&gt; Formula: Richness ~ 1 + NAP * Exposure + (1 + NAP | Beach)\n#&gt;    Data: df_long\n#&gt; \n#&gt; REML criterion at convergence: 207.2\n#&gt; \n#&gt; Scaled residuals: \n#&gt;      Min       1Q   Median       3Q      Max \n#&gt; -1.92384 -0.36066 -0.13343  0.09819  2.84228 \n#&gt; \n#&gt; Random effects:\n#&gt;  Groups   Name        Variance Std.Dev. Corr \n#&gt;  Beach    (Intercept) 3.758    1.938         \n#&gt;           NAP         2.837    1.684    -1.00\n#&gt;  Residual             6.535    2.556         \n#&gt; Number of obs: 45, groups:  Beach, 9\n#&gt; \n#&gt; Fixed effects:\n#&gt;                Estimate Std. Error t value\n#&gt; (Intercept)     13.3457     2.2784   5.858\n#&gt; NAP             -4.1753     2.1243  -1.965\n#&gt; Exposure10      -5.3273     2.5556  -2.085\n#&gt; Exposure11      -9.7660     2.5653  -3.807\n#&gt; NAP:Exposure10   0.1646     2.3621   0.070\n#&gt; NAP:Exposure11   2.7273     2.3715   1.150\n#&gt; \n#&gt; Correlation of Fixed Effects:\n#&gt;             (Intr) NAP    Exps10 Exps11 NAP:E10\n#&gt; NAP         -0.770                             \n#&gt; Exposure10  -0.892  0.686                      \n#&gt; Exposure11  -0.888  0.683  0.792               \n#&gt; NAP:Expsr10  0.692 -0.899 -0.775 -0.615        \n#&gt; NAP:Expsr11  0.689 -0.896 -0.615 -0.779  0.806 \n#&gt; optimizer (nloptwrap) convergence code: 0 (OK)\n#&gt; boundary (singular) fit: see help('isSingular')\nAIC(lme1)\n#&gt; [1] 227.1558\nBIC(lme1)\n#&gt; [1] 245.2224\nlogLik(lme1)\n#&gt; 'log Lik.' -103.5779 (df=10)\n\n2*(1-pt(-3.914605,35,lower.tail = F))\n#&gt; [1] 0.0003993968\nlibrary(broom.mixed)\ntidy(lme1)\n#&gt; # A tibble: 10 × 6\n#&gt;    effect   group    term                 estimate std.error statistic\n#&gt;    &lt;chr&gt;    &lt;chr&gt;    &lt;chr&gt;                   &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;\n#&gt;  1 fixed    &lt;NA&gt;     (Intercept)            13.3        2.28    5.86  \n#&gt;  2 fixed    &lt;NA&gt;     NAP                    -4.18       2.12   -1.97  \n#&gt;  3 fixed    &lt;NA&gt;     Exposure10             -5.33       2.56   -2.08  \n#&gt;  4 fixed    &lt;NA&gt;     Exposure11             -9.77       2.57   -3.81  \n#&gt;  5 fixed    &lt;NA&gt;     NAP:Exposure10          0.165      2.36    0.0697\n#&gt;  6 fixed    &lt;NA&gt;     NAP:Exposure11          2.73       2.37    1.15  \n#&gt;  7 ran_pars Beach    sd__(Intercept)         1.94      NA      NA     \n#&gt;  8 ran_pars Beach    cor__(Intercept).NAP   -1         NA      NA     \n#&gt;  9 ran_pars Beach    sd__NAP                 1.68      NA      NA     \n#&gt; 10 ran_pars Residual sd__Observation         2.56      NA      NA\n\nlibrary(nlme)\n\nnlme1 &lt;- lme(Richness ~ 1 + NAP * Exposure,\n             random = ~ 1 + NAP | Beach ,\n             data = df_long,\n             control = lmeControl(opt = \"optim\", msMaxIter = 100, msMaxEval = 5000))\nsummary(nlme1)\n#&gt; Linear mixed-effects model fit by REML\n#&gt;   Data: df_long \n#&gt;        AIC      BIC    logLik\n#&gt;   227.2046 243.8402 -103.6023\n#&gt; \n#&gt; Random effects:\n#&gt;  Formula: ~1 + NAP | Beach\n#&gt;  Structure: General positive-definite, Log-Cholesky parametrization\n#&gt;             StdDev   Corr  \n#&gt; (Intercept) 1.939709 (Intr)\n#&gt; NAP         1.689580 -0.996\n#&gt; Residual    2.554676       \n#&gt; \n#&gt; Fixed effects:  Richness ~ 1 + NAP * Exposure \n#&gt;                    Value Std.Error DF   t-value p-value\n#&gt; (Intercept)    13.345694  2.278989 33  5.855970  0.0000\n#&gt; NAP            -4.175271  2.128084 33 -1.961986  0.0582\n#&gt; Exposure10     -5.323695  2.556406  6 -2.082492  0.0825\n#&gt; Exposure11     -9.765613  2.566035  6 -3.805720  0.0089\n#&gt; NAP:Exposure10  0.167146  2.366467 33  0.070631  0.9441\n#&gt; NAP:Exposure11  2.726865  2.375786 33  1.147774  0.2593\n#&gt;  Correlation: \n#&gt;                (Intr) NAP    Exps10 Exps11 NAP:E10\n#&gt; NAP            -0.767                             \n#&gt; Exposure10     -0.891  0.684                      \n#&gt; Exposure11     -0.888  0.682  0.792               \n#&gt; NAP:Exposure10  0.690 -0.899 -0.772 -0.613        \n#&gt; NAP:Exposure11  0.687 -0.896 -0.613 -0.777  0.806 \n#&gt; \n#&gt; Standardized Within-Group Residuals:\n#&gt;        Min         Q1        Med         Q3        Max \n#&gt; -1.9251786 -0.3608959 -0.1327685  0.0992999  2.8420571 \n#&gt; \n#&gt; Number of Observations: 45\n#&gt; Number of Groups: 9\n\ntidy(nlme1)\n#&gt; # A tibble: 10 × 8\n#&gt;    effect   group    term            estimate std.error    df statistic  p.value\n#&gt;    &lt;chr&gt;    &lt;chr&gt;    &lt;chr&gt;              &lt;dbl&gt;     &lt;dbl&gt; &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt;\n#&gt;  1 fixed    &lt;NA&gt;     (Intercept)       13.3        2.28    33    5.86    1.47e-6\n#&gt;  2 fixed    &lt;NA&gt;     NAP               -4.18       2.13    33   -1.96    5.82e-2\n#&gt;  3 fixed    &lt;NA&gt;     Exposure10        -5.32       2.56     6   -2.08    8.25e-2\n#&gt;  4 fixed    &lt;NA&gt;     Exposure11        -9.77       2.57     6   -3.81    8.91e-3\n#&gt;  5 fixed    &lt;NA&gt;     NAP:Exposure10     0.167      2.37    33    0.0706  9.44e-1\n#&gt;  6 fixed    &lt;NA&gt;     NAP:Exposure11     2.73       2.38    33    1.15    2.59e-1\n#&gt;  7 ran_pars Beach    sd_(Intercept)     1.94      NA       NA   NA      NA      \n#&gt;  8 ran_pars Beach    cor_NAP.(Inter…   -0.996     NA       NA   NA      NA      \n#&gt;  9 ran_pars Beach    sd_NAP             1.69      NA       NA   NA      NA      \n#&gt; 10 ran_pars Residual sd_Observation     2.55      NA       NA   NA      NA\n\n\n这个模型的公式可以分解为：\n\n固定效应部分：Richness 的预测由截距、NAP（数值变量）和 Exposure（分类变量，包含 Exposure10 和 Exposure11）及其交互项构成。\n随机效应部分：Beach 作为随机因子，包含随机截距和随机斜率（NAP）。\n\n\nShow the code# 标准化模型残差分布\nquantile(residuals(lme1,type=\"pearson\",scaled=T))\n#&gt;         0%        25%        50%        75%       100% \n#&gt; -1.9238372 -0.3606612 -0.1334336  0.0981939  2.8422803\n\n# 随机因子随机效应和显著性检验\nranef(lme1)\n#&gt; $Beach\n#&gt;     (Intercept)           NAP\n#&gt; 1 -4.274356e-02  3.713708e-02\n#&gt; 2 -2.709479e-14  2.354089e-14\n#&gt; 3  3.819348e-03 -3.318381e-03\n#&gt; 4 -2.741786e-01  2.382158e-01\n#&gt; 5  3.269522e+00 -2.840673e+00\n#&gt; 6  2.736093e-01 -2.377212e-01\n#&gt; 7 -3.250033e-03  2.823741e-03\n#&gt; 8 -2.148947e+00  1.867079e+00\n#&gt; 9 -1.077831e+00  9.364564e-01\n#&gt; \n#&gt; with conditional variances for \"Beach\"\nlmerTest::ranova(lme1)\n#&gt; ANOVA-like table for random-effects: Single term deletions\n#&gt; \n#&gt; Model:\n#&gt; Richness ~ NAP + Exposure + (1 + NAP | Beach) + NAP:Exposure\n#&gt;                          npar  logLik    AIC    LRT Df Pr(&gt;Chisq)\n#&gt; &lt;none&gt;                     10 -103.58 227.16                     \n#&gt; NAP in (1 + NAP | Beach)    8 -105.67 227.35 4.1935  2     0.1229\n\n# 查看固定效应和显著性检验\ncoef(lme1)\n#&gt; $Beach\n#&gt;   (Intercept)       NAP Exposure10 Exposure11 NAP:Exposure10 NAP:Exposure11\n#&gt; 1    13.30295 -4.138134  -5.327265  -9.766048      0.1646123       2.727307\n#&gt; 2    13.34569 -4.175271  -5.327265  -9.766048      0.1646123       2.727307\n#&gt; 3    13.34951 -4.178590  -5.327265  -9.766048      0.1646123       2.727307\n#&gt; 4    13.07152 -3.937055  -5.327265  -9.766048      0.1646123       2.727307\n#&gt; 5    16.61522 -7.015944  -5.327265  -9.766048      0.1646123       2.727307\n#&gt; 6    13.61930 -4.412992  -5.327265  -9.766048      0.1646123       2.727307\n#&gt; 7    13.34244 -4.172447  -5.327265  -9.766048      0.1646123       2.727307\n#&gt; 8    11.19675 -2.308192  -5.327265  -9.766048      0.1646123       2.727307\n#&gt; 9    12.26786 -3.238815  -5.327265  -9.766048      0.1646123       2.727307\n#&gt; \n#&gt; attr(,\"class\")\n#&gt; [1] \"coef.mer\"\nanova(lme1)\n#&gt; Analysis of Variance Table\n#&gt;              npar  Sum Sq Mean Sq F value\n#&gt; NAP             1 124.279 124.279 19.0178\n#&gt; Exposure        2 142.983  71.492 10.9400\n#&gt; NAP:Exposure    2  22.308  11.154  1.7068\n\n#  查看 类和方法\nclass(lme1)\n#&gt; [1] \"lmerMod\"\n#&gt; attr(,\"package\")\n#&gt; [1] \"lme4\"\n# methods(class = \"lmerMod\")\n\n# confint(lme1,level = 0.95)",
    "crumbs": [
      "统计模型",
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>线性混合模型</span>"
    ]
  },
  {
    "objectID": "LME.html#随机截距固定斜率",
    "href": "LME.html#随机截距固定斜率",
    "title": "\n14  线性混合模型\n",
    "section": "\n14.4 随机截距+固定斜率",
    "text": "14.4 随机截距+固定斜率\n\\[\n\\eta_{(nrow \\ \\times 1)}=\\mathbf{X_{nrow×1}}\\beta_{1\\times1} +Z_{nrow\\times n_{subjects}} \\mathbf{\\gamma}_{n_{subjects}\\times 1}+\\epsilon_i\n\\]\nZ有一倍于受试者数量的列，每个受试者的随机截距。\n\nShow the codelme2 &lt;- lmer(Richness ~ 1 + NAP+ (1 |Beach) ,data = df_long)\nsummary(lme2)\n#&gt; Linear mixed model fit by REML ['lmerMod']\n#&gt; Formula: Richness ~ 1 + NAP + (1 | Beach)\n#&gt;    Data: df_long\n#&gt; \n#&gt; REML criterion at convergence: 239.5\n#&gt; \n#&gt; Scaled residuals: \n#&gt;     Min      1Q  Median      3Q     Max \n#&gt; -1.4227 -0.4848 -0.1576  0.2519  3.9794 \n#&gt; \n#&gt; Random effects:\n#&gt;  Groups   Name        Variance Std.Dev.\n#&gt;  Beach    (Intercept) 8.668    2.944   \n#&gt;  Residual             9.362    3.060   \n#&gt; Number of obs: 45, groups:  Beach, 9\n#&gt; \n#&gt; Fixed effects:\n#&gt;             Estimate Std. Error t value\n#&gt; (Intercept)   6.5819     1.0958   6.007\n#&gt; NAP          -2.5684     0.4947  -5.192\n#&gt; \n#&gt; Correlation of Fixed Effects:\n#&gt;     (Intr)\n#&gt; NAP -0.157\nAIC(lme2)\n#&gt; [1] 247.4802\nBIC(lme2)\n#&gt; [1] 254.7069\nlogLik(lme2)\n#&gt; 'log Lik.' -119.7401 (df=4)\n\n2*(1-pt(6.007,35,lower.tail = T))\n#&gt; [1] 7.558855e-07\n\n\n\nnlme2 &lt;- lme(Richness ~ 1 + NAP * Exposure,random= ~ 1 |Beach ,data = df_long)\nsummary(nlme2)\n#&gt; Linear mixed-effects model fit by REML\n#&gt;   Data: df_long \n#&gt;        AIC      BIC    logLik\n#&gt;   227.3493 240.6578 -105.6747\n#&gt; \n#&gt; Random effects:\n#&gt;  Formula: ~1 | Beach\n#&gt;         (Intercept) Residual\n#&gt; StdDev:   0.5138683 2.971793\n#&gt; \n#&gt; Fixed effects:  Richness ~ 1 + NAP * Exposure \n#&gt;                    Value Std.Error DF   t-value p-value\n#&gt; (Intercept)    13.345694  1.483557 33  8.995739  0.0000\n#&gt; NAP            -4.175271  1.505110 33 -2.774063  0.0090\n#&gt; Exposure10     -5.544983  1.657659  6 -3.345069  0.0155\n#&gt; Exposure11     -9.730595  1.670518  6 -5.824898  0.0011\n#&gt; NAP:Exposure10  0.671731  1.643864 33  0.408629  0.6855\n#&gt; NAP:Exposure11  2.688806  1.656743 33  1.622947  0.1141\n#&gt;  Correlation: \n#&gt;                (Intr) NAP    Exps10 Exps11 NAP:E10\n#&gt; NAP            -0.278                             \n#&gt; Exposure10     -0.895  0.249                      \n#&gt; Exposure11     -0.888  0.247  0.795               \n#&gt; NAP:Exposure10  0.255 -0.916 -0.276 -0.226        \n#&gt; NAP:Exposure11  0.253 -0.908 -0.226 -0.296  0.832 \n#&gt; \n#&gt; Standardized Within-Group Residuals:\n#&gt;        Min         Q1        Med         Q3        Max \n#&gt; -1.5652904 -0.4386841 -0.1164805  0.1783113  4.1098230 \n#&gt; \n#&gt; Number of Observations: 45\n#&gt; Number of Groups: 9",
    "crumbs": [
      "统计模型",
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>线性混合模型</span>"
    ]
  },
  {
    "objectID": "LME.html#固定截距随机斜率",
    "href": "LME.html#固定截距随机斜率",
    "title": "\n14  线性混合模型\n",
    "section": "\n14.5 固定截距+随机斜率",
    "text": "14.5 固定截距+随机斜率\n\\[\n\\eta_{(nrow \\times 1)} = \\mathbf{X}_{nrow \\times 1} \\beta_{1 \\times 1} + \\mathbf{Z}_{nrow \\times n_{subjects}} \\mathbf{\\gamma}_{n_{subjects} \\times 1} + \\epsilon_i\n\\]\nZ 有一倍于受试者数量的列，每个受试者的随机斜率。\n\nShow the codelme3 &lt;- lmer(Richness ~ 1 +  NAP+ (0 + NAP |Beach) ,data = df_long)\nsummary(lme3)\n#&gt; Linear mixed model fit by REML ['lmerMod']\n#&gt; Formula: Richness ~ 1 + NAP + (0 + NAP | Beach)\n#&gt;    Data: df_long\n#&gt; \n#&gt; REML criterion at convergence: 252.2\n#&gt; \n#&gt; Scaled residuals: \n#&gt;     Min      1Q  Median      3Q     Max \n#&gt; -1.2182 -0.6636 -0.1930  0.3253  3.3347 \n#&gt; \n#&gt; Random effects:\n#&gt;  Groups   Name Variance Std.Dev.\n#&gt;  Beach    NAP   0.00    0.00    \n#&gt;  Residual      17.31    4.16    \n#&gt; Number of obs: 45, groups:  Beach, 9\n#&gt; \n#&gt; Fixed effects:\n#&gt;             Estimate Std. Error t value\n#&gt; (Intercept)   6.6857     0.6578  10.164\n#&gt; NAP          -2.8669     0.6307  -4.545\n#&gt; \n#&gt; Correlation of Fixed Effects:\n#&gt;     (Intr)\n#&gt; NAP -0.333\n#&gt; optimizer (nloptwrap) convergence code: 0 (OK)\n#&gt; boundary (singular) fit: see help('isSingular')\n\nnlme3 &lt;- lme(Richness ~ 1 + NAP,random= ~ 0+NAP |Beach ,data = df_long)\nsummary(nlme3)\n#&gt; Linear mixed-effects model fit by REML\n#&gt;   Data: df_long \n#&gt;       AIC      BIC    logLik\n#&gt;   260.201 267.2458 -126.1005\n#&gt; \n#&gt; Random effects:\n#&gt;  Formula: ~0 + NAP | Beach\n#&gt;                  NAP Residual\n#&gt; StdDev: 0.0001127408 4.159929\n#&gt; \n#&gt; Fixed effects:  Richness ~ 1 + NAP \n#&gt;                 Value Std.Error DF   t-value p-value\n#&gt; (Intercept)  6.685662 0.6577579 35 10.164320   0e+00\n#&gt; NAP         -2.866853 0.6307186 35 -4.545376   1e-04\n#&gt;  Correlation: \n#&gt;     (Intr)\n#&gt; NAP -0.333\n#&gt; \n#&gt; Standardized Within-Group Residuals:\n#&gt;        Min         Q1        Med         Q3        Max \n#&gt; -1.2181663 -0.6636488 -0.1930031  0.3253447  3.3347473 \n#&gt; \n#&gt; Number of Observations: 45\n#&gt; Number of Groups: 9",
    "crumbs": [
      "统计模型",
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>线性混合模型</span>"
    ]
  },
  {
    "objectID": "LME.html#随机效应模型",
    "href": "LME.html#随机效应模型",
    "title": "\n14  线性混合模型\n",
    "section": "\n14.6 随机效应模型",
    "text": "14.6 随机效应模型\n\nShow the code\nlme4 &lt;- lmer(Richness ~ 1 + (1|Beach) ,data = df_long)\nsummary(lme4)\n#&gt; Linear mixed model fit by REML ['lmerMod']\n#&gt; Formula: Richness ~ 1 + (1 | Beach)\n#&gt;    Data: df_long\n#&gt; \n#&gt; REML criterion at convergence: 261.1\n#&gt; \n#&gt; Scaled residuals: \n#&gt;     Min      1Q  Median      3Q     Max \n#&gt; -1.7797 -0.5070 -0.0980  0.2547  3.8063 \n#&gt; \n#&gt; Random effects:\n#&gt;  Groups   Name        Variance Std.Dev.\n#&gt;  Beach    (Intercept) 10.48    3.237   \n#&gt;  Residual             15.51    3.938   \n#&gt; Number of obs: 45, groups:  Beach, 9\n#&gt; \n#&gt; Fixed effects:\n#&gt;             Estimate Std. Error t value\n#&gt; (Intercept)    5.689      1.228   4.631\n\nnlme4 &lt;- lme(Richness ~ 1 ,random= ~ 1 |Beach ,data = df_long)\nsummary(nlme4)\n#&gt; Linear mixed-effects model fit by REML\n#&gt;   Data: df_long \n#&gt;        AIC      BIC    logLik\n#&gt;   267.1142 272.4668 -130.5571\n#&gt; \n#&gt; Random effects:\n#&gt;  Formula: ~1 | Beach\n#&gt;         (Intercept) Residual\n#&gt; StdDev:    3.237112 3.938415\n#&gt; \n#&gt; Fixed effects:  Richness ~ 1 \n#&gt;                Value Std.Error DF  t-value p-value\n#&gt; (Intercept) 5.688889  1.228419 36 4.631066       0\n#&gt; \n#&gt; Standardized Within-Group Residuals:\n#&gt;         Min          Q1         Med          Q3         Max \n#&gt; -1.77968689 -0.50704111 -0.09795286  0.25468670  3.80631705 \n#&gt; \n#&gt; Number of Observations: 45\n#&gt; Number of Groups: 9",
    "crumbs": [
      "统计模型",
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>线性混合模型</span>"
    ]
  },
  {
    "objectID": "LME.html#线性模型固定截距-固定斜率",
    "href": "LME.html#线性模型固定截距-固定斜率",
    "title": "\n14  线性混合模型\n",
    "section": "\n14.7 线性模型：固定截距+ 固定斜率",
    "text": "14.7 线性模型：固定截距+ 固定斜率\n\nShow the codelm &lt;- lm(Richness ~ 1 + NAP ,data = df_long)\nlm\n#&gt; \n#&gt; Call:\n#&gt; lm(formula = Richness ~ 1 + NAP, data = df_long)\n#&gt; \n#&gt; Coefficients:\n#&gt; (Intercept)          NAP  \n#&gt;       6.686       -2.867",
    "crumbs": [
      "统计模型",
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>线性混合模型</span>"
    ]
  },
  {
    "objectID": "LME.html#模型选择",
    "href": "LME.html#模型选择",
    "title": "\n14  线性混合模型\n",
    "section": "\n14.8 模型选择",
    "text": "14.8 模型选择\n限制最大似然法REML\n\n\n赤池信息准则（AIC）\n\\[ kIC=−2log(\\mathcal{L})+2k\\]\n其中：\n\n\\(\\mathcal{L}\\) 是似然函数。\n\\(k\\) 是模型参数的数量。\n\n\n\n贝叶斯信息准则（BIC）\n\\[ BIC=−2log(\\mathcal{L})+klog(n) \\]\n其中：\n\n\n\\(n\\) 是样本量。\n\n\n\n\nShow the code\nplot_lme &lt;- function(model, title) {\n    ggplot(df_long, aes(NAP, Richness, group = Beach, color = Beach)) +\n        geom_point() +\n        geom_line(\n            data =  bind_cols(df_long, .pred = predict(model, df_long)),\n            mapping = aes(y = .pred),\n            linewidth = 1\n        ) +\n        labs(title = title)+\n        scale_x_continuous(expand = (mult=c(0,.1)))+\n        scale_y_continuous(expand = (mult=c(0,.1)))+\n    ggsci::scale_color_jco() +\n        ggpubr::theme_pubr() +\n        theme(legend.position = \"right\",\n              plot.title = element_text(hjust = .5))\n}\n\n\nlme_plot &lt;- map2(list(lme1,lme2,lme3,lm),list(\"随机截距+随机斜率\",\"随机截距+固定斜率\",\"固定截距+随机斜率\",\"固定截距+固定斜率\"),plot_lme)\n\n\nlme_plot\n#&gt; [[1]]\n\n\n\n\n\n\n#&gt; \n#&gt; [[2]]\n\n\n\n\n\n\n#&gt; \n#&gt; [[3]]\n\n\n\n\n\n\n#&gt; \n#&gt; [[4]]\n\n\n\n\n\n\n\n\nShow the codeanova(lme1,lme2,lme3)\n#&gt; Data: df_long\n#&gt; Models:\n#&gt; lme2: Richness ~ 1 + NAP + (1 | Beach)\n#&gt; lme3: Richness ~ 1 + NAP + (0 + NAP | Beach)\n#&gt; lme1: Richness ~ 1 + NAP * Exposure + (1 + NAP | Beach)\n#&gt;      npar    AIC    BIC  logLik deviance  Chisq Df Pr(&gt;Chisq)    \n#&gt; lme2    4 249.83 257.06 -120.92   241.83                         \n#&gt; lme3    4 261.95 269.18 -126.98   253.95  0.000  0               \n#&gt; lme1   10 238.20 256.27 -109.10   218.20 35.754  6  3.077e-06 ***\n#&gt; ---\n#&gt; Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\nanova(lme1,lme2,lme3,lme4,lm)\n#&gt; Data: df_long\n#&gt; Models:\n#&gt; lme4: Richness ~ 1 + (1 | Beach)\n#&gt; lm: Richness ~ 1 + NAP\n#&gt; lme2: Richness ~ 1 + NAP + (1 | Beach)\n#&gt; lme3: Richness ~ 1 + NAP + (0 + NAP | Beach)\n#&gt; lme1: Richness ~ 1 + NAP * Exposure + (1 + NAP | Beach)\n#&gt;      npar    AIC    BIC  logLik deviance  Chisq Df Pr(&gt;Chisq)    \n#&gt; lme4    3 269.30 274.72 -131.65   263.30                         \n#&gt; lm      3 259.95 265.37 -126.98   253.95  9.350  0               \n#&gt; lme2    4 249.83 257.06 -120.92   241.83 12.124  1  0.0004977 ***\n#&gt; lme3    4 261.95 269.18 -126.98   253.95  0.000  0               \n#&gt; lme1   10 238.20 256.27 -109.10   218.20 35.754  6  3.077e-06 ***\n#&gt; ---\n#&gt; Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n# p小于0.05,说明全模型与简化后模型存在差异，最终采用lme1,AIC",
    "crumbs": [
      "统计模型",
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>线性混合模型</span>"
    ]
  },
  {
    "objectID": "LME.html#模型诊断",
    "href": "LME.html#模型诊断",
    "title": "\n14  线性混合模型\n",
    "section": "\n14.9 模型诊断",
    "text": "14.9 模型诊断\nsleepstudy\n\nShow the code# 拟合线性混合模型\nmodel &lt;- lme1\n# 1. 残差图\nresiduals &lt;- resid(model)\nfitted &lt;- fitted(model)\nggplot(data.frame(fitted, residuals), aes(fitted, residuals)) +\n  geom_point() +\n  geom_smooth(method = \"loess\", se = FALSE) +\n  labs(title = \"Residuals vs Fitted\", x = \"Fitted values\", y = \"Residuals\")\n\n\n\n\n\n\nShow the code\n# 2. QQ图\nqqnorm(residuals)\nqqline(residuals)\n\n\n\n\n\n\nShow the code\n# 3. Cook's 距离\ncooksd &lt;- cooks.distance(model)\nplot(cooksd, type = \"h\", main = \"Cook's Distance\")\n\n\n\n\n\n\nShow the code\n# 4. 随机效应的分布\nrand_dist &lt;- ranef(model)\n\nqqnorm(rand_dist$Beach$NAP)\nqqline(rand_dist$Beach$NAP)",
    "crumbs": [
      "统计模型",
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>线性混合模型</span>"
    ]
  },
  {
    "objectID": "GLM.html",
    "href": "GLM.html",
    "title": "\n15  广义线性模型\n",
    "section": "",
    "text": "15.1 GLM 组件\n在统计学上，广义线性模型（generalized linear model， GLM）是一种应用灵活的线性回归模型。该模型允许因变量的误差分布有除了正态分布之外的其它分布。此模型假设实验者所测量的随机变量的分布函数与实验中系统性效应（即非随机的效应）可经由一链接函数（link function）建立可解释其相关性的函数。\n在广义线性模式中，假设每个资料的观测值 Y 来自某个指数族分布 f 。\n广义线性模型是对线性模型的扩展，适用于非正态分布的数据，假设观测值之间是独立的，不能处理组内相关性。模型形式为：\n\\[\ng(E(Y))=\\mathbf{X} \\beta\n\\]\n\\[\n\\eta = \\mathbf{X} \\beta\n\\]\n\\[\nE(y)=\\mu\n\\]\n\\[\n\\eta =g(\\mu)=g(E(y))\n\\]\n\\[\nE(y)=g^{-1}(\\eta)\n\\]\n典型链接函数",
    "crumbs": [
      "统计模型",
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>广义线性模型</span>"
    ]
  },
  {
    "objectID": "GLM.html#glm-组件",
    "href": "GLM.html#glm-组件",
    "title": "\n15  广义线性模型\n",
    "section": "",
    "text": "线性预测子：\n\n\n\n因变量的期望值与线性预测函数的关系：\n\n\n\n链接函数 g(.) ：\n\n\n\n反链接函数g-1 (.)：\n\n\n\n\ny 的方差：\n\\[\nVar(y)=f(\\mu)=f(g^{-1}(\\mathbf{X}\\beta))\n\\]\n\n\n\n\n\nY的分布\n名称\n链接函数\n均值函数\n\n\n\n正态\n恒等\n\n\n\n\n\n指数 / Gamma\n倒数\n\n\n\n\n泊松\n自然对数\n\n\n\n\n\n二项式\n多项式\n\nLogit",
    "crumbs": [
      "统计模型",
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>广义线性模型</span>"
    ]
  },
  {
    "objectID": "GLM.html#数据来源",
    "href": "GLM.html#数据来源",
    "title": "\n15  广义线性模型\n",
    "section": "\n15.2 数据来源",
    "text": "15.2 数据来源\n数据下载网站\n\nShow the codelibrary(tidyverse)\nlibrary(patchwork)\ndf &lt;- read_csv(\"data/Default.csv\")\n\ndf &lt;- df %&gt;% \n    mutate(across(1:2, ~ factor(.x,levels = c(\"No\",\"Yes\"),labels = c(0,1))\n                  )\n           )\nstr(df)\n#&gt; tibble [10,000 × 4] (S3: tbl_df/tbl/data.frame)\n#&gt;  $ default: Factor w/ 2 levels \"0\",\"1\": 1 1 1 1 1 1 1 1 1 1 ...\n#&gt;  $ student: Factor w/ 2 levels \"0\",\"1\": 1 2 1 1 1 2 1 2 1 1 ...\n#&gt;  $ balance: num [1:10000] 730 817 1074 529 786 ...\n#&gt;  $ income : num [1:10000] 44362 12106 31767 35704 38463 ...\n\n# 是否违约 是否学生 余额 收入\nhead(df)\n#&gt; # A tibble: 6 × 4\n#&gt;   default student balance income\n#&gt;   &lt;fct&gt;   &lt;fct&gt;     &lt;dbl&gt;  &lt;dbl&gt;\n#&gt; 1 0       0          730. 44362.\n#&gt; 2 0       1          817. 12106.\n#&gt; 3 0       0         1074. 31767.\n#&gt; 4 0       0          529. 35704.\n#&gt; 5 0       0          786. 38463.\n#&gt; 6 0       1          920.  7492.\ntable(df$default,df$student)\n#&gt;    \n#&gt;        0    1\n#&gt;   0 6850 2817\n#&gt;   1  206  127\n\n\n\nShow the codeggplot(df,aes(balance,income))+\n  geom_point(aes(shape=default,color=default),show.legend = F)|\nggplot(df,aes(default,balance,fill=default),)+\n  geom_boxplot(show.legend = F)+\nggplot(df,aes(default,income,fill=default))+\n  geom_boxplot()",
    "crumbs": [
      "统计模型",
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>广义线性模型</span>"
    ]
  },
  {
    "objectID": "GLM.html#恒等链接线性回归",
    "href": "GLM.html#恒等链接线性回归",
    "title": "\n15  广义线性模型\n",
    "section": "\n15.3 恒等链接线性回归",
    "text": "15.3 恒等链接线性回归\n线性回归是一种简单的线性回归模型，其中假设响应变量服从正态分布，并且使用恒等链接函数（identity link function），t-statistic\n\nShow the codelibrary(tidymodels)\nlibrary(ggfortify)\n# 使用 glm() 函数进行高斯线性回归\nglm_gauss &lt;- linear_reg() %&gt;% \n  set_engine(\"glm\", family = stats::gaussian(link = \"identity\")) %&gt;% \n  fit(as.numeric(default)-1~balance,data=df)\n\n# 查看模型的系数\ntidy(glm_gauss)\n#&gt; # A tibble: 2 × 5\n#&gt;   term         estimate  std.error statistic   p.value\n#&gt;   &lt;chr&gt;           &lt;dbl&gt;      &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;\n#&gt; 1 (Intercept) -0.0752   0.00335        -22.4 1.26e-108\n#&gt; 2 balance      0.000130 0.00000347      37.4 2.77e-286\n\n# 查看模型性能的 AIC 和 Deviance\nglance(glm_gauss) %&gt;% dplyr::select(AIC, deviance)\n#&gt; # A tibble: 1 × 2\n#&gt;      AIC deviance\n#&gt;    &lt;dbl&gt;    &lt;dbl&gt;\n#&gt; 1 -7284.     282.\n\n\n# Change the theme and colour\nautoplot(glm_gauss, which = 1:6, ncol = 2, label.size = 3,\n         colour = \"steelblue\") + theme_bw()\n\n\n\n\n\n\n\n\nShow the codeggplot(df,aes(balance,as.numeric(default)-1))+\n  geom_point(color=\"orange\",size=1.25)+\n  geom_smooth(method = \"lm\",se=FALSE)+\n  geom_hline(yintercept = c(0,1),linetype=2)+\n  ggtitle(\"linear regression\")",
    "crumbs": [
      "统计模型",
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>广义线性模型</span>"
    ]
  },
  {
    "objectID": "GLM.html#逻辑回归",
    "href": "GLM.html#逻辑回归",
    "title": "\n15  广义线性模型\n",
    "section": "\n15.4 逻辑回归",
    "text": "15.4 逻辑回归\n逻辑回归用于处理分类问题。其模型假设响应变量的对数优势（log odds）服从线性模型。\nSigmoid 激活函数：\n\\[\nf(x)=\\frac{1}{1+e^{-x}}=\\frac{e^x}{1+e^x}\n\\]\n\nShow the codesigmoid &lt;- tibble(\n    x=seq(-6,6,length.out=1000),\n    y=1/(1+exp(-x)),\n)\nggplot(sigmoid,aes(x,y))+\n    geom_line()\n\n\n\n\n\n\n\n逻辑回归( logistic regression )的一般表达式：\n\\[\n\\pi(Y=k|X=(X_1,X_2,...,X_p)=\\frac{e^{\\beta_{k0}+\\beta_{k1}X_1+\\beta_{k2}X_2+...+\\beta_{kp}X_p}}{1+\\sum_{l=1}^{K-1} e^{\\beta_{l0}+\\beta_{l1}X_1+\\beta_{l2}X_2+...+\\beta_{lp}X_p}}\n\\] 其中\\(\\pi\\) 是成功概率，\\(k=1,2,...,K-1\\)是因变量的第k个水平，共K 个水平，\\(p\\) 是自变量个数。\nlogit link function\nz-statistic\n\n15.4.1 二分类Binary\n\n\n当\\(K=2\\)时，\\(k=l=p=1\\)即二分类逻辑回归，一般需要引入虚拟变量（哑变量，dummy variable），通常取值为 0或1。\n极大似然法（maximum likelihood），likelihood function：\n\\[\n\\ell (\\beta_0,\\beta_1)=\\prod_{i:y_i=1}\\pi(x_i)\\prod_{i':y_{i'}=0}(1-\\pi(x_{i'}))\n\\]\n\n\n\nShow the codelogit_spec &lt;- logistic_reg() %&gt;%\n  set_engine(\"glm\",family= binomial(link = \"logit\")) \n\n\nlogit_binary_y &lt;- logit_spec %&gt;% fit(default~balance,data=df)\n\nlogit_binary_y %&gt;% glance()\n#&gt; # A tibble: 1 × 8\n#&gt;   null.deviance df.null logLik   AIC   BIC deviance df.residual  nobs\n#&gt;           &lt;dbl&gt;   &lt;int&gt;  &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;    &lt;dbl&gt;       &lt;int&gt; &lt;int&gt;\n#&gt; 1         2921.    9999  -798. 1600. 1615.    1596.        9998 10000\n\ntidy(logit_binary_y,  conf.int = TRUE) %&gt;% \n    mutate(\n        z_value = estimate/std.error,\n        Wald_ChiSquare=z_value^2, #  Wald卡方值可以用来检验各个变量系数是否显著 不同于零。 它是通过系数估计的平方除以其标准误差的平方来计算的。即 z值的平方\n        OR = exp(estimate),\n        `OR 95% CI`= sprintf(\"%.3f ~ %3.f\",exp(conf.low),exp(conf.high)),\n    )\n#&gt; # A tibble: 2 × 11\n#&gt;   term         estimate std.error statistic   p.value conf.low conf.high z_value\n#&gt;   &lt;chr&gt;           &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt;     &lt;dbl&gt;   &lt;dbl&gt;\n#&gt; 1 (Intercept) -10.7      0.361        -29.5 3.62e-191 -1.14e+1  -9.97      -29.5\n#&gt; 2 balance       0.00550  0.000220      25.0 1.98e-137  5.08e-3   0.00594    25.0\n#&gt; # ℹ 3 more variables: Wald_ChiSquare &lt;dbl&gt;, OR &lt;dbl&gt;, `OR 95% CI` &lt;chr&gt;\n\n\nggplot(df,aes(balance,as.numeric(default)-1))+\n  geom_point(color=\"orange\",size=1.25)+\n  geom_smooth(method = \"glm\",\n              method.args=list(family=binomial(link = \"logit\")),se=FALSE)+\n  geom_hline(yintercept = c(0,1),linetype=2)+\n  ggtitle(\"binary logistic regression with continuous x\")\n\n\n\n\n\n\n\n\nShow the codelogit_binary_x &lt;- logit_spec %&gt;%fit(default ~ student, data = df)\n\ntidy(logit_binary_x)\n#&gt; # A tibble: 2 × 5\n#&gt;   term        estimate std.error statistic  p.value\n#&gt;   &lt;chr&gt;          &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt;\n#&gt; 1 (Intercept)   -3.50     0.0707    -49.6  0       \n#&gt; 2 student1       0.405    0.115       3.52 0.000431\n\n\nggplot(df,aes(student,as.numeric(default)-1))+\n  geom_point(color=\"orange\",size=1.25)+\n  geom_smooth(method = \"glm\",\n              method.args=list(family=binomial(link = \"logit\")),se=FALSE)+\n  geom_hline(yintercept = c(0,1),linetype=2)+\n    scale_y_continuous(\"default\", breaks = c(0,1))+\n  ggtitle(\"binary logistic regression with binary x\")\n\n\n\n\n\n\n\n\n15.4.2 二分类多元逻辑回归\n\n\n当\\(K=2\\)时，\\(k=l=1,p&gt;1\\)即多元逻辑回归（multiple logistic regression）。\n优势（odds）\n\\[\nOdds=\\frac{\\pi(X)}{1-\\pi(X)}=e^{\\beta_0+\\beta_1X_1+\\beta_2X_2+...+\\beta_pX_p}\n\\]\nlog odds (logit)\n\\[\nlogit(\\pi(X))=\\ln (\\frac{\\pi(X)}{1-\\pi(X)})=\\beta_0+\\beta_1X_1+\\beta_2X_2+...+\\beta_pX_p\n\\]\n\n\n\nShow the codelogit_multiple&lt;-logit_spec %&gt;% fit(default~balance+income+student,data=df)\n\ntidy(logit_multiple)\n#&gt; # A tibble: 4 × 5\n#&gt;   term            estimate  std.error statistic   p.value\n#&gt;   &lt;chr&gt;              &lt;dbl&gt;      &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;\n#&gt; 1 (Intercept) -10.9        0.492        -22.1   4.91e-108\n#&gt; 2 balance       0.00574    0.000232      24.7   4.22e-135\n#&gt; 3 income        0.00000303 0.00000820     0.370 7.12e-  1\n#&gt; 4 student1     -0.647      0.236         -2.74  6.19e-  3\n\n# confusion matrix 混淆矩阵\naugment(logit_multiple, new_data = df) %&gt;%\n  conf_mat(truth = default, estimate = .pred_class) %&gt;% \n    autoplot(type = \"heatmap\")\n\n\n\n\n\n\nShow the code\n#准确性 \n(9627+105)/(9627+105+40+228)\n#&gt; [1] 0.9732\naugment(logit_multiple, new_data = df) %&gt;%\n  accuracy(truth = default, estimate = .pred_class)\n#&gt; # A tibble: 1 × 3\n#&gt;   .metric  .estimator .estimate\n#&gt;   &lt;chr&gt;    &lt;chr&gt;          &lt;dbl&gt;\n#&gt; 1 accuracy binary         0.973\n\n\n\nShow the codedf_new &lt;- tibble(\n  balance = c(1000, 2000), \n  income = c(14144,24141),\n  student = factor(c(1, 0)),)\npredict(logit_multiple, new_data = df_new,type=\"class\")\n#&gt; # A tibble: 2 × 1\n#&gt;   .pred_class\n#&gt;   &lt;fct&gt;      \n#&gt; 1 0          \n#&gt; 2 1\npredict(logit_multiple, new_data = df_new, type = \"prob\")\n#&gt; # A tibble: 2 × 2\n#&gt;   .pred_0 .pred_1\n#&gt;     &lt;dbl&gt;   &lt;dbl&gt;\n#&gt; 1   0.997 0.00322\n#&gt; 2   0.337 0.663\n\n\n\n15.4.3 似然比检验\nlikelihood ratio tests (LRT)\n比较两个嵌套模型，log-likelihood (logLL)\n\n相应的p-value 源自具有 个自由度的 卡方 分布（即模型中测试的参数数量之差）。\n\nShow the codelogit_binary_y\n#&gt; parsnip model object\n#&gt; \n#&gt; \n#&gt; Call:  stats::glm(formula = default ~ balance, family = ~binomial(link = \"logit\"), \n#&gt;     data = data)\n#&gt; \n#&gt; Coefficients:\n#&gt; (Intercept)      balance  \n#&gt;  -10.651331     0.005499  \n#&gt; \n#&gt; Degrees of Freedom: 9999 Total (i.e. Null);  9998 Residual\n#&gt; Null Deviance:       2921 \n#&gt; Residual Deviance: 1596  AIC: 1600\nlogit_multiple\n#&gt; parsnip model object\n#&gt; \n#&gt; \n#&gt; Call:  stats::glm(formula = default ~ balance + income + student, family = ~binomial(link = \"logit\"), \n#&gt;     data = data)\n#&gt; \n#&gt; Coefficients:\n#&gt; (Intercept)      balance       income     student1  \n#&gt;  -1.087e+01    5.737e-03    3.033e-06   -6.468e-01  \n#&gt; \n#&gt; Degrees of Freedom: 9999 Total (i.e. Null);  9996 Residual\n#&gt; Null Deviance:       2921 \n#&gt; Residual Deviance: 1572  AIC: 1580\n\n\nLRT=2*(logLik(logit_multiple$fit)-logLik(logit_binary_y$fit))\nLRT\n#&gt; 'log Lik.' 24.90686 (df=4)\n\npval=1-pchisq(LRT,2)\npval\n#&gt; 'log Lik.' 3.904316e-06 (df=4)\n\nout&lt;-anova(logit_binary_y$fit, logit_multiple$fit)\nout\n#&gt; Analysis of Deviance Table\n#&gt; \n#&gt; Model 1: default ~ balance\n#&gt; Model 2: default ~ balance + income + student\n#&gt;   Resid. Df Resid. Dev Df Deviance  Pr(&gt;Chi)    \n#&gt; 1      9998     1596.5                          \n#&gt; 2      9996     1571.5  2   24.907 3.904e-06 ***\n#&gt; ---\n#&gt; Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n1-pchisq(out$Deviance[2],2)\n#&gt; [1] 3.904316e-06\n\n\n\n15.4.4 K&gt;2 多分类逻辑回归\n用于处理具有多于两个类别的响应变量的情况。例如，分类问题中的三个或更多类别。\n\n\n当\\(K&gt;2\\)时，\\(k,l,p&gt;1\\)即多项逻辑回归（multinomial logistic regression）。\n\\[\n\\ln (\\frac{P(Y=k|X=x)}{P(Y=K|X=x)})=\\beta_{k0}+\\beta_{k1}X_1+\\beta_{k2}X_2+...+\\beta_{kp}X_p\n\\]\n\n\n\n15.4.4.1 nnet::multinom()\n\n\nShow the codemn_spec &lt;- multinom_reg(mode = \"classification\", engine = \"nnet\")\n\niris_mnlogit &lt;- mn_spec %&gt;% \n    fit(Species ~ ., data = iris)\n\niris_mnlogit %&gt;% glance()\n#&gt; # A tibble: 1 × 4\n#&gt;     edf deviance   AIC  nobs\n#&gt;   &lt;dbl&gt;    &lt;dbl&gt; &lt;dbl&gt; &lt;int&gt;\n#&gt; 1    10     11.9  31.9   150\niris_mnlogit %&gt;% tidy()\n#&gt; # A tibble: 10 × 6\n#&gt;    y.level    term         estimate std.error statistic p.value\n#&gt;    &lt;chr&gt;      &lt;chr&gt;           &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;   &lt;dbl&gt;\n#&gt;  1 versicolor (Intercept)     18.7       35.0    0.534    0.593\n#&gt;  2 versicolor Sepal.Length    -5.46      89.9   -0.0607   0.952\n#&gt;  3 versicolor Sepal.Width     -8.71     157.    -0.0554   0.956\n#&gt;  4 versicolor Petal.Length    14.2       60.2    0.237    0.813\n#&gt;  5 versicolor Petal.Width     -3.10      45.5   -0.0681   0.946\n#&gt;  6 virginica  (Intercept)    -23.8       35.8   -0.666    0.505\n#&gt;  7 virginica  Sepal.Length    -7.92      89.9   -0.0881   0.930\n#&gt;  8 virginica  Sepal.Width    -15.4      157.    -0.0978   0.922\n#&gt;  9 virginica  Petal.Length    23.7       60.5    0.391    0.696\n#&gt; 10 virginica  Petal.Width     15.1       45.9    0.330    0.742\n\n\naugment(iris_mnlogit, new_data = iris) %&gt;%\n    conf_mat(truth = Species, estimate = .pred_class) %&gt;%\n    autoplot(type = \"heatmap\")\n\n\n\n\n\n\n\n\n15.4.4.2 glmnet::glmnet()\n\n\nShow the codelibrary(glmnet) # 多项回归\niris_glmnet &lt;- glmnet(x = iris[, -5], y = iris[, 5], family = \"multinomial\")\niris_glmnet\n#&gt; \n#&gt; Call:  glmnet(x = iris[, -5], y = iris[, 5], family = \"multinomial\") \n#&gt; \n#&gt;     Df  %Dev  Lambda\n#&gt; 1    0  0.00 0.43500\n#&gt; 2    1  6.56 0.39640\n#&gt; 3    1 12.05 0.36110\n#&gt; 4    1 16.73 0.32910\n#&gt; 5    1 20.78 0.29980\n#&gt; 6    2 25.37 0.27320\n#&gt; 7    2 29.66 0.24890\n#&gt; 8    2 33.54 0.22680\n#&gt; 9    2 37.10 0.20670\n#&gt; 10   2 40.40 0.18830\n#&gt; 11   2 43.47 0.17160\n#&gt; 12   3 46.47 0.15630\n#&gt; 13   3 49.57 0.14240\n#&gt; 14   3 52.38 0.12980\n#&gt; 15   3 54.97 0.11830\n#&gt; 16   3 57.36 0.10780\n#&gt; 17   3 59.60 0.09818\n#&gt; 18   3 61.71 0.08946\n#&gt; 19   3 63.72 0.08151\n#&gt; 20   3 65.70 0.07427\n#&gt; 21   3 67.65 0.06767\n#&gt; 22   3 69.54 0.06166\n#&gt; 23   3 71.38 0.05618\n#&gt; 24   3 73.12 0.05119\n#&gt; 25   3 74.71 0.04664\n#&gt; 26   3 76.24 0.04250\n#&gt; 27   3 77.67 0.03872\n#&gt; 28   3 78.99 0.03528\n#&gt; 29   3 80.21 0.03215\n#&gt; 30   3 81.33 0.02929\n#&gt; 31   3 82.36 0.02669\n#&gt; 32   3 83.31 0.02432\n#&gt; 33   3 84.18 0.02216\n#&gt; 34   3 84.99 0.02019\n#&gt; 35   3 85.73 0.01840\n#&gt; 36   3 86.53 0.01676\n#&gt; 37   3 87.34 0.01527\n#&gt; 38   3 88.06 0.01392\n#&gt; 39   3 88.73 0.01268\n#&gt; 40   3 89.34 0.01155\n#&gt; 41   3 89.89 0.01053\n#&gt; 42   3 90.40 0.00959\n#&gt; 43   4 90.87 0.00874\n#&gt; 44   4 91.34 0.00796\n#&gt; 45   4 91.77 0.00726\n#&gt; 46   4 92.16 0.00661\n#&gt; 47   4 92.52 0.00602\n#&gt; 48   4 92.85 0.00549\n#&gt; 49   4 93.16 0.00500\n#&gt; 50   4 93.44 0.00456\n#&gt; 51   4 93.69 0.00415\n#&gt; 52   4 93.92 0.00378\n#&gt; 53   4 94.14 0.00345\n#&gt; 54   4 94.34 0.00314\n#&gt; 55   4 94.52 0.00286\n#&gt; 56   4 94.68 0.00261\n#&gt; 57   4 94.83 0.00238\n#&gt; 58   4 94.97 0.00216\n#&gt; 59   4 95.10 0.00197\n#&gt; 60   4 95.22 0.00180\n#&gt; 61   4 95.33 0.00164\n#&gt; 62   4 95.43 0.00149\n#&gt; 63   4 95.52 0.00136\n#&gt; 64   4 95.60 0.00124\n#&gt; 65   4 95.68 0.00113\n#&gt; 66   4 95.75 0.00103\n#&gt; 67   4 95.81 0.00094\n#&gt; 68   4 95.87 0.00085\n#&gt; 69   4 95.92 0.00078\n#&gt; 70   4 95.97 0.00071\n#&gt; 71   4 96.01 0.00065\n#&gt; 72   4 96.05 0.00059\n#&gt; 73   4 96.09 0.00054\n#&gt; 74   4 96.12 0.00049\n#&gt; 75   4 96.15 0.00045\n#&gt; 76   4 96.18 0.00041\n#&gt; 77   4 96.20 0.00037\n#&gt; 78   4 96.22 0.00034\n#&gt; 79   4 96.24 0.00031\n#&gt; 80   4 96.26 0.00028\n#&gt; 81   4 96.27 0.00025\n#&gt; 82   4 96.29 0.00023\n#&gt; 83   4 96.30 0.00021\n#&gt; 84   4 96.31 0.00019\n#&gt; 85   4 96.32 0.00018\n#&gt; 86   4 96.33 0.00016\n#&gt; 87   4 96.33 0.00015\n#&gt; 88   4 96.34 0.00013\n#&gt; 89   4 96.35 0.00012\n#&gt; 90   4 96.35 0.00011\n#&gt; 91   4 96.35 0.00010\n#&gt; 92   4 96.36 0.00009\n#&gt; 93   4 96.36 0.00008\n#&gt; 94   4 96.36 0.00008\n#&gt; 95   4 96.37 0.00007\n#&gt; 96   4 96.37 0.00006\n#&gt; 97   4 96.37 0.00006\n#&gt; 98   4 96.37 0.00005\n#&gt; 99   4 96.38 0.00005\n#&gt; 100  4 96.38 0.00004\nsummary(iris_glmnet )\n#&gt;            Length Class  Mode     \n#&gt; a0         300    -none- numeric  \n#&gt; beta         3    -none- list     \n#&gt; dfmat      300    -none- numeric  \n#&gt; df         100    -none- numeric  \n#&gt; dim          2    -none- numeric  \n#&gt; lambda     100    -none- numeric  \n#&gt; dev.ratio  100    -none- numeric  \n#&gt; nulldev      1    -none- numeric  \n#&gt; npasses      1    -none- numeric  \n#&gt; jerr         1    -none- numeric  \n#&gt; offset       1    -none- logical  \n#&gt; classnames   3    -none- character\n#&gt; grouped      1    -none- logical  \n#&gt; call         4    -none- call     \n#&gt; nobs         1    -none- numeric\nplot(iris_glmnet)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nShow the codeplot(iris_glmnet$lambda,\n  ylab = expression(lambda), xlab = \"迭代次数\", main = \"惩罚系数的迭代路径\"\n)\n\n\n\n\n\n\nShow the code\n# 选择一个迭代趋于稳定时的 lambda，比如 iris_glmnet$lambda[80]\ncoef(iris_glmnet, s = 0.0002796185)\n#&gt; $setosa\n#&gt; 5 x 1 sparse Matrix of class \"dgCMatrix\"\n#&gt;                      1\n#&gt; (Intercept)  17.015429\n#&gt; Sepal.Length  .       \n#&gt; Sepal.Width   4.486992\n#&gt; Petal.Length -3.250342\n#&gt; Petal.Width  -3.315393\n#&gt; \n#&gt; $versicolor\n#&gt; 5 x 1 sparse Matrix of class \"dgCMatrix\"\n#&gt;                     1\n#&gt; (Intercept)  8.132656\n#&gt; Sepal.Length 2.123980\n#&gt; Sepal.Width  .       \n#&gt; Petal.Length .       \n#&gt; Petal.Width  .       \n#&gt; \n#&gt; $virginica\n#&gt; 5 x 1 sparse Matrix of class \"dgCMatrix\"\n#&gt;                       1\n#&gt; (Intercept)  -25.148085\n#&gt; Sepal.Length   .       \n#&gt; Sepal.Width   -5.176029\n#&gt; Petal.Length   7.536940\n#&gt; Petal.Width   14.481524\n\niris_pred_glmnet &lt;- predict(\n  object = iris_glmnet, newx = as.matrix(iris[, -5]),\n  s = 0.0002796185, type = \"class\"\n)\n\n\n\nShow the codemn_spec &lt;- multinom_reg(mode = \"classification\", engine = \"glmnet\" ,penalty = tune())\n\niris_mnlogit &lt;- mn_spec %&gt;% \n    fit(Species ~ ., data = iris)\niris_mnlogit %&gt;% glance()\n#&gt; # A tibble: 1 × 3\n#&gt;   nulldev npasses  nobs\n#&gt;     &lt;dbl&gt;   &lt;int&gt; &lt;int&gt;\n#&gt; 1    330.    6546   150\niris_mnlogit$fit %&gt;% tidy() %&gt;% DT::datatable()\n\n\n\n\n\n\n15.4.5 有序逻辑回归\n\\[\n    \\ln \\left(\\frac{P(Y\\le k|X=x)}{1-P(Y\\le k|X=x)}\\right)\n\\]\n\nShow the code# 数据集 icpsr\nacl &lt;- read_rds(\"data/advanced_acl_data.rds\")\nacl$PhysActCat_W1 &lt;- factor(acl$PhysActCat_W1,ordered = T)\nstr(acl$PhysActCat_W1)\n#&gt;  Ord.factor w/ 5 levels \"(1) Low_5th\"&lt;..: 1 3 5 3 2 2 3 1 4 5 ...\n\nordered_logit &lt;- MASS::polr(PhysActCat_W1 ~ SelfEfficacy_W1, data = acl,\n                            method = \"logistic\")\nordered_logit %&gt;% summary()\n#&gt; Call:\n#&gt; MASS::polr(formula = PhysActCat_W1 ~ SelfEfficacy_W1, data = acl, \n#&gt;     method = \"logistic\")\n#&gt; \n#&gt; Coefficients:\n#&gt;                  Value Std. Error t value\n#&gt; SelfEfficacy_W1 0.2431    0.02893   8.404\n#&gt; \n#&gt; Intercepts:\n#&gt;                           Value    Std. Error t value \n#&gt; (1) Low_5th|(2) 2Low_5th   -0.9332   0.0371   -25.1533\n#&gt; (2) 2Low_5th|(3) 3Low_5th  -0.2688   0.0338    -7.9606\n#&gt; (3) 3Low_5th|(4) 4Low_5th   0.8470   0.0364    23.2527\n#&gt; (4) 4Low_5th|(5) Hi_5th     1.5298   0.0435    35.1647\n#&gt; \n#&gt; Residual Deviance: 11196.86 \n#&gt; AIC: 11206.86\n\npredict(ordered_logit ,acl ,type = \"prob\") %&gt;% \n    as_tibble() %&gt;% \n    DT::datatable()\n\n\n\n\nShow the code\npredict(ordered_logit ,acl ,type = \"class\") %&gt;% \n    as_tibble() %&gt;% \n    DT::datatable()",
    "crumbs": [
      "统计模型",
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>广义线性模型</span>"
    ]
  },
  {
    "objectID": "GLM.html#泊松回归",
    "href": "GLM.html#泊松回归",
    "title": "\n15  广义线性模型\n",
    "section": "\n15.5 泊松回归",
    "text": "15.5 泊松回归\n泊松回归用于计数数据，假设响应变量服从泊松分布，并使用对数链接函数（log link function），z-statistic\nfamily=poisson(link = \"log\")\nfamily = quasipoisson(link = \"log\"))\n\\[\nP(X=x;\\lambda)=\\frac{e^{-\\lambda}\\lambda ^x}{x!}\n\\]\n\nShow the codeggplot(tibble(x=0:20,\n              y1=dpois(x,lambda = 2),\n              y2=dpois(x,lambda = 6),\n              ),\n       aes(x)\n       )+\n    geom_col(aes(y=y1),fill = \"lightblue\")+\n    geom_col(aes(y=y2),fill = \"yellow\",alpha=.3)+\n    ylab(\"Poisson Density\")\n\n\n\n\n\n\n\n\nShow the codelibrary(poissonreg)\ndf2 &lt;- read_csv(\"data/Bikeshare.csv\")\n\n\n\nShow the code# 泊松回归模型\npois_spec &lt;- poisson_reg() %&gt;% \n  set_mode(\"regression\") %&gt;% \n  set_engine(\"glm\",family=poisson(link = \"log\"))\n\npois_rec_spec &lt;- recipe(bikers ~ mnth + hr + workingday + temp + weathersit, data = df2) %&gt;% \n    step_dummy(all_nominal_predictors()) # 虚拟变量\n\npois_wf &lt;- workflow() %&gt;% \n  add_recipe(pois_rec_spec) %&gt;% \n  add_model(pois_spec)\n\npois_fit &lt;- pois_wf %&gt;% fit(data = df2)\n\n\ntidy(pois_fit)\n#&gt; # A tibble: 18 × 5\n#&gt;    term                       estimate std.error statistic   p.value\n#&gt;    &lt;chr&gt;                         &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;\n#&gt;  1 (Intercept)                 3.01     0.00632     477.   0        \n#&gt;  2 hr                          0.0507   0.000144    352.   0        \n#&gt;  3 workingday                 -0.0128   0.00195      -6.57 4.91e- 11\n#&gt;  4 temp                        2.56     0.00995     258.   0        \n#&gt;  5 mnth_Aug                   -0.229    0.00470     -48.7  0        \n#&gt;  6 mnth_Dec                    0.298    0.00501      59.5  0        \n#&gt;  7 mnth_Feb                   -0.102    0.00592     -17.2  5.28e- 66\n#&gt;  8 mnth_Jan                   -0.145    0.00678     -21.4  1.74e-101\n#&gt;  9 mnth_July                  -0.378    0.00496     -76.2  0        \n#&gt; 10 mnth_June                  -0.150    0.00462     -32.5  1.32e-231\n#&gt; 11 mnth_March                 -0.0312   0.00534      -5.83 5.44e-  9\n#&gt; 12 mnth_May                    0.0508   0.00434      11.7  1.43e- 31\n#&gt; 13 mnth_Nov                    0.285    0.00461      61.8  0        \n#&gt; 14 mnth_Oct                    0.267    0.00432      61.7  0        \n#&gt; 15 mnth_Sept                  -0.00653  0.00443      -1.47 1.41e-  1\n#&gt; 16 weathersit_cloudy.misty    -0.0308   0.00216     -14.2  5.70e- 46\n#&gt; 17 weathersit_heavy.rain.snow -0.646    0.167        -3.87 1.08e-  4\n#&gt; 18 weathersit_light.rain.snow -0.473    0.00404    -117.   0\n\n\n# 绘制实际值与预测值的关系图\naugment(pois_fit, new_data = df2, type = \"response\") %&gt;%\n    ggplot(aes(bikers, .pred)) +\n    geom_point(alpha = 0.1) +\n    geom_abline(slope = 1,\n                linewidth = 1,\n                color = \"grey40\") +\n    labs(title = \"Predicting the number of bikers per hour using Poission Regression\", x = \"Actual\", y = \"Predicted\")\n\n\n\n\n\n\n\n\nShow the codepois_fit_coef_mnths &lt;- \n  tidy(pois_fit) %&gt;% \n  dplyr::filter(grepl(\"^mnth\", term)) %&gt;% \n  mutate(\n    term = stringr::str_replace(term, \"mnth_\", \"\"),\n    term = forcats::fct_inorder(term)\n  ) \n\npois_fit_coef_mnths %&gt;% \n  ggplot(aes(term, estimate)) +\n  geom_line(group = 1,na.rm = TRUE) +\n  geom_point(shape = 21, size = 3, stroke = 1.5, \n             fill = \"black\", color = \"white\",na.rm = TRUE) +\n  labs(title = \"Coefficient value from Poission Regression\",\n       x = \"Month\", y = \"Coefficient\")\n\n\n\n\n\n\n\n\nShow the codepois_acl &lt;- pois_spec %&gt;% \n    fit(NChronic12_W1 ~ SelfEfficacy_W1,data = acl)\n\npois_acl %&gt;% glance()\n#&gt; # A tibble: 1 × 8\n#&gt;   null.deviance df.null logLik    AIC    BIC deviance df.residual  nobs\n#&gt;           &lt;dbl&gt;   &lt;int&gt;  &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;    &lt;dbl&gt;       &lt;int&gt; &lt;int&gt;\n#&gt; 1         5217.    3616 -5161. 10327. 10339.    5114.        3615  3617\n\npois_acl %&gt;% tidy()\n#&gt; # A tibble: 2 × 5\n#&gt;   term            estimate std.error statistic  p.value\n#&gt;   &lt;chr&gt;              &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt;\n#&gt; 1 (Intercept)       0.0713    0.0162      4.40 1.06e- 5\n#&gt; 2 SelfEfficacy_W1  -0.150     0.0144    -10.4  3.97e-25\n\nAIC(pois_acl$fit)\n#&gt; [1] 10326.52\nBIC(pois_acl$fit)\n#&gt; [1] 10338.9",
    "crumbs": [
      "统计模型",
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>广义线性模型</span>"
    ]
  },
  {
    "objectID": "GLM.html#负二项回归",
    "href": "GLM.html#负二项回归",
    "title": "\n15  广义线性模型\n",
    "section": "\n15.6 负二项回归",
    "text": "15.6 负二项回归\n负二项回归用于处理计数数据且存在过度离散（overdispersion）的问题即当均值不等于方差。\nlog link function，z-statistic\nprobability mass function ：\n\\[\nP(X=x;\\lambda,\\nu)=\\binom{x+\\nu - 1}{ x} \\left ( \\frac{\\lambda}{\\lambda +\\nu} \\right)^x \\left ( \\frac{\\nu}{\\nu + \\lambda} \\right)^{\\nu}\n\\]\n负二项分布的均值是 \\(\\lambda\\) ，\n方差是 \\(\\lambda + \\frac{\\lambda ^2}{\\nu}\\) 。\n\nShow the codelibrary(MASS)\n# 负二项回归模型\nnb_spec &lt;- linear_reg() %&gt;% \n  set_engine(\"glm\", family = MASS::negative.binomial(theta = 1, link = \"log\"))\n\nnb_acl &lt;- nb_spec %&gt;% \n  fit(NChronic12_W1 ~ SelfEfficacy_W1, data = acl)\n\n# 查看模型结果\nnb_acl %&gt;% glance()\n#&gt; # A tibble: 1 × 8\n#&gt;   null.deviance df.null logLik    AIC    BIC deviance df.residual  nobs\n#&gt;           &lt;dbl&gt;   &lt;int&gt;  &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;    &lt;dbl&gt;       &lt;int&gt; &lt;int&gt;\n#&gt; 1         2946.    3616 -5220. 10443. 10456.    2898.        3615  3617\nnb_acl %&gt;% tidy()\n#&gt; # A tibble: 2 × 5\n#&gt;   term            estimate std.error statistic  p.value\n#&gt;   &lt;chr&gt;              &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt;\n#&gt; 1 (Intercept)       0.0715    0.0181      3.95 8.10e- 5\n#&gt; 2 SelfEfficacy_W1  -0.148     0.0169     -8.75 3.18e-18\n\n\nAIC(nb_acl$fit)\n#&gt; [1] 10443.43\nBIC(nb_acl$fit)\n#&gt; [1] 10455.82\n\n# MASS::glm.nb()",
    "crumbs": [
      "统计模型",
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>广义线性模型</span>"
    ]
  },
  {
    "objectID": "GLM.html#零膨胀模型zero-inflated",
    "href": "GLM.html#零膨胀模型zero-inflated",
    "title": "\n15  广义线性模型\n",
    "section": "\n15.7 零膨胀模型（zero-inflated）",
    "text": "15.7 零膨胀模型（zero-inflated）\n逻辑回归+以上之一",
    "crumbs": [
      "统计模型",
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>广义线性模型</span>"
    ]
  },
  {
    "objectID": "GLM.html#正则化广义线性模型",
    "href": "GLM.html#正则化广义线性模型",
    "title": "\n15  广义线性模型\n",
    "section": "\n15.8 正则化广义线性模型",
    "text": "15.8 正则化广义线性模型\nRidge、Lasso\n\nShow the codelibrary(glmnet)\ndata(QuickStartExample)\nfit &lt;- glmnet::glmnet(x = QuickStartExample$x, y = QuickStartExample$y)\nautoplot(fit)\n\n\n\n\n\n\nShow the code\nfit &lt;- glmnet::cv.glmnet(x = QuickStartExample$x, y = QuickStartExample$y)\nautoplot(fit, colour = 'blue')",
    "crumbs": [
      "统计模型",
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>广义线性模型</span>"
    ]
  },
  {
    "objectID": "GEE.html",
    "href": "GEE.html",
    "title": "\n16  广义估计方程\n",
    "section": "",
    "text": "16.1 数据集处理\nMixed Effects Models and Extensions in Ecology with R 第12章\n广义估计方程（Generalized Estimating Equations，GEE）是一种用于分析重复测量或相关数据的统计方法。 GEE的核心思想是通过建立一个广义线性模型来估计一组总体均值参数，同时考虑数据的相关性结构和缺失数据，而不依赖于特定的分布假设，从而使其适用于多种数据类型，包括二项分布、正态分布、负二项分布。\n广义估计方程用于处理具有组内相关性的非正态分布数据。模型形式类似于广义线性模型，但使用了估计方程来考虑组内相关性。\n数据集 Analyzing ecological data\nShow the coderfb &lt;- read_delim(\"data/AED/RiceFieldBirds.txt\")\nrfb$richness &lt;- rowSums(rfb[, 8:56] &gt; 0)\nrfb |&gt; mutate(\n    FIELD = factor(FIELD),\n    SPTREAT = factor(SPTREAT),\n    log_AREA = log(rfb$AREA),\n    DEPTH2 = DEPTH ^ 2,\n    .after = 4\n) -&gt; rfb\n\n\nggplot(rfb, aes(Time, richness)) +\n    geom_point(pch = 21) +\n    geom_smooth(method = \"loess\", se = F) +\n    facet_wrap(vars(FIELD), labeller = \"label_both\")\nShow the codeowls &lt;- read_delim(\"data/AED/Owls.txt\")\n\nowls |&gt;\n    mutate(NCalls = SiblingNegotiation, log_broodsize = log(BroodSize), ) -&gt;\n    owls\nShow the codede &lt;- read_delim(\"data/AED/DeerEcervi.txt\")\n\nde |&gt;\n    mutate(\n        Ecervi_binary = if_else(Ecervi &gt; 0, 1, Ecervi),\n        Sex = factor(Sex),\n        Length_center = scale(Length, center = T , scale = F),\n    ) -&gt; de",
    "crumbs": [
      "统计模型",
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>广义估计方程</span>"
    ]
  },
  {
    "objectID": "GEE.html#glm-连接函数",
    "href": "GEE.html#glm-连接函数",
    "title": "\n16  广义估计方程\n",
    "section": "\n16.2 GLM 连接函数",
    "text": "16.2 GLM 连接函数\nGLM的形式如下：\n\\[ g(\\mu_{ij})=\\beta_0+\\beta_1x_{ij_1}+\\beta_2x_{ij_2}+...+\\beta_px_{ij_p} \\]\n其中，g() 是一个连接函数，用于将自变量的线性组合与因变量的均值联系起来。常见的连接函数包括恒等连接函数（identity）、logistic连接函数（logit）、逆正弦连接函数（inverse sine）函数等。i 表示观测对象的索引，j 表示时间点或相关性结构的索引，uij 表示因变量的均值，β 表示待估计的系数，Xij 表示自变量。\n\\[\n\\eta = \\beta  \\mathbf{X}+ \\alpha\n\\]\n\\[\nE(y)=g^{-1}(\\eta)\n\\]\n对于计数数据：\n\\[\nE(y)=e^{\\eta}=e^{\\beta \\mathbf{X} +\\alpha}, 此时g(\\mu)=\\ln(\\mu)=\\mathbf{X}\\beta\n\\]\n\nShow the coderfb_glm &lt;- glm(richness ~ offset(log_AREA) +SPTREAT + DEPTH +DEPTH2,\n            family = quasipoisson(link = \"log\"),\n            data = rfb)\n\nowls_glm &lt;- glm(\n    NCalls ~ offset(log_broodsize) + SexParent * FoodTreatment + SexParent *\n        ArrivalTime,\n    family = poisson(link = \"log\"),\n    data = owls\n)\n\n\n对于二分类数据：\n\\[\nE(y)=\\frac{e^{\\beta \\mathbf{X} +\\alpha}}{1+e^{\\beta\\mathbf{X}+\\alpha}}, 此时g(\\mu)=\\ln(\\frac{\\mu}{1-\\mu})=logit(\\mu)\n\\]\n\nShow the codede_glm &lt;- glm(Ecervi_binary ~ Length_center *Sex,\n              family = binomial(link = \"logit\"),\n              data = de)\nsummary(de_glm)\n#&gt; \n#&gt; Call:\n#&gt; glm(formula = Ecervi_binary ~ Length_center * Sex, family = binomial(link = \"logit\"), \n#&gt;     data = de)\n#&gt; \n#&gt; Coefficients:\n#&gt;                    Estimate Std. Error z value Pr(&gt;|z|)    \n#&gt; (Intercept)        0.652409   0.109602   5.953 2.64e-09 ***\n#&gt; Length_center      0.025112   0.005576   4.504 6.68e-06 ***\n#&gt; Sex2               0.163873   0.174235   0.941   0.3469    \n#&gt; Length_center:Sex2 0.020109   0.009722   2.068   0.0386 *  \n#&gt; ---\n#&gt; Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n#&gt; \n#&gt; (Dispersion parameter for binomial family taken to be 1)\n#&gt; \n#&gt;     Null deviance: 1073.1  on 825  degrees of freedom\n#&gt; Residual deviance: 1003.7  on 822  degrees of freedom\n#&gt; AIC: 1011.7\n#&gt; \n#&gt; Number of Fisher Scoring iterations: 4",
    "crumbs": [
      "统计模型",
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>广义估计方程</span>"
    ]
  },
  {
    "objectID": "GEE.html#方差",
    "href": "GEE.html#方差",
    "title": "\n16  广义估计方程\n",
    "section": "\n16.3 方差",
    "text": "16.3 方差\n\\[\nvar(Y_{is}|X_{is})=\\Phi × \\nu(\\mu_{is})\n\\]\n其中，Φ 是scale parameter （overdispersion），v() 是方差函数。",
    "crumbs": [
      "统计模型",
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>广义估计方程</span>"
    ]
  },
  {
    "objectID": "GEE.html#相关性结构",
    "href": "GEE.html#相关性结构",
    "title": "\n16  广义估计方程\n",
    "section": "\n16.4 相关性结构",
    "text": "16.4 相关性结构\nR(α)\n\n非结构化相关：cor(Yis,Yit)=αst\n自回归相关：cor(Yis,Yit)=α|s-t|\nexchangeable 等相关：cor(Yis,Yit)=α\nindependence，独立，cor(Yis,Yit)=I",
    "crumbs": [
      "统计模型",
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>广义估计方程</span>"
    ]
  },
  {
    "objectID": "GEE.html#gee",
    "href": "GEE.html#gee",
    "title": "\n16  广义估计方程\n",
    "section": "\n16.5 GEE",
    "text": "16.5 GEE\nGLM的期望和方差：\n\\[ E(Y_{ij})=b'(\\theta_{ij})\\\\ Var(Y_{ij})=b''(\\theta_{ij})\\ \\Phi \\]\n假定潜在的随机成分Vi ：\n\\[\nV_i=A_i^{1/2}R(\\alpha)A_i^{1/2}\\ \\Phi\n\\]\n其中，Ai =diag（b''(θi1)，...，b''(θij)） 。\nGEE的形式如下：\n\\[\nU(\\beta)=\\sum_{i=1}^{n} D'_iV_i^{-1}(y_i-\\mu_i)=0\n\\]\n其中，$U(β) $是一个包含待估计参数的函数，quasi-deviance \\(D'_i = \\left(\\frac{\\partial \\mu_i}{\\partial \\beta}\\right)'\\)，\\(V_i\\) 是方差-协方差矩阵，\\(R(\\alpha)\\) 是相关性结构矩阵，y 是观测数据，μ 是模型的均值预测值。采用迭代重复加权最小二乘法（iteratively reweighted least squares ，IWLS)），偏微分方程估计参数。",
    "crumbs": [
      "统计模型",
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>广义估计方程</span>"
    ]
  },
  {
    "objectID": "GEE.html#gee-1",
    "href": "GEE.html#gee-1",
    "title": "\n16  广义估计方程\n",
    "section": "\n16.6 gee\n",
    "text": "16.6 gee\n\nhttps://www.statsmodels.org/stable//gee.html\n\nShow the code\n\nlibrary(nlme)\nOxboys |&gt; head(n=18)\n#&gt; Grouped Data: height ~ age | Subject\n#&gt;    Subject     age height Occasion\n#&gt; 1        1 -1.0000  140.5        1\n#&gt; 2        1 -0.7479  143.4        2\n#&gt; 3        1 -0.4630  144.8        3\n#&gt; 4        1 -0.1643  147.1        4\n#&gt; 5        1 -0.0027  147.7        5\n#&gt; 6        1  0.2466  150.2        6\n#&gt; 7        1  0.5562  151.7        7\n#&gt; 8        1  0.7781  153.3        8\n#&gt; 9        1  0.9945  155.8        9\n#&gt; 10       2 -1.0000  136.9        1\n#&gt; 11       2 -0.7479  139.1        2\n#&gt; 12       2 -0.4630  140.1        3\n#&gt; 13       2 -0.1643  142.6        4\n#&gt; 14       2 -0.0027  143.2        5\n#&gt; 15       2  0.2466  144.0        6\n#&gt; 16       2  0.5562  145.8        7\n#&gt; 17       2  0.7781  146.8        8\n#&gt; 18       2  0.9945  148.3        9\n\ndf_long &lt;- Oxboys\n\n\n\nShow the codelibrary(gee)\n\ng1 &lt;- gee(height~age,data = df_long ,id = Subject,corstr = \"AR-M\",Mv = 1)\n#&gt; (Intercept)         age \n#&gt;  149.371801    6.521022\ng1\n#&gt; \n#&gt;  GEE:  GENERALIZED LINEAR MODELS FOR DEPENDENT DATA\n#&gt;  gee S-function, version 4.13 modified 98/01/27 (1998) \n#&gt; \n#&gt; Model:\n#&gt;  Link:                      Identity \n#&gt;  Variance to Mean Relation: Gaussian \n#&gt;  Correlation Structure:     AR-M , M = 1 \n#&gt; \n#&gt; Call:\n#&gt; gee(formula = height ~ age, id = Subject, data = df_long, corstr = \"AR-M\", \n#&gt;     Mv = 1)\n#&gt; \n#&gt; Number of observations :  234 \n#&gt; \n#&gt; Maximum cluster size   :  9 \n#&gt; \n#&gt; \n#&gt; Coefficients:\n#&gt; (Intercept)         age \n#&gt;  149.719096    6.547328 \n#&gt; \n#&gt; Estimated Scale Parameter:  65.41743\n#&gt; Number of Iterations:  2\n#&gt; \n#&gt; Working Correlation[1:4,1:4]\n#&gt;           [,1]      [,2]      [,3]      [,4]\n#&gt; [1,] 1.0000000 0.9892949 0.9787045 0.9682274\n#&gt; [2,] 0.9892949 1.0000000 0.9892949 0.9787045\n#&gt; [3,] 0.9787045 0.9892949 1.0000000 0.9892949\n#&gt; [4,] 0.9682274 0.9787045 0.9892949 1.0000000\n#&gt; \n#&gt; \n#&gt; Returned Error Value:\n#&gt; [1] 0\nsummary(g1)\n#&gt; \n#&gt;  GEE:  GENERALIZED LINEAR MODELS FOR DEPENDENT DATA\n#&gt;  gee S-function, version 4.13 modified 98/01/27 (1998) \n#&gt; \n#&gt; Model:\n#&gt;  Link:                      Identity \n#&gt;  Variance to Mean Relation: Gaussian \n#&gt;  Correlation Structure:     AR-M , M = 1 \n#&gt; \n#&gt; Call:\n#&gt; gee(formula = height ~ age, id = Subject, data = df_long, corstr = \"AR-M\", \n#&gt;     Mv = 1)\n#&gt; \n#&gt; Summary of Residuals:\n#&gt;         Min          1Q      Median          3Q         Max \n#&gt; -22.0304139  -5.4912438   0.1324571   4.3822174  18.5695861 \n#&gt; \n#&gt; \n#&gt; Coefficients:\n#&gt;               Estimate Naive S.E.  Naive z Robust S.E. Robust z\n#&gt; (Intercept) 149.719096  1.5531285 96.39840   1.5847569 94.47449\n#&gt; age           6.547328  0.3177873 20.60286   0.3042478 21.51972\n#&gt; \n#&gt; Estimated Scale Parameter:  65.41743\n#&gt; Number of Iterations:  2\n#&gt; \n#&gt; Working Correlation\n#&gt;            [,1]      [,2]      [,3]      [,4]      [,5]      [,6]      [,7]\n#&gt;  [1,] 1.0000000 0.9892949 0.9787045 0.9682274 0.9578625 0.9476085 0.9374643\n#&gt;  [2,] 0.9892949 1.0000000 0.9892949 0.9787045 0.9682274 0.9578625 0.9476085\n#&gt;  [3,] 0.9787045 0.9892949 1.0000000 0.9892949 0.9787045 0.9682274 0.9578625\n#&gt;  [4,] 0.9682274 0.9787045 0.9892949 1.0000000 0.9892949 0.9787045 0.9682274\n#&gt;  [5,] 0.9578625 0.9682274 0.9787045 0.9892949 1.0000000 0.9892949 0.9787045\n#&gt;  [6,] 0.9476085 0.9578625 0.9682274 0.9787045 0.9892949 1.0000000 0.9892949\n#&gt;  [7,] 0.9374643 0.9476085 0.9578625 0.9682274 0.9787045 0.9892949 1.0000000\n#&gt;  [8,] 0.9274287 0.9374643 0.9476085 0.9578625 0.9682274 0.9787045 0.9892949\n#&gt;  [9,] 0.9175005 0.9274287 0.9374643 0.9476085 0.9578625 0.9682274 0.9787045\n#&gt;            [,8]      [,9]\n#&gt;  [1,] 0.9274287 0.9175005\n#&gt;  [2,] 0.9374643 0.9274287\n#&gt;  [3,] 0.9476085 0.9374643\n#&gt;  [4,] 0.9578625 0.9476085\n#&gt;  [5,] 0.9682274 0.9578625\n#&gt;  [6,] 0.9787045 0.9682274\n#&gt;  [7,] 0.9892949 0.9787045\n#&gt;  [8,] 1.0000000 0.9892949\n#&gt;  [9,] 0.9892949 1.0000000\n\n\ndata(epil,package = \"MASS\")\ngee1 &lt;- gee(y ~ age + trt + base,id=subject,data = epil,family = poisson,corstr =\"exchangeable\" )\n#&gt;  (Intercept)          age trtprogabide         base \n#&gt;   0.57304359   0.02234757  -0.15188049   0.02263524\nsummary(gee1)\n#&gt; \n#&gt;  GEE:  GENERALIZED LINEAR MODELS FOR DEPENDENT DATA\n#&gt;  gee S-function, version 4.13 modified 98/01/27 (1998) \n#&gt; \n#&gt; Model:\n#&gt;  Link:                      Logarithm \n#&gt;  Variance to Mean Relation: Poisson \n#&gt;  Correlation Structure:     Exchangeable \n#&gt; \n#&gt; Call:\n#&gt; gee(formula = y ~ age + trt + base, id = subject, data = epil, \n#&gt;     family = poisson, corstr = \"exchangeable\")\n#&gt; \n#&gt; Summary of Residuals:\n#&gt;        Min         1Q     Median         3Q        Max \n#&gt; -15.742906  -3.318756  -1.186874   1.295122  63.957902 \n#&gt; \n#&gt; \n#&gt; Coefficients:\n#&gt;                 Estimate  Naive S.E.   Naive z Robust S.E.   Robust z\n#&gt; (Intercept)   0.57304359 0.451797966  1.268362 0.360726141  1.5885835\n#&gt; age           0.02234757 0.013412798  1.666138 0.011400956  1.9601489\n#&gt; trtprogabide -0.15188049 0.159304397 -0.953398 0.171051111 -0.8879246\n#&gt; base          0.02263524 0.001696439 13.342795 0.001226748 18.4514092\n#&gt; \n#&gt; Estimated Scale Parameter:  5.087384\n#&gt; Number of Iterations:  1\n#&gt; \n#&gt; Working Correlation\n#&gt;           [,1]      [,2]      [,3]      [,4]\n#&gt; [1,] 1.0000000 0.3933815 0.3933815 0.3933815\n#&gt; [2,] 0.3933815 1.0000000 0.3933815 0.3933815\n#&gt; [3,] 0.3933815 0.3933815 1.0000000 0.3933815\n#&gt; [4,] 0.3933815 0.3933815 0.3933815 1.0000000",
    "crumbs": [
      "统计模型",
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>广义估计方程</span>"
    ]
  },
  {
    "objectID": "GEE.html#geepack",
    "href": "GEE.html#geepack",
    "title": "\n16  广义估计方程\n",
    "section": "\n16.7 geepack\n",
    "text": "16.7 geepack\n\n\nShow the codelibrary(geepack)\n\nrfb_gee &lt;- geeglm(richness ~ offset(log_AREA) +SPTREAT + DEPTH +DEPTH2,\n            family = poisson(link = \"log\"),\n            data = rfb,\n            id=FIELD,\n            corstr = \"ar1\")\n\nsummary(rfb_gee)\n#&gt; \n#&gt; Call:\n#&gt; geeglm(formula = richness ~ offset(log_AREA) + SPTREAT + DEPTH + \n#&gt;     DEPTH2, family = poisson(link = \"log\"), data = rfb, id = FIELD, \n#&gt;     corstr = \"ar1\")\n#&gt; \n#&gt;  Coefficients:\n#&gt;                Estimate    Std.err  Wald Pr(&gt;|W|)   \n#&gt; (Intercept)  -0.6782034  0.2610088 6.752  0.00937 **\n#&gt; SPTREATrlfld -0.5223137  0.2287644 5.213  0.02242 * \n#&gt; DEPTH         0.0498238  0.0193149 6.654  0.00989 **\n#&gt; DEPTH2       -0.0011411  0.0004908 5.406  0.02007 * \n#&gt; ---\n#&gt; Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n#&gt; \n#&gt; Correlation structure = ar1 \n#&gt; Estimated Scale Parameters:\n#&gt; \n#&gt;             Estimate Std.err\n#&gt; (Intercept)    2.334  0.2927\n#&gt;   Link = identity \n#&gt; \n#&gt; Estimated Correlation Parameters:\n#&gt;       Estimate Std.err\n#&gt; alpha   0.4215 0.09034\n#&gt; Number of clusters:   11  Maximum cluster size: 10\nrfb_gee2 &lt;- geeglm(richness ~ offset(log_AREA) +SPTREAT ,\n            family = poisson(link = \"log\"),\n            data = rfb,\n            id=FIELD,\n            corstr = \"ar1\")\n\n# Wald's Test\nanova(rfb_gee,rfb_gee2)\n#&gt; Analysis of 'Wald statistic' Table\n#&gt; \n#&gt; Model 1 richness ~ offset(log_AREA) + SPTREAT + DEPTH + DEPTH2 \n#&gt; Model 2 richness ~ offset(log_AREA) + SPTREAT\n#&gt;   Df   X2 P(&gt;|Chi|)  \n#&gt; 1  2 6.88     0.032 *\n#&gt; ---\n#&gt; Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\n\\[\nE(Y_{is})=\\mu_{is}=e^{-0.678+0.0498×DEPTH-0.001×DEPTH^2-0.522×SPTREAT_{is}}\\\\\nvar(Y_{is})= 2.33 × \\mu_{is} \\\\\ncor(Y_{is},Y_{it})=0.422^{|s-t|}\n\\]\n作业相关矩阵 corstr ，比较QIC，一般越小越好。\n\nShow the codeQIC(rfb_gee)\n#&gt;       QIC      QICu Quasi Lik       CIC    params      QICC \n#&gt;  -467.536  -471.921   239.961     6.193     4.000  -455.536\nQIC(rfb_gee2)\n#&gt;       QIC      QICu Quasi Lik       CIC    params      QICC \n#&gt;  -451.065  -457.436   230.718     5.185     2.000  -447.637",
    "crumbs": [
      "统计模型",
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>广义估计方程</span>"
    ]
  },
  {
    "objectID": "SurvivalAnalysis.html",
    "href": "SurvivalAnalysis.html",
    "title": "\n17  生存分析\n",
    "section": "",
    "text": "17.1 生存函数\n医学研究中的生存数据建模\n\\[\nS(t)=P(T&gt;t)=1-F(t)=\\int_{t}^{+\\infty}f(x)dx\n\\]\n其中S(t)是累计生存概率或生存率，量化了生存时间大于t的概率。f(x)是密度函数，呈右偏态分布，反映了任意时间点 t 终点事件的瞬时发生率。F(t)=P(T&lt;t)是f(t)在区间[0,t]的累计形式，也称为分布函数或累积函数。",
    "crumbs": [
      "生存分析",
      "<span class='chapter-number'>17</span>  <span class='chapter-title'>生存分析</span>"
    ]
  },
  {
    "objectID": "SurvivalAnalysis.html#乘积极限法kaplan-meier",
    "href": "SurvivalAnalysis.html#乘积极限法kaplan-meier",
    "title": "\n17  生存分析\n",
    "section": "\n17.2 乘积极限法(Kaplan-Meier)",
    "text": "17.2 乘积极限法(Kaplan-Meier)\nproduct limit method 也称为Kaplan-Meier 法。\n\\(t_1&lt;t_2&lt;t_3&lt;...&lt;t_n\\)，样本量大小n，ti 代表个体i发生终点事件或右删失的时间。由于一些个体有相同的生存时间，它们被称为 tied 观测时间，生存时间的个数小于样本量n。\n\n17.2.1 点估计S(t)\n\\(n_1&gt;n_2&gt;n_3&gt;...&gt;n_n\\) ,ni d代表在时间点ti 暴露于特定事件风险的幸存者数量。\n\\(d_i\\) 代表在时间点ti 发生终点事件的数量。（如果没有 tie，di=1或0）\n生存率的KM方法估计公式：\n\\[\n\\hat S(t)=\\prod_{t_i\\le t}\\frac{n_i-d_i}{n_i}\n\\tag{17.1}\\]\nEquation 17.1 包括了删失情况，如果从ti-1 到ti 发生了删失，但没有终点事件，di =0，条件概率等于1。\n\n17.2.2 区间估计S(t)\n(1-α)×100% CI \\([\\hat S(t)-z_{1-\\alpha/2}\\sqrt{Var\\left [\\hat S(t)  \\right]},\\hat S(t)+z_{1-\\alpha/2}\\sqrt{Var\\left [\\hat S(t)  \\right]}]\\)\n其中\\(Var\\left [\\hat S(t)  \\right]=\\hat S(t)^2\\sum_{t_i\\le t}\\frac{d_i}{n_i(n_i-d_i)}\\) (Greenwood method )\n\n17.2.3 示例\nhttps://biostatsquid.com/easy-survival-analysis-r-tutorial/\n\nShow the codelibrary(survminer)\nlibrary(survival)\nlibrary(ggsurvfit)\ndf &lt;- read_csv(\"data/log-rank-survival.csv\")\n\n\nsurv_obj &lt;- with(df, Surv(Days,status))\n\nsurv_fit1 &lt;-survfit(surv_obj ~1,data=df)\n# t_i  =  surv_fit1$time\n# n_i = surv_fit1$n.risk\n\n# d_i = surv_fit1$n.event\n\n# cnesored\nsurv_fit1$n.censor\n#&gt;  [1]  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 17\n\n# 生存率survival\nsurv_fit1$surv\n#&gt;  [1] 0.9821429 0.9285714 0.8928571 0.8571429 0.8392857 0.7857143 0.7678571\n#&gt;  [8] 0.7321429 0.6250000 0.5892857 0.5714286 0.5535714 0.5178571 0.4642857\n#&gt; [15] 0.4464286 0.3928571 0.3750000 0.3571429 0.3392857 0.3214286 0.3035714\n#&gt; [22] 0.3035714\n\nsummary(surv_fit1)\n#&gt; Call: survfit(formula = surv_obj ~ 1, data = df)\n#&gt; \n#&gt;  time n.risk n.event survival std.err lower 95% CI upper 95% CI\n#&gt;    11     56       1    0.982  0.0177        0.948        1.000\n#&gt;    13     55       3    0.929  0.0344        0.864        0.999\n#&gt;    14     52       2    0.893  0.0413        0.815        0.978\n#&gt;    15     50       2    0.857  0.0468        0.770        0.954\n#&gt;    16     48       1    0.839  0.0491        0.748        0.941\n#&gt;    17     47       3    0.786  0.0548        0.685        0.901\n#&gt;    18     44       1    0.768  0.0564        0.665        0.887\n#&gt;    19     43       2    0.732  0.0592        0.625        0.858\n#&gt;    20     41       6    0.625  0.0647        0.510        0.766\n#&gt;    21     35       2    0.589  0.0657        0.474        0.733\n#&gt;    23     33       1    0.571  0.0661        0.455        0.717\n#&gt;    24     32       1    0.554  0.0664        0.438        0.700\n#&gt;    25     31       2    0.518  0.0668        0.402        0.667\n#&gt;    27     29       3    0.464  0.0666        0.350        0.615\n#&gt;    28     26       1    0.446  0.0664        0.333        0.598\n#&gt;    30     25       3    0.393  0.0653        0.284        0.544\n#&gt;    32     22       1    0.375  0.0647        0.267        0.526\n#&gt;    38     21       1    0.357  0.0640        0.251        0.508\n#&gt;    39     20       1    0.339  0.0633        0.235        0.489\n#&gt;    40     19       1    0.321  0.0624        0.220        0.470\n#&gt;    45     18       1    0.304  0.0614        0.204        0.451\n\nggsurvfit(surv_fit1, linewidth =1)+\n    add_confidence_interval()+\n    scale_ggsurvfit()+\n    add_risktable() +\n    labs(x = \"Days\")\n\n\n\n\n\n\n\n\nShow the code# 估计 x-天 的生存率\n\nsummary( surv_fit1, times = c(0,30,50))$surv\n#&gt; [1] 1.0000000 0.3928571 0.3035714\n\n# 中位生存率 median\nsurv_fit1\n#&gt; Call: survfit(formula = surv_obj ~ 1, data = df)\n#&gt; \n#&gt;       n events median 0.95LCL 0.95UCL\n#&gt; [1,] 56     39     27      21      39",
    "crumbs": [
      "生存分析",
      "<span class='chapter-number'>17</span>  <span class='chapter-title'>生存分析</span>"
    ]
  },
  {
    "objectID": "SurvivalAnalysis.html#单因素生存曲线的比较",
    "href": "SurvivalAnalysis.html#单因素生存曲线的比较",
    "title": "\n17  生存分析\n",
    "section": "\n17.3 单因素生存曲线的比较",
    "text": "17.3 单因素生存曲线的比较\n\n\n检验方法\n权重\n\n\n\nlog-rank test\n1\n\n\nWilcoxon test\nnj\n\n\n\nTarone-Ware test\n\\(\\sqrt{n_j}\\)\n\n\nPeto test\n\\(\\hat S(t_j)\\)\n\n\n\n\\[\n\\chi^2=\\frac{\\left(\\sum_jw(t_j)(m_{ij}-e_{ij})\\right)^2}{\\hat {Var}\\left(\\sum_jw(t_j)(m_{ij}-e_{ij})\\right)}\n\\]",
    "crumbs": [
      "生存分析",
      "<span class='chapter-number'>17</span>  <span class='chapter-title'>生存分析</span>"
    ]
  },
  {
    "objectID": "SurvivalAnalysis.html#log-rank-test",
    "href": "SurvivalAnalysis.html#log-rank-test",
    "title": "\n17  生存分析\n",
    "section": "\n17.4 log-rank test",
    "text": "17.4 log-rank test\n\nH0 :两总体的生存曲线是相同的。\n\n计算当第j次发生终点事件各组终点事件的期望值（e1j ,e2j ）\n\\(e_{1j}=\\left ( \\frac{n_{1j}}{n_{1j}+n_{2j}}\\right)\\times (m_{1j}+m_{2j})\\)\n\\(e_{2j}=\\left ( \\frac{n_{2j}}{n_{1j}+n_{2j}}\\right)\\times (m_{1j}+m_{2j})\\)\n其中mij 表示在第 j 个时间点第 i 组终点事件的数量，nij 表示在第 j 个时间点第 i 组初始观测的数量\n\n\n对所有时间点对终点事件的观测值和期望值的差异求和\n\\(O_i-Ei=\\sum_j(m_{ij}-e_{ij})\\ \\ \\ (i=1,2)\\)\n计算其方差估计值\n\\(\\hat{Var}=\\sum_j\\frac{n_{1j}n_{2j}(m_{1j}+m_{2j})(n_{1j}+n_{2j}-m_{1j}-m_{2j})}{(n_{1j}+n_{2j})^2(n_{1j}+n_{2j}-1)}\\ \\ \\ (i=1,2)\\)\n\n\n计算log-rank test 的检验统计量\n\\[\n\\chi^2=\\frac{(O_1-E_1)^2}{\\hat{Var}(O_1-E_1)} \\ 或者 \\ \\chi^2=\\frac{(O_2-E_2)^2}{\\hat{Var}(O_2-E_2)}\n\\]\n也可以近似估计为\n\\[\n\\chi^2=\\sum_{i=1}^2\\frac{(O_i-E_i)^2}{E_i} \\sim \\chi^2(\\nu=1)\n\\]\n\n\n\nShow the code\nsurv_fit2&lt;-survfit(surv_obj ~ treatment,data=df)\nggsurvplot(surv_fit2, linewidth =1,\n          data = df,\n          censor.shape = \"|\", censor.size = 4,\n          pval = T,conf.int = T,risk.table = T,risk.table.col = \"strata\",\n          legend.labs = c(\"CON\",\"DPVB\",\"LDRT\",\"LR-DPVB\"),\n          risk.table.height = .25,\n          ggtheme = theme_bw()\n            )+\n    labs(x = \"Days\")\n\n\n\n\n\n\n\n\nShow the code# 执行Log-rank检验\nlogrank_test &lt;- survdiff( Surv(Days,status) ~ treatment,data = df)\nlogrank_test\n#&gt; Call:\n#&gt; survdiff(formula = Surv(Days, status) ~ treatment, data = df)\n#&gt; \n#&gt;                    N Observed Expected (O-E)^2/E (O-E)^2/V\n#&gt; treatment=CON     14       14     4.46     20.40     26.03\n#&gt; treatment=DPVB    14        9    13.26      1.37      2.19\n#&gt; treatment=LDRT    14       14     5.53     12.99     16.92\n#&gt; treatment=LR_DPVB 14        2    15.76     12.01     22.67\n#&gt; \n#&gt;  Chisq= 58.4  on 3 degrees of freedom, p= 1e-12\nlogrank_test$chisq\n#&gt; [1] 58.43627\nlogrank_test$pvalue\n#&gt; [1] 1.268397e-12\n\n\n\nShow the codesurvdiff( Surv(Days,status) ~ treatment,\n          data = df %&gt;% filter(treatment %in% c(\"CON\", \"DPVB\")))\n#&gt; Call:\n#&gt; survdiff(formula = Surv(Days, status) ~ treatment, data = df %&gt;% \n#&gt;     filter(treatment %in% c(\"CON\", \"DPVB\")))\n#&gt; \n#&gt;                 N Observed Expected (O-E)^2/E (O-E)^2/V\n#&gt; treatment=CON  14       14      5.3     14.31      24.1\n#&gt; treatment=DPVB 14        9     17.7      4.28      24.1\n#&gt; \n#&gt;  Chisq= 24.1  on 1 degrees of freedom, p= 9e-07\n\nsurvdiff( Surv(Days,status) ~ treatment,\n          data = df %&gt;% filter(treatment %in% c(\"CON\", \"LDRT\")))\n#&gt; Call:\n#&gt; survdiff(formula = Surv(Days, status) ~ treatment, data = df %&gt;% \n#&gt;     filter(treatment %in% c(\"CON\", \"LDRT\")))\n#&gt; \n#&gt;                 N Observed Expected (O-E)^2/E (O-E)^2/V\n#&gt; treatment=CON  14       14       12     0.331     0.716\n#&gt; treatment=LDRT 14       14       16     0.248     0.716\n#&gt; \n#&gt;  Chisq= 0.7  on 1 degrees of freedom, p= 0.4\n\nsurvdiff( Surv(Days,status) ~ treatment,\n          data = df %&gt;% filter(treatment %in% c(\"CON\", \"LR_DPVB\")))\n#&gt; Call:\n#&gt; survdiff(formula = Surv(Days, status) ~ treatment, data = df %&gt;% \n#&gt;     filter(treatment %in% c(\"CON\", \"LR_DPVB\")))\n#&gt; \n#&gt;                    N Observed Expected (O-E)^2/E (O-E)^2/V\n#&gt; treatment=CON     14       14     4.73     18.16      31.1\n#&gt; treatment=LR_DPVB 14        2    11.27      7.62      31.1\n#&gt; \n#&gt;  Chisq= 31.1  on 1 degrees of freedom, p= 2e-08",
    "crumbs": [
      "生存分析",
      "<span class='chapter-number'>17</span>  <span class='chapter-title'>生存分析</span>"
    ]
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "医学与生物统计学",
    "section": "",
    "text": "前言",
    "crumbs": [
      "前言"
    ]
  },
  {
    "objectID": "index.html#推荐阅读",
    "href": "index.html#推荐阅读",
    "title": "医学与生物统计学",
    "section": "推荐阅读",
    "text": "推荐阅读\n\nR语言实战医学统计\nR语言教程 Ⅶ 统计模型 ——李东风\n医学研究中的生存数据建模（4e）",
    "crumbs": [
      "前言"
    ]
  },
  {
    "objectID": "index.html#前提条件",
    "href": "index.html#前提条件",
    "title": "医学与生物统计学",
    "section": "前提条件",
    "text": "前提条件\n\nShow the codepkgs &lt;- c(\"psych\", \"modeest\", \"moments\", \"DescTools\", \"vcd\",\n          \"epiDisplay\", \"correlation\", \"ggcorrplot\",\"nortest\",\n          \"HH\",\"coin\",\"ggfortify\", \"rms\",\"broom.mixed\",\"glmnet\", \n          \"poissonreg\",\"gee\", \"geepack\",\"survminer\",\"ggsurvfit\",\n          \"pROC\",\"randomizeR\",\"blockrand\"\n          )\n\nfor (pkg in pkgs) {\n    if (!require(pkg, character.only = TRUE)) {\n        install.packages(pkg)\n    }\n}",
    "crumbs": [
      "前言"
    ]
  },
  {
    "objectID": "diagnostic_test.html",
    "href": "diagnostic_test.html",
    "title": "\n20  诊断性测试\n",
    "section": "",
    "text": "20.1 混淆矩阵\nShow the codem&lt;- matrix(c(\"TP\",\"FN\",\"FP\",\"TN\"),nrow = 2,\n           dimnames = list(predict=c(\"+\",\"-\"),\n                           truth=c(\"+\",\"-\")))\nprint(m)\n#&gt;        truth\n#&gt; predict +    -   \n#&gt;       + \"TP\" \"FP\"\n#&gt;       - \"FN\" \"TN\"",
    "crumbs": [
      "临床研究设计",
      "<span class='chapter-number'>20</span>  <span class='chapter-title'>诊断性测试</span>"
    ]
  },
  {
    "objectID": "diagnostic_test.html#灵敏度sensitivity",
    "href": "diagnostic_test.html#灵敏度sensitivity",
    "title": "\n20  诊断性测试\n",
    "section": "\n20.2 灵敏度（Sensitivity）",
    "text": "20.2 灵敏度（Sensitivity）\n真阳性率：指在所有真实状况为阳性的样本中，被正确识别出阳性的比例。\n\\[\nSe=\\frac{TP}{TP+FN}\n\\]\n其中TP 是真阳性的数量，FN 是假阴性的数量。\n\n20.2.1 假阴性率(FNR) /漏诊率\n\\[\nFNR=1-Se\n\\]",
    "crumbs": [
      "临床研究设计",
      "<span class='chapter-number'>20</span>  <span class='chapter-title'>诊断性测试</span>"
    ]
  },
  {
    "objectID": "diagnostic_test.html#特异度specificity",
    "href": "diagnostic_test.html#特异度specificity",
    "title": "\n20  诊断性测试\n",
    "section": "\n20.3 特异度（Specificity）",
    "text": "20.3 特异度（Specificity）\n真阴性率：指在所有真实状况为阴性的样本中，被正确识别出阴性的比例。\n\\[\nSp=\\frac{TN}{TN+FP}\n\\]\n其中 TN 是真阴性的数量，FP 是假阳性的数量。\n\n20.3.1 假阳性率(FPR) /误诊率\n\\[ FPR=1-Sp \\]\n\n\n\n\n\nShow the code# 构建列联表\nobserved_sensitivity &lt;- matrix(c(28, 11, 37, 2), nrow = 2, byrow = TRUE,\n                   dimnames = list('检验方式' = c('尿糖检验', '血糖检验'),\n                                   '结果' = c('检出阳性', '未检出阳性')))\nobserved_sensitivity\n#&gt;           结果\n#&gt; 检验方式 检出阳性 未检出阳性\n#&gt;   尿糖检验       28         11\n#&gt;   血糖检验       37          2\n# 进行卡方检验\ns &lt;- chisq.test(observed_sensitivity,correct = F)\n\n# 输出结果\ns\n#&gt; \n#&gt;  Pearson's Chi-squared test\n#&gt; \n#&gt; data:  observed_sensitivity\n#&gt; X-squared = 7.4769, df = 1, p-value = 0.006249\n\n\n# 构建列联表\nobserved_accuracy &lt;- matrix(c(29, 11, 38, 2), nrow = 2, byrow = TRUE,\n                            dimnames = list('检验方式' = c('尿糖检验', '血糖检验'),\n                                            '结果' = c('检准', '不准')))\n\n# 进行卡方检验\naccuracy &lt;- chisq.test(observed_accuracy,correct = F)\n\n# 输出结果\naccuracy\n#&gt; \n#&gt;  Pearson's Chi-squared test\n#&gt; \n#&gt; data:  observed_accuracy\n#&gt; X-squared = 7.4397, df = 1, p-value = 0.00638",
    "crumbs": [
      "临床研究设计",
      "<span class='chapter-number'>20</span>  <span class='chapter-title'>诊断性测试</span>"
    ]
  },
  {
    "objectID": "diagnostic_test.html#youdens-index",
    "href": "diagnostic_test.html#youdens-index",
    "title": "\n20  诊断性测试\n",
    "section": "\n20.4 Youden’s Index",
    "text": "20.4 Youden’s Index\n\\[\nJ=Se-FPR =Se+Sp-1,J[1,-1]\n\\]\n\nJ 越大诊断有效性越高\nJ=1 表示完美的诊断性能，因为Se，Sp都是1。\nJ≤0 表示没有诊断价值",
    "crumbs": [
      "临床研究设计",
      "<span class='chapter-number'>20</span>  <span class='chapter-title'>诊断性测试</span>"
    ]
  },
  {
    "objectID": "diagnostic_test.html#likelihood-ratio",
    "href": "diagnostic_test.html#likelihood-ratio",
    "title": "\n20  诊断性测试\n",
    "section": "\n20.5 Likelihood Ratio",
    "text": "20.5 Likelihood Ratio\n\n20.5.1 正似然比\n\\[\nLR+=\\frac{Se}{FPR}=\\frac{Se}{1-Sp}\n\\]\n\nLR+越大表示患病测出阳性结果的优势越大\nLR+=1表示诊断无效\n\n20.5.2 负似然比\n\\[\nLR-=\\frac{FNR}{Sp}=\\frac{1-Sp}{Sp}\n\\]\n\nLR-越小表示患病测出阴性结果的优势越小\nLR-=1表示诊断无效",
    "crumbs": [
      "临床研究设计",
      "<span class='chapter-number'>20</span>  <span class='chapter-title'>诊断性测试</span>"
    ]
  },
  {
    "objectID": "diagnostic_test.html#预测值",
    "href": "diagnostic_test.html#预测值",
    "title": "\n20  诊断性测试\n",
    "section": "\n20.6 预测值",
    "text": "20.6 预测值\n\nShow the codem\n#&gt;        truth\n#&gt; predict +    -   \n#&gt;       + \"TP\" \"FP\"\n#&gt;       - \"FN\" \"TN\"\n\n\n阳性预测值（Positive Predictive Value, PPV）：在所有被测试为阳性的样本中，真正的阳性比例。\n\\[\nPPV=\\frac{TP}{TP+NP}\n\\]\n阴性预测值（Negative Predictive Value, NPV）：在所有被测试为阴性的样本中，真正的阴性比例。\n\\[\nPPV=\\frac{TN}{TN+FN}\n\\]\n配对样本设计\n\\(\\chi^2\\)配对检验\n完全随机设计\n\\(\\chi^2\\)检验",
    "crumbs": [
      "临床研究设计",
      "<span class='chapter-number'>20</span>  <span class='chapter-title'>诊断性测试</span>"
    ]
  },
  {
    "objectID": "diagnostic_test.html#一致性agreement",
    "href": "diagnostic_test.html#一致性agreement",
    "title": "\n20  诊断性测试\n",
    "section": "\n20.7 一致性（agreement）",
    "text": "20.7 一致性（agreement）\n准确度（Accuracy）：指测试正确地分类（阳性或阴性）的样本占总样本的比例。\n\\[\nAccuracy=\\frac{TP+TN}{N}\n\\]\nkappa 系数\n\\[\n\\kappa =\\frac{Accuracy-[(a+b)(a+c)+(c+d)(b+d)]/N^2}{1-[(a+b)(a+c)+(c+d)(b+d)]/N^2}\n\\]\n\nκ=1表示完全一致\nκ=-1表示完全不一致\nκ=0表示一致性与偶然一致性Pe相同\n\n通常κ＞0.7即可以认为两种诊断方法有较好的一致性",
    "crumbs": [
      "临床研究设计",
      "<span class='chapter-number'>20</span>  <span class='chapter-title'>诊断性测试</span>"
    ]
  },
  {
    "objectID": "diagnostic_test.html#roc曲线receiver-operating-characteristic-curve",
    "href": "diagnostic_test.html#roc曲线receiver-operating-characteristic-curve",
    "title": "\n20  诊断性测试\n",
    "section": "\n20.8 ROC曲线（Receiver Operating Characteristic Curve）",
    "text": "20.8 ROC曲线（Receiver Operating Characteristic Curve）\nROC曲线（Receiver Operating Characteristic Curve）：是一个图形工具，用于展示不同阈值下灵敏度和特异度之间的关系。曲线下面积（AUC）越接近1，表示测试的性能越好。\n\nShow the codelibrary(pROC)\n\nroc_data &lt;- aSAH %&gt;%\n    dplyr::filter(gender == \"Female\") %&gt;%\n    roc(outcome, s100b)\n\n\n\n# 绘制ROC曲线\nplot(roc_data, print.thres = \"best\", print.thres.pattern = \"Best cutoff: %.2f\", main = \"ROC Curve\")\n\n\n\n\n\n\nShow the code\n\n# 计算AUC\nauc_value &lt;- auc(roc_data)\nprint(paste(\"AUC:\", auc_value))\n#&gt; [1] \"AUC: 0.72\"\n\n\n\n20.8.1 AUC\nA=P(X&gt;Y)\n\\[\nS(X,Y)=\n\\begin{cases}\n1,\\ \\ \\ \\  X&gt;Y\\\\\n1/2,X=Y\\\\\n0,\\ \\ \\ \\ X&lt;Y\\\\\n\\end{cases}\n\\]\n\\[\n\\hat A=\\frac{1}{n_0n_1}\\sum_1^{n1}\\sum_1^{n_0}S(X, Y)\n\\]\n\n20.8.2 分组AUC的比较\n完全随机设计\n\\[\nZ=\\frac{\\hat A_1-\\hat A_2}{\\sqrt{Var(\\hat A_1)+Var(\\hat A_2)}}\n\\]\n配对样本设计\n\\[\nZ=\\frac{\\hat A_1-\\hat A_2}{\\sqrt{Var(\\hat A_1)+Var(\\hat A_2)-2Cov(\\hat A_1,\\hat A_2)}}\n\\]",
    "crumbs": [
      "临床研究设计",
      "<span class='chapter-number'>20</span>  <span class='chapter-title'>诊断性测试</span>"
    ]
  },
  {
    "objectID": "RCT.html",
    "href": "RCT.html",
    "title": "\n21  随机对照试验\n",
    "section": "",
    "text": "21.1 随机\nhttps://www.equator-network.org/\nShow the codeif(!require(randomizeR)) install.packages(\"randomizeR\")\n#&gt; package 'V8' successfully unpacked and MD5 sums checked\n#&gt; package 'reactR' successfully unpacked and MD5 sums checked\n#&gt; package 'bigD' successfully unpacked and MD5 sums checked\n#&gt; package 'bitops' successfully unpacked and MD5 sums checked\n#&gt; package 'juicyjuice' successfully unpacked and MD5 sums checked\n#&gt; package 'reactable' successfully unpacked and MD5 sums checked\n#&gt; package 'gt' successfully unpacked and MD5 sums checked\n#&gt; package 'r2rtf' successfully unpacked and MD5 sums checked\n#&gt; package 'plotrix' successfully unpacked and MD5 sums checked\n#&gt; package 'mstate' successfully unpacked and MD5 sums checked\n#&gt; package 'PwrGSD' successfully unpacked and MD5 sums checked\n#&gt; package 'gsDesign' successfully unpacked and MD5 sums checked\n#&gt; package 'randomizeR' successfully unpacked and MD5 sums checked\n#&gt; \n#&gt; The downloaded binary packages are in\n#&gt;  C:\\Users\\WANGANLIN\\AppData\\Local\\Temp\\RtmpOOW51E\\downloaded_packages",
    "crumbs": [
      "临床研究设计",
      "<span class='chapter-number'>21</span>  <span class='chapter-title'>随机对照试验</span>"
    ]
  },
  {
    "objectID": "RCT.html#随机",
    "href": "RCT.html#随机",
    "title": "\n21  随机对照试验\n",
    "section": "",
    "text": "21.1.1 简单随机化\n完全随机化\n\n\nTable 21.1\n\nShow the code# 假设需要 100 个样本,分为 4 个组\nraw_data &lt;- tibble(\n    id = 1:100\n)\n\nset.seed(20241011)\nraw_data %&gt;%\n  mutate(assign = sample(1:4, size = 100, replace = TRUE)) -&gt; raw_data\n\ntable(raw_data$assign)\n#&gt; \n#&gt;  1  2  3  4 \n#&gt; 24 24 27 25\n\nraw_data\n#&gt; # A tibble: 100 × 2\n#&gt;       id assign\n#&gt;    &lt;int&gt;  &lt;int&gt;\n#&gt;  1     1      3\n#&gt;  2     2      2\n#&gt;  3     3      2\n#&gt;  4     4      4\n#&gt;  5     5      1\n#&gt;  6     6      1\n#&gt;  7     7      2\n#&gt;  8     8      3\n#&gt;  9     9      2\n#&gt; 10    10      1\n#&gt; # ℹ 90 more rows\n\n\n\n\n如果是针对受试者的分组，可按照受试者的入组顺序，筛选成功的第1名受试者进入组3，筛选成功的第2名受试者分入组2，以此类推。\n\n21.1.2 区组随机化\n区组(block)是对受试对象进行划分,即由若干特征相似的试验对象组成,如同一窝的动物、批号相同的试剂、体重相近的受试者等。\n目的是将受试者按相同数量分组。区组大小由研究者决定，通常通过乘以分组数来确定（如有两个治疗组，则应有4、6或8个区组）。区组取预定分组中较小的组，这有助于在整个临床试验中保持治疗组大小相似。决定区组大小后，必须确定每个区组大小相等的分组。然后随机选择区组对受试者进行分组。\n\nShow the codeif(!require(blockrand)) install.packages(\"blockrand\")\n#&gt; package 'blockrand' successfully unpacked and MD5 sums checked\n#&gt; \n#&gt; The downloaded binary packages are in\n#&gt;  C:\\Users\\WANGANLIN\\AppData\\Local\\Temp\\RtmpOOW51E\\downloaded_packages\n\n\n\nShow the codelibrary(blockrand)\n\n# 使用区组随机化，指定区组大小为4\nblock_size &lt;- 1:4  # 区组大小\nn &lt;- 100  # 样本总数\n\n\nset.seed(20241012)\nblocks &lt;- blockrand(n = n, num.levels = 2,levels = c(\"Treatment\", \"Control\"),\n                    block.sizes = block_size )\n\nblocks\n#&gt;      id block.id block.size treatment\n#&gt; 1     1        1          4 Treatment\n#&gt; 2     2        1          4   Control\n#&gt; 3     3        1          4 Treatment\n#&gt; 4     4        1          4   Control\n#&gt; 5     5        2          8 Treatment\n#&gt; 6     6        2          8 Treatment\n#&gt; 7     7        2          8   Control\n#&gt; 8     8        2          8   Control\n#&gt; 9     9        2          8 Treatment\n#&gt; 10   10        2          8 Treatment\n#&gt; 11   11        2          8   Control\n#&gt; 12   12        2          8   Control\n#&gt; 13   13        3          6 Treatment\n#&gt; 14   14        3          6 Treatment\n#&gt; 15   15        3          6   Control\n#&gt; 16   16        3          6   Control\n#&gt; 17   17        3          6 Treatment\n#&gt; 18   18        3          6   Control\n#&gt; 19   19        4          4 Treatment\n#&gt; 20   20        4          4   Control\n#&gt; 21   21        4          4   Control\n#&gt; 22   22        4          4 Treatment\n#&gt; 23   23        5          2   Control\n#&gt; 24   24        5          2 Treatment\n#&gt; 25   25        6          6 Treatment\n#&gt; 26   26        6          6 Treatment\n#&gt; 27   27        6          6 Treatment\n#&gt; 28   28        6          6   Control\n#&gt; 29   29        6          6   Control\n#&gt; 30   30        6          6   Control\n#&gt; 31   31        7          6   Control\n#&gt; 32   32        7          6   Control\n#&gt; 33   33        7          6 Treatment\n#&gt; 34   34        7          6   Control\n#&gt; 35   35        7          6 Treatment\n#&gt; 36   36        7          6 Treatment\n#&gt; 37   37        8          6   Control\n#&gt; 38   38        8          6 Treatment\n#&gt; 39   39        8          6   Control\n#&gt; 40   40        8          6 Treatment\n#&gt; 41   41        8          6   Control\n#&gt; 42   42        8          6 Treatment\n#&gt; 43   43        9          6   Control\n#&gt; 44   44        9          6 Treatment\n#&gt; 45   45        9          6   Control\n#&gt; 46   46        9          6 Treatment\n#&gt; 47   47        9          6 Treatment\n#&gt; 48   48        9          6   Control\n#&gt; 49   49       10          2   Control\n#&gt; 50   50       10          2 Treatment\n#&gt; 51   51       11          2   Control\n#&gt; 52   52       11          2 Treatment\n#&gt; 53   53       12          4   Control\n#&gt; 54   54       12          4 Treatment\n#&gt; 55   55       12          4   Control\n#&gt; 56   56       12          4 Treatment\n#&gt; 57   57       13          2 Treatment\n#&gt; 58   58       13          2   Control\n#&gt; 59   59       14          8 Treatment\n#&gt; 60   60       14          8 Treatment\n#&gt; 61   61       14          8 Treatment\n#&gt; 62   62       14          8 Treatment\n#&gt; 63   63       14          8   Control\n#&gt; 64   64       14          8   Control\n#&gt; 65   65       14          8   Control\n#&gt; 66   66       14          8   Control\n#&gt; 67   67       15          4   Control\n#&gt; 68   68       15          4 Treatment\n#&gt; 69   69       15          4 Treatment\n#&gt; 70   70       15          4   Control\n#&gt; 71   71       16          4 Treatment\n#&gt; 72   72       16          4   Control\n#&gt; 73   73       16          4 Treatment\n#&gt; 74   74       16          4   Control\n#&gt; 75   75       17          6 Treatment\n#&gt; 76   76       17          6   Control\n#&gt; 77   77       17          6 Treatment\n#&gt; 78   78       17          6   Control\n#&gt; 79   79       17          6   Control\n#&gt; 80   80       17          6 Treatment\n#&gt; 81   81       18          2   Control\n#&gt; 82   82       18          2 Treatment\n#&gt; 83   83       19          8 Treatment\n#&gt; 84   84       19          8 Treatment\n#&gt; 85   85       19          8   Control\n#&gt; 86   86       19          8 Treatment\n#&gt; 87   87       19          8 Treatment\n#&gt; 88   88       19          8   Control\n#&gt; 89   89       19          8   Control\n#&gt; 90   90       19          8   Control\n#&gt; 91   91       20          4   Control\n#&gt; 92   92       20          4 Treatment\n#&gt; 93   93       20          4   Control\n#&gt; 94   94       20          4 Treatment\n#&gt; 95   95       21          2   Control\n#&gt; 96   96       21          2 Treatment\n#&gt; 97   97       22          4 Treatment\n#&gt; 98   98       22          4   Control\n#&gt; 99   99       22          4 Treatment\n#&gt; 100 100       22          4   Control\n\ntable(blocks$block.id)\n#&gt; \n#&gt;  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 \n#&gt;  4  8  6  4  2  6  6  6  6  2  2  4  2  8  4  4  6  2  8  4  2  4\n\n\n区组随机化的问题\n\n选择偏倚更为常见，因为研究人员可以轻松预测分组的治疗分配。\n\n21.1.3 分层随机化\n根据不同的因素（性别）对受试者进行分组。如果性别是选定因素，则层数是二，对每层应用随机分组。这种形式的随机化可以减少治疗组中的特征不平衡，并提高统计功效。这种方法可以更容易地为不同的预后因素生成区组随机化列表。\n分层随机化的问题\n\n虽然其目的是消除选择偏倚，但这也意味着各分组并不总是具有相同的重要特征。\n\n分层区组随机化分组\n多中心临床试验中普遍采用的方法是以中心分层,然后在各中心内进行区组随机化,即称为分层的区组随机化。\n\nShow the codemale &lt;- blockrand(n=100, id.prefix='M', block.prefix='M',stratum='Male')\nfemale &lt;- blockrand(n=100, id.prefix='F', block.prefix='F',stratum='Female')\n\nmy.study &lt;- rbind(male,female)\nmy.study\n#&gt;       id stratum block.id block.size treatment\n#&gt; 1   M001    Male      M01          4         A\n#&gt; 2   M002    Male      M01          4         B\n#&gt; 3   M003    Male      M01          4         B\n#&gt; 4   M004    Male      M01          4         A\n#&gt; 5   M005    Male      M02          6         B\n#&gt; 6   M006    Male      M02          6         B\n#&gt; 7   M007    Male      M02          6         A\n#&gt; 8   M008    Male      M02          6         B\n#&gt; 9   M009    Male      M02          6         A\n#&gt; 10  M010    Male      M02          6         A\n#&gt; 11  M011    Male      M03          2         A\n#&gt; 12  M012    Male      M03          2         B\n#&gt; 13  M013    Male      M04          6         B\n#&gt; 14  M014    Male      M04          6         B\n#&gt; 15  M015    Male      M04          6         A\n#&gt; 16  M016    Male      M04          6         A\n#&gt; 17  M017    Male      M04          6         A\n#&gt; 18  M018    Male      M04          6         B\n#&gt; 19  M019    Male      M05          4         B\n#&gt; 20  M020    Male      M05          4         A\n#&gt; 21  M021    Male      M05          4         B\n#&gt; 22  M022    Male      M05          4         A\n#&gt; 23  M023    Male      M06          8         A\n#&gt; 24  M024    Male      M06          8         A\n#&gt; 25  M025    Male      M06          8         A\n#&gt; 26  M026    Male      M06          8         B\n#&gt; 27  M027    Male      M06          8         B\n#&gt; 28  M028    Male      M06          8         A\n#&gt; 29  M029    Male      M06          8         B\n#&gt; 30  M030    Male      M06          8         B\n#&gt; 31  M031    Male      M07          8         B\n#&gt; 32  M032    Male      M07          8         A\n#&gt; 33  M033    Male      M07          8         A\n#&gt; 34  M034    Male      M07          8         B\n#&gt; 35  M035    Male      M07          8         A\n#&gt; 36  M036    Male      M07          8         A\n#&gt; 37  M037    Male      M07          8         B\n#&gt; 38  M038    Male      M07          8         B\n#&gt; 39  M039    Male      M08          8         B\n#&gt; 40  M040    Male      M08          8         A\n#&gt; 41  M041    Male      M08          8         A\n#&gt; 42  M042    Male      M08          8         A\n#&gt; 43  M043    Male      M08          8         B\n#&gt; 44  M044    Male      M08          8         A\n#&gt; 45  M045    Male      M08          8         B\n#&gt; 46  M046    Male      M08          8         B\n#&gt; 47  M047    Male      M09          4         B\n#&gt; 48  M048    Male      M09          4         B\n#&gt; 49  M049    Male      M09          4         A\n#&gt; 50  M050    Male      M09          4         A\n#&gt; 51  M051    Male      M10          2         A\n#&gt; 52  M052    Male      M10          2         B\n#&gt; 53  M053    Male      M11          4         A\n#&gt; 54  M054    Male      M11          4         A\n#&gt; 55  M055    Male      M11          4         B\n#&gt; 56  M056    Male      M11          4         B\n#&gt; 57  M057    Male      M12          6         A\n#&gt; 58  M058    Male      M12          6         B\n#&gt; 59  M059    Male      M12          6         B\n#&gt; 60  M060    Male      M12          6         B\n#&gt; 61  M061    Male      M12          6         A\n#&gt; 62  M062    Male      M12          6         A\n#&gt; 63  M063    Male      M13          8         A\n#&gt; 64  M064    Male      M13          8         A\n#&gt; 65  M065    Male      M13          8         A\n#&gt; 66  M066    Male      M13          8         A\n#&gt; 67  M067    Male      M13          8         B\n#&gt; 68  M068    Male      M13          8         B\n#&gt; 69  M069    Male      M13          8         B\n#&gt; 70  M070    Male      M13          8         B\n#&gt; 71  M071    Male      M14          8         B\n#&gt; 72  M072    Male      M14          8         B\n#&gt; 73  M073    Male      M14          8         B\n#&gt; 74  M074    Male      M14          8         A\n#&gt; 75  M075    Male      M14          8         A\n#&gt; 76  M076    Male      M14          8         B\n#&gt; 77  M077    Male      M14          8         A\n#&gt; 78  M078    Male      M14          8         A\n#&gt; 79  M079    Male      M15          6         A\n#&gt; 80  M080    Male      M15          6         B\n#&gt; 81  M081    Male      M15          6         A\n#&gt; 82  M082    Male      M15          6         A\n#&gt; 83  M083    Male      M15          6         B\n#&gt; 84  M084    Male      M15          6         B\n#&gt; 85  M085    Male      M16          8         A\n#&gt; 86  M086    Male      M16          8         B\n#&gt; 87  M087    Male      M16          8         B\n#&gt; 88  M088    Male      M16          8         A\n#&gt; 89  M089    Male      M16          8         B\n#&gt; 90  M090    Male      M16          8         B\n#&gt; 91  M091    Male      M16          8         A\n#&gt; 92  M092    Male      M16          8         A\n#&gt; 93  M093    Male      M17          2         A\n#&gt; 94  M094    Male      M17          2         B\n#&gt; 95  M095    Male      M18          8         B\n#&gt; 96  M096    Male      M18          8         A\n#&gt; 97  M097    Male      M18          8         A\n#&gt; 98  M098    Male      M18          8         B\n#&gt; 99  M099    Male      M18          8         B\n#&gt; 100 M100    Male      M18          8         B\n#&gt; 101 M101    Male      M18          8         A\n#&gt; 102 M102    Male      M18          8         A\n#&gt; 103 F001  Female      F01          2         B\n#&gt; 104 F002  Female      F01          2         A\n#&gt; 105 F003  Female      F02          2         A\n#&gt; 106 F004  Female      F02          2         B\n#&gt; 107 F005  Female      F03          8         A\n#&gt; 108 F006  Female      F03          8         A\n#&gt; 109 F007  Female      F03          8         B\n#&gt; 110 F008  Female      F03          8         A\n#&gt; 111 F009  Female      F03          8         A\n#&gt; 112 F010  Female      F03          8         B\n#&gt; 113 F011  Female      F03          8         B\n#&gt; 114 F012  Female      F03          8         B\n#&gt; 115 F013  Female      F04          4         B\n#&gt; 116 F014  Female      F04          4         B\n#&gt; 117 F015  Female      F04          4         A\n#&gt; 118 F016  Female      F04          4         A\n#&gt; 119 F017  Female      F05          4         A\n#&gt; 120 F018  Female      F05          4         A\n#&gt; 121 F019  Female      F05          4         B\n#&gt; 122 F020  Female      F05          4         B\n#&gt; 123 F021  Female      F06          4         B\n#&gt; 124 F022  Female      F06          4         B\n#&gt; 125 F023  Female      F06          4         A\n#&gt; 126 F024  Female      F06          4         A\n#&gt; 127 F025  Female      F07          2         A\n#&gt; 128 F026  Female      F07          2         B\n#&gt; 129 F027  Female      F08          2         A\n#&gt; 130 F028  Female      F08          2         B\n#&gt; 131 F029  Female      F09          2         B\n#&gt; 132 F030  Female      F09          2         A\n#&gt; 133 F031  Female      F10          6         B\n#&gt; 134 F032  Female      F10          6         B\n#&gt; 135 F033  Female      F10          6         B\n#&gt; 136 F034  Female      F10          6         A\n#&gt; 137 F035  Female      F10          6         A\n#&gt; 138 F036  Female      F10          6         A\n#&gt; 139 F037  Female      F11          8         A\n#&gt; 140 F038  Female      F11          8         B\n#&gt; 141 F039  Female      F11          8         B\n#&gt; 142 F040  Female      F11          8         B\n#&gt; 143 F041  Female      F11          8         B\n#&gt; 144 F042  Female      F11          8         A\n#&gt; 145 F043  Female      F11          8         A\n#&gt; 146 F044  Female      F11          8         A\n#&gt; 147 F045  Female      F12          2         B\n#&gt; 148 F046  Female      F12          2         A\n#&gt; 149 F047  Female      F13          6         B\n#&gt; 150 F048  Female      F13          6         A\n#&gt; 151 F049  Female      F13          6         B\n#&gt; 152 F050  Female      F13          6         A\n#&gt; 153 F051  Female      F13          6         A\n#&gt; 154 F052  Female      F13          6         B\n#&gt; 155 F053  Female      F14          2         A\n#&gt; 156 F054  Female      F14          2         B\n#&gt; 157 F055  Female      F15          6         B\n#&gt; 158 F056  Female      F15          6         A\n#&gt; 159 F057  Female      F15          6         B\n#&gt; 160 F058  Female      F15          6         B\n#&gt; 161 F059  Female      F15          6         A\n#&gt; 162 F060  Female      F15          6         A\n#&gt; 163 F061  Female      F16          4         A\n#&gt; 164 F062  Female      F16          4         A\n#&gt; 165 F063  Female      F16          4         B\n#&gt; 166 F064  Female      F16          4         B\n#&gt; 167 F065  Female      F17          6         B\n#&gt; 168 F066  Female      F17          6         B\n#&gt; 169 F067  Female      F17          6         A\n#&gt; 170 F068  Female      F17          6         B\n#&gt; 171 F069  Female      F17          6         A\n#&gt; 172 F070  Female      F17          6         A\n#&gt; 173 F071  Female      F18          8         A\n#&gt; 174 F072  Female      F18          8         B\n#&gt; 175 F073  Female      F18          8         B\n#&gt; 176 F074  Female      F18          8         B\n#&gt; 177 F075  Female      F18          8         A\n#&gt; 178 F076  Female      F18          8         A\n#&gt; 179 F077  Female      F18          8         A\n#&gt; 180 F078  Female      F18          8         B\n#&gt; 181 F079  Female      F19          4         B\n#&gt; 182 F080  Female      F19          4         B\n#&gt; 183 F081  Female      F19          4         A\n#&gt; 184 F082  Female      F19          4         A\n#&gt; 185 F083  Female      F20          4         B\n#&gt; 186 F084  Female      F20          4         B\n#&gt; 187 F085  Female      F20          4         A\n#&gt; 188 F086  Female      F20          4         A\n#&gt; 189 F087  Female      F21          8         B\n#&gt; 190 F088  Female      F21          8         B\n#&gt; 191 F089  Female      F21          8         A\n#&gt; 192 F090  Female      F21          8         B\n#&gt; 193 F091  Female      F21          8         A\n#&gt; 194 F092  Female      F21          8         B\n#&gt; 195 F093  Female      F21          8         A\n#&gt; 196 F094  Female      F21          8         A\n#&gt; 197 F095  Female      F22          8         B\n#&gt; 198 F096  Female      F22          8         A\n#&gt; 199 F097  Female      F22          8         A\n#&gt; 200 F098  Female      F22          8         B\n#&gt; 201 F099  Female      F22          8         B\n#&gt; 202 F100  Female      F22          8         A\n#&gt; 203 F101  Female      F22          8         B\n#&gt; 204 F102  Female      F22          8         A\n\n\n\n21.1.4 动态随机化\n动态随机化是指在临床试验的过程中每例患者分到各组的概率不是固定不变的,而是根据一定的条件进行调整的方法,它能有效地保证各试验组间例数和某些重要的非处理因素接近一致。动态随机化包括瓮(urn)法、偏币(biased coin)法、最小化(minimization)法等。\n最小化\n最小化随机化的核心是通过动态平衡组内特征分配，使得组间的差异最小。\n最小化被用作平衡临床试验预后因素的工具。第一例受试者通过简单随机化分配到一个治疗组，然后根据先前的受试者及其在临床试验中的安置分配其余受试者，以平衡预后因素。目的是克服分层随机化的挑战。\n\nShow the code# 加载randomizeR包\nlibrary(randomizeR)\n\n\n最小化的问题\n\n不符合随机化的所有要求。",
    "crumbs": [
      "临床研究设计",
      "<span class='chapter-number'>21</span>  <span class='chapter-title'>随机对照试验</span>"
    ]
  },
  {
    "objectID": "RCT.html#分配隐匿",
    "href": "RCT.html#分配隐匿",
    "title": "\n21  随机对照试验\n",
    "section": "\n21.2 分配隐匿",
    "text": "21.2 分配隐匿\n在分配前对受试者的治疗组分配保密。这有助于减少选择偏倚，防止研究人员影响受试者分组。\n\n首先要求产生随机分配序列和确定受试对象合格性的研究人员不应该是同一个人\n其次,如果可能,产生和保存随机分配序列的人员最好是不参与试验的人员\n\n按顺序编码、不透光、密封的信封(sequentially numbered,opaque, sealed envelopes )这是最常用的一种方法。每个研究对象所接受的治疗方案由产生的随机分配序列产生,并被放入按顺序、密封、不透光的信封中。合格的受试对象同意进入试验时,信封才能被打开,受试对象才能接受相应的处理措施。但是这种方法有一定的局限性。(1)如果研究者在试验前提前打开信封而将患者分配至预期的治疗组,将会破坏了研究的随机性。(2)如果将信封对着极强的光线,有时信封里面的内容能被看见。因此,为了避免这些问题,目前在临床研究中比较常用的做法是用来无碳复写纸按顺序、密封、不透光的信封。一旦无碳复写纸被开启后,就无法还原。这样,就比较容易发现研究者是否提前知道随机分配序列。信封法适用于单中心小样本的临床研究。\n中心随机( central randomisation)系统为了避免按顺序、密封、不透光的信封所带来的问题,常用的一种方法是“远程”随机。“远程随机”是指当研究人员确定合格的研究对象后,通过电话或者网络将患者的基本信息传递给中心随机系统,然后获得每个患者的治疗分配方案。从今后的发展趋势来看,这种“远程”的中心随机系统将会取代信封系统。中心随机法适用于大型多中心研究。\n随机分配方案隐匿与盲法\n常与盲法相混淆。随机分配方案的隐匿是指通过在随机分配时防止随机序列被事先知道,而避免选择性偏倚;它在临床试验最后一名患者完成分组后即告结束;而盲法是为了避免干预措施实施过程中和结局指标测量时来自受试者和研究者的主观偏性,盲法需要在整个治疗和随访过程中保持盲的状态,直到试验干预和结局测量完成后才结束。盲法并非是在所有的临床试验中都能进行,但是随机分配方案的隐匿却在任何临床试验中都能进行,无论是分配前或者在分配的时点时。例如,比较针灸和药物两种疗法治疗某种疾病的疗效,盲法是难以实施的,而随机分配方案的隐匿却是可行的。",
    "crumbs": [
      "临床研究设计",
      "<span class='chapter-number'>21</span>  <span class='chapter-title'>随机对照试验</span>"
    ]
  },
  {
    "objectID": "RCT.html#盲法",
    "href": "RCT.html#盲法",
    "title": "\n21  随机对照试验\n",
    "section": "\n21.3 盲法",
    "text": "21.3 盲法\n\n\n\n\n\n21.3.1 开放试验\n盲法是RCT的基本原则之一，但并不是所有的研究都必须采用或均能实行。比如比较某种手术与某药物治疗肺癌的效果，就不必要，也没有条件实施盲法。在这种情况下，只能进行开放试验，即研究对象和研究者均知道试验组和对照组的分组情况，试验公开进行。\n在开放试验中，盲法无法实施，但是分组隐匿仍然可以实施。同时可以考虑对结局评价者、数据监察和统计分析人员设盲。其优点是易于设计和实施，研究者了解分组情况，便于对研究对象及时作出处理，其主要缺点是容易产生偏倚。\n\n21.3.2 单盲\n单盲试验（single-blinded）：单盲试验是仅研究者知道每个病人用药的具体内容，而病人不知道，单盲试验虽可以避免来自病人主观因素的偏倚，但仍未能防止来自研究者方面的影响。\n\n21.3.3 双盲\n双盲(double blinded)试验：单盲试验是仅研究者知道每个病人用药的具体内容，而病人不知道，单盲试验虽可以避免来自病人主观因素的偏倚，但仍未能防止来自研究者方面的影响。\n在双盲实施过程中，可能会出现一种情况：假设本研究中006号研究对象在研究过程中出现了严重的不良反应，要分析原因以便采取对策，此时必须揭盲。揭盲后研究实施者就知道了006号研究对象在使用乙药。但是，研究实施者在分组时已经知道006号研究对象为2组，揭盲后便知道了所有2组研究对象均在使用乙药，这会出现一人揭盲人人揭盲的情况。要避免这种情况，严格而规范的双盲试验不是给每个研究对象一个组别，按组别发药；而是给每个研究对象一个编码，按编码发药。盲底则由专人统一保管。\n要避免一人揭盲人人揭盲的情况，双盲的具体做法是:\n\n研究设计者在随机化分组时，对每个研究对象分配一个设盲编码。\n\n\n\nTable 21.2\n\nShow the coderaw_data %&gt;% \n    mutate(\n        blind_id = 1001:1100,\n        drug_id = 1001:1100,\n    ) -&gt;raw_data\nraw_data \n#&gt; # A tibble: 100 × 4\n#&gt;       id assign blind_id drug_id\n#&gt;    &lt;int&gt;  &lt;int&gt;    &lt;int&gt;   &lt;int&gt;\n#&gt;  1     1      3     1001    1001\n#&gt;  2     2      2     1002    1002\n#&gt;  3     3      2     1003    1003\n#&gt;  4     4      4     1004    1004\n#&gt;  5     5      1     1005    1005\n#&gt;  6     6      1     1006    1006\n#&gt;  7     7      2     1007    1007\n#&gt;  8     8      3     1008    1008\n#&gt;  9     9      2     1009    1009\n#&gt; 10    10      1     1010    1010\n#&gt; # ℹ 90 more rows\n\n# 给研究实施者提供\nraw_data %&gt;% select(contains(\"id\"))\n#&gt; # A tibble: 100 × 3\n#&gt;       id blind_id drug_id\n#&gt;    &lt;int&gt;    &lt;int&gt;   &lt;int&gt;\n#&gt;  1     1     1001    1001\n#&gt;  2     2     1002    1002\n#&gt;  3     3     1003    1003\n#&gt;  4     4     1004    1004\n#&gt;  5     5     1005    1005\n#&gt;  6     6     1006    1006\n#&gt;  7     7     1007    1007\n#&gt;  8     8     1008    1008\n#&gt;  9     9     1009    1009\n#&gt; 10    10     1010    1010\n#&gt; # ℹ 90 more rows\n\n\n\n\n\n同时，分发的药品包装上也有与设盲编码一一对应的编码。\n在随机化分组完成后，001号研究对象将分入3组，002号将分入2组。研究设计者在编码为1001的药品包装内分装C药，在编码为1002的药品包装内分装乙药。同时仅给研究实施者提供研究对象序号、设盲编码和标有设盲编码的药品 ( Table 21.2)。\n而盲底（ Table 21.1 ）则只有研究设计者知道，并由专人保管。此时，研究实施者按照顺序纳入研究对象后，仅给研究对象标有编码的药品即可。研究实施者和研究对象均不知道分组和用药情况。\n\n这样做的优点是：出现严重不良反应需要揭盲时，只需个别地揭盲，不容易泄密。但需要注意的是，必须建立与健全专项的药品保管、领用和发放制度；领发药品的各个环节都要认真核对编码，防止出错。实际上，如此执行，也做到了分组隐匿。\n需要注意的是，试验结束前盲底泄露或应急信件拆阅超过20%，双盲试验即告失败。\n\n21.3.4 三盲\n在双盲实施的时候，还有可能出现一种偏倚：数据监察和统计分析人员知道研究分组情况，可能会对数据有选择性的取舍，造成不真实的情况。如在双盲实施的过程中，对数据监察和统计分析人员也设盲，此为三盲。\n在研究实施过程中，将所有的临床试验数据输入数据库并经过核查，确证准确无误将数据锁定后，才进行第一次揭盲，即分出A、B两组，但哪一组是试验组、哪一组是对照组并不清楚。之后进行统计分析，待A组和B组分析数据出来后，再第二次揭盲，即明确A、B两组分别代表试验组还是对照组。\n盲法与前述分配隐匿的区别在于：分配隐匿主要控制一种选择偏倚，即控制研究实施者有倾向地选择研究对象进入试验组或对照组；而盲法除此之外，还能控制信息偏倚，即控制研究实施者、资料收集和数据分析者有倾向性的取舍研究结果。",
    "crumbs": [
      "临床研究设计",
      "<span class='chapter-number'>21</span>  <span class='chapter-title'>随机对照试验</span>"
    ]
  },
  {
    "objectID": "RCT.html#对照",
    "href": "RCT.html#对照",
    "title": "\n21  随机对照试验\n",
    "section": "\n21.4 对照",
    "text": "21.4 对照\n空白对照 安慰剂（placebo）对照 阳性对照",
    "crumbs": [
      "临床研究设计",
      "<span class='chapter-number'>21</span>  <span class='chapter-title'>随机对照试验</span>"
    ]
  },
  {
    "objectID": "RCT.html#重复",
    "href": "RCT.html#重复",
    "title": "\n21  随机对照试验\n",
    "section": "\n21.5 重复",
    "text": "21.5 重复\n有一定的重复观察样本, 一项研究不允许有太多的受试者失访, 在选择研究样本时一定要特别注意。",
    "crumbs": [
      "临床研究设计",
      "<span class='chapter-number'>21</span>  <span class='chapter-title'>随机对照试验</span>"
    ]
  },
  {
    "objectID": "RCT.html#评价方法",
    "href": "RCT.html#评价方法",
    "title": "\n21  随机对照试验\n",
    "section": "\n21.6 评价方法",
    "text": "21.6 评价方法\nCochrane 偏倚风险评估工具包括 7 个方面：\n\n随机序列的产生(选择偏倚)；\n盲法分配(选择偏倚)；\n所有研究参与者和人员采用盲法(执行偏倚)；\n结果评估的盲法(观察偏倚)；\n结果数据的完整性(失访偏倚)；\n选择报道(报告偏倚)；\n其他。最后以文字、表格或图示方法显示对所有纳入文献的评价结果\n\nJadad 量表在临床试验的评价工作中简单易行，具有一定的科学性，得到了许多学者的认可， 发表了大量以 Jadad 量表作为评价工具的系统评价， 其中相当一部分文献集中在药物临床试验为主的研究， 在非开放式 RCT 评价中发挥了重要作用，得到了大多数学者的认可。 但是，随着人们对临床试验实施标准的不断修改完善，尤其是开放式非药物临床试验的RCT 研究在临床上广泛开展，Jadad 量表的评价标准有时不能完全客观、透明地反映出开放式 RCT 的研究质量，从而可能将质量较高的 RCT 误认为低质量 RCT。",
    "crumbs": [
      "临床研究设计",
      "<span class='chapter-number'>21</span>  <span class='chapter-title'>随机对照试验</span>"
    ]
  }
]