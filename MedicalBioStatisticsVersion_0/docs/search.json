[
  {
    "objectID": "multiple_linear_regression.html",
    "href": "multiple_linear_regression.html",
    "title": "\n17  多元线性回归\n",
    "section": "",
    "text": "17.1 多元回归\nCodelibrary(tidymodels)\nlibrary(patchwork)\nlibrary(ggfortify)\n\n# 检测变量相关关系\nad &lt;- advertising %&gt;% select(-1)\ncor(ad)\n#&gt;                   TV      radio  newspaper     sales\n#&gt; TV        1.00000000 0.05480866 0.05664787 0.7822244\n#&gt; radio     0.05480866 1.00000000 0.35410375 0.5762226\n#&gt; newspaper 0.05664787 0.35410375 1.00000000 0.2282990\n#&gt; sales     0.78222442 0.57622257 0.22829903 1.0000000",
    "crumbs": [
      "推断统计模型",
      "<span class='chapter-number'>17</span>  <span class='chapter-title'>多元线性回归</span>"
    ]
  },
  {
    "objectID": "multiple_linear_regression.html#多元回归",
    "href": "multiple_linear_regression.html#多元回归",
    "title": "\n17  多元线性回归\n",
    "section": "",
    "text": "17.1.1 rms::ols()\n\n\nCode\nols_mlm &lt;- rms::ols(sales~TV+radio+newspaper,data = advertising)\nols_mlm \n#&gt; Linear Regression Model\n#&gt; \n#&gt; rms::ols(formula = sales ~ TV + radio + newspaper, data = advertising)\n#&gt; \n#&gt;                 Model Likelihood    Discrimination    \n#&gt;                       Ratio Test           Indexes    \n#&gt; Obs     200    LR chi2    455.01    R2       0.897    \n#&gt; sigma1.6855    d.f.            3    R2 adj   0.896    \n#&gt; d.f.    196    Pr(&gt; chi2) 0.0000    g        5.685    \n#&gt; \n#&gt; Residuals\n#&gt; \n#&gt;     Min      1Q  Median      3Q     Max \n#&gt; -8.8277 -0.8908  0.2418  1.1893  2.8292 \n#&gt; \n#&gt; \n#&gt;           Coef    S.E.   t     Pr(&gt;|t|)\n#&gt; Intercept  2.9389 0.3119  9.42 &lt;0.0001 \n#&gt; TV         0.0458 0.0014 32.81 &lt;0.0001 \n#&gt; radio      0.1885 0.0086 21.89 &lt;0.0001 \n#&gt; newspaper -0.0010 0.0059 -0.18 0.8599\ntexreg::texreg(ols_mlm)\n#&gt; \n#&gt; \\begin{table}\n#&gt; \\begin{center}\n#&gt; \\begin{tabular}{l c}\n#&gt; \\hline\n#&gt;  & Model 1 \\\\\n#&gt; \\hline\n#&gt; Intercept  & $2.94^{***}$ \\\\\n#&gt;            & $(0.31)$     \\\\\n#&gt; TV         & $0.05^{***}$ \\\\\n#&gt;            & $(0.00)$     \\\\\n#&gt; radio      & $0.19^{***}$ \\\\\n#&gt;            & $(0.01)$     \\\\\n#&gt; newspaper  & $-0.00$      \\\\\n#&gt;            & $(0.01)$     \\\\\n#&gt; \\hline\n#&gt; Num. obs.  & $200$        \\\\\n#&gt; R$^2$      & $0.90$       \\\\\n#&gt; Adj. R$^2$ & $0.90$       \\\\\n#&gt; L.R.       & $455.01$     \\\\\n#&gt; \\hline\n#&gt; \\multicolumn{2}{l}{\\scriptsize{$^{***}p&lt;0.001$; $^{**}p&lt;0.01$; $^{*}p&lt;0.05$}}\n#&gt; \\end{tabular}\n#&gt; \\caption{Statistical models}\n#&gt; \\label{table:coefficients}\n#&gt; \\end{center}\n#&gt; \\end{table}\n\ncar::vif(ols_mlm)\n#&gt;        TV     radio newspaper \n#&gt;  3.966283  3.970266  3.410504\nanova(ols_mlm)\n#&gt;                 Analysis of Variance          Response: sales \n#&gt; \n#&gt;  Factor     d.f. Partial SS   MS           F       P     \n#&gt;  TV           1  3.058010e+03 3.058010e+03 1076.41 &lt;.0001\n#&gt;  radio        1  1.361737e+03 1.361737e+03  479.33 &lt;.0001\n#&gt;  newspaper    1  8.871717e-02 8.871717e-02    0.03 0.8599\n#&gt;  REGRESSION   3  4.860323e+03 1.620108e+03  570.27 &lt;.0001\n#&gt;  ERROR      196  5.568253e+02 2.840945e+00\n\n\n\n17.1.2 lm()\n\n\nCode# 多元线性回归\nlm_spec &lt;-linear_reg() %&gt;%\n  set_mode(\"regression\") %&gt;%\n  set_engine(\"lm\")  \nlm_spec\n#&gt; Linear Regression Model Specification (regression)\n#&gt; \n#&gt; Computational engine: lm\nlm_sales_multi&lt;- lm_spec %&gt;% fit(sales~TV+radio+newspaper,data = advertising)\nsummary(lm_sales_multi$fit)\n#&gt; \n#&gt; Call:\n#&gt; stats::lm(formula = sales ~ TV + radio + newspaper, data = data)\n#&gt; \n#&gt; Residuals:\n#&gt;     Min      1Q  Median      3Q     Max \n#&gt; -8.8277 -0.8908  0.2418  1.1893  2.8292 \n#&gt; \n#&gt; Coefficients:\n#&gt;              Estimate Std. Error t value Pr(&gt;|t|)    \n#&gt; (Intercept)  2.938889   0.311908   9.422   &lt;2e-16 ***\n#&gt; TV           0.045765   0.001395  32.809   &lt;2e-16 ***\n#&gt; radio        0.188530   0.008611  21.893   &lt;2e-16 ***\n#&gt; newspaper   -0.001037   0.005871  -0.177     0.86    \n#&gt; ---\n#&gt; Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n#&gt; \n#&gt; Residual standard error: 1.686 on 196 degrees of freedom\n#&gt; Multiple R-squared:  0.8972, Adjusted R-squared:  0.8956 \n#&gt; F-statistic: 570.3 on 3 and 196 DF,  p-value: &lt; 2.2e-16\n\ntidy(lm_sales_multi)\n\n\n\n\nterm\nestimate\nstd.error\nstatistic\np.value\n\n\n\n(Intercept)\n2.9388894\n0.3119082\n9.4222884\n0.0000000\n\n\nTV\n0.0457646\n0.0013949\n32.8086244\n0.0000000\n\n\nradio\n0.1885300\n0.0086112\n21.8934961\n0.0000000\n\n\nnewspaper\n-0.0010375\n0.0058710\n-0.1767146\n0.8599151\n\n\n\n\n\nCodeglance(lm_sales_multi)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nr.squared\nadj.r.squared\nsigma\nstatistic\np.value\ndf\nlogLik\nAIC\nBIC\ndeviance\ndf.residual\nnobs\n\n\n0.8972106\n0.8956373\n1.68551\n570.2707\n0\n3\n-386.1811\n782.3622\n798.8538\n556.8253\n196\n200\n\n\n\n\nCode\nlogLik(lm_sales_multi$fit)\n#&gt; 'log Lik.' -386.1811 (df=5)\ncar::vif(lm_sales_multi$fit)\n#&gt;        TV     radio newspaper \n#&gt;  1.004611  1.144952  1.145187\n\n\n\n17.1.3 线性组合\n我们经常希望对回归系数的线性组合进行推断，特别是对于多个类别的分类变量。例如，对于分类变量，回归系数表示其中一个组与参考类别之间的平均差异\n\nCodelm_multiple &lt;- lm(sales~TV+radio+newspaper,data = advertising)\nlm_multiple\n#&gt; \n#&gt; Call:\n#&gt; lm(formula = sales ~ TV + radio + newspaper, data = advertising)\n#&gt; \n#&gt; Coefficients:\n#&gt; (Intercept)           TV        radio    newspaper  \n#&gt;    2.938889     0.045765     0.188530    -0.001037\nlibrary(multcomp, quietly = T)\nconfint(lm_multiple)\n#&gt;                   2.5 %     97.5 %\n#&gt; (Intercept)  2.32376228 3.55401646\n#&gt; TV           0.04301371 0.04851558\n#&gt; radio        0.17154745 0.20551259\n#&gt; newspaper   -0.01261595 0.01054097\n# 在 R 中，我们通过首先指定一个矩阵来执行此计算，该矩阵指定要进行的比较。此处的矩阵必须具有与回归方程中的回归系数相同的列数\ncomparison &lt;- matrix(c(0,3,1,1), nrow=1)\n\nlincom &lt;- glht(lm_multiple, linfct = comparison)\nsummary(lincom)\n#&gt; \n#&gt;   Simultaneous Tests for General Linear Hypotheses\n#&gt; \n#&gt; Fit: lm(formula = sales ~ TV + radio + newspaper, data = advertising)\n#&gt; \n#&gt; Linear Hypotheses:\n#&gt;        Estimate Std. Error t value Pr(&gt;|t|)    \n#&gt; 1 == 0 0.324786   0.009268   35.05   &lt;2e-16 ***\n#&gt; ---\n#&gt; Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n#&gt; (Adjusted p values reported -- single-step method)\nconfint(lincom)\n#&gt; \n#&gt;   Simultaneous Confidence Intervals\n#&gt; \n#&gt; Fit: lm(formula = sales ~ TV + radio + newspaper, data = advertising)\n#&gt; \n#&gt; Quantile = 1.9721\n#&gt; 95% family-wise confidence level\n#&gt;  \n#&gt; \n#&gt; Linear Hypotheses:\n#&gt;        Estimate lwr    upr   \n#&gt; 1 == 0 0.3248   0.3065 0.3431",
    "crumbs": [
      "推断统计模型",
      "<span class='chapter-number'>17</span>  <span class='chapter-title'>多元线性回归</span>"
    ]
  },
  {
    "objectID": "multiple_linear_regression.html#交互项",
    "href": "multiple_linear_regression.html#交互项",
    "title": "\n17  多元线性回归\n",
    "section": "\n17.2 交互项",
    "text": "17.2 交互项\n\nCodelm_interact&lt;- lm_spec %&gt;%  fit(sales ~ .+ TV:radio, data = advertising)\n\nlm_interact\n#&gt; parsnip model object\n#&gt; \n#&gt; \n#&gt; Call:\n#&gt; stats::lm(formula = sales ~ . + TV:radio, data = data)\n#&gt; \n#&gt; Coefficients:\n#&gt; (Intercept)           id           TV        radio    newspaper     TV:radio  \n#&gt;   6.7912439   -0.0005502    0.0190783    0.0278567    0.0012488    0.0010873",
    "crumbs": [
      "推断统计模型",
      "<span class='chapter-number'>17</span>  <span class='chapter-title'>多元线性回归</span>"
    ]
  },
  {
    "objectID": "multiple_linear_regression.html#变换",
    "href": "multiple_linear_regression.html#变换",
    "title": "\n17  多元线性回归\n",
    "section": "\n17.3 变换",
    "text": "17.3 变换\n\n17.3.1 多项式\n\nCoderec_spec_square &lt;- recipe(sales ~ TV, data = advertising) %&gt;%  \n  step_mutate(`TV^2` = TV^2)  \nrec_spec_square\n\nlm_wf_square &lt;- workflow() %&gt;%  \n  add_model(lm_spec) %&gt;%  \n  add_recipe(rec_spec_square)  \n\nlm_wf_square %&gt;%\n  fit(advertising)\n#&gt; ══ Workflow [trained] ══════════════════════════════════════════════════════════\n#&gt; Preprocessor: Recipe\n#&gt; Model: linear_reg()\n#&gt; \n#&gt; ── Preprocessor ────────────────────────────────────────────────────────────────\n#&gt; 1 Recipe Step\n#&gt; \n#&gt; • step_mutate()\n#&gt; \n#&gt; ── Model ───────────────────────────────────────────────────────────────────────\n#&gt; \n#&gt; Call:\n#&gt; stats::lm(formula = ..y ~ ., data = data)\n#&gt; \n#&gt; Coefficients:\n#&gt; (Intercept)           TV       `TV^2`  \n#&gt;   6.114e+00    6.727e-02   -6.847e-05\n\nlm(sales ~ TV+ I(TV^2),data = advertising)\n#&gt; \n#&gt; Call:\n#&gt; lm(formula = sales ~ TV + I(TV^2), data = advertising)\n#&gt; \n#&gt; Coefficients:\n#&gt; (Intercept)           TV      I(TV^2)  \n#&gt;   6.114e+00    6.727e-02   -6.847e-05\n\n\n\n17.3.2 对数变换\n\nCoderec_spec_log &lt;- recipe(sales ~ TV, data = advertising) %&gt;%  \n  step_log(TV)  \n\nlm_wf_log &lt;- workflow() %&gt;% \n  add_model(lm_spec) %&gt;%  \n  add_recipe(rec_spec_log) \n\nlm_wf_log %&gt;%\n  fit(advertising)\n#&gt; ══ Workflow [trained] ══════════════════════════════════════════════════════════\n#&gt; Preprocessor: Recipe\n#&gt; Model: linear_reg()\n#&gt; \n#&gt; ── Preprocessor ────────────────────────────────────────────────────────────────\n#&gt; 1 Recipe Step\n#&gt; \n#&gt; • step_log()\n#&gt; \n#&gt; ── Model ───────────────────────────────────────────────────────────────────────\n#&gt; \n#&gt; Call:\n#&gt; stats::lm(formula = ..y ~ ., data = data)\n#&gt; \n#&gt; Coefficients:\n#&gt; (Intercept)           TV  \n#&gt;      -4.203        3.901\n\nlm(sales ~ log(TV),data = advertising)\n#&gt; \n#&gt; Call:\n#&gt; lm(formula = sales ~ log(TV), data = advertising)\n#&gt; \n#&gt; Coefficients:\n#&gt; (Intercept)      log(TV)  \n#&gt;      -4.203        3.901",
    "crumbs": [
      "推断统计模型",
      "<span class='chapter-number'>17</span>  <span class='chapter-title'>多元线性回归</span>"
    ]
  },
  {
    "objectID": "multiple_linear_regression.html#回归诊断",
    "href": "multiple_linear_regression.html#回归诊断",
    "title": "\n17  多元线性回归\n",
    "section": "\n17.4 回归诊断",
    "text": "17.4 回归诊断\nhttps://www.statmethods.net/stats/rdiagnostics.html\n\nCodelibrary(car)\ncar::scatterplotMatrix(ad)  # 多重共线性\n\n\n\n\n\n\nCodeconfint(lm_sales_multi$fit)  # 95%置信区间\n#&gt;                   2.5 %     97.5 %\n#&gt; (Intercept)  2.32376228 3.55401646\n#&gt; TV           0.04301371 0.04851558\n#&gt; radio        0.17154745 0.20551259\n#&gt; newspaper   -0.01261595 0.01054097\nplot(lm_sales_multi$fit)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCodeautoplot(lm_sales_multi) #回归诊断图\n\n\n\n\n\n\n\n\n17.4.1 线性假设\n残差图， 成分残差图\n\nCodeplot(lm_sales_multi$fit,1)  \n\n\n\n\n\n\nCodecrPlots(lm_sales_multi$fit)\n\n\n\n\n\n\n\n\n17.4.2 正态性假设Q-Q图\nStandardized Residuals\n\nCodeplot(lm_sales_multi$fit,2) \n\n\n\n\n\n\nCodesummary(powerTransform(lm_sales_multi$fit))  \n#&gt; bcPower Transformation to Normality \n#&gt;    Est Power Rounded Pwr Wald Lwr Bnd Wald Upr Bnd\n#&gt; Y1    0.9074           1       0.7569       1.0578\n#&gt; \n#&gt; Likelihood ratio test that transformation parameter is equal to 0\n#&gt;  (log transformation)\n#&gt;                            LRT df       pval\n#&gt; LR test, lambda = (0) 147.1578  1 &lt; 2.22e-16\n#&gt; \n#&gt; Likelihood ratio test that no transformation is needed\n#&gt;                           LRT df    pval\n#&gt; LR test, lambda = (1) 1.41991  1 0.23342\n\n\n\nCodeplot(lm_sales_multi$fit,3)\n\n\n\n\n\n\n\n\n17.4.3 误差相关性\n\nCodedurbinWatsonTest(lm_sales_multi$fit)      #结果表明rho=0\n#&gt;  lag Autocorrelation D-W Statistic p-value\n#&gt;    1     -0.04687792      2.083648   0.554\n#&gt;  Alternative hypothesis: rho != 0\n\n\n\n17.4.4 误差项的方差齐性\n\nCodencvTest(lm_sales_multi$fit)\n#&gt; Non-constant Variance Score Test \n#&gt; Variance formula: ~ fitted.values \n#&gt; Chisquare = 5.355982, Df = 1, p = 0.020651\nspreadLevelPlot(lm_sales_multi$fit)\n\n\n\n\n\n\n#&gt; \n#&gt; Suggested power transformation:  1.499852\n\n\nCodetibble(\n    abs_studentized_residuals=abs(rstudent(lm_sales_multi$fit)),\n    fitted_values=lm_sales_multi$fit$model$sales\n) %&gt;% ggplot(aes(fitted_values,abs_studentized_residuals))+\n    geom_point(pch=21)+\n    geom_smooth()\n\n\n\n\n\n\n\n\n17.4.5 异常观测点\n\nCode# studentized residual Plot\nresidplot&lt;-function(fit,nbreaks=10){\n  z&lt;-rstudent(fit)\n  hist(z,breaks=nbreaks,freq=FALSE)     #密度直方图\n  title(xlab=\"Studentized Residual\")\n  rug(z,col=\"brown\")                    #轴须图\n  curve(dnorm(x,mean=mean(z),sd=sd(z)),add=TRUE,col=\"blue\",lwd=2) #正态密度曲线\n  lines(density(z)$x,density(z)$y,col=\"red\",lwd=2)       #样本密度曲线\n  legend(\"topright\",c(\"Normal Curve\",\"Kernel Density Curve\"),#图例\n  lty = c(3,2),pch = c(21,22),col=c(\"blue\",\"red\"),cex=.7)\n}\nresidplot(lm_sales_multi$fit)\n\n\n\n\n\n\n\n\nCode#######################################################################\nlibrary(car)\noutlierTest(lm_sales_multi$fit)            #离群点\n#高杠杆值点\nhat.plot&lt;-function(fit){\n  p&lt;-length(coefficients(fit)) #模型估计的参数数目（包含截距项）\n  n&lt;-length(fitted(fit))       #样本量\n  plot(hatvalues(fit),main=\"Index Plot of Hat Values\")#帽子值\n  abline(h=c(2,3)*p/n,col=\"red\",lty=2)  #大于帽子均值p/n的2或3倍被认为是高杠杆值\n  identity(1:n,hatvalues(fit),names(hatvalues(fit)))\n}\nhat.plot(lm_sales_multi$fit)\n####强影响点\n#Cook's D图形    大于4/(n-k-1)  k为预测变量数目\ncutoff&lt;-4/(nrow(advertising)-length(lm_sales_multi$fit$coefficients)-2)\n{plot(lm_sales_multi$fit,which=4,cook.levels=cutoff)\nabline(h=cutoff,lty=2,col=\"red\")}\n#变量添加图\navPlots(lm_sales_multi$fit,ask=FALSE,id.method=\"identity\")\n\n###\ninfluencePlot(lm_sales_multi$fit,id.method=\"identity\",main=\"Influence Plot\")\n\n\n\n17.4.6 多重共线性\n\nCodevif(lm_sales_multi$fit)\n#&gt;        TV     radio newspaper \n#&gt;  1.004611  1.144952  1.145187\n\nsqrt(vif(lm_sales_multi$fit))&gt;=2       #vif平方根 ≥2 存在\n#&gt;        TV     radio newspaper \n#&gt;     FALSE     FALSE     FALSE",
    "crumbs": [
      "推断统计模型",
      "<span class='chapter-number'>17</span>  <span class='chapter-title'>多元线性回归</span>"
    ]
  },
  {
    "objectID": "multiple_linear_regression.html#逐步回归",
    "href": "multiple_linear_regression.html#逐步回归",
    "title": "\n17  多元线性回归\n",
    "section": "\n17.5 逐步回归",
    "text": "17.5 逐步回归\n逐步回归是筛选变量，有向前、向后和两个方向同时进行三个方法。\n\ndirection = \"both\"双向\ndirection = \"backward\"向后\ndirection = \"forward\"向前\n\n\nCodestep_full &lt;- lm(sales~ . ,data = advertising[-1])\nstep_lm_0 &lt;- lm(sales~ 1 ,data = advertising[-1])\n\nstep_forward &lt;- stats::step(step_lm_0,scope =formula(step_full),  \n                            direction = \"forward\")\n#&gt; Start:  AIC=661.8\n#&gt; sales ~ 1\n#&gt; \n#&gt;             Df Sum of Sq    RSS    AIC\n#&gt; + TV         1    3314.6 2102.5 474.52\n#&gt; + radio      1    1798.7 3618.5 583.10\n#&gt; + newspaper  1     282.3 5134.8 653.10\n#&gt; &lt;none&gt;                   5417.1 661.80\n#&gt; \n#&gt; Step:  AIC=474.52\n#&gt; sales ~ TV\n#&gt; \n#&gt;             Df Sum of Sq     RSS    AIC\n#&gt; + radio      1   1545.62  556.91 210.82\n#&gt; + newspaper  1    183.97 1918.56 458.20\n#&gt; &lt;none&gt;                   2102.53 474.52\n#&gt; \n#&gt; Step:  AIC=210.82\n#&gt; sales ~ TV + radio\n#&gt; \n#&gt;             Df Sum of Sq    RSS    AIC\n#&gt; &lt;none&gt;                   556.91 210.82\n#&gt; + newspaper  1  0.088717 556.83 212.79\nsummary(step_forward)\n#&gt; \n#&gt; Call:\n#&gt; lm(formula = sales ~ TV + radio, data = advertising[-1])\n#&gt; \n#&gt; Residuals:\n#&gt;     Min      1Q  Median      3Q     Max \n#&gt; -8.7977 -0.8752  0.2422  1.1708  2.8328 \n#&gt; \n#&gt; Coefficients:\n#&gt;             Estimate Std. Error t value Pr(&gt;|t|)    \n#&gt; (Intercept)  2.92110    0.29449   9.919   &lt;2e-16 ***\n#&gt; TV           0.04575    0.00139  32.909   &lt;2e-16 ***\n#&gt; radio        0.18799    0.00804  23.382   &lt;2e-16 ***\n#&gt; ---\n#&gt; Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n#&gt; \n#&gt; Residual standard error: 1.681 on 197 degrees of freedom\n#&gt; Multiple R-squared:  0.8972, Adjusted R-squared:  0.8962 \n#&gt; F-statistic: 859.6 on 2 and 197 DF,  p-value: &lt; 2.2e-16\n\n\n\nstep_backward &lt;- stats::step(object = step_full,#scope = formula(step_lm_0) ,\n                         direction = \"backward\")\n#&gt; Start:  AIC=212.79\n#&gt; sales ~ TV + radio + newspaper\n#&gt; \n#&gt;             Df Sum of Sq    RSS    AIC\n#&gt; - newspaper  1      0.09  556.9 210.82\n#&gt; &lt;none&gt;                    556.8 212.79\n#&gt; - radio      1   1361.74 1918.6 458.20\n#&gt; - TV         1   3058.01 3614.8 584.90\n#&gt; \n#&gt; Step:  AIC=210.82\n#&gt; sales ~ TV + radio\n#&gt; \n#&gt;         Df Sum of Sq    RSS    AIC\n#&gt; &lt;none&gt;                556.9 210.82\n#&gt; - radio  1    1545.6 2102.5 474.52\n#&gt; - TV     1    3061.6 3618.5 583.10\nsummary(step_backward )\n#&gt; \n#&gt; Call:\n#&gt; lm(formula = sales ~ TV + radio, data = advertising[-1])\n#&gt; \n#&gt; Residuals:\n#&gt;     Min      1Q  Median      3Q     Max \n#&gt; -8.7977 -0.8752  0.2422  1.1708  2.8328 \n#&gt; \n#&gt; Coefficients:\n#&gt;             Estimate Std. Error t value Pr(&gt;|t|)    \n#&gt; (Intercept)  2.92110    0.29449   9.919   &lt;2e-16 ***\n#&gt; TV           0.04575    0.00139  32.909   &lt;2e-16 ***\n#&gt; radio        0.18799    0.00804  23.382   &lt;2e-16 ***\n#&gt; ---\n#&gt; Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n#&gt; \n#&gt; Residual standard error: 1.681 on 197 degrees of freedom\n#&gt; Multiple R-squared:  0.8972, Adjusted R-squared:  0.8962 \n#&gt; F-statistic: 859.6 on 2 and 197 DF,  p-value: &lt; 2.2e-16\n\nstep_both&lt;- stats::step(object = step_lm_0, scope = formula(step_full) ,\n                         direction = \"both\")\n#&gt; Start:  AIC=661.8\n#&gt; sales ~ 1\n#&gt; \n#&gt;             Df Sum of Sq    RSS    AIC\n#&gt; + TV         1    3314.6 2102.5 474.52\n#&gt; + radio      1    1798.7 3618.5 583.10\n#&gt; + newspaper  1     282.3 5134.8 653.10\n#&gt; &lt;none&gt;                   5417.1 661.80\n#&gt; \n#&gt; Step:  AIC=474.52\n#&gt; sales ~ TV\n#&gt; \n#&gt;             Df Sum of Sq    RSS    AIC\n#&gt; + radio      1    1545.6  556.9 210.82\n#&gt; + newspaper  1     184.0 1918.6 458.20\n#&gt; &lt;none&gt;                   2102.5 474.52\n#&gt; - TV         1    3314.6 5417.1 661.80\n#&gt; \n#&gt; Step:  AIC=210.82\n#&gt; sales ~ TV + radio\n#&gt; \n#&gt;             Df Sum of Sq    RSS    AIC\n#&gt; &lt;none&gt;                    556.9 210.82\n#&gt; + newspaper  1      0.09  556.8 212.79\n#&gt; - radio      1   1545.62 2102.5 474.52\n#&gt; - TV         1   3061.57 3618.5 583.10\nsummary(step_both)\n#&gt; \n#&gt; Call:\n#&gt; lm(formula = sales ~ TV + radio, data = advertising[-1])\n#&gt; \n#&gt; Residuals:\n#&gt;     Min      1Q  Median      3Q     Max \n#&gt; -8.7977 -0.8752  0.2422  1.1708  2.8328 \n#&gt; \n#&gt; Coefficients:\n#&gt;             Estimate Std. Error t value Pr(&gt;|t|)    \n#&gt; (Intercept)  2.92110    0.29449   9.919   &lt;2e-16 ***\n#&gt; TV           0.04575    0.00139  32.909   &lt;2e-16 ***\n#&gt; radio        0.18799    0.00804  23.382   &lt;2e-16 ***\n#&gt; ---\n#&gt; Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n#&gt; \n#&gt; Residual standard error: 1.681 on 197 degrees of freedom\n#&gt; Multiple R-squared:  0.8972, Adjusted R-squared:  0.8962 \n#&gt; F-statistic: 859.6 on 2 and 197 DF,  p-value: &lt; 2.2e-16",
    "crumbs": [
      "推断统计模型",
      "<span class='chapter-number'>17</span>  <span class='chapter-title'>多元线性回归</span>"
    ]
  },
  {
    "objectID": "multiple_linear_regression.html#模型选择和优化",
    "href": "multiple_linear_regression.html#模型选择和优化",
    "title": "\n17  多元线性回归\n",
    "section": "\n17.6 模型选择和优化",
    "text": "17.6 模型选择和优化\n\n\nn是观测值的数量，p是模型的参数数（等于回归系数的数量）\n\n\n\\(\\mathcal{L}\\)是模型拟合的最大似然值\n\nCode########################两模型比较\nlm1 &lt;- lm_spec %&gt;% fit(sales~TV+radio+newspaper,data = advertising)\nlm2 &lt;- lm_spec %&gt;% fit(sales~TV*radio*newspaper,data = advertising[-1])\n\nanova(lm2$fit,lm1$fit) #anova() 嵌套模型\n\n\n\n\nRes.Df\nRSS\nDf\nSum of Sq\nF\nPr(&gt;F)\n\n\n\n192\n169.8597\nNA\nNA\nNA\nNA\n\n\n196\n556.8253\n-4\n-386.9656\n109.3511\n0\n\n\n\n\n\nCode\n\n##########################################            AIC \nAIC(lm2$fit,lm1$fit)  # 赤池信息准则  AIC值小的优先选择\n\n\n\n\n\ndf\nAIC\n\n\nlm2\\(fit |  9| 552.9065|\n|lm1\\)fit\n5\n782.3622\n\n\n\n\nCode#BIC\n\n\n####################################相对重要性##################################\nad &lt;- scale(advertising[-1])\nad\n#&gt;                 TV        radio    newspaper        sales\n#&gt;   [1,]  0.96742460  0.979065591  1.774492530  1.548168135\n#&gt;   [2,] -1.19437904  1.080097401  0.667902716 -0.694303815\n#&gt;   [3,] -1.51235985  1.524637364  1.779084189 -0.905134512\n#&gt;   [4,]  0.05191939  1.214806480  1.283185019  0.858176766\n#&gt;   [5,]  0.39319551 -0.839506984  1.278593360 -0.215143142\n#&gt;   [6,] -1.61136487  1.726700983  2.040808751 -1.307629477\n#&gt;   [7,] -1.04295960  0.642292892 -0.323895625 -0.425973838\n#&gt;   [8,] -0.31265202 -0.246787034 -0.870303044 -0.157643861\n#&gt;   [9,] -1.61252963 -1.425491481 -1.357018896 -1.767623723\n#&gt;  [10,]  0.61450084 -1.391814211 -0.429503781 -0.655970962\n#&gt;  [11,] -0.94278982 -1.176279684 -0.291754012 -1.039299500\n#&gt;  [12,]  0.78805080  0.049572941 -1.219269126  0.647346069\n#&gt;  [13,] -1.43548537  0.797208333  1.622967784 -0.924300938\n#&gt;  [14,] -0.57705364 -1.055041512 -1.072336039 -0.828468804\n#&gt;  [15,]  0.66458573  0.649028346  0.709227646  0.954008900\n#&gt;  [16,]  0.56325118  1.645875535  1.026052116  1.605667416\n#&gt;  [17,] -0.92298882  0.898240143  3.831555755 -0.291808850\n#&gt;  [18,]  1.56494899  1.100303763  1.159210227  1.988995954\n#&gt;  [19,] -0.90668211 -0.186167948 -0.562661892 -0.521805973\n#&gt;  [20,]  0.00299927  0.042837487 -0.525928620  0.110686115\n#&gt;  [21,]  0.83114711  0.298784739  1.049010411  0.762344631\n#&gt;  [22,]  1.05245243 -1.223427861 -0.323895625 -0.291808850\n#&gt;  [23,] -1.55895045 -0.495998831  0.874527370 -1.614292308\n#&gt;  [24,]  0.94645883 -0.428644291 -0.199920832  0.283183958\n#&gt;  [25,] -0.98705089 -0.718268813 -0.562661892 -0.828468804\n#&gt;  [26,]  1.34946748 -1.331195125 -0.507561984 -0.387640985\n#&gt;  [27,] -0.04825039  0.406552002 -0.824386454  0.187351823\n#&gt;  [28,]  1.08390109 -0.442115199 -0.351445579  0.359849666\n#&gt;  [29,]  1.18523563  0.258372015 -0.351445579  0.934842473\n#&gt;  [30,] -0.89037540 -0.489263377  0.470461379 -0.675137388\n#&gt;  [31,]  1.69889695  0.339197463  0.580661195  1.414003146\n#&gt;  [32,] -0.39767985 -0.394967022  0.369444882 -0.406807411\n#&gt;  [33,] -0.58054794 -1.465904205 -0.025437791 -0.847635231\n#&gt;  [34,]  1.38091613 -0.219845218 -1.389160509  0.647346069\n#&gt;  [35,] -0.59801941 -1.472639659 -1.063152721 -0.866801658\n#&gt;  [36,]  1.67327212 -1.290782401 -1.012644472 -0.234309569\n#&gt;  [37,]  1.39605808  1.383192830 -1.173352536  2.180660223\n#&gt;  [38,] -0.84262004  1.760378253  0.695452669  0.129852542\n#&gt;  [39,] -1.21068574  0.231430199  0.208736817 -0.751803096\n#&gt;  [40,]  0.94296453  0.972330137  0.066395389  1.433169573\n#&gt;  [41,]  0.64594949 -0.064929776  0.048028753  0.494014654\n#&gt;  [42,]  0.34893444  0.682705616  0.374036541  0.589846789\n#&gt;  [43,]  1.70705030  0.298784739 -1.320285624  1.279838158\n#&gt;  [44,]  0.69719914 -1.001157880 -0.190737514 -0.215143142\n#&gt;  [45,] -1.42034342  0.164075659  0.585252854 -1.058465927\n#&gt;  [46,]  0.32680391 -0.051458868  0.043437094  0.168185396\n#&gt;  [47,] -0.66790531 -0.900126070  0.236286771 -0.655970962\n#&gt;  [48,]  1.08157156  1.228277388 -0.553478574  1.758998831\n#&gt;  [49,]  0.93364642 -0.502734285  0.888302347  0.149018969\n#&gt;  [50,] -0.93347170 -0.778887899  0.286795020 -0.828468804\n#&gt;  [51,]  0.61450084 -1.358136941  0.185778522 -0.502639546\n#&gt;  [52,] -0.54327546 -0.920332432 -1.237635762 -0.636804535\n#&gt;  [53,]  0.80785181  1.241748296  0.415361472  1.644000269\n#&gt;  [54,]  0.41416128  1.544843726  1.292368337  1.375670293\n#&gt;  [55,]  1.34713795  0.372874732 -0.672861707  1.184006023\n#&gt;  [56,]  0.60401795  1.760378253  1.352059904  1.854830966\n#&gt;  [57,] -1.62767157  0.325726555  0.498011333 -1.633458735\n#&gt;  [58,] -0.12628963 -0.273728850 -0.640720094 -0.157643861\n#&gt;  [59,]  0.74262497  1.773849161  0.328119951  1.873997393\n#&gt;  [60,]  0.74146021  0.420022910 -0.975911200  0.839010339\n#&gt;  [61,] -1.08955020 -1.432226935 -0.420320463 -1.135131635\n#&gt;  [62,]  1.33083124  1.309102836  1.108701978  1.950663100\n#&gt;  [63,]  1.07458297 -0.522940647 -0.149412583  0.321516812\n#&gt;  [64,] -0.51648587  0.426758364 -1.017236131 -0.004312446\n#&gt;  [65,] -0.18569264  1.315838290 -0.075946040  0.762344631\n#&gt;  [66,] -0.90901164 -0.940538794 -1.361610555 -0.905134512\n#&gt;  [67,] -1.34579847  0.089985665 -1.301918988 -0.866801658\n#&gt;  [68,] -0.09018192 -0.590295187 -0.934586269 -0.119311008\n#&gt;  [69,]  1.05245243  0.285313831 -0.897852997  0.934842473\n#&gt;  [70,]  0.81251087  1.389928284 -0.154004242  1.586500989\n#&gt;  [71,]  0.60634748  0.494112904  0.374036541  0.819843912\n#&gt;  [72,] -0.43378756 -0.603766095  0.052620412 -0.310975277\n#&gt;  [73,] -1.40054242  0.655763800 -0.516745302 -1.000966646\n#&gt;  [74,] -0.20549365 -1.183015138  0.034253776 -0.579305254\n#&gt;  [75,]  0.77290886  0.089985665 -0.801428159  0.570680362\n#&gt;  [76,] -1.51585415  1.376457376  2.702007645 -1.020133073\n#&gt;  [77,] -1.39238907 -1.459168751 -0.452462076 -1.365128758\n#&gt;  [78,] -0.30915772  0.352668371 -0.750919910  0.034020408\n#&gt;  [79,] -1.64980211  0.446964726 -0.971319541 -1.671791589\n#&gt;  [80,] -0.36157214 -1.048306058 -0.342262261 -0.579305254\n#&gt;  [81,] -0.82281904  0.231430199 -0.378995532 -0.425973838\n#&gt;  [82,]  1.08040679 -1.290782401  0.291386679 -0.330141704\n#&gt;  [83,] -0.83563145 -0.199638856  0.089353684 -0.521805973\n#&gt;  [84,] -0.91600023  1.430341008  0.231695112 -0.080978154\n#&gt;  [85,]  0.77407363  1.329309198  0.149045251  1.471502427\n#&gt;  [86,]  0.53762635 -0.327612482  1.613784466  0.225684677\n#&gt;  [87,] -0.82398380  0.285313831 -0.668270048 -0.387640985\n#&gt;  [88,] -0.42330468  1.167658302  1.498992991  0.379016092\n#&gt;  [89,] -0.68421201  0.150604751  1.967342208 -0.215143142\n#&gt;  [90,] -0.43378756  1.652610989  0.957177231  0.513181081\n#&gt;  [91,] -0.14842017 -1.236898769 -0.975911200 -0.540972400\n#&gt;  [92,] -1.37957665 -1.465904205  0.112311979 -1.288463050\n#&gt;  [93,]  0.82299375  0.689441070  1.306143314  1.030674608\n#&gt;  [94,]  1.20969569  0.891504689  1.916833959  1.567334562\n#&gt;  [95,] -0.46174192 -0.623972457 -0.902444656 -0.483473119\n#&gt;  [96,]  0.18936165  0.561467444  1.026052116  0.551513935\n#&gt;  [97,]  0.58887601 -1.331195125 -1.132027606 -0.445140265\n#&gt;  [98,]  0.44095087 -0.152490678 -0.392770509  0.283183958\n#&gt;  [99,]  1.66162447  1.282161020  0.947993914  2.180660223\n#&gt; [100,] -0.13793728  1.241748296  0.704635987  0.609013216\n#&gt; [101,]  0.87773770 -1.277311493  0.883710688 -0.445140265\n#&gt; [102,]  1.73966372  0.878033781  3.230048428  1.873997393\n#&gt; [103,]  1.55097181 -0.886655162 -0.420320463  0.149018969\n#&gt; [104,]  0.47589381 -0.408437930 -0.581028528  0.129852542\n#&gt; [105,]  1.06177055  0.743324702 -1.159577559  1.279838158\n#&gt; [106,] -0.10648863  1.558314633  1.306143314  0.992341754\n#&gt; [107,] -1.42150819 -0.826036076 -0.039212768 -1.307629477\n#&gt; [108,] -0.65975195 -1.546729653 -0.337670602 -1.020133073\n#&gt; [109,] -1.56011521 -1.539994199 -0.227470786 -1.671791589\n#&gt; [110,]  1.26211011  0.244901107 -1.150394241  1.107340316\n#&gt; [111,]  0.91733971 -1.014628788  1.191351840 -0.119311008\n#&gt; [112,]  1.10253732  0.992536499 -0.337670602  1.490668854\n#&gt; [113,]  0.33379250 -0.529676101 -1.292735670  0.014853981\n#&gt; [114,]  0.72864780 -0.179432494 -0.911627974  0.359849666\n#&gt; [115,] -0.80185327  1.585256449  0.181186863  0.110686115\n#&gt; [116,] -0.83796098  0.790472879  1.016868798 -0.272642423\n#&gt; [117,] -0.09134669 -0.603766095 -0.227470786 -0.349308131\n#&gt; [118,] -0.82281904 -1.513052383 -0.723369956 -0.885968085\n#&gt; [119,] -0.24858995  0.918446505  2.233658429  0.359849666\n#&gt; [120,] -1.48673502 -0.489263377 -0.378995532 -1.422628038\n#&gt; [121,] -0.06688662  0.238165653  0.718410964  0.283183958\n#&gt; [122,] -1.49372361 -0.105342500  0.911260642 -1.345962331\n#&gt; [123,]  0.89637394 -1.405285119 -0.686636684 -0.464306692\n#&gt; [124,] -0.27887383  0.763531064 -0.833569772  0.225684677\n#&gt; [125,]  0.96043601  0.608615622  2.004075480  1.088173889\n#&gt; [126,] -0.69702443 -0.772152445 -0.213695809 -0.655970962\n#&gt; [127,] -1.62184775  1.053155585  0.920443960 -1.422628038\n#&gt; [128,] -0.77855797 -1.566936015 -0.980502859 -1.000966646\n#&gt; [129,]  0.85327764  1.733436437 -1.256002398  2.046495235\n#&gt; [130,] -1.01849954 -0.758681537  0.576069536 -0.828468804\n#&gt; [131,] -1.70454606  1.100303763 -1.003461154 -2.380949385\n#&gt; [132,]  1.37625707 -1.371607849  0.571477877 -0.253475996\n#&gt; [133,] -1.61485916  0.265107469 -1.306510647 -1.595125881\n#&gt; [134,]  0.84745381  0.689441070  0.667902716  1.069007462\n#&gt; [135,] -1.28290117  1.032949223  1.609192807 -0.617638108\n#&gt; [136,] -1.15011797  1.598727357 -1.012644472 -0.464306692\n#&gt; [137,] -1.41451960  1.059891039 -0.975911200 -0.866801658\n#&gt; [138,]  1.47526209  0.379610186  1.338284927  1.299004585\n#&gt; [139,] -1.21185051  0.177546567 -0.461645394 -0.847635231\n#&gt; [140,]  0.44095087  1.389928284 -1.324877283  1.279838158\n#&gt; [141,] -0.85776198 -0.421908837 -0.810611477 -0.598471681\n#&gt; [142,]  0.54345018  0.817414695  2.068358705  0.992341754\n#&gt; [143,]  0.85560717  0.669234708  0.337303269  1.164839596\n#&gt; [144,] -0.49435534 -1.183015138  0.176595204 -0.694303815\n#&gt; [145,] -0.59219559 -0.570088825  0.383219859 -0.502639546\n#&gt; [146,] -0.07853427 -1.438962389 -0.989686177 -0.713470242\n#&gt; [147,]  1.08390109 -1.075247874 -1.003461154 -0.157643861\n#&gt; [148,]  1.12000880  1.733436437  0.631169444  2.180660223\n#&gt; [149,] -1.27008875  1.147451941 -0.856528067 -0.598471681\n#&gt; [150,] -1.19204951  0.170811113 -0.457053735 -0.751803096\n#&gt; [151,]  1.55679563 -0.630707911  0.295978338  0.398182519\n#&gt; [152,] -0.30333390 -1.001157880  0.833202439 -0.464306692\n#&gt; [153,]  0.58887601  0.002424763 -0.750919910  0.494014654\n#&gt; [154,]  0.28254284  1.107039217  0.328119951  0.954008900\n#&gt; [155,]  0.47472905 -0.145755224 -0.966727882  0.302350385\n#&gt; [156,] -1.66494405 -0.785623353 -1.141210924 -2.074286554\n#&gt; [157,] -0.61898518  1.362986468  0.915852301  0.244851104\n#&gt; [158,]  0.03211839 -1.479375113 -0.287162353 -0.751803096\n#&gt; [159,] -1.57642192  0.918446505  0.672494375 -1.288463050\n#&gt; [160,] -0.17870405 -0.327612482  0.185778522 -0.215143142\n#&gt; [161,]  0.29652002 -0.347818844  0.006703822  0.072353262\n#&gt; [162,] -0.71449590  0.844356511  0.860752393 -0.138477435\n#&gt; [163,]  0.48171764 -0.347818844 -0.227470786  0.168185396\n#&gt; [164,]  0.19169118  0.911711051 -1.063152721  0.762344631\n#&gt; [165,] -0.34759496 -0.576824279 -1.154985900 -0.406807411\n#&gt; [166,]  1.01867425 -1.337930579  2.490791332 -0.406807411\n#&gt; [167,] -1.50420650  0.965594683 -0.411137145 -1.154298062\n#&gt; [168,]  0.69603438 -1.216692407 -0.512153643 -0.349308131\n#&gt; [169,]  0.79620416  0.022631125  1.241860088  0.589846789\n#&gt; [170,]  1.59872717 -0.852977892 -1.109069311  0.187351823\n#&gt; [171,] -1.13031697 -0.785623353 -0.558070233 -1.077632354\n#&gt; [172,]  0.20333883 -0.159226132  0.773510872  0.091519689\n#&gt; [173,] -1.48440549 -0.213109764 -0.622353458 -1.230963769\n#&gt; [174,]  0.24876466 -1.088718782 -0.815203136 -0.445140265\n#&gt; [175,]  0.87773770 -1.337930579 -0.801428159 -0.483473119\n#&gt; [176,]  1.51253457  1.726700983  0.516377969  2.487323054\n#&gt; [177,]  1.18057657  0.467171088 -0.470828712  1.184006023\n#&gt; [178,]  0.26973043 -1.041570604  0.213328476 -0.445140265\n#&gt; [179,]  1.51020504 -1.412020573 -0.314712307 -0.425973838\n#&gt; [180,]  0.21615124 -0.893390616 -0.594803505 -0.272642423\n#&gt; [181,]  0.11132240 -1.391814211 -1.021827790 -0.675137388\n#&gt; [182,]  0.83231187 -1.203221500 -0.144820924 -0.349308131\n#&gt; [183,] -1.05810154 -1.183015138 -0.039212768 -1.020133073\n#&gt; [184,]  1.63716441  1.329309198  1.893875664  2.333991639\n#&gt; [185,]  1.24347388 -0.132284316 -0.025437791  0.685678923\n#&gt; [186,]  0.67506861  1.470753732 -0.502970325  1.644000269\n#&gt; [187,] -0.08785239 -1.425491481 -0.181554196 -0.713470242\n#&gt; [188,]  0.51316629  0.366139279 -0.567253551  0.628179642\n#&gt; [189,]  1.61852817 -0.630707911 -1.233044103  0.359849666\n#&gt; [190,] -1.49488838 -0.751946083 -0.328487284 -1.403461612\n#&gt; [191,] -1.25261728  1.201335572 -1.136619265 -0.617638108\n#&gt; [192,] -0.83330192 -0.839506984 -1.127435947 -0.790135950\n#&gt; [193,] -1.51235985 -1.290782401  0.048028753 -1.556793027\n#&gt; [194,]  0.23012842  1.261954658 -1.237635762  1.069007462\n#&gt; [195,]  0.03095363  0.830885603 -1.127435947  0.628179642\n#&gt; [196,] -1.26775922 -1.317724217 -0.769286546 -1.230963769\n#&gt; [197,] -0.61549089 -1.236898769 -1.031011108 -0.828468804\n#&gt; [198,]  0.34893444 -0.940538794 -1.109069311 -0.234309569\n#&gt; [199,]  1.59057381  1.261954658  1.636742761  2.199826650\n#&gt; [200,]  0.99071990 -0.987686972 -1.003461154 -0.119311008\n#&gt; attr(,\"scaled:center\")\n#&gt;        TV     radio newspaper     sales \n#&gt;  147.0425   23.2640   30.5540   14.0225 \n#&gt; attr(,\"scaled:scale\")\n#&gt;        TV     radio newspaper     sales \n#&gt; 85.854236 14.846809 21.778621  5.217457\n#R平方贡献率  #相对权重 \nrelweights&lt;-function(fit,...){\n  R&lt;-cor(fit$model)\n  nvar&lt;-ncol(R)\n  rxx&lt;-R[2:nvar,2:nvar]\n  rxy&lt;-R[2:nvar,1]\n  svd&lt;-eigen(rxx)\n  evec&lt;-svd$vectors\n  ev&lt;-svd$values\n  delta&lt;-diag(sqrt(ev))\n  lambda&lt;-evec %*%delta %*% t(evec)\n  lambdaasq&lt;-lambda^2\n  beta&lt;-solve(lambda) %*% rxy\n  r2&lt;-colSums(beta^2)\n  rawwgt&lt;-lambdaasq%*%beta^2\n  import&lt;-(rawwgt/r2)*100            #计算相对权重\n  import&lt;-data.frame(Weights=import)  #数据框化\n  row.names(import)&lt;-names(fit$model[2:nvar])\n  import&lt;-import[order(import$Weights),1,drop=FALSE] #升序排序\n  dotchart(import$Weights,labels=row.names(import),   #点图\n           xlab = \"% of R-Square\",pch=19,\n           main=\"Relative Importiance of Predictor Variables \",\n           sub=paste(\"Total R-Square =\",round(r2,digits = 3)),\n  ...)\nreturn(import)\n}\nrelweights(lm1$fit,col=\"blue\")\n\n\n\n\n\n\n\n\n\n\n\nWeights\n\n\n\nnewspaper\n2.468097\n\n\nradio\n32.198236\n\n\nTV\n65.333667",
    "crumbs": [
      "推断统计模型",
      "<span class='chapter-number'>17</span>  <span class='chapter-title'>多元线性回归</span>"
    ]
  },
  {
    "objectID": "multiple_linear_regression.html#线性可加模型",
    "href": "multiple_linear_regression.html#线性可加模型",
    "title": "\n17  多元线性回归\n",
    "section": "\n17.7 线性可加模型",
    "text": "17.7 线性可加模型\nadditive model\n\\[\nY_i=\\beta_0+ \\beta_1 X_i+  \\beta_2 X_i^2+\\epsilon_i\n\\]\n\\[\nY_i=\\beta_0+ \\beta_1\\times \\log(X_i)+\\epsilon_i\n\\]\n\\[\nY_i=\\beta_0+ \\beta_1 (X_i\\times W_i)+\\epsilon_i\n\\]\n\\[\nY_i=\\beta_0+ \\beta_1\\times \\exp(X_i)+\\epsilon_i\n\\]\n\\[\nY_i=\\beta_0+ \\beta_1\\times \\sin(X_i)+\\epsilon_i\n\\]",
    "crumbs": [
      "推断统计模型",
      "<span class='chapter-number'>17</span>  <span class='chapter-title'>多元线性回归</span>"
    ]
  },
  {
    "objectID": "GLM.html",
    "href": "GLM.html",
    "title": "\n18  广义线性模型\n",
    "section": "",
    "text": "18.1 GLM 组件\n广义线性模型是对线性模型的扩展，适用于非正态分布的数据，假设观测值之间是独立的，不能处理组内相关性。模型形式为：\n\\[\ng(E(Y))=\\mathbf{X} \\beta\n\\]\n\\[\n\\eta = \\mathbf{X} \\beta\n\\]\n\\[\nE(y)=\\mu\n\\]\n\\[\n\\eta =g(\\mu)=g(E(y))\n\\]\n\\[\nE(y)=g^{-1}(\\eta)\n\\]\n典型链接函数",
    "crumbs": [
      "推断统计模型",
      "<span class='chapter-number'>18</span>  <span class='chapter-title'>广义线性模型</span>"
    ]
  },
  {
    "objectID": "GLM.html#glm-组件",
    "href": "GLM.html#glm-组件",
    "title": "\n18  广义线性模型\n",
    "section": "",
    "text": "线性预测子：\n\n\n\n因变量的期望值与线性预测函数的关系：\n\n\n\n连接函数 g(.) ：\n\n\n\n反连接函数g-1 (.)：\n\n\n\n\ny 的方差：\n\\[\nVar(y)=f(\\mu)=f(g^{-1}(\\mathbf{X}\\beta))\n\\]\n\n\n\n\n\nY的分布\n名称\n链接函数\n均值函数\n\n\n\n正态\n恒等\nXβ=μ\n\nμ=Xβ\n\n\n\n指数\n倒数\nXβ=μ−1\n\nμ=(Xβ)−1\n\n\n\nGamma\n\n\n\n\n\n逆高斯\n二次倒数\nXβ=μ−2\n\nμ=(Xβ)−1/2\n\n\n\n泊松\n自然对数\nXβ=ln⁡(μ)\n\nμ=exp⁡(Xβ)\n\n\n\n二项式\nLogit\nXβ=ln⁡[μ/(1−μ)]\n\nμ=exp⁡(Xβ)/(1+exp⁡(Xβ)\n\n\n\n多项式",
    "crumbs": [
      "推断统计模型",
      "<span class='chapter-number'>18</span>  <span class='chapter-title'>广义线性模型</span>"
    ]
  },
  {
    "objectID": "GLM.html#广义线性回归",
    "href": "GLM.html#广义线性回归",
    "title": "\n18  广义线性模型\n",
    "section": "\n18.2 广义线性回归",
    "text": "18.2 广义线性回归\n高斯线性回归是一种简单的线性回归模型，其中假设响应变量服从正态分布，并且使用恒等连接函数（identity link function）。t-statistic\n\nCodelibrary(tidymodels)\nlibrary(patchwork)\nlibrary(ggfortify)\n# 使用 glm() 函数进行高斯线性回归\nglm1 &lt;- linear_reg() %&gt;% \n  set_engine(\"glm\", family = stats::gaussian(link = \"identity\")) %&gt;% \n  fit(Fertility ~ Agriculture + Education + Catholic + Infant.Mortality,\n      data = swiss)\n\n# 查看模型的系数\ntidy(glm1)\n\n\n\n\nterm\nestimate\nstd.error\nstatistic\np.value\n\n\n\n(Intercept)\n62.1013116\n9.6048861\n6.465596\n0.0000001\n\n\nAgriculture\n-0.1546175\n0.0681899\n-2.267454\n0.0285697\n\n\nEducation\n-0.9802638\n0.1481367\n-6.617293\n0.0000001\n\n\nCatholic\n0.1246664\n0.0288935\n4.314686\n0.0000950\n\n\nInfant.Mortality\n1.0784422\n0.3818662\n2.824136\n0.0072204\n\n\n\n\n\nCode\n# 查看模型的 AIC 和 Deviance\nglance(glm1) %&gt;% dplyr::select(AIC, deviance)\n\n\n\n\nAIC\ndeviance\n\n\n325.2408\n2158.069\n\n\n\n\nCode\n\n# Change the theme and colour\nautoplot(glm1, which = 1:6, ncol = 2, label.size = 3,\n         colour = \"steelblue\") + theme_bw()",
    "crumbs": [
      "推断统计模型",
      "<span class='chapter-number'>18</span>  <span class='chapter-title'>广义线性模型</span>"
    ]
  },
  {
    "objectID": "GLM.html#逻辑回归",
    "href": "GLM.html#逻辑回归",
    "title": "\n18  广义线性模型\n",
    "section": "\n18.3 逻辑回归",
    "text": "18.3 逻辑回归\n逻辑回归用于处理二元分类问题。其模型假设响应变量的对数优势（log odds）服从线性模型。\nSigmoid 激活函数：\n\\[\nf(x)=\\frac{1}{1+e^{-x}}=\\frac{e^x}{1+e^x}\n\\]\n\nCodesigmoid &lt;- tibble(\n    x=seq(-6,6,length.out=1000),\n    y=1/(1+exp(-x)),\n)\nggplot(sigmoid,aes(x,y))+\n    geom_line()\n\n\n\n\n\n\n\n逻辑回归( logistic regression )的一般数学方程：\n\\[\n\\pi(Y=k|X=(X_1,X_2,...,X_p)=\\frac{e^{\\beta_{k0}+\\beta_{k1}X_1+\\beta_{k2}X_2+...+\\beta_{kp}X_p}}{1+\\sum_{l=1}^{K-1} e^{\\beta_{l0}+\\beta_{l1}X_1+\\beta_{l2}X_2+...+\\beta_{lp}X_p}}\n\\] 其中\\(\\pi\\) 是成功概率，\\(k=1,2,...,K-1\\)是因变量的水平数，\\(p\\) 是自变量个数。\n逻辑回归一般需要引入虚拟变量（哑变量，dummy variable），通常取值伪0或1。\n\n\n当\\(K=2\\)时，\\(k=l=p=1\\)即简单逻辑回归。\n极大似然法（maximum likelihood），likelihood function：\n\\[\n\\ell (\\beta_0,\\beta_1)=\\prod_{i:y_i=1}\\pi(x_i)\\prod_{i':y_{i'}=0}(1-\\pi(x_{i'}))\n\\]\n\n\n当\\(K=2\\)时，\\(k=l=1,p&gt;1\\)即多元逻辑回归（multiple logistic regression）。\n优势（odds）\n\\[\nOdds=\\frac{\\pi(X)}{1-\\pi(X)}=e^{\\beta_0+\\beta_1X_1+\\beta_2X_2+...+\\beta_pX_p}\n\\]\nlog odds (logit)\n\\[\nlogit(\\pi(X))=\\ln (\\frac{\\pi(X)}{1-\\pi(X)})=\\beta_0+\\beta_1X_1+\\beta_2X_2+...+\\beta_pX_p\n\\]\n\n\n当\\(K&gt;2\\)时，\\(k,l,p&gt;1\\)即多项逻辑回归（multinomial logistic regression）。\n\\[\n\\log (\\frac{P(Y=k|X=x)}{P(Y=K|X=x)})=\\beta_{k0}+\\beta_{k1}X_1+\\beta_{k2}X_2+...+\\beta_{kp}X_p\n\\]\n\n\n数据下载网站\n\nCodedf &lt;- read_csv(\"data/ISLR/Default.csv\")\ndf$default &lt;- factor(df$default,levels = c(\"No\",\"Yes\"),labels = c(0,1))\ndf$student&lt;- factor(df$student,levels = c(\"No\",\"Yes\"),labels = c(0,1))\n# 违约 学生 余额 收入\nhead(df)\n\n\n\n\ndefault\nstudent\nbalance\nincome\n\n\n\n0\n0\n729.5265\n44361.625\n\n\n0\n1\n817.1804\n12106.135\n\n\n0\n0\n1073.5492\n31767.139\n\n\n0\n0\n529.2506\n35704.494\n\n\n0\n0\n785.6559\n38463.496\n\n\n0\n1\n919.5885\n7491.559\n\n\n\n\n\nCodetable(df$default,df$student)\n#&gt;    \n#&gt;        0    1\n#&gt;   0 6850 2817\n#&gt;   1  206  127\n\n\n\nCodeggplot(df,aes(balance,income))+\n  geom_point(aes(shape=default,color=default),show.legend = F)|\nggplot(df,aes(default,balance,fill=default),)+\n  geom_boxplot(show.legend = F)+\nggplot(df,aes(default,income,fill=default))+\n  geom_boxplot()\n\n\n\n\n\n\n\n\n18.3.1 \n\n18.3.2 线性回归\n\nCodelm_spec&lt;-linear_reg(mode =\"regression\",engine = \"lm\" )\n\nlm_default_balance&lt;-lm_spec %&gt;% \n  fit(as.numeric(default)-1~balance,data=df)\nlm_default_balance$fit\n#&gt; \n#&gt; Call:\n#&gt; stats::lm(formula = as.numeric(default) - 1 ~ balance, data = data)\n#&gt; \n#&gt; Coefficients:\n#&gt; (Intercept)      balance  \n#&gt;  -0.0751920    0.0001299\n\nggplot(df,aes(balance,as.numeric(default)-1))+\n  geom_point(color=\"orange\",size=1.25)+\n  geom_smooth(method = \"lm\",se=FALSE)+\n  geom_hline(yintercept = c(0,1),linetype=2)+\n  ggtitle(\"linear regression\")\n\n\n\n\n\n\n\n\n18.3.3 二分类逻辑回归\nBinary logistic regression\nlogit link function\nz-statistic\n\nCodelogit_spec &lt;- logistic_reg() %&gt;%\n  set_engine(\"glm\",family= binomial(link = \"logit\")) \n\n\nlogit_default_balance &lt;- logit_spec %&gt;% fit(default~balance,data=df)\n\nlogit_default_balance %&gt;% glance()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nnull.deviance\ndf.null\nlogLik\nAIC\nBIC\ndeviance\ndf.residual\nnobs\n\n\n2920.65\n9999\n-798.2258\n1600.452\n1614.872\n1596.452\n9998\n10000\n\n\n\n\nCode\ntidy(logit_default_balance)\n\n\n\n\nterm\nestimate\nstd.error\nstatistic\np.value\n\n\n\n(Intercept)\n-10.6513306\n0.3611574\n-29.49221\n0\n\n\nbalance\n0.0054989\n0.0002204\n24.95309\n0\n\n\n\n\n\nCode\n\nggplot(df,aes(balance,as.numeric(default)-1))+\n  geom_point(color=\"orange\",size=1.25)+\n  geom_smooth(method = \"glm\",\n              method.args=list(family=binomial(link = \"logit\")),se=FALSE)+\n  geom_hline(yintercept = c(0,1),linetype=2)+\n  ggtitle(\"logistic regression\")\n\n\n\n\n\n\n\n\n18.3.3.1 自变量是分类变量\n\nCodelogit_default_student &lt;- logit_spec %&gt;%fit(default ~ student, data = df)\n\ntidy(logit_default_student)\n\n\n\n\nterm\nestimate\nstd.error\nstatistic\np.value\n\n\n\n(Intercept)\n-3.5041278\n0.0707130\n-49.554219\n0.0000000\n\n\nstudent1\n0.4048871\n0.1150188\n3.520181\n0.0004313\n\n\n\n\n\nCode\ndf %&gt;% \n  mutate(\n    prob=1/(1+exp(-(logit_default_student$fit$coefficients[1]+logit_default_student$fit$coefficients[2]*(as.numeric(student)-1)))),\n    logit=log(prob/(1-prob))\n  ) %&gt;% \n    dplyr::select(student,prob) %&gt;% \n    DT::datatable()\n\n\n\n\n\n\n18.3.4 K=2,p&gt;1 多元逻辑回归\n\nCodelogit_multiple&lt;-logit_spec %&gt;% fit(default~balance+income+student,data=df)\n\ntidy(logit_multiple)\n\n\n\n\nterm\nestimate\nstd.error\nstatistic\np.value\n\n\n\n(Intercept)\n-10.8690452\n0.4922555\n-22.080088\n0.0000000\n\n\nbalance\n0.0057365\n0.0002319\n24.737563\n0.0000000\n\n\nincome\n0.0000030\n0.0000082\n0.369815\n0.7115203\n\n\nstudent1\n-0.6467758\n0.2362525\n-2.737646\n0.0061881\n\n\n\n\n\nCode\n# confusion matrix 混淆矩阵\naugment(logit_multiple, new_data = df) %&gt;%\n  conf_mat(truth = default, estimate = .pred_class) %&gt;% \n    autoplot(type = \"heatmap\")\n\n\n\n\n\n\nCode\n#准确性 \n(9627+105)/(9627+105+40+228)\n#&gt; [1] 0.9732\naugment(logit_multiple, new_data = df) %&gt;%\n  accuracy(truth = default, estimate = .pred_class)\n\n\n\n\n.metric\n.estimator\n.estimate\n\n\naccuracy\nbinary\n0.9732\n\n\n\n\n\n\n18.3.4.1 预测\n\nCodedf_new &lt;- tibble(\n  balance = c(1000, 2000), \n  income = c(14144,24141),\n  student = factor(c(1, 0)),\n)\npredict(logit_multiple, new_data = df_new,type=\"class\")\n\n\n\n\n.pred_class\n\n\n\n0\n\n\n1\n\n\n\n\n\nCodepredict(logit_multiple, new_data = df_new, type = \"prob\")\n\n\n\n\n.pred_0\n.pred_1\n\n\n\n0.9967840\n0.0032160\n\n\n0.3368875\n0.6631125\n\n\n\n\n\n\n\n18.3.4.2 优势比，Wald卡方检验\n\nCodelibrary(broom)\n\n# 示例数据\nset.seed(123)\nn &lt;- 200\ndata &lt;- data.frame(\n    outcome = sample(c(0, 1), n, replace = TRUE),\n    age = rnorm(n, 50, 10),\n    gender = factor(sample(c(\"male\", \"female\"), n, replace = TRUE)),\n    bmi = rnorm(n, 25, 5)\n)\n\n# 拟合逻辑回归模型\nlogit_model &lt;- glm(outcome ~ age + gender + bmi, data = data, family = binomial)\n\nlogit_model\n#&gt; \n#&gt; Call:  glm(formula = outcome ~ age + gender + bmi, family = binomial, \n#&gt;     data = data)\n#&gt; \n#&gt; Coefficients:\n#&gt; (Intercept)          age   gendermale          bmi  \n#&gt;    -0.13852     -0.01602      0.03211      0.03432  \n#&gt; \n#&gt; Degrees of Freedom: 199 Total (i.e. Null);  196 Residual\n#&gt; Null Deviance:       277.1 \n#&gt; Residual Deviance: 274.4     AIC: 282.4\n\n\nsummary &lt;- summary(logit_model)\n\n# 提取模型结果\n\nmodel_summary &lt;- tidy(logit_model, conf.int = TRUE)  # 计算置信区间\n\n# 计算优势比（OR）\nmodel_summary &lt;- model_summary %&gt;%\n    mutate(\n        estimate_OR = exp(estimate),\n        # 计算优势比\n        conf.low_OR = exp(conf.low),\n        # 置信区间下限\n        conf.high_OR = exp(conf.high),  # 置信区间上限\n        Estimate = summary$coefficients[, \"Estimate\"],\n        Std.Error = summary$coefficients[, \"Std. Error\"],\n        z_value = summary$coefficients[, \"Estimate\"] / summary$coefficients[, \"Std. Error\"],\n        Wald.ChiSq = (summary$coefficients[, \"Estimate\"] / summary$coefficients[, \"Std. Error\"]) ^\n            2,\n        # Wald卡方值可以用来检验各个变量系数是否显著不同于零。它是通过系数估计的平方除以其标准误差的平方来计算的。\n        # 即 z值的平方\n        P.Value = summary$coefficients[, \"Pr(&gt;|z|)\"]\n    )\n\n\n# 打印结果表格\nprint(model_summary)\n#&gt; # A tibble: 4 × 15\n#&gt;   term       estimate std.error statistic p.value conf.low conf.high estimate_OR\n#&gt;   &lt;chr&gt;         &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;   &lt;dbl&gt;    &lt;dbl&gt;     &lt;dbl&gt;       &lt;dbl&gt;\n#&gt; 1 (Intercep…  -0.139     1.10      -0.126   0.900  -2.31      2.03         0.871\n#&gt; 2 age         -0.0160    0.0150    -1.07    0.285  -0.0459    0.0132       0.984\n#&gt; 3 gendermale   0.0321    0.285      0.112   0.910  -0.528     0.593        1.03 \n#&gt; 4 bmi          0.0343    0.0300     1.15    0.252  -0.0240    0.0940       1.03 \n#&gt; # ℹ 7 more variables: conf.low_OR &lt;dbl&gt;, conf.high_OR &lt;dbl&gt;, Estimate &lt;dbl&gt;,\n#&gt; #   Std.Error &lt;dbl&gt;, z_value &lt;dbl&gt;, Wald.ChiSq &lt;dbl&gt;, P.Value &lt;dbl&gt;\n\n\n\n18.3.5 似然比检验\nlikelihood ratio tests (LRT)\n比较两个嵌套模型，log-likelihood (logLL)\n\n相应的p-value 源自具有 个自由度的 卡方 分布（即模型中测试的参数数量之差）。\n\nCodelogit_default_balance\n#&gt; parsnip model object\n#&gt; \n#&gt; \n#&gt; Call:  stats::glm(formula = default ~ balance, family = ~binomial(link = \"logit\"), \n#&gt;     data = data)\n#&gt; \n#&gt; Coefficients:\n#&gt; (Intercept)      balance  \n#&gt;  -10.651331     0.005499  \n#&gt; \n#&gt; Degrees of Freedom: 9999 Total (i.e. Null);  9998 Residual\n#&gt; Null Deviance:       2921 \n#&gt; Residual Deviance: 1596  AIC: 1600\nlogit_multiple\n#&gt; parsnip model object\n#&gt; \n#&gt; \n#&gt; Call:  stats::glm(formula = default ~ balance + income + student, family = ~binomial(link = \"logit\"), \n#&gt;     data = data)\n#&gt; \n#&gt; Coefficients:\n#&gt; (Intercept)      balance       income     student1  \n#&gt;  -1.087e+01    5.737e-03    3.033e-06   -6.468e-01  \n#&gt; \n#&gt; Degrees of Freedom: 9999 Total (i.e. Null);  9996 Residual\n#&gt; Null Deviance:       2921 \n#&gt; Residual Deviance: 1572  AIC: 1580\n\n\nLRT=2*(logLik(logit_multiple$fit)-logLik(logit_default_balance$fit))\nLRT\n#&gt; 'log Lik.' 24.90686 (df=4)\n\npval=1-pchisq(LRT,2)\npval\n#&gt; 'log Lik.' 3.904316e-06 (df=4)\n\nout&lt;-anova(logit_default_balance$fit, logit_multiple$fit)\nout\n\n\n\n\nResid. Df\nResid. Dev\nDf\nDeviance\nPr(&gt;Chi)\n\n\n\n9998\n1596.452\nNA\nNA\nNA\n\n\n9996\n1571.545\n2\n24.90686\n3.9e-06\n\n\n\n\n\nCode\n1-pchisq(out$Deviance[2],2)\n#&gt; [1] 3.904316e-06\n\n\n\n18.3.6 有序逻辑回归\n\\[\n    \\log \\left(\\frac{P(Y\\le k|X=x)}{1-P(Y\\le k|X=x)}\\right)\n\\]\n\nCodeacl &lt;- read_rds(\"data/icpsr/advanced_acl_data.rds\")\nacl$PhysActCat_W1 &lt;- factor(acl$PhysActCat_W1,ordered = T)\nlevels(acl$PhysActCat_W1)\n#&gt; [1] \"(1) Low_5th\"  \"(2) 2Low_5th\" \"(3) 3Low_5th\" \"(4) 4Low_5th\" \"(5) Hi_5th\"\n\nordered_logit &lt;- MASS::polr(PhysActCat_W1 ~ SelfEfficacy_W1, data = acl,\n                            method = \"logistic\")\nordered_logit %&gt;% summary()\n#&gt; Call:\n#&gt; MASS::polr(formula = PhysActCat_W1 ~ SelfEfficacy_W1, data = acl, \n#&gt;     method = \"logistic\")\n#&gt; \n#&gt; Coefficients:\n#&gt;                  Value Std. Error t value\n#&gt; SelfEfficacy_W1 0.2431    0.02893   8.404\n#&gt; \n#&gt; Intercepts:\n#&gt;                           Value    Std. Error t value \n#&gt; (1) Low_5th|(2) 2Low_5th   -0.9332   0.0371   -25.1533\n#&gt; (2) 2Low_5th|(3) 3Low_5th  -0.2688   0.0338    -7.9606\n#&gt; (3) 3Low_5th|(4) 4Low_5th   0.8470   0.0364    23.2527\n#&gt; (4) 4Low_5th|(5) Hi_5th     1.5298   0.0435    35.1647\n#&gt; \n#&gt; Residual Deviance: 11196.86 \n#&gt; AIC: 11206.86\n\n\npredict(ordered_logit ,acl ,type = \"p\") %&gt;% \n    as_tibble() %&gt;% \n    DT::datatable()\n\n\n\n\n\n\n18.3.7 K&gt;2,p&gt;1 多分类逻辑回归\n用于处理具有多于两个类别的响应变量的情况。例如，分类问题中的三个或更多类别。\n\n18.3.7.1 nnet::multinom()\n\n\nCodemn_spec &lt;- multinom_reg(mode = \"classification\", engine = \"nnet\")\n\niris_mnlogit &lt;- mn_spec %&gt;% \n    fit(Species ~ ., data = iris)\n\niris_mnlogit %&gt;% glance()\n\n\n\n\nedf\ndeviance\nAIC\nnobs\n\n\n10\n11.89973\n31.89973\n150\n\n\n\n\nCodeiris_mnlogit %&gt;% tidy()\n\n\n\n\n\n\n\n\n\n\n\n\ny.level\nterm\nestimate\nstd.error\nstatistic\np.value\n\n\n\nversicolor\n(Intercept)\n18.690374\n34.97116\n0.5344511\n0.5930295\n\n\nversicolor\nSepal.Length\n-5.458424\n89.89215\n-0.0607219\n0.9515807\n\n\nversicolor\nSepal.Width\n-8.707401\n157.04152\n-0.0554465\n0.9557828\n\n\nversicolor\nPetal.Length\n14.244770\n60.19170\n0.2366567\n0.8129231\n\n\nversicolor\nPetal.Width\n-3.097684\n45.48852\n-0.0680981\n0.9457075\n\n\nvirginica\n(Intercept)\n-23.836276\n35.76649\n-0.6664417\n0.5051288\n\n\nvirginica\nSepal.Length\n-7.923634\n89.91153\n-0.0881270\n0.9297757\n\n\nvirginica\nSepal.Width\n-15.370769\n157.11962\n-0.0978285\n0.9220685\n\n\nvirginica\nPetal.Length\n23.659779\n60.46753\n0.3912807\n0.6955898\n\n\nvirginica\nPetal.Width\n15.135300\n45.93406\n0.3295006\n0.7417773\n\n\n\n\n\nCode\n\naugment(iris_mnlogit, new_data = iris) %&gt;%\n    conf_mat(truth = Species, estimate = .pred_class) %&gt;%\n    autoplot(type = \"heatmap\")\n\n\n\n\n\n\n\n\n18.3.7.2 glmnet::glmnet()\n\n\nCodelibrary(glmnet) # 多项回归\niris_glmnet &lt;- glmnet(x = iris[, -5], y = iris[, 5], family = \"multinomial\")\niris_glmnet\n#&gt; \n#&gt; Call:  glmnet(x = iris[, -5], y = iris[, 5], family = \"multinomial\") \n#&gt; \n#&gt;     Df  %Dev  Lambda\n#&gt; 1    0  0.00 0.43500\n#&gt; 2    1  6.56 0.39640\n#&gt; 3    1 12.05 0.36110\n#&gt; 4    1 16.73 0.32910\n#&gt; 5    1 20.78 0.29980\n#&gt; 6    2 25.37 0.27320\n#&gt; 7    2 29.66 0.24890\n#&gt; 8    2 33.54 0.22680\n#&gt; 9    2 37.10 0.20670\n#&gt; 10   2 40.40 0.18830\n#&gt; 11   2 43.47 0.17160\n#&gt; 12   3 46.47 0.15630\n#&gt; 13   3 49.57 0.14240\n#&gt; 14   3 52.38 0.12980\n#&gt; 15   3 54.97 0.11830\n#&gt; 16   3 57.36 0.10780\n#&gt; 17   3 59.60 0.09818\n#&gt; 18   3 61.71 0.08946\n#&gt; 19   3 63.72 0.08151\n#&gt; 20   3 65.70 0.07427\n#&gt; 21   3 67.65 0.06767\n#&gt; 22   3 69.54 0.06166\n#&gt; 23   3 71.38 0.05618\n#&gt; 24   3 73.12 0.05119\n#&gt; 25   3 74.71 0.04664\n#&gt; 26   3 76.24 0.04250\n#&gt; 27   3 77.67 0.03872\n#&gt; 28   3 78.99 0.03528\n#&gt; 29   3 80.21 0.03215\n#&gt; 30   3 81.33 0.02929\n#&gt; 31   3 82.36 0.02669\n#&gt; 32   3 83.31 0.02432\n#&gt; 33   3 84.18 0.02216\n#&gt; 34   3 84.99 0.02019\n#&gt; 35   3 85.73 0.01840\n#&gt; 36   3 86.53 0.01676\n#&gt; 37   3 87.34 0.01527\n#&gt; 38   3 88.06 0.01392\n#&gt; 39   3 88.73 0.01268\n#&gt; 40   3 89.34 0.01155\n#&gt; 41   3 89.89 0.01053\n#&gt; 42   3 90.40 0.00959\n#&gt; 43   4 90.87 0.00874\n#&gt; 44   4 91.34 0.00796\n#&gt; 45   4 91.77 0.00726\n#&gt; 46   4 92.16 0.00661\n#&gt; 47   4 92.52 0.00602\n#&gt; 48   4 92.85 0.00549\n#&gt; 49   4 93.16 0.00500\n#&gt; 50   4 93.44 0.00456\n#&gt; 51   4 93.69 0.00415\n#&gt; 52   4 93.92 0.00378\n#&gt; 53   4 94.14 0.00345\n#&gt; 54   4 94.34 0.00314\n#&gt; 55   4 94.52 0.00286\n#&gt; 56   4 94.68 0.00261\n#&gt; 57   4 94.83 0.00238\n#&gt; 58   4 94.97 0.00216\n#&gt; 59   4 95.10 0.00197\n#&gt; 60   4 95.22 0.00180\n#&gt; 61   4 95.33 0.00164\n#&gt; 62   4 95.43 0.00149\n#&gt; 63   4 95.52 0.00136\n#&gt; 64   4 95.60 0.00124\n#&gt; 65   4 95.68 0.00113\n#&gt; 66   4 95.75 0.00103\n#&gt; 67   4 95.81 0.00094\n#&gt; 68   4 95.87 0.00085\n#&gt; 69   4 95.92 0.00078\n#&gt; 70   4 95.97 0.00071\n#&gt; 71   4 96.01 0.00065\n#&gt; 72   4 96.05 0.00059\n#&gt; 73   4 96.09 0.00054\n#&gt; 74   4 96.12 0.00049\n#&gt; 75   4 96.15 0.00045\n#&gt; 76   4 96.18 0.00041\n#&gt; 77   4 96.20 0.00037\n#&gt; 78   4 96.22 0.00034\n#&gt; 79   4 96.24 0.00031\n#&gt; 80   4 96.26 0.00028\n#&gt; 81   4 96.27 0.00025\n#&gt; 82   4 96.29 0.00023\n#&gt; 83   4 96.30 0.00021\n#&gt; 84   4 96.31 0.00019\n#&gt; 85   4 96.32 0.00018\n#&gt; 86   4 96.33 0.00016\n#&gt; 87   4 96.33 0.00015\n#&gt; 88   4 96.34 0.00013\n#&gt; 89   4 96.35 0.00012\n#&gt; 90   4 96.35 0.00011\n#&gt; 91   4 96.35 0.00010\n#&gt; 92   4 96.36 0.00009\n#&gt; 93   4 96.36 0.00008\n#&gt; 94   4 96.36 0.00008\n#&gt; 95   4 96.37 0.00007\n#&gt; 96   4 96.37 0.00006\n#&gt; 97   4 96.37 0.00006\n#&gt; 98   4 96.37 0.00005\n#&gt; 99   4 96.38 0.00005\n#&gt; 100  4 96.38 0.00004\nsummary(iris_glmnet )\n#&gt;            Length Class  Mode     \n#&gt; a0         300    -none- numeric  \n#&gt; beta         3    -none- list     \n#&gt; dfmat      300    -none- numeric  \n#&gt; df         100    -none- numeric  \n#&gt; dim          2    -none- numeric  \n#&gt; lambda     100    -none- numeric  \n#&gt; dev.ratio  100    -none- numeric  \n#&gt; nulldev      1    -none- numeric  \n#&gt; npasses      1    -none- numeric  \n#&gt; jerr         1    -none- numeric  \n#&gt; offset       1    -none- logical  \n#&gt; classnames   3    -none- character\n#&gt; grouped      1    -none- logical  \n#&gt; call         4    -none- call     \n#&gt; nobs         1    -none- numeric\nplot(iris_glmnet)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCodeplot(iris_glmnet$lambda,\n  ylab = expression(lambda), xlab = \"迭代次数\", main = \"惩罚系数的迭代路径\"\n)\n\n\n\n\n\n\nCode\n# 选择一个迭代趋于稳定时的 lambda，比如 iris_glmnet$lambda[80]\ncoef(iris_glmnet, s = 0.0002796185)\n#&gt; $setosa\n#&gt; 5 x 1 sparse Matrix of class \"dgCMatrix\"\n#&gt;                      1\n#&gt; (Intercept)  17.015429\n#&gt; Sepal.Length  .       \n#&gt; Sepal.Width   4.486992\n#&gt; Petal.Length -3.250342\n#&gt; Petal.Width  -3.315393\n#&gt; \n#&gt; $versicolor\n#&gt; 5 x 1 sparse Matrix of class \"dgCMatrix\"\n#&gt;                     1\n#&gt; (Intercept)  8.132656\n#&gt; Sepal.Length 2.123980\n#&gt; Sepal.Width  .       \n#&gt; Petal.Length .       \n#&gt; Petal.Width  .       \n#&gt; \n#&gt; $virginica\n#&gt; 5 x 1 sparse Matrix of class \"dgCMatrix\"\n#&gt;                       1\n#&gt; (Intercept)  -25.148085\n#&gt; Sepal.Length   .       \n#&gt; Sepal.Width   -5.176029\n#&gt; Petal.Length   7.536940\n#&gt; Petal.Width   14.481524\n\niris_pred_glmnet &lt;- predict(\n  object = iris_glmnet, newx = as.matrix(iris[, -5]),\n  s = 0.0002796185, type = \"class\"\n)\n\n\n\nCodemn_spec &lt;- multinom_reg(mode = \"classification\", engine = \"glmnet\" ,penalty = tune())\n\niris_mnlogit &lt;- mn_spec %&gt;% \n    fit(Species ~ ., data = iris)\niris_mnlogit %&gt;% glance()\n\n\n\n\nnulldev\nnpasses\nnobs\n\n\n329.5837\n6546\n150\n\n\n\n\nCodeiris_mnlogit$fit %&gt;% tidy() %&gt;% DT::datatable()",
    "crumbs": [
      "推断统计模型",
      "<span class='chapter-number'>18</span>  <span class='chapter-title'>广义线性模型</span>"
    ]
  },
  {
    "objectID": "GLM.html#泊松回归",
    "href": "GLM.html#泊松回归",
    "title": "\n18  广义线性模型\n",
    "section": "\n18.4 泊松回归",
    "text": "18.4 泊松回归\n泊松回归用于计数数据，假设响应变量服从泊松分布，并使用对数连接函数（log link function）。z-statistic\nfamily=poisson(link = \"log\")\nfamily = quasipoisson(link = \"log\"))\n\\[\nP(X=x;\\lambda)=\\frac{e^{-\\lambda}\\lambda ^x}{x!}\n\\]\n\nCode\nggplot(tibble(x=0:20,\n              y1=dpois(x,lambda = 2),\n              y2=dpois(x,lambda = 6),\n              ),\n       aes(x)\n       )+\n    geom_col(aes(y=y1),fill = \"lightblue\")+\n    geom_col(aes(y=y2),fill = \"yellow\",alpha=.3)+\n    ylab(\"Poisson Density\")\n\n\n\n\n\n\n\n\nCodelibrary(poissonreg)\ndf2 &lt;- read_csv(\"data/ISLR/Bikeshare.csv\")\n\n\n\nCode# 泊松回归模型\npois_spec &lt;- poisson_reg() %&gt;% \n  set_mode(\"regression\") %&gt;% \n  set_engine(\"glm\",family=poisson(link = \"log\"))\n\npois_rec_spec &lt;- recipe(bikers ~ mnth + hr + workingday + temp + weathersit, data = df2) %&gt;% \n    step_dummy(all_nominal_predictors()) # 虚拟变量\n\npois_wf &lt;- workflow() %&gt;% \n  add_recipe(pois_rec_spec) %&gt;% \n  add_model(pois_spec)\n\npois_fit &lt;- pois_wf %&gt;% fit(data = df2)\n\n\ntidy(pois_fit)\n\n\n\n\n\n\n\n\n\n\n\nterm\nestimate\nstd.error\nstatistic\np.value\n\n\n\n(Intercept)\n3.0117662\n0.0063169\n476.780725\n0.0000000\n\n\nhr\n0.0506926\n0.0001441\n351.838257\n0.0000000\n\n\nworkingday\n-0.0128398\n0.0019533\n-6.573519\n0.0000000\n\n\ntemp\n2.5638652\n0.0099520\n257.623318\n0.0000000\n\n\nmnth_Aug\n-0.2287982\n0.0046963\n-48.718729\n0.0000000\n\n\nmnth_Dec\n0.2980823\n0.0050089\n59.511067\n0.0000000\n\n\nmnth_Feb\n-0.1015251\n0.0059163\n-17.160118\n0.0000000\n\n\nmnth_Jan\n-0.1450225\n0.0067806\n-21.387732\n0.0000000\n\n\nmnth_July\n-0.3777099\n0.0049579\n-76.183572\n0.0000000\n\n\nmnth_June\n-0.1501555\n0.0046211\n-32.493432\n0.0000000\n\n\nmnth_March\n-0.0311769\n0.0053447\n-5.833195\n0.0000000\n\n\nmnth_May\n0.0507776\n0.0043437\n11.690022\n0.0000000\n\n\nmnth_Nov\n0.2845274\n0.0046053\n61.782729\n0.0000000\n\n\nmnth_Oct\n0.2667007\n0.0043237\n61.683349\n0.0000000\n\n\nmnth_Sept\n-0.0065336\n0.0044343\n-1.473415\n0.1406391\n\n\nweathersit_cloudy.misty\n-0.0308035\n0.0021642\n-14.233203\n0.0000000\n\n\nweathersit_heavy.rain.snow\n-0.6455169\n0.1667492\n-3.871185\n0.0001083\n\n\nweathersit_light.rain.snow\n-0.4727684\n0.0040430\n-116.934850\n0.0000000\n\n\n\n\n\nCode\n\n# 绘制实际值与预测值的关系图\naugment(pois_fit, new_data = df2, type = \"response\") %&gt;%\n    ggplot(aes(bikers, .pred)) +\n    geom_point(alpha = 0.1) +\n    geom_abline(slope = 1,\n                linewidth = 1,\n                color = \"grey40\") +\n    labs(title = \"Predicting the number of bikers per hour using Poission Regression\", x = \"Actual\", y = \"Predicted\")\n\n\n\n\n\n\n\n\nCodepois_fit_coef_mnths &lt;- \n  tidy(pois_fit) %&gt;% \n  dplyr::filter(grepl(\"^mnth\", term)) %&gt;% \n  mutate(\n    term = stringr::str_replace(term, \"mnth_\", \"\"),\n    term = forcats::fct_inorder(term)\n  ) \n\npois_fit_coef_mnths %&gt;% \n  ggplot(aes(term, estimate)) +\n  geom_line(group = 1,na.rm = TRUE) +\n  geom_point(shape = 21, size = 3, stroke = 1.5, \n             fill = \"black\", color = \"white\",na.rm = TRUE) +\n  labs(title = \"Coefficient value from Poission Regression\",\n       x = \"Month\", y = \"Coefficient\")\n\n\n\n\n\n\n\n\nCodepois_acl &lt;- pois_spec %&gt;% \n    fit(NChronic12_W1 ~ SelfEfficacy_W1,data = acl)\n\npois_acl %&gt;% glance()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nnull.deviance\ndf.null\nlogLik\nAIC\nBIC\ndeviance\ndf.residual\nnobs\n\n\n5217.261\n3616\n-5161.259\n10326.52\n10338.9\n5113.99\n3615\n3617\n\n\n\n\nCode\npois_acl %&gt;% tidy()\n\n\n\n\nterm\nestimate\nstd.error\nstatistic\np.value\n\n\n\n(Intercept)\n0.0713171\n0.0161919\n4.404498\n1.06e-05\n\n\nSelfEfficacy_W1\n-0.1495381\n0.0144411\n-10.355019\n0.00e+00\n\n\n\n\n\nCode\nAIC(pois_acl$fit)\n#&gt; [1] 10326.52\nBIC(pois_acl$fit)\n#&gt; [1] 10338.9",
    "crumbs": [
      "推断统计模型",
      "<span class='chapter-number'>18</span>  <span class='chapter-title'>广义线性模型</span>"
    ]
  },
  {
    "objectID": "GLM.html#负二项回归",
    "href": "GLM.html#负二项回归",
    "title": "\n18  广义线性模型\n",
    "section": "\n18.5 负二项回归",
    "text": "18.5 负二项回归\n负二项回归用于处理计数数据且存在过度离散（overdispersion）的问题。\nlog link function，z-statistic\nprobability mass function ：\n\\[\nP(X=x;\\lambda,\\nu)=\\binom{x+\\nu - 1}{ x} \\left ( \\frac{\\lambda}{\\lambda +\\nu} \\right)^x \\left ( \\frac{\\nu}{\\nu + \\lambda} \\right)^{\\nu}\n\\]\n负二项分布的均值是 \\(\\lambda\\) ，\n方差是 \\(\\lambda + \\frac{\\lambda ^2}{\\nu}\\) 。\n\nCodelibrary(MASS)\n# 负二项回归模型\nnb_spec &lt;- linear_reg() %&gt;% \n  set_engine(\"glm\", family = MASS::negative.binomial(theta = 1, link = \"log\"))\n\nnb_acl &lt;- nb_spec %&gt;% \n  fit(NChronic12_W1 ~ SelfEfficacy_W1, data = acl)\n\n# 查看模型结果\nnb_acl %&gt;% glance()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nnull.deviance\ndf.null\nlogLik\nAIC\nBIC\ndeviance\ndf.residual\nnobs\n\n\n2945.585\n3616\n-5219.717\n10443.43\n10455.82\n2897.897\n3615\n3617\n\n\n\n\nCodenb_acl %&gt;% tidy()\n\n\n\n\nterm\nestimate\nstd.error\nstatistic\np.value\n\n\n\n(Intercept)\n0.0715048\n0.0181211\n3.945943\n8.1e-05\n\n\nSelfEfficacy_W1\n-0.1480585\n0.0169183\n-8.751399\n0.0e+00\n\n\n\n\n\nCode\n\nAIC(nb_acl$fit)\n#&gt; [1] 10443.43\nBIC(nb_acl$fit)\n#&gt; [1] 10455.82\n\n# MASS::glm.nb()",
    "crumbs": [
      "推断统计模型",
      "<span class='chapter-number'>18</span>  <span class='chapter-title'>广义线性模型</span>"
    ]
  },
  {
    "objectID": "GLM.html#正则化广义线性模型",
    "href": "GLM.html#正则化广义线性模型",
    "title": "\n18  广义线性模型\n",
    "section": "\n18.6 正则化广义线性模型",
    "text": "18.6 正则化广义线性模型\nRidge、Lasso\n\nCodelibrary(glmnet)\ndata(QuickStartExample)\nfit &lt;- glmnet::glmnet(x = QuickStartExample$x, y = QuickStartExample$y)\nautoplot(fit)\n\n\n\n\n\n\nCode\nfit &lt;- glmnet::cv.glmnet(x = QuickStartExample$x, y = QuickStartExample$y)\nautoplot(fit, colour = 'blue')",
    "crumbs": [
      "推断统计模型",
      "<span class='chapter-number'>18</span>  <span class='chapter-title'>广义线性模型</span>"
    ]
  },
  {
    "objectID": "LME.html",
    "href": "LME.html",
    "title": "\n19  线性混合模型\n",
    "section": "",
    "text": "19.1 lme4::lmer()\nCodelme4::lmer\n#&gt; function (formula, data = NULL, REML = TRUE, control = lmerControl(), \n#&gt;     start = NULL, verbose = 0L, subset, weights, na.action, offset, \n#&gt;     contrasts = NULL, devFunOnly = FALSE) \n#&gt; {\n#&gt;     mc &lt;- mcout &lt;- match.call()\n#&gt;     missCtrl &lt;- missing(control)\n#&gt;     if (!missCtrl && !inherits(control, \"lmerControl\")) {\n#&gt;         if (!is.list(control)) \n#&gt;             stop(\"'control' is not a list; use lmerControl()\")\n#&gt;         warning(\"passing control as list is deprecated: please use lmerControl() instead\", \n#&gt;             immediate. = TRUE)\n#&gt;         control &lt;- do.call(lmerControl, control)\n#&gt;     }\n#&gt;     mc$control &lt;- control\n#&gt;     mc[[1]] &lt;- quote(lme4::lFormula)\n#&gt;     lmod &lt;- eval(mc, parent.frame(1L))\n#&gt;     mcout$formula &lt;- lmod$formula\n#&gt;     lmod$formula &lt;- NULL\n#&gt;     if (is.matrix(y &lt;- model.response(lmod$fr)) && ncol(y) &gt; \n#&gt;         1) {\n#&gt;         stop(\"can't handle matrix-valued responses: consider using refit()\")\n#&gt;     }\n#&gt;     devfun &lt;- do.call(mkLmerDevfun, c(lmod, list(start = start, \n#&gt;         verbose = verbose, control = control)))\n#&gt;     if (devFunOnly) \n#&gt;         return(devfun)\n#&gt;     if (identical(control$optimizer, \"none\")) \n#&gt;         stop(\"deprecated use of optimizer=='none'; use NULL instead\")\n#&gt;     opt &lt;- if (length(control$optimizer) == 0) {\n#&gt;         s &lt;- getStart(start, environment(devfun)$pp)\n#&gt;         list(par = s, fval = devfun(s), conv = 1000, message = \"no optimization\")\n#&gt;     }\n#&gt;     else {\n#&gt;         optimizeLmer(devfun, optimizer = control$optimizer, restart_edge = control$restart_edge, \n#&gt;             boundary.tol = control$boundary.tol, control = control$optCtrl, \n#&gt;             verbose = verbose, start = start, calc.derivs = control$calc.derivs, \n#&gt;             use.last.params = control$use.last.params)\n#&gt;     }\n#&gt;     cc &lt;- checkConv(attr(opt, \"derivs\"), opt$par, ctrl = control$checkConv, \n#&gt;         lbound = environment(devfun)$lower)\n#&gt;     mkMerMod(environment(devfun), opt, lmod$reTrms, fr = lmod$fr, \n#&gt;         mc = mcout, lme4conv = cc)\n#&gt; }\n#&gt; &lt;bytecode: 0x0000021bb56bef28&gt;\n#&gt; &lt;environment: namespace:lme4&gt;\nlmer() 的表达式如下：\n\\[\nlmer (data,formual= DV ~ Fixed\\_Factor + (Random\\_intercept + Random\\_slope | Random\\_Factor))\n\\]\n截距中，1表示随机截距，0表示固定截距，默认截距为1。",
    "crumbs": [
      "推断统计模型",
      "<span class='chapter-number'>19</span>  <span class='chapter-title'>线性混合模型</span>"
    ]
  },
  {
    "objectID": "LME.html#lme4lmer",
    "href": "LME.html#lme4lmer",
    "title": "\n19  线性混合模型\n",
    "section": "",
    "text": "LME\n表达式\n简写\n\n\n\n随机截距+随机斜率\ny~x+( 1+x | id )\ny~x+( x | id )\n\n\n随机截距+固定斜率\ny~x+( 1+1 | id )\ny~x+( 1 | id )\n\n\n固定截距+随机斜率\ny~x+( 0+x | id )\nNA\n\n\n线性模型：固定截距+固定斜率\ny~x\nNA",
    "crumbs": [
      "推断统计模型",
      "<span class='chapter-number'>19</span>  <span class='chapter-title'>线性混合模型</span>"
    ]
  },
  {
    "objectID": "LME.html#nlmelme",
    "href": "LME.html#nlmelme",
    "title": "\n19  线性混合模型\n",
    "section": "\n19.2 nlme::lme()\n",
    "text": "19.2 nlme::lme()\n\n\nCodenlme::nlme\n#&gt; function (model, data = sys.frame(sys.parent()), fixed, random = fixed, \n#&gt;     groups, start, correlation = NULL, weights = NULL, subset, \n#&gt;     method = c(\"ML\", \"REML\"), na.action = na.fail, naPattern, \n#&gt;     control = list(), verbose = FALSE) \n#&gt; {\n#&gt;     UseMethod(\"nlme\")\n#&gt; }\n#&gt; &lt;bytecode: 0x0000021bb8b7b550&gt;\n#&gt; &lt;environment: namespace:nlme&gt;",
    "crumbs": [
      "推断统计模型",
      "<span class='chapter-number'>19</span>  <span class='chapter-title'>线性混合模型</span>"
    ]
  },
  {
    "objectID": "LME.html#随机截距随机斜率",
    "href": "LME.html#随机截距随机斜率",
    "title": "\n19  线性混合模型\n",
    "section": "\n19.3 随机截距+随机斜率",
    "text": "19.3 随机截距+随机斜率\n\nCodedf_long &lt;- read_delim(\"data/AED/RIKZ.txt\")\ndf_long$Beach &lt;- factor(df_long$Beach)\ndf_long$Exposure &lt;- factor(df_long$Exposure)\nhead(df_long)\n\n\n\n\nSample\nRichness\nExposure\nNAP\nBeach\n\n\n\n1\n11\n10\n0.045\n1\n\n\n2\n10\n10\n-1.036\n1\n\n\n3\n13\n10\n-1.336\n1\n\n\n4\n11\n10\n0.616\n1\n\n\n5\n10\n10\n-0.684\n1\n\n\n6\n8\n8\n1.190\n2\n\n\n\n\n\n\n\\[\n\\eta_{(nrow \\times 1)} = \\mathbf{X}_{nrow \\times 1} \\beta_{1 \\times 1} + \\mathbf{Z}_{nrow \\times 2n_{subjects}} \\mathbf{\\gamma}_{2n_{subjects} \\times 1} + \\epsilon_i\n\\]\nZ有两倍于受试者数量的列，每个受试者的随机截距和随机斜率\n\nCodelibrary(lme4)\nlme1 &lt;- lmer(Richness ~ 1 + NAP * Exposure+ (1 +NAP |Beach) ,data = df_long)\nsummary(lme1)\n#&gt; Linear mixed model fit by REML ['lmerMod']\n#&gt; Formula: Richness ~ 1 + NAP * Exposure + (1 + NAP | Beach)\n#&gt;    Data: df_long\n#&gt; \n#&gt; REML criterion at convergence: 207.2\n#&gt; \n#&gt; Scaled residuals: \n#&gt;      Min       1Q   Median       3Q      Max \n#&gt; -1.92384 -0.36066 -0.13343  0.09819  2.84228 \n#&gt; \n#&gt; Random effects:\n#&gt;  Groups   Name        Variance Std.Dev. Corr \n#&gt;  Beach    (Intercept) 3.758    1.938         \n#&gt;           NAP         2.837    1.684    -1.00\n#&gt;  Residual             6.535    2.556         \n#&gt; Number of obs: 45, groups:  Beach, 9\n#&gt; \n#&gt; Fixed effects:\n#&gt;                Estimate Std. Error t value\n#&gt; (Intercept)     13.3457     2.2784   5.858\n#&gt; NAP             -4.1753     2.1243  -1.965\n#&gt; Exposure10      -5.3273     2.5556  -2.085\n#&gt; Exposure11      -9.7660     2.5653  -3.807\n#&gt; NAP:Exposure10   0.1646     2.3621   0.070\n#&gt; NAP:Exposure11   2.7273     2.3715   1.150\n#&gt; \n#&gt; Correlation of Fixed Effects:\n#&gt;             (Intr) NAP    Exps10 Exps11 NAP:E10\n#&gt; NAP         -0.770                             \n#&gt; Exposure10  -0.892  0.686                      \n#&gt; Exposure11  -0.888  0.683  0.792               \n#&gt; NAP:Expsr10  0.692 -0.899 -0.775 -0.615        \n#&gt; NAP:Expsr11  0.689 -0.896 -0.615 -0.779  0.806 \n#&gt; optimizer (nloptwrap) convergence code: 0 (OK)\n#&gt; boundary (singular) fit: see help('isSingular')\nAIC(lme1)\n#&gt; [1] 227.1558\nBIC(lme1)\n#&gt; [1] 245.2224\nlogLik(lme1)\n#&gt; 'log Lik.' -103.5779 (df=10)\n\n2*(1-pt(-3.914605,35,lower.tail = F))\n#&gt; [1] 0.0003993968\n\nlibrary(nlme)\n\nnlme1 &lt;- lme(Richness ~ 1 + NAP * Exposure,\n             random = ~ 1 + NAP | Beach ,\n             data = df_long,\n             control = lmeControl(opt = \"optim\", msMaxIter = 100, msMaxEval = 5000))\nsummary(nlme1)\n#&gt; Linear mixed-effects model fit by REML\n#&gt;   Data: df_long \n#&gt;        AIC      BIC    logLik\n#&gt;   227.2046 243.8402 -103.6023\n#&gt; \n#&gt; Random effects:\n#&gt;  Formula: ~1 + NAP | Beach\n#&gt;  Structure: General positive-definite, Log-Cholesky parametrization\n#&gt;             StdDev   Corr  \n#&gt; (Intercept) 1.939709 (Intr)\n#&gt; NAP         1.689580 -0.996\n#&gt; Residual    2.554676       \n#&gt; \n#&gt; Fixed effects:  Richness ~ 1 + NAP * Exposure \n#&gt;                    Value Std.Error DF   t-value p-value\n#&gt; (Intercept)    13.345694  2.278989 33  5.855970  0.0000\n#&gt; NAP            -4.175271  2.128084 33 -1.961986  0.0582\n#&gt; Exposure10     -5.323695  2.556406  6 -2.082492  0.0825\n#&gt; Exposure11     -9.765613  2.566035  6 -3.805720  0.0089\n#&gt; NAP:Exposure10  0.167146  2.366467 33  0.070631  0.9441\n#&gt; NAP:Exposure11  2.726865  2.375786 33  1.147774  0.2593\n#&gt;  Correlation: \n#&gt;                (Intr) NAP    Exps10 Exps11 NAP:E10\n#&gt; NAP            -0.767                             \n#&gt; Exposure10     -0.891  0.684                      \n#&gt; Exposure11     -0.888  0.682  0.792               \n#&gt; NAP:Exposure10  0.690 -0.899 -0.772 -0.613        \n#&gt; NAP:Exposure11  0.687 -0.896 -0.613 -0.777  0.806 \n#&gt; \n#&gt; Standardized Within-Group Residuals:\n#&gt;        Min         Q1        Med         Q3        Max \n#&gt; -1.9251786 -0.3608959 -0.1327685  0.0992999  2.8420571 \n#&gt; \n#&gt; Number of Observations: 45\n#&gt; Number of Groups: 9\n\n\n这个模型的公式可以分解为：\n\n固定效应部分：Richness 的预测由截距、NAP（数值变量）和 Exposure（分类变量，包含 Exposure10 和 Exposure11）及其交互项构成。\n随机效应部分：Beach 作为随机因子，包含随机截距和随机斜率（NAP）。\n\n\nCode# 标准化模型残差分布\nquantile(residuals(lme1,type=\"pearson\",scaled=T))\n#&gt;         0%        25%        50%        75%       100% \n#&gt; -1.9238372 -0.3606612 -0.1334336  0.0981939  2.8422803\n\n# 随机因子随机效应和显著性检验\nranef(lme1)\n#&gt; $Beach\n#&gt;     (Intercept)           NAP\n#&gt; 1 -4.274356e-02  3.713708e-02\n#&gt; 2 -2.709479e-14  2.354089e-14\n#&gt; 3  3.819348e-03 -3.318381e-03\n#&gt; 4 -2.741786e-01  2.382158e-01\n#&gt; 5  3.269522e+00 -2.840673e+00\n#&gt; 6  2.736093e-01 -2.377212e-01\n#&gt; 7 -3.250033e-03  2.823741e-03\n#&gt; 8 -2.148947e+00  1.867079e+00\n#&gt; 9 -1.077831e+00  9.364564e-01\n#&gt; \n#&gt; with conditional variances for \"Beach\"\nlmerTest::ranova(lme1)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nnpar\nlogLik\nAIC\nLRT\nDf\nPr(&gt;Chisq)\n\n\n\n\n10\n-103.5779\n227.1558\nNA\nNA\nNA\n\n\nNAP in (1 + NAP | Beach)\n8\n-105.6747\n227.3493\n4.193538\n2\n0.1228527\n\n\n\n\n\nCode\n# 查看固定效应和显著性检验\ncoef(lme1)\n#&gt; $Beach\n#&gt;   (Intercept)       NAP Exposure10 Exposure11 NAP:Exposure10 NAP:Exposure11\n#&gt; 1    13.30295 -4.138134  -5.327265  -9.766048      0.1646123       2.727307\n#&gt; 2    13.34569 -4.175271  -5.327265  -9.766048      0.1646123       2.727307\n#&gt; 3    13.34951 -4.178590  -5.327265  -9.766048      0.1646123       2.727307\n#&gt; 4    13.07152 -3.937055  -5.327265  -9.766048      0.1646123       2.727307\n#&gt; 5    16.61522 -7.015944  -5.327265  -9.766048      0.1646123       2.727307\n#&gt; 6    13.61930 -4.412992  -5.327265  -9.766048      0.1646123       2.727307\n#&gt; 7    13.34244 -4.172447  -5.327265  -9.766048      0.1646123       2.727307\n#&gt; 8    11.19675 -2.308192  -5.327265  -9.766048      0.1646123       2.727307\n#&gt; 9    12.26786 -3.238815  -5.327265  -9.766048      0.1646123       2.727307\n#&gt; \n#&gt; attr(,\"class\")\n#&gt; [1] \"coef.mer\"\nanova(lme1)\n\n\n\n\n\nnpar\nSum Sq\nMean Sq\nF value\n\n\n\nNAP\n1\n124.27890\n124.27890\n19.017821\n\n\nExposure\n2\n142.98343\n71.49172\n10.940045\n\n\nNAP:Exposure\n2\n22.30791\n11.15395\n1.706838\n\n\n\n\n\nCode\n#  查看 类和方法\nclass(lme1)\n#&gt; [1] \"lmerMod\"\n#&gt; attr(,\"package\")\n#&gt; [1] \"lme4\"\n# methods(class = \"lmerMod\")\n\n# confint(lme1,level = 0.95)",
    "crumbs": [
      "推断统计模型",
      "<span class='chapter-number'>19</span>  <span class='chapter-title'>线性混合模型</span>"
    ]
  },
  {
    "objectID": "LME.html#随机截距固定斜率",
    "href": "LME.html#随机截距固定斜率",
    "title": "\n19  线性混合模型\n",
    "section": "\n19.4 随机截距+固定斜率",
    "text": "19.4 随机截距+固定斜率\n\\[\n\\eta_{(nrow \\ \\times 1)}=\\mathbf{X_{nrow×1}}\\beta_{1\\times1} +Z_{nrow\\times n_{subjects}} \\mathbf{\\gamma}_{n_{subjects}\\times 1}+\\epsilon_i\n\\]\nZ有一倍于受试者数量的列，每个受试者的随机截距。\n\nCodelme2 &lt;- lmer(Richness ~ 1 + NAP+ (1 |Beach) ,data = df_long)\nsummary(lme2)\n#&gt; Linear mixed model fit by REML ['lmerMod']\n#&gt; Formula: Richness ~ 1 + NAP + (1 | Beach)\n#&gt;    Data: df_long\n#&gt; \n#&gt; REML criterion at convergence: 239.5\n#&gt; \n#&gt; Scaled residuals: \n#&gt;     Min      1Q  Median      3Q     Max \n#&gt; -1.4227 -0.4848 -0.1576  0.2519  3.9794 \n#&gt; \n#&gt; Random effects:\n#&gt;  Groups   Name        Variance Std.Dev.\n#&gt;  Beach    (Intercept) 8.668    2.944   \n#&gt;  Residual             9.362    3.060   \n#&gt; Number of obs: 45, groups:  Beach, 9\n#&gt; \n#&gt; Fixed effects:\n#&gt;             Estimate Std. Error t value\n#&gt; (Intercept)   6.5819     1.0958   6.007\n#&gt; NAP          -2.5684     0.4947  -5.192\n#&gt; \n#&gt; Correlation of Fixed Effects:\n#&gt;     (Intr)\n#&gt; NAP -0.157\nAIC(lme2)\n#&gt; [1] 247.4802\nBIC(lme2)\n#&gt; [1] 254.7069\nlogLik(lme2)\n#&gt; 'log Lik.' -119.7401 (df=4)\n\n2*(1-pt(6.007,35,lower.tail = T))\n#&gt; [1] 7.558855e-07\n\n\n\nnlme2 &lt;- lme(Richness ~ 1 + NAP * Exposure,random= ~ 1 |Beach ,data = df_long)\nsummary(nlme2)\n#&gt; Linear mixed-effects model fit by REML\n#&gt;   Data: df_long \n#&gt;        AIC      BIC    logLik\n#&gt;   227.3493 240.6578 -105.6747\n#&gt; \n#&gt; Random effects:\n#&gt;  Formula: ~1 | Beach\n#&gt;         (Intercept) Residual\n#&gt; StdDev:   0.5138683 2.971793\n#&gt; \n#&gt; Fixed effects:  Richness ~ 1 + NAP * Exposure \n#&gt;                    Value Std.Error DF   t-value p-value\n#&gt; (Intercept)    13.345694  1.483557 33  8.995739  0.0000\n#&gt; NAP            -4.175271  1.505110 33 -2.774063  0.0090\n#&gt; Exposure10     -5.544983  1.657659  6 -3.345069  0.0155\n#&gt; Exposure11     -9.730595  1.670518  6 -5.824898  0.0011\n#&gt; NAP:Exposure10  0.671731  1.643864 33  0.408629  0.6855\n#&gt; NAP:Exposure11  2.688806  1.656743 33  1.622947  0.1141\n#&gt;  Correlation: \n#&gt;                (Intr) NAP    Exps10 Exps11 NAP:E10\n#&gt; NAP            -0.278                             \n#&gt; Exposure10     -0.895  0.249                      \n#&gt; Exposure11     -0.888  0.247  0.795               \n#&gt; NAP:Exposure10  0.255 -0.916 -0.276 -0.226        \n#&gt; NAP:Exposure11  0.253 -0.908 -0.226 -0.296  0.832 \n#&gt; \n#&gt; Standardized Within-Group Residuals:\n#&gt;        Min         Q1        Med         Q3        Max \n#&gt; -1.5652904 -0.4386841 -0.1164805  0.1783113  4.1098230 \n#&gt; \n#&gt; Number of Observations: 45\n#&gt; Number of Groups: 9",
    "crumbs": [
      "推断统计模型",
      "<span class='chapter-number'>19</span>  <span class='chapter-title'>线性混合模型</span>"
    ]
  },
  {
    "objectID": "LME.html#固定截距随机斜率",
    "href": "LME.html#固定截距随机斜率",
    "title": "\n19  线性混合模型\n",
    "section": "\n19.5 固定截距+随机斜率",
    "text": "19.5 固定截距+随机斜率\n\\[\n\\eta_{(nrow \\times 1)} = \\mathbf{X}_{nrow \\times 1} \\beta_{1 \\times 1} + \\mathbf{Z}_{nrow \\times n_{subjects}} \\mathbf{\\gamma}_{n_{subjects} \\times 1} + \\epsilon_i\n\\]\nZ 有一倍于受试者数量的列，每个受试者的随机斜率。\n\nCodelme3 &lt;- lmer(Richness ~ 1 +  NAP+ (0 + NAP |Beach) ,data = df_long)\nsummary(lme3)\n#&gt; Linear mixed model fit by REML ['lmerMod']\n#&gt; Formula: Richness ~ 1 + NAP + (0 + NAP | Beach)\n#&gt;    Data: df_long\n#&gt; \n#&gt; REML criterion at convergence: 252.2\n#&gt; \n#&gt; Scaled residuals: \n#&gt;     Min      1Q  Median      3Q     Max \n#&gt; -1.2182 -0.6636 -0.1930  0.3253  3.3347 \n#&gt; \n#&gt; Random effects:\n#&gt;  Groups   Name Variance Std.Dev.\n#&gt;  Beach    NAP   0.00    0.00    \n#&gt;  Residual      17.31    4.16    \n#&gt; Number of obs: 45, groups:  Beach, 9\n#&gt; \n#&gt; Fixed effects:\n#&gt;             Estimate Std. Error t value\n#&gt; (Intercept)   6.6857     0.6578  10.164\n#&gt; NAP          -2.8669     0.6307  -4.545\n#&gt; \n#&gt; Correlation of Fixed Effects:\n#&gt;     (Intr)\n#&gt; NAP -0.333\n#&gt; optimizer (nloptwrap) convergence code: 0 (OK)\n#&gt; boundary (singular) fit: see help('isSingular')\n\nnlme3 &lt;- lme(Richness ~ 1 + NAP,random= ~ 0+NAP |Beach ,data = df_long)\nsummary(nlme3)\n#&gt; Linear mixed-effects model fit by REML\n#&gt;   Data: df_long \n#&gt;       AIC      BIC    logLik\n#&gt;   260.201 267.2458 -126.1005\n#&gt; \n#&gt; Random effects:\n#&gt;  Formula: ~0 + NAP | Beach\n#&gt;                  NAP Residual\n#&gt; StdDev: 0.0001127408 4.159929\n#&gt; \n#&gt; Fixed effects:  Richness ~ 1 + NAP \n#&gt;                 Value Std.Error DF   t-value p-value\n#&gt; (Intercept)  6.685662 0.6577579 35 10.164320   0e+00\n#&gt; NAP         -2.866853 0.6307186 35 -4.545376   1e-04\n#&gt;  Correlation: \n#&gt;     (Intr)\n#&gt; NAP -0.333\n#&gt; \n#&gt; Standardized Within-Group Residuals:\n#&gt;        Min         Q1        Med         Q3        Max \n#&gt; -1.2181663 -0.6636488 -0.1930031  0.3253447  3.3347473 \n#&gt; \n#&gt; Number of Observations: 45\n#&gt; Number of Groups: 9",
    "crumbs": [
      "推断统计模型",
      "<span class='chapter-number'>19</span>  <span class='chapter-title'>线性混合模型</span>"
    ]
  },
  {
    "objectID": "LME.html#随机效应模型",
    "href": "LME.html#随机效应模型",
    "title": "\n19  线性混合模型\n",
    "section": "\n19.6 随机效应模型",
    "text": "19.6 随机效应模型\n\nCode\nlme4 &lt;- lmer(Richness ~ 1 + (1|Beach) ,data = df_long)\nsummary(lme4)\n#&gt; Linear mixed model fit by REML ['lmerMod']\n#&gt; Formula: Richness ~ 1 + (1 | Beach)\n#&gt;    Data: df_long\n#&gt; \n#&gt; REML criterion at convergence: 261.1\n#&gt; \n#&gt; Scaled residuals: \n#&gt;     Min      1Q  Median      3Q     Max \n#&gt; -1.7797 -0.5070 -0.0980  0.2547  3.8063 \n#&gt; \n#&gt; Random effects:\n#&gt;  Groups   Name        Variance Std.Dev.\n#&gt;  Beach    (Intercept) 10.48    3.237   \n#&gt;  Residual             15.51    3.938   \n#&gt; Number of obs: 45, groups:  Beach, 9\n#&gt; \n#&gt; Fixed effects:\n#&gt;             Estimate Std. Error t value\n#&gt; (Intercept)    5.689      1.228   4.631\n\nnlme4 &lt;- lme(Richness ~ 1 ,random= ~ 1 |Beach ,data = df_long)\nsummary(nlme4)\n#&gt; Linear mixed-effects model fit by REML\n#&gt;   Data: df_long \n#&gt;        AIC      BIC    logLik\n#&gt;   267.1142 272.4668 -130.5571\n#&gt; \n#&gt; Random effects:\n#&gt;  Formula: ~1 | Beach\n#&gt;         (Intercept) Residual\n#&gt; StdDev:    3.237112 3.938415\n#&gt; \n#&gt; Fixed effects:  Richness ~ 1 \n#&gt;                Value Std.Error DF  t-value p-value\n#&gt; (Intercept) 5.688889  1.228419 36 4.631066       0\n#&gt; \n#&gt; Standardized Within-Group Residuals:\n#&gt;         Min          Q1         Med          Q3         Max \n#&gt; -1.77968689 -0.50704111 -0.09795286  0.25468670  3.80631705 \n#&gt; \n#&gt; Number of Observations: 45\n#&gt; Number of Groups: 9",
    "crumbs": [
      "推断统计模型",
      "<span class='chapter-number'>19</span>  <span class='chapter-title'>线性混合模型</span>"
    ]
  },
  {
    "objectID": "LME.html#线性模型固定截距-固定斜率",
    "href": "LME.html#线性模型固定截距-固定斜率",
    "title": "\n19  线性混合模型\n",
    "section": "\n19.7 线性模型：固定截距+ 固定斜率",
    "text": "19.7 线性模型：固定截距+ 固定斜率\n\nCodelm &lt;- lm(Richness ~ 1 + NAP ,data = df_long)\nlm\n#&gt; \n#&gt; Call:\n#&gt; lm(formula = Richness ~ 1 + NAP, data = df_long)\n#&gt; \n#&gt; Coefficients:\n#&gt; (Intercept)          NAP  \n#&gt;       6.686       -2.867",
    "crumbs": [
      "推断统计模型",
      "<span class='chapter-number'>19</span>  <span class='chapter-title'>线性混合模型</span>"
    ]
  },
  {
    "objectID": "LME.html#模型选择",
    "href": "LME.html#模型选择",
    "title": "\n19  线性混合模型\n",
    "section": "\n19.8 模型选择",
    "text": "19.8 模型选择\n限制最大似然法REML\n\n\n赤池信息准则（AIC）\n\\[ kIC=−2log(\\mathcal{L})+2k\\]\n其中：\n\n\\(\\mathcal{L}\\) 是似然函数。\n\\(k\\) 是模型参数的数量。\n\n\n\n贝叶斯信息准则（BIC）\n\\[ BIC=−2log(\\mathcal{L})+klog(n) \\]\n其中：\n\n\n\\(n\\) 是样本量。\n\n\n\n\nCode\nplot_lme &lt;- function(model, title) {\n    ggplot(df_long, aes(NAP, Richness, group = Beach, color = Beach)) +\n        geom_point() +\n        geom_line(\n            data =  bind_cols(df_long, .pred = predict(model, df_long)),\n            mapping = aes(y = .pred),\n            linewidth = 1\n        ) +\n        labs(title = title)+\n        scale_x_continuous(expand = (mult=c(0,.1)))+\n        scale_y_continuous(expand = (mult=c(0,.1)))+\n    ggsci::scale_color_jco() +\n        ggpubr::theme_pubr() +\n        theme(legend.position = \"right\",\n              plot.title = element_text(hjust = .5))\n}\n\n\nlme_plot &lt;- map2(list(lme1,lme2,lme3,lm),list(\"随机截距+随机斜率\",\"随机截距+固定斜率\",\"固定截距+随机斜率\",\"固定截距+固定斜率\"),plot_lme)\n\n\nlme_plot\n#&gt; [[1]]\n\n\n\n\n\n\n#&gt; \n#&gt; [[2]]\n\n\n\n\n\n\n#&gt; \n#&gt; [[3]]\n\n\n\n\n\n\n#&gt; \n#&gt; [[4]]\n\n\n\n\n\n\n\n\nCodeanova(lme1,lme2,lme3)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nnpar\nAIC\nBIC\nlogLik\ndeviance\nChisq\nDf\nPr(&gt;Chisq)\n\n\n\nlme2\n4\n249.8291\n257.0557\n-120.9145\n241.8291\nNA\nNA\nNA\n\n\nlme3\n4\n261.9535\n269.1801\n-126.9767\n253.9535\n0.00000\n0\nNA\n\n\nlme1\n10\n238.1993\n256.2660\n-109.0997\n218.1993\n35.75415\n6\n3.1e-06\n\n\n\n\n\nCodeanova(lme1,lme2,lme3,lme4,lm)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nnpar\nAIC\nBIC\nlogLik\ndeviance\nChisq\nDf\nPr(&gt;Chisq)\n\n\n\nlme4\n3\n269.3035\n274.7235\n-131.6518\n263.3035\nNA\nNA\nNA\n\n\nlm\n3\n259.9535\n265.3735\n-126.9767\n253.9535\n9.350043\n0\nNA\n\n\nlme2\n4\n249.8291\n257.0557\n-120.9145\n241.8291\n12.124401\n1\n0.0004977\n\n\nlme3\n4\n261.9535\n269.1801\n-126.9767\n253.9535\n0.000000\n0\nNA\n\n\nlme1\n10\n238.1993\n256.2660\n-109.0997\n218.1993\n35.754147\n6\n0.0000031\n\n\n\n\n\nCode\n# p小于0.05,说明全模型与简化后模型存在差异，最终采用lme1,AIC",
    "crumbs": [
      "推断统计模型",
      "<span class='chapter-number'>19</span>  <span class='chapter-title'>线性混合模型</span>"
    ]
  },
  {
    "objectID": "LME.html#模型诊断",
    "href": "LME.html#模型诊断",
    "title": "\n19  线性混合模型\n",
    "section": "\n19.9 模型诊断",
    "text": "19.9 模型诊断\nsleepstudy\n\nCode# 拟合线性混合模型\nmodel &lt;- lme1\n# 1. 残差图\nresiduals &lt;- resid(model)\nfitted &lt;- fitted(model)\nggplot(data.frame(fitted, residuals), aes(fitted, residuals)) +\n  geom_point() +\n  geom_smooth(method = \"loess\", se = FALSE) +\n  labs(title = \"Residuals vs Fitted\", x = \"Fitted values\", y = \"Residuals\")\n\n\n\n\n\n\nCode\n# 2. QQ图\nqqnorm(residuals)\nqqline(residuals)\n\n\n\n\n\n\nCode\n# 3. Cook's 距离\ncooksd &lt;- cooks.distance(model)\nplot(cooksd, type = \"h\", main = \"Cook's Distance\")\n\n\n\n\n\n\nCode\n# 4. 随机效应的分布\nrand_dist &lt;- ranef(model)\n\nqqnorm(rand_dist$Beach$NAP)\nqqline(rand_dist$Beach$NAP)",
    "crumbs": [
      "推断统计模型",
      "<span class='chapter-number'>19</span>  <span class='chapter-title'>线性混合模型</span>"
    ]
  },
  {
    "objectID": "GEE.html",
    "href": "GEE.html",
    "title": "\n20  广义估计方程\n",
    "section": "",
    "text": "20.1 数据集处理\n数据集 Analyzing ecological data\nCoderfb &lt;- read_delim(\"data/AED/RiceFieldBirds.txt\")\nrfb$richness &lt;- rowSums(rfb[, 8:56] &gt; 0)\nrfb |&gt; mutate(\n    FIELD = factor(FIELD),\n    SPTREAT = factor(SPTREAT),\n    log_AREA = log(rfb$AREA),\n    DEPTH2 = DEPTH ^ 2,\n    .after = 4\n) -&gt; rfb\n\n\nggplot(rfb, aes(Time, richness)) +\n    geom_point(pch = 21) +\n    geom_smooth(method = \"loess\", se = F) +\n    facet_wrap(vars(FIELD), labeller = \"label_both\")\nCodeowls &lt;- read_delim(\"data/AED/Owls.txt\")\n\nowls |&gt;\n    mutate(NCalls = SiblingNegotiation, log_broodsize = log(BroodSize), ) -&gt;\n    owls\nCodede &lt;- read_delim(\"data/AED/DeerEcervi.txt\")\n\nde |&gt;\n    mutate(\n        Ecervi_binary = if_else(Ecervi &gt; 0, 1, Ecervi),\n        Sex = factor(Sex),\n        Length_center = scale(Length, center = T , scale = F),\n    ) -&gt; de",
    "crumbs": [
      "推断统计模型",
      "<span class='chapter-number'>20</span>  <span class='chapter-title'>广义估计方程</span>"
    ]
  },
  {
    "objectID": "GEE.html#glm-连接函数",
    "href": "GEE.html#glm-连接函数",
    "title": "\n20  广义估计方程\n",
    "section": "\n20.2 GLM 连接函数",
    "text": "20.2 GLM 连接函数\nGLM的形式如下：\n\\[ g(\\mu_{ij})=\\beta_0+\\beta_1x_{ij_1}+\\beta_2x_{ij_2}+...+\\beta_px_{ij_p} \\]\n其中，g() 是一个连接函数，用于将自变量的线性组合与因变量的均值联系起来。常见的连接函数包括恒等连接函数（identity）、logistic连接函数（logit）、逆正弦连接函数（inverse sine）函数等。i 表示观测对象的索引，j 表示时间点或相关性结构的索引，uij 表示因变量的均值，β 表示待估计的系数，Xij 表示自变量。\n\\[\n\\eta = \\beta  \\mathbf{X}+ \\alpha\n\\]\n\\[\nE(y)=g^{-1}(\\eta)\n\\]\n对于计数数据：\n\\[\nE(y)=e^{\\eta}=e^{\\beta \\mathbf{X} +\\alpha}, 此时g(\\mu)=\\ln(\\mu)=\\mathbf{X}\\beta\n\\]\n\nCoderfb_glm &lt;- glm(richness ~ offset(log_AREA) +SPTREAT + DEPTH +DEPTH2,\n            family = quasipoisson(link = \"log\"),\n            data = rfb)\n\nowls_glm &lt;- glm(\n    NCalls ~ offset(log_broodsize) + SexParent * FoodTreatment + SexParent *\n        ArrivalTime,\n    family = poisson(link = \"log\"),\n    data = owls\n)\n\n\n对于二分类数据：\n\\[\nE(y)=\\frac{e^{\\beta \\mathbf{X} +\\alpha}}{1+e^{\\beta\\mathbf{X}+\\alpha}}, 此时g(\\mu)=\\ln(\\frac{\\mu}{1-\\mu})=logit(\\mu)\n\\]\n\nCodede_glm &lt;- glm(Ecervi_binary ~ Length_center *Sex,\n              family = binomial(link = \"logit\"),\n              data = de)\nsummary(de_glm)\n#&gt; \n#&gt; Call:\n#&gt; glm(formula = Ecervi_binary ~ Length_center * Sex, family = binomial(link = \"logit\"), \n#&gt;     data = de)\n#&gt; \n#&gt; Coefficients:\n#&gt;                    Estimate Std. Error z value Pr(&gt;|z|)    \n#&gt; (Intercept)        0.652409   0.109602   5.953 2.64e-09 ***\n#&gt; Length_center      0.025112   0.005576   4.504 6.68e-06 ***\n#&gt; Sex2               0.163873   0.174235   0.941   0.3469    \n#&gt; Length_center:Sex2 0.020109   0.009722   2.068   0.0386 *  \n#&gt; ---\n#&gt; Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n#&gt; \n#&gt; (Dispersion parameter for binomial family taken to be 1)\n#&gt; \n#&gt;     Null deviance: 1073.1  on 825  degrees of freedom\n#&gt; Residual deviance: 1003.7  on 822  degrees of freedom\n#&gt; AIC: 1011.7\n#&gt; \n#&gt; Number of Fisher Scoring iterations: 4",
    "crumbs": [
      "推断统计模型",
      "<span class='chapter-number'>20</span>  <span class='chapter-title'>广义估计方程</span>"
    ]
  },
  {
    "objectID": "GEE.html#方差",
    "href": "GEE.html#方差",
    "title": "\n20  广义估计方程\n",
    "section": "\n20.3 方差",
    "text": "20.3 方差\n\\[\nvar(Y_{is}|X_{is})=\\Phi × \\nu(\\mu_{is})\n\\]\n其中，Φ 是scale parameter （overdispersion），v() 是方差函数。",
    "crumbs": [
      "推断统计模型",
      "<span class='chapter-number'>20</span>  <span class='chapter-title'>广义估计方程</span>"
    ]
  },
  {
    "objectID": "GEE.html#相关性结构",
    "href": "GEE.html#相关性结构",
    "title": "\n20  广义估计方程\n",
    "section": "\n20.4 相关性结构",
    "text": "20.4 相关性结构\nR(α)\n\n非结构化相关：cor(Yis,Yit)=αst\n自回归相关：cor(Yis,Yit)=α|s-t|\nexchangeable 等相关：cor(Yis,Yit)=α\nindependence，独立，cor(Yis,Yit)=I",
    "crumbs": [
      "推断统计模型",
      "<span class='chapter-number'>20</span>  <span class='chapter-title'>广义估计方程</span>"
    ]
  },
  {
    "objectID": "GEE.html#gee",
    "href": "GEE.html#gee",
    "title": "\n20  广义估计方程\n",
    "section": "\n20.5 GEE",
    "text": "20.5 GEE\nGLM的期望和方差：\n\\[ E(Y_{ij})=b'(\\theta_{ij})\\\\ Var(Y_{ij})=b''(\\theta_{ij})\\ \\Phi \\]\n假定潜在的随机成分Vi ：\n\\[\nV_i=A_i^{1/2}R(\\alpha)A_i^{1/2}\\ \\Phi\n\\]\n其中，Ai =diag（b''(θi1)，...，b''(θij)） 。\nGEE的形式如下：\n\\[\nU(\\beta)=\\sum_{i=1}^{n} D'_iV_i^{-1}(y_i-\\mu_i)=0\n\\]\n其中，$U(β) $是一个包含待估计参数的函数，quasi-deviance \\(D'_i = \\left(\\frac{\\partial \\mu_i}{\\partial \\beta}\\right)'\\)，\\(V_i\\) 是方差-协方差矩阵，\\(R(\\alpha)\\) 是相关性结构矩阵，y 是观测数据，μ 是模型的均值预测值。采用迭代重复加权最小二乘法（iteratively reweighted least squares ，IWLS)），偏微分方程估计参数。",
    "crumbs": [
      "推断统计模型",
      "<span class='chapter-number'>20</span>  <span class='chapter-title'>广义估计方程</span>"
    ]
  },
  {
    "objectID": "GEE.html#gee-1",
    "href": "GEE.html#gee-1",
    "title": "\n20  广义估计方程\n",
    "section": "\n20.6 gee\n",
    "text": "20.6 gee\n\nhttps://www.statsmodels.org/stable//gee.html\n\nCodedata(epil,package = \"MASS\")\nOxboys |&gt; head(n=18)\n\n\n\n\nSubject\nage\nheight\nOccasion\n\n\n\n1\n-1.0000\n140.5\n1\n\n\n1\n-0.7479\n143.4\n2\n\n\n1\n-0.4630\n144.8\n3\n\n\n1\n-0.1643\n147.1\n4\n\n\n1\n-0.0027\n147.7\n5\n\n\n1\n0.2466\n150.2\n6\n\n\n1\n0.5562\n151.7\n7\n\n\n1\n0.7781\n153.3\n8\n\n\n1\n0.9945\n155.8\n9\n\n\n2\n-1.0000\n136.9\n1\n\n\n2\n-0.7479\n139.1\n2\n\n\n2\n-0.4630\n140.1\n3\n\n\n2\n-0.1643\n142.6\n4\n\n\n2\n-0.0027\n143.2\n5\n\n\n2\n0.2466\n144.0\n6\n\n\n2\n0.5562\n145.8\n7\n\n\n2\n0.7781\n146.8\n8\n\n\n2\n0.9945\n148.3\n9\n\n\n\n\n\nCode\n\ndf_long &lt;- Oxboys\n\n\n\nCodelibrary(gee)\n\ng1 &lt;- gee(height~age,data = df_long ,id = Subject,corstr = \"AR-M\",Mv = 1)\n#&gt; (Intercept)         age \n#&gt;  149.371801    6.521022\ng1\n#&gt; \n#&gt;  GEE:  GENERALIZED LINEAR MODELS FOR DEPENDENT DATA\n#&gt;  gee S-function, version 4.13 modified 98/01/27 (1998) \n#&gt; \n#&gt; Model:\n#&gt;  Link:                      Identity \n#&gt;  Variance to Mean Relation: Gaussian \n#&gt;  Correlation Structure:     AR-M , M = 1 \n#&gt; \n#&gt; Call:\n#&gt; gee(formula = height ~ age, id = Subject, data = df_long, corstr = \"AR-M\", \n#&gt;     Mv = 1)\n#&gt; \n#&gt; Number of observations :  234 \n#&gt; \n#&gt; Maximum cluster size   :  9 \n#&gt; \n#&gt; \n#&gt; Coefficients:\n#&gt; (Intercept)         age \n#&gt;  149.719096    6.547328 \n#&gt; \n#&gt; Estimated Scale Parameter:  65.41743\n#&gt; Number of Iterations:  2\n#&gt; \n#&gt; Working Correlation[1:4,1:4]\n#&gt;           [,1]      [,2]      [,3]      [,4]\n#&gt; [1,] 1.0000000 0.9892949 0.9787045 0.9682274\n#&gt; [2,] 0.9892949 1.0000000 0.9892949 0.9787045\n#&gt; [3,] 0.9787045 0.9892949 1.0000000 0.9892949\n#&gt; [4,] 0.9682274 0.9787045 0.9892949 1.0000000\n#&gt; \n#&gt; \n#&gt; Returned Error Value:\n#&gt; [1] 0\nsummary(g1)\n#&gt; \n#&gt;  GEE:  GENERALIZED LINEAR MODELS FOR DEPENDENT DATA\n#&gt;  gee S-function, version 4.13 modified 98/01/27 (1998) \n#&gt; \n#&gt; Model:\n#&gt;  Link:                      Identity \n#&gt;  Variance to Mean Relation: Gaussian \n#&gt;  Correlation Structure:     AR-M , M = 1 \n#&gt; \n#&gt; Call:\n#&gt; gee(formula = height ~ age, id = Subject, data = df_long, corstr = \"AR-M\", \n#&gt;     Mv = 1)\n#&gt; \n#&gt; Summary of Residuals:\n#&gt;         Min          1Q      Median          3Q         Max \n#&gt; -22.0304139  -5.4912438   0.1324571   4.3822174  18.5695861 \n#&gt; \n#&gt; \n#&gt; Coefficients:\n#&gt;               Estimate Naive S.E.  Naive z Robust S.E. Robust z\n#&gt; (Intercept) 149.719096  1.5531285 96.39840   1.5847569 94.47449\n#&gt; age           6.547328  0.3177873 20.60286   0.3042478 21.51972\n#&gt; \n#&gt; Estimated Scale Parameter:  65.41743\n#&gt; Number of Iterations:  2\n#&gt; \n#&gt; Working Correlation\n#&gt;            [,1]      [,2]      [,3]      [,4]      [,5]      [,6]      [,7]\n#&gt;  [1,] 1.0000000 0.9892949 0.9787045 0.9682274 0.9578625 0.9476085 0.9374643\n#&gt;  [2,] 0.9892949 1.0000000 0.9892949 0.9787045 0.9682274 0.9578625 0.9476085\n#&gt;  [3,] 0.9787045 0.9892949 1.0000000 0.9892949 0.9787045 0.9682274 0.9578625\n#&gt;  [4,] 0.9682274 0.9787045 0.9892949 1.0000000 0.9892949 0.9787045 0.9682274\n#&gt;  [5,] 0.9578625 0.9682274 0.9787045 0.9892949 1.0000000 0.9892949 0.9787045\n#&gt;  [6,] 0.9476085 0.9578625 0.9682274 0.9787045 0.9892949 1.0000000 0.9892949\n#&gt;  [7,] 0.9374643 0.9476085 0.9578625 0.9682274 0.9787045 0.9892949 1.0000000\n#&gt;  [8,] 0.9274287 0.9374643 0.9476085 0.9578625 0.9682274 0.9787045 0.9892949\n#&gt;  [9,] 0.9175005 0.9274287 0.9374643 0.9476085 0.9578625 0.9682274 0.9787045\n#&gt;            [,8]      [,9]\n#&gt;  [1,] 0.9274287 0.9175005\n#&gt;  [2,] 0.9374643 0.9274287\n#&gt;  [3,] 0.9476085 0.9374643\n#&gt;  [4,] 0.9578625 0.9476085\n#&gt;  [5,] 0.9682274 0.9578625\n#&gt;  [6,] 0.9787045 0.9682274\n#&gt;  [7,] 0.9892949 0.9787045\n#&gt;  [8,] 1.0000000 0.9892949\n#&gt;  [9,] 0.9892949 1.0000000\n\n\ngee1 &lt;- gee(y ~ age + trt + base,id=subject,data = epil,family = poisson,corstr =\"exchangeable\" )\n#&gt;  (Intercept)          age trtprogabide         base \n#&gt;   0.57304359   0.02234757  -0.15188049   0.02263524\nsummary(gee1)\n#&gt; \n#&gt;  GEE:  GENERALIZED LINEAR MODELS FOR DEPENDENT DATA\n#&gt;  gee S-function, version 4.13 modified 98/01/27 (1998) \n#&gt; \n#&gt; Model:\n#&gt;  Link:                      Logarithm \n#&gt;  Variance to Mean Relation: Poisson \n#&gt;  Correlation Structure:     Exchangeable \n#&gt; \n#&gt; Call:\n#&gt; gee(formula = y ~ age + trt + base, id = subject, data = epil, \n#&gt;     family = poisson, corstr = \"exchangeable\")\n#&gt; \n#&gt; Summary of Residuals:\n#&gt;        Min         1Q     Median         3Q        Max \n#&gt; -15.742906  -3.318756  -1.186874   1.295122  63.957902 \n#&gt; \n#&gt; \n#&gt; Coefficients:\n#&gt;                 Estimate  Naive S.E.   Naive z Robust S.E.   Robust z\n#&gt; (Intercept)   0.57304359 0.451797966  1.268362 0.360726141  1.5885835\n#&gt; age           0.02234757 0.013412798  1.666138 0.011400956  1.9601489\n#&gt; trtprogabide -0.15188049 0.159304397 -0.953398 0.171051111 -0.8879246\n#&gt; base          0.02263524 0.001696439 13.342795 0.001226748 18.4514092\n#&gt; \n#&gt; Estimated Scale Parameter:  5.087384\n#&gt; Number of Iterations:  1\n#&gt; \n#&gt; Working Correlation\n#&gt;           [,1]      [,2]      [,3]      [,4]\n#&gt; [1,] 1.0000000 0.3933815 0.3933815 0.3933815\n#&gt; [2,] 0.3933815 1.0000000 0.3933815 0.3933815\n#&gt; [3,] 0.3933815 0.3933815 1.0000000 0.3933815\n#&gt; [4,] 0.3933815 0.3933815 0.3933815 1.0000000",
    "crumbs": [
      "推断统计模型",
      "<span class='chapter-number'>20</span>  <span class='chapter-title'>广义估计方程</span>"
    ]
  },
  {
    "objectID": "GEE.html#geepack",
    "href": "GEE.html#geepack",
    "title": "\n20  广义估计方程\n",
    "section": "\n20.7 geepack\n",
    "text": "20.7 geepack\n\n\nCodelibrary(geepack)\n\nrfb_gee &lt;- geeglm(richness ~ offset(log_AREA) +SPTREAT + DEPTH +DEPTH2,\n            family = poisson(link = \"log\"),\n            data = rfb,\n            id=FIELD,\n            corstr = \"ar1\")\n\nsummary(rfb_gee)\n#&gt; \n#&gt; Call:\n#&gt; geeglm(formula = richness ~ offset(log_AREA) + SPTREAT + DEPTH + \n#&gt;     DEPTH2, family = poisson(link = \"log\"), data = rfb, id = FIELD, \n#&gt;     corstr = \"ar1\")\n#&gt; \n#&gt;  Coefficients:\n#&gt;                Estimate    Std.err  Wald Pr(&gt;|W|)   \n#&gt; (Intercept)  -0.6782034  0.2610088 6.752  0.00937 **\n#&gt; SPTREATrlfld -0.5223137  0.2287644 5.213  0.02242 * \n#&gt; DEPTH         0.0498238  0.0193149 6.654  0.00989 **\n#&gt; DEPTH2       -0.0011411  0.0004908 5.406  0.02007 * \n#&gt; ---\n#&gt; Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n#&gt; \n#&gt; Correlation structure = ar1 \n#&gt; Estimated Scale Parameters:\n#&gt; \n#&gt;             Estimate Std.err\n#&gt; (Intercept)    2.334  0.2927\n#&gt;   Link = identity \n#&gt; \n#&gt; Estimated Correlation Parameters:\n#&gt;       Estimate Std.err\n#&gt; alpha   0.4215 0.09034\n#&gt; Number of clusters:   11  Maximum cluster size: 10\nrfb_gee2 &lt;- geeglm(richness ~ offset(log_AREA) +SPTREAT ,\n            family = poisson(link = \"log\"),\n            data = rfb,\n            id=FIELD,\n            corstr = \"ar1\")\n\n# Wald's Test\nanova(rfb_gee,rfb_gee2)\n\n\n\n\nDf\nX2\nP(&gt;|Chi|)\n\n\n2\n6.885\n0.032\n\n\n\n\n\n\\[\nE(Y_{is})=\\mu_{is}=e^{-0.678+0.0498×DEPTH-0.001×DEPTH^2-0.522×SPTREAT_{is}}\\\\\nvar(Y_{is})= 2.33 × \\mu_{is} \\\\\ncor(Y_{is},Y_{it})=0.422^{|s-t|}\n\\]\n作业相关矩阵 corstr ，比较QIC，一般越小越好。\n\nCodeQIC(rfb_gee)\n#&gt;       QIC      QICu Quasi Lik       CIC    params      QICC \n#&gt;  -467.536  -471.921   239.961     6.193     4.000  -455.536\nQIC(rfb_gee2)\n#&gt;       QIC      QICu Quasi Lik       CIC    params      QICC \n#&gt;  -451.065  -457.436   230.718     5.185     2.000  -447.637\n\n\n\n20.7.1 示例\n\nCodedf &lt;- read_delim(\"data/麻醉诱导时相.txt\")\ndf_long &lt;- df |&gt; pivot_longer(\n    cols = starts_with(\"t\"),\n    names_to = \"time\",\n    values_to = \"SBP\"\n)\n\n\n\nCodeg3 &lt;- geeglm(SBP~ group * time,data = df_long ,id = id,corstr = \"ar1\")\n\ng3\n#&gt; \n#&gt; Call:\n#&gt; geeglm(formula = SBP ~ group * time, data = df_long, id = id, \n#&gt;     corstr = \"ar1\")\n#&gt; \n#&gt; Coefficients:\n#&gt;   (Intercept)        groupB        groupC        timet1        timet2 \n#&gt;         121.0           0.2           5.2          -8.6          -2.6 \n#&gt;        timet3        timet4 groupB:timet1 groupC:timet1 groupB:timet2 \n#&gt;           4.8          -0.2           7.2           5.4          -0.6 \n#&gt; groupC:timet2 groupB:timet3 groupC:timet3 groupB:timet4 groupC:timet4 \n#&gt;          -5.0           2.2          11.6          14.2           4.6 \n#&gt; \n#&gt; Degrees of Freedom: 75 Total (i.e. Null);  60 Residual\n#&gt; \n#&gt; Scale Link:                   identity\n#&gt; Estimated Scale Parameters:  [1] 16.13\n#&gt; \n#&gt; Correlation:  Structure = ar1    Link = identity \n#&gt; Estimated Correlation Parameters:\n#&gt;  alpha \n#&gt; 0.8464 \n#&gt; \n#&gt; Number of clusters:   15   Maximum cluster size: 5\nsummary(g3)\n#&gt; \n#&gt; Call:\n#&gt; geeglm(formula = SBP ~ group * time, data = df_long, id = id, \n#&gt;     corstr = \"ar1\")\n#&gt; \n#&gt;  Coefficients:\n#&gt;               Estimate Std.err    Wald Pr(&gt;|W|)    \n#&gt; (Intercept)    121.000   1.414 7320.50  &lt; 2e-16 ***\n#&gt; groupB           0.200   2.234    0.01  0.92867    \n#&gt; groupC           5.200   2.028    6.58  0.01034 *  \n#&gt; timet1          -8.600   0.921   87.22  &lt; 2e-16 ***\n#&gt; timet2          -2.600   1.315    3.91  0.04794 *  \n#&gt; timet3           4.800   1.180   16.55  4.7e-05 ***\n#&gt; timet4          -0.200   1.213    0.03  0.86907    \n#&gt; groupB:timet1    7.200   1.173   37.67  8.4e-10 ***\n#&gt; groupC:timet1    5.400   2.191    6.08  0.01371 *  \n#&gt; groupB:timet2   -0.600   1.470    0.17  0.68309    \n#&gt; groupC:timet2   -5.000   1.943    6.62  0.01008 *  \n#&gt; groupB:timet3    2.200   1.397    2.48  0.11534    \n#&gt; groupC:timet3   11.600   3.098   14.02  0.00018 ***\n#&gt; groupB:timet4   14.200   1.425   99.23  &lt; 2e-16 ***\n#&gt; groupC:timet4    4.600   2.498    3.39  0.06555 .  \n#&gt; ---\n#&gt; Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n#&gt; \n#&gt; Correlation structure = ar1 \n#&gt; Estimated Scale Parameters:\n#&gt; \n#&gt;             Estimate Std.err\n#&gt; (Intercept)     16.1    4.44\n#&gt;   Link = identity \n#&gt; \n#&gt; Estimated Correlation Parameters:\n#&gt;       Estimate Std.err\n#&gt; alpha    0.846  0.0661\n#&gt; Number of clusters:   15  Maximum cluster size: 5\nQIC(g3)\n#&gt;       QIC      QICu Quasi Lik       CIC    params      QICC \n#&gt;      1240      1240      -605        15        15       968",
    "crumbs": [
      "推断统计模型",
      "<span class='chapter-number'>20</span>  <span class='chapter-title'>广义估计方程</span>"
    ]
  },
  {
    "objectID": "SurvivalAnalysis.html",
    "href": "SurvivalAnalysis.html",
    "title": "\n21  生存分析\n",
    "section": "",
    "text": "21.1 生存函数\n\\[\nS(t)=P(T&gt;t)=1-F(t)=\\int_{t}^{+\\infty}f(x)dx\n\\]\n其中S(t)是累计生存概率或生存率，量化了生存时间大于t的概率。f(x)是密度函数，呈右偏态分布，反映了任意时间点 t 终点事件的瞬时发生率。F(t)=P(T&lt;t)是f(t)在区间[0,t]的累计形式，也称为分布函数或累积函数。",
    "crumbs": [
      "生存分析",
      "<span class='chapter-number'>21</span>  <span class='chapter-title'>生存分析</span>"
    ]
  },
  {
    "objectID": "SurvivalAnalysis.html#风险函数",
    "href": "SurvivalAnalysis.html#风险函数",
    "title": "\n21  生存分析\n",
    "section": "\n21.2 风险函数",
    "text": "21.2 风险函数\n\\[\n\\begin{aligned}\nh(t)=&\\lim_{\\Delta t\\to 0}\\frac{P(t\\le T&lt;t+\\Delta t|T\\ge t)}{\\Delta t}\\\\\n=&\\lim_{\\Delta t\\to 0}\\frac{P(t\\le T&lt;t+\\Delta t\\ \\&\\ T\\ge t)}{\\Delta t·P(T\\ge t) }\\\\\n=&\\lim_{\\Delta t\\to 0}\\frac{S(t)- S(t+\\Delta t)}{\\Delta t·S(t)}\\\\\n=&-\\frac{d(\\ln S(t))}{dt}\n\\end{aligned}\n\\]\n\\[S(t)=e^{-\\int_0^t h(u)du} \\]\n\\[\n\\begin{aligned}\nh(t)\\Delta t=&P(t\\le T&lt;t+\\Delta t|T\\ge t)\n=\\frac{P(t\\le T&lt;t+\\Delta t\\ \\&\\ T\\ge t)}{P(T\\ge t) }\\\\\n=&\\frac{P(t\\le T&lt;t+\\Delta t)}{P(T\\ge t) }\\\\\n=&\\frac{f(t)\\Delta t}{S(t)}\n\\end{aligned}\n\\]\n\\(f(t)=h(t)S(t)\\)",
    "crumbs": [
      "生存分析",
      "<span class='chapter-number'>21</span>  <span class='chapter-title'>生存分析</span>"
    ]
  },
  {
    "objectID": "SurvivalAnalysis.html#乘积极限法",
    "href": "SurvivalAnalysis.html#乘积极限法",
    "title": "\n21  生存分析\n",
    "section": "\n21.3 乘积极限法",
    "text": "21.3 乘积极限法\nproduct limit method 也称为Kaplan-Meier 法。\n\\(t_1&lt;t_2&lt;t_3&lt;...&lt;t_n\\)，样本量大小n，ti 代表个体i发生终点事件或右删失的时间。由于一些个体有相同的生存时间，它们被称为 tied 观测时间，生存时间的个数小于样本量n。\n\n21.3.1 点估计S(t)\n\\(n_1&gt;n_2&gt;n_3&gt;...&gt;n_n\\) ,ni d代表在时间点ti 暴露于特定事件风险的幸存者数量。\n\\(d_i\\) 代表在时间点ti 发生终点事件的数量。（如果没有 tie，di=1或0）\n生存率的KM估计计算公式：\n\\[\n\\hat S(t)=\\prod_{t_i\\le t}\\frac{n_i-d_i}{n_i}\n\\tag{21.1}\\]\nEquation 21.1 包括了删失情况，如果从ti-1 到ti 发生了删失，但没有终点事件，di =0，条件概率等于1。\n\n21.3.2 区间估计S(t)\n(1-α)×100% CI \\([\\hat S(t)-z_{1-\\alpha/2}\\sqrt{Var\\left [\\hat S(t)  \\right]},\\hat S(t)+z_{1-\\alpha/2}\\sqrt{Var\\left [\\hat S(t)  \\right]}]\\)\n其中\\(Var\\left [\\hat S(t)  \\right]=\\hat S(t)^2\\sum_{t_i\\le t}\\frac{d_i}{n_i(n_i-d_i)}\\) (Greenwood method )\n\nCodedf_raw &lt;- tibble(\n    id=1:5,\n    sex=factor(c(\"Male\",\"Male\",\"Female\",\"Male\",\"Female\")),\n    age_years=c(53,62,75,73,61),\n    outcome=c(\"Loss to follow-up\",\"Death\",\"Death\",\"Relapse\",\"Survival\"),\n    time=c(\"37.5+\",44.3,25.3,18.1,\"56.7+\")\n)\ndf &lt;- df_raw |&gt; arrange(time) |&gt; select(id,outcome,time) |&gt; \n    mutate(\n        d_i=if_else(outcome==\"Relapse\"|outcome==\"Death\",1,0),\n        time=parse_number(time),\n    )\ndf\n\n\n\n\nid\noutcome\ntime\nd_i\n\n\n\n4\nRelapse\n18.1\n1\n\n\n3\nDeath\n25.3\n1\n\n\n1\nLoss to follow-up\n37.5\n0\n\n\n2\nDeath\n44.3\n1\n\n\n5\nSurvival\n56.7\n0\n\n\n\n\n\nCode\nlibrary(survminer)\nlibrary(survival)\n\nkm_fit&lt;-survfit(Surv(time,d_i)~1,data=df)\n# t_i\nkm_fit$time\n#&gt; [1] 18.1 25.3 37.5 44.3 56.7\n# d_i\nkm_fit$n.event\n#&gt; [1] 1 1 0 1 0\n# cnesored\nkm_fit$n.censor\n#&gt; [1] 0 0 1 0 1\n# n_i\nkm_fit$n.risk\n#&gt; [1] 5 4 3 2 1\n\n# 生存率\nkm_fit$surv\n#&gt; [1] 0.8 0.6 0.6 0.3 0.3\n\nsummary(km_fit)\n#&gt; Call: survfit(formula = Surv(time, d_i) ~ 1, data = df)\n#&gt; \n#&gt;  time n.risk n.event survival std.err lower 95% CI upper 95% CI\n#&gt;  18.1      5       1      0.8   0.179       0.5161            1\n#&gt;  25.3      4       1      0.6   0.219       0.2933            1\n#&gt;  44.3      2       1      0.3   0.239       0.0631            1",
    "crumbs": [
      "生存分析",
      "<span class='chapter-number'>21</span>  <span class='chapter-title'>生存分析</span>"
    ]
  },
  {
    "objectID": "SurvivalAnalysis.html#单因素分组生存曲线的比较",
    "href": "SurvivalAnalysis.html#单因素分组生存曲线的比较",
    "title": "\n21  生存分析\n",
    "section": "\n21.4 单因素分组生存曲线的比较",
    "text": "21.4 单因素分组生存曲线的比较\n\n\n检验方法\n权重\n\n\n\nlog-rank test\n1\n\n\nWilcoxon test\nnj\n\n\n\nTarone-Ware test\n\\(\\sqrt{n_j}\\)\n\n\nPeto test\n\\(\\hat S(t_j)\\)\n\n\n\n\\[\n\\chi^2=\\frac{\\left(\\sum_jw(t_j)(m_{ij}-e_{ij})\\right)^2}{\\hat {Var}\\left(\\sum_jw(t_j)(m_{ij}-e_{ij})\\right)}\n\\]\n\n21.4.1 log-rank test\n\nH0 :两总体的生存曲线是相同的。\n\n计算当第j次发生终点事件各组终点事件的期望值（e1j ,e2j ）\n\\(e_{1j}=\\left ( \\frac{n_{1j}}{n_{1j}+n_{2j}}\\right)\\times (m_{1j}+m_{2j})\\)\n\\(e_{2j}=\\left ( \\frac{n_{2j}}{n_{1j}+n_{2j}}\\right)\\times (m_{1j}+m_{2j})\\)\n其中mij 表示在第 j 个时间点第 i 组终点事件的数量，nij 表示在第 j 个时间点第 i 组初始观测的数量\n\n\n对所有时间点对终点事件的观测值和期望值的差异求和\n\\(O_i-Ei=\\sum_j(m_{ij}-e_{ij})\\ \\ \\ (i=1,2)\\)\n计算其方差估计值\n\\(\\hat{Var}=\\sum_j\\frac{n_{1j}n_{2j}(m_{1j}+m_{2j})(n_{1j}+n_{2j}-m_{1j}-m_{2j})}{(n_{1j}+n_{2j})^2(n_{1j}+n_{2j}-1)}\\ \\ \\ (i=1,2)\\)\n\n\n计算log-rank test 的检验统计量\n\\[\n\\chi^2=\\frac{(O_1-E_1)^2}{\\hat{Var}(O_1-E_1)} \\ 或者 \\ \\chi^2=\\frac{(O_2-E_2)^2}{\\hat{Var}(O_2-E_2)}\n\\]\n也可以近似估计为\n\\[\n\\chi^2=\\sum_{i=1}^2\\frac{(O_i-E_i)^2}{E_i} \\sim \\chi^2(\\nu=1)\n\\]\n\n\n\nCodedf &lt;- read_csv(\"data/log-rank-survival.csv\")\n\n# 使用 Kaplan-Meier 方法创建一个Surv对象\nsurv_formula &lt;- Surv(Days,status)~treatment\n\nkm&lt;-survfit(surv_formula,data=df)\nsummary(km)\n#&gt; Call: survfit(formula = surv_formula, data = df)\n#&gt; \n#&gt;                 treatment=CON \n#&gt;  time n.risk n.event survival std.err lower 95% CI upper 95% CI\n#&gt;    11     14       1   0.9286  0.0688       0.8030        1.000\n#&gt;    13     13       1   0.8571  0.0935       0.6921        1.000\n#&gt;    14     12       2   0.7143  0.1207       0.5129        0.995\n#&gt;    15     10       1   0.6429  0.1281       0.4351        0.950\n#&gt;    17      9       3   0.4286  0.1323       0.2341        0.785\n#&gt;    20      6       2   0.2857  0.1207       0.1248        0.654\n#&gt;    21      4       2   0.1429  0.0935       0.0396        0.515\n#&gt;    25      2       1   0.0714  0.0688       0.0108        0.472\n#&gt;    27      1       1   0.0000     NaN           NA           NA\n#&gt; \n#&gt;                 treatment=DPVB \n#&gt;  time n.risk n.event survival std.err lower 95% CI upper 95% CI\n#&gt;    20     14       1    0.929  0.0688        0.803        1.000\n#&gt;    23     13       1    0.857  0.0935        0.692        1.000\n#&gt;    27     12       1    0.786  0.1097        0.598        1.000\n#&gt;    28     11       1    0.714  0.1207        0.513        0.995\n#&gt;    30     10       1    0.643  0.1281        0.435        0.950\n#&gt;    32      9       1    0.571  0.1323        0.363        0.899\n#&gt;    38      8       1    0.500  0.1336        0.296        0.844\n#&gt;    39      7       1    0.429  0.1323        0.234        0.785\n#&gt;    45      6       1    0.357  0.1281        0.177        0.721\n#&gt; \n#&gt;                 treatment=LDRT \n#&gt;  time n.risk n.event survival std.err lower 95% CI upper 95% CI\n#&gt;    13     14       2   0.8571  0.0935       0.6921        1.000\n#&gt;    15     12       1   0.7857  0.1097       0.5977        1.000\n#&gt;    16     11       1   0.7143  0.1207       0.5129        0.995\n#&gt;    18     10       1   0.6429  0.1281       0.4351        0.950\n#&gt;    19      9       2   0.5000  0.1336       0.2961        0.844\n#&gt;    20      7       3   0.2857  0.1207       0.1248        0.654\n#&gt;    24      4       1   0.2143  0.1097       0.0786        0.584\n#&gt;    25      3       1   0.1429  0.0935       0.0396        0.515\n#&gt;    27      2       1   0.0714  0.0688       0.0108        0.472\n#&gt;    30      1       1   0.0000     NaN           NA           NA\n#&gt; \n#&gt;                 treatment=LR_DPVB \n#&gt;  time n.risk n.event survival std.err lower 95% CI upper 95% CI\n#&gt;    30     14       1    0.929  0.0688        0.803            1\n#&gt;    40     13       1    0.857  0.0935        0.692            1\n\n# 执行Log-rank检验\nlogrank_test &lt;- survdiff(surv_formula,data = df,subset = T,na.action = \"na.omit\")\nlogrank_test$chisq\n#&gt; [1] 58.43627\nlogrank_test$pvalue\n#&gt; [1] 1.268397e-12",
    "crumbs": [
      "生存分析",
      "<span class='chapter-number'>21</span>  <span class='chapter-title'>生存分析</span>"
    ]
  },
  {
    "objectID": "CoxProportionalHazardsModel.html",
    "href": "CoxProportionalHazardsModel.html",
    "title": "\n22  Cox比例风险模型\n",
    "section": "",
    "text": "22.1 风险函数\n\\[\n\\begin{aligned} h(t)=&\\lim_{\\Delta t\\to 0}\\frac{P(t\\le T&lt;t+\\Delta t|T\\ge t)}{\\Delta t}\\\\ =&\\lim_{\\Delta t\\to 0}\\frac{P(t\\le T&lt;t+\\Delta t\\ \\&\\ T\\ge t)}{\\Delta t·P(T\\ge t) }\\\\ =&\\lim_{\\Delta t\\to 0}\\frac{S(t)- S(t+\\Delta t)}{\\Delta t·S(t)}\\\\ =&-\\frac{d(\\ln S(t))}{dt} \\end{aligned}\n\\]",
    "crumbs": [
      "生存分析",
      "<span class='chapter-number'>22</span>  <span class='chapter-title'>Cox比例风险模型</span>"
    ]
  },
  {
    "objectID": "CoxProportionalHazardsModel.html#风险率",
    "href": "CoxProportionalHazardsModel.html#风险率",
    "title": "\n22  Cox比例风险模型\n",
    "section": "\n22.2 风险率",
    "text": "22.2 风险率\n对于有风险因子\\(x_1,x_2,...,x_k\\) 的个体在时间 t 的风险率\\(h(t|x_1,x_2,...,x_k)\\)\n\\[ h(t|x_1,x_2,...,x_k)=h_0(t)g(x_1,x_2,...,x_k)=h_0(t)exp(\\sum_{j=1}^k\\beta_jx_j) \\]\n其中\n\n\\(h0 (t)\\)是给定所有风险因子（协变量）为零的随时间变化的基线风险函数。\n\\(g(X)\\)是k个独立风险因子的集合函数，代表变量的风险效应。\n\\(β_j\\)是部分回归系数，表示风险比的比例变化。",
    "crumbs": [
      "生存分析",
      "<span class='chapter-number'>22</span>  <span class='chapter-title'>Cox比例风险模型</span>"
    ]
  },
  {
    "objectID": "CoxProportionalHazardsModel.html#比例风险假设",
    "href": "CoxProportionalHazardsModel.html#比例风险假设",
    "title": "\n22  Cox比例风险模型\n",
    "section": "\n22.3 比例风险假设",
    "text": "22.3 比例风险假设\n（proportional hazards assumption）\n\\[ \\frac{h(t)}{h_0(t)}=exp(\\sum_{j=1}^k\\beta_jx_j) \\]",
    "crumbs": [
      "生存分析",
      "<span class='chapter-number'>22</span>  <span class='chapter-title'>Cox比例风险模型</span>"
    ]
  },
  {
    "objectID": "CoxProportionalHazardsModel.html#风险比hazard-ratio",
    "href": "CoxProportionalHazardsModel.html#风险比hazard-ratio",
    "title": "\n22  Cox比例风险模型\n",
    "section": "\n22.4 风险比（hazard ratio）",
    "text": "22.4 风险比（hazard ratio）\n假设有两个个体，分别具有独立变量，两个个体的风险函数之比称为风险比\n\\[ HR=\\frac{h(t|x_1,x_2,...,x_k)}{h(t|x_1^*,x_2^*,...,x_k^*)}=exp(\\sum_{j=1}^k\\beta_j(x_j-x_j^*)) \\]\n\nCodedf &lt;- read_csv(\"data/log-rank-survival.csv\")\n\n\nlibrary(survminer)\nlibrary(survival)\n# 使用 Kaplan-Meier 方法创建一个Surv对象\nsurv_formula &lt;- Surv(Days,status)~treatment\n\n# 拟合Cox比例风险模型 \ncox_model &lt;- coxph(surv_formula, data = df)  \n# 查看模型结果 \nsummary(cox_model)  \n#&gt; Call:\n#&gt; coxph(formula = surv_formula, data = df)\n#&gt; \n#&gt;   n= 56, number of events= 39 \n#&gt; \n#&gt;                       coef exp(coef)  se(coef)      z Pr(&gt;|z|)    \n#&gt; treatmentDPVB    -2.740141  0.064561  0.580664 -4.719 2.37e-06 ***\n#&gt; treatmentLDRT    -0.383558  0.681432  0.387499 -0.990    0.322    \n#&gt; treatmentLR_DPVB -4.632850  0.009727  0.878661 -5.273 1.34e-07 ***\n#&gt; ---\n#&gt; Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n#&gt; \n#&gt;                  exp(coef) exp(-coef) lower .95 upper .95\n#&gt; treatmentDPVB     0.064561     15.489  0.020688   0.20148\n#&gt; treatmentLDRT     0.681432      1.467  0.318848   1.45634\n#&gt; treatmentLR_DPVB  0.009727    102.807  0.001738   0.05444\n#&gt; \n#&gt; Concordance= 0.822  (se = 0.025 )\n#&gt; Likelihood ratio test= 61.41  on 3 df,   p=3e-13\n#&gt; Wald test            = 36.01  on 3 df,   p=7e-08\n#&gt; Score (logrank) test = 60.47  on 3 df,   p=5e-13\n# 检查比例风险假设 \ncox.zph(cox_model)\n#&gt;           chisq df    p\n#&gt; treatment 0.833  3 0.84\n#&gt; GLOBAL    0.833  3 0.84\n\n\n\n22.4.1 模型系数的估计\n条件死亡概率和局部似然函数方法\n\\[ \\ln L_p(\\beta)=\\sum_{i=1}^{d}\\left[ \\sum_{j=1}^k\\beta_jx_{ij}-\\ln\\sum_{m\\in R_i}exp( \\sum_{j=1}^k\\beta_jx_{mj})         \\right] \\]\nNewton-Raphson iterative method\n\\[  \\begin{cases}  \\frac{\\partial \\ln L_p(\\beta)}{\\partial \\beta_1}=0\\\\ \\frac{\\partial \\ln L_p(\\beta)}{\\partial \\beta_2}=0\\\\ \\vdots\\\\ \\frac{\\partial \\ln L_p(\\beta)}{\\partial \\beta_k}=0\\\\ \\end{cases} \\]\n\n22.4.2 模型系数的假设检验\n\n\nWald‘s test\n检验是否有独立变量需要被消除，统计量\\(Z=b_j/S_{b_j}\\)\n当样本量足够大时，Z服从标准正态分布，Z2 服从自由度为1 的\\(\\chi^2\\) 分布\n\\[ \\chi^2_W=(b_j/S_{b_j})^2\\sim \\chi^2(1) \\]\n\n\nPartial likelihood Ratio test\n主要用于非显著性变量的消除，新变量的引入和模型的比较。\n\\[ \\chi^2_{LR}=2\\left[ \\ln L_p(\\beta_k)-\\ln L_p(\\beta_{k-1}) \\right]\\sim\\chi^2(1) \\]\n其中分别是包含 k 个和 k-1 个（不包含要检验的第 j 个变量）独立变量的对数局部似然函数",
    "crumbs": [
      "生存分析",
      "<span class='chapter-number'>22</span>  <span class='chapter-title'>Cox比例风险模型</span>"
    ]
  },
  {
    "objectID": "PropensityScore.html",
    "href": "PropensityScore.html",
    "title": "倾向性评分",
    "section": "",
    "text": "加权（Weighting）\n……",
    "crumbs": [
      "倾向性评分"
    ]
  },
  {
    "objectID": "PropensityScore.html#回归",
    "href": "PropensityScore.html#回归",
    "title": "倾向性评分",
    "section": "回归",
    "text": "回归\n……",
    "crumbs": [
      "倾向性评分"
    ]
  },
  {
    "objectID": "PropensityScore.html#psapsa_shiny",
    "href": "PropensityScore.html#psapsa_shiny",
    "title": "倾向性评分",
    "section": "psa::psa_shiny()",
    "text": "psa::psa_shiny()\n\nCodepsa::psa_shiny()",
    "crumbs": [
      "倾向性评分"
    ]
  },
  {
    "objectID": "stratification.html",
    "href": "stratification.html",
    "title": "\n23  分层（Stratification）\n",
    "section": "",
    "text": "23.1 估计倾向得分（逻辑回归）\nCodedata(lalonde, package='Matching')\nglimpse(lalonde)\n#&gt; Rows: 445\n#&gt; Columns: 12\n#&gt; $ age     &lt;int&gt; 37, 22, 30, 27, 33, 22, 23, 32, 22, 33, 19, 21, 18, 27, 17, 19…\n#&gt; $ educ    &lt;int&gt; 11, 9, 12, 11, 8, 9, 12, 11, 16, 12, 9, 13, 8, 10, 7, 10, 13, …\n#&gt; $ black   &lt;int&gt; 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,…\n#&gt; $ hisp    &lt;int&gt; 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,…\n#&gt; $ married &lt;int&gt; 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0,…\n#&gt; $ nodegr  &lt;int&gt; 1, 1, 0, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1, 0, 1, 0, 0, 1,…\n#&gt; $ re74    &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,…\n#&gt; $ re75    &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,…\n#&gt; $ re78    &lt;dbl&gt; 9930.05, 3595.89, 24909.50, 7506.15, 289.79, 4056.49, 0.00, 84…\n#&gt; $ u74     &lt;int&gt; 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,…\n#&gt; $ u75     &lt;int&gt; 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,…\n#&gt; $ treat   &lt;int&gt; 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,…\n\nlalonde_formu &lt;- treat ~ age + I(age^2) + educ + I(educ^2) + black +\n    hisp + married + nodegr + re74  + I(re74^2) + re75 + I(re75^2)\nlr_out &lt;- glm(formula = lalonde_formu,\n              data = lalonde,\n              family = binomial(link = 'logit'))\n倾向性得分就是模型的拟合值，检查倾向得分的分布，以确保我们有良好的重叠\nCodelalonde$lr_ps &lt;- fitted(lr_out)\n\nggplot(lalonde, aes(x = lr_ps, color = as.logical(treat))) + \n    geom_density() +\n    xlab('Propensity Score')",
    "crumbs": [
      "倾向性评分",
      "<span class='chapter-number'>23</span>  <span class='chapter-title'>分层（Stratification）</span>"
    ]
  },
  {
    "objectID": "stratification.html#估计倾向得分逻辑回归",
    "href": "stratification.html#估计倾向得分逻辑回归",
    "title": "\n23  分层（Stratification）\n",
    "section": "",
    "text": "23.1.1 分层\n根据倾向分数使用五分位数进行分层\n\nCodebreaks5 &lt;- psa::get_strata_breaks(lalonde$lr_ps)\nstr(breaks5)\n#&gt; List of 2\n#&gt;  $ breaks: Named num [1:6] 0.0849 0.3403 0.3594 0.408 0.5112 ...\n#&gt;   ..- attr(*, \"names\")= chr [1:6] \"0%\" \"20%\" \"40%\" \"60%\" ...\n#&gt;  $ labels:'data.frame':  5 obs. of  4 variables:\n#&gt;   ..$ strata: chr [1:5] \"A\" \"B\" \"C\" \"D\" ...\n#&gt;   ..$ xmin  : num [1:5] 0.0849 0.3403 0.3594 0.408 0.5112\n#&gt;   ..$ xmax  : num [1:5] 0.34 0.359 0.408 0.511 0.83\n#&gt;   ..$ xmid  : num [1:5] 0.213 0.35 0.384 0.46 0.671\n\nlalonde$lr_strata5 &lt;- cut(x = lalonde$lr_ps, \n                          breaks = breaks5$breaks, \n                          include.lowest = TRUE, \n                          labels = breaks5$labels$strata)\ntable(lalonde$treat, lalonde$lr_strata5)\n#&gt;    \n#&gt;      A  B  C  D  E\n#&gt;   0 66 61 51 42 40\n#&gt;   1 23 28 38 47 49\n\n\n\nCodeggplot(lalonde, aes(x = lr_ps, color = as.logical(treat))) + \n    geom_density(aes(fill = as.logical(treat)), alpha = 0.2) +\n    geom_vline(xintercept = breaks5$breaks, alpha = 0.5) +\n    geom_text(data = breaks5$labels, \n              aes(x = xmid, y = 0, label = strata),\n              color = 'black', vjust = 1) +\n    xlab('Propensity Score') + ylab('Density') +\n    xlim(c(0, 1))\n\n\n\n\n\n\n\n\nCodeggplot() +\n    geom_vline(xintercept = breaks5$breaks) +\n    geom_point(data = lalonde, aes(x = lr_ps, y = log(re78 + 1), color = as.logical(treat)), alpha = 0.5) +\n    geom_text(data = breaks5$labels, aes(x = xmid, y = 0, label = strata), color = 'black', vjust = 1) +\n    xlab('Propensity Score')\n\n\n\n\n\n\n\n\n23.1.2 查看平衡混杂效应\n\nCodecovars &lt;- all.vars(lalonde_formu)\ncovars &lt;- lalonde[,covars[-1]]\nPSAgraphics::cv.bal.psa(covariates = covars, \n                        treatment = lalonde$treat,\n                        propensity = lalonde$lr_ps,\n                        strata = lalonde$lr_strata)\n\n\n\n\n\n\n\n\n23.1.2.1 数值变量的协变量平衡图\n\nCodePSAgraphics::box.psa(continuous = lalonde$age, \n                     treatment = lalonde$treat, \n                     strata = lalonde$lr_strata,\n                     xlab = \"Strata\", \n                     balance = FALSE,\n                     main = 'Covariate: age')\n\n\n\n\n\n\n\n\n23.1.2.2 分类变量的协变量平衡图\n\nCodePSAgraphics::cat.psa(categorical = lalonde$nodegr, \n                     treatment = lalonde$treat, \n                     strata = lalonde$lr_strata, \n                     xlab = 'Strata',\n                     balance = FALSE,\n                     main = 'Covariate: nodegr')\n\n\n\n\n\n\n#&gt; $`treatment:stratum.proportions`\n#&gt;   0:A 1:A 0:B   1:B   0:C 1:C   0:D   1:D   0:E   1:E\n#&gt; 0   0   0   0 0.036 0.039   0 0.333 0.383 0.675 0.714\n#&gt; 1   1   1   1 0.964 0.961   1 0.667 0.617 0.325 0.286",
    "crumbs": [
      "倾向性评分",
      "<span class='chapter-number'>23</span>  <span class='chapter-title'>分层（Stratification）</span>"
    ]
  },
  {
    "objectID": "stratification.html#估计因果效应",
    "href": "stratification.html#估计因果效应",
    "title": "\n23  分层（Stratification）\n",
    "section": "\n23.2 估计因果效应",
    "text": "23.2 估计因果效应\n\nCodePSAgraphics::loess.psa(response = log(lalonde$re78 + 1),\n                       treatment = lalonde$treat,\n                       propensity = lalonde$lr_ps)\n\n\n\n\n\n\n#&gt; $ATE\n#&gt; [1] 0.9008386\n#&gt; \n#&gt; $se.wtd\n#&gt; [1] 0.3913399\n#&gt; \n#&gt; $CI95\n#&gt; [1] 0.1181588 1.6835185\n#&gt; \n#&gt; $summary.strata\n#&gt;    counts.0 counts.1  means.0  means.1 diff.means\n#&gt; 1        34       11 6.268705 6.474912  0.2062076\n#&gt; 2        32       12 5.491717 5.659280  0.1675631\n#&gt; 3        31       14 5.467712 5.703584  0.2358722\n#&gt; 4        30       14 5.425593 5.747613  0.3220194\n#&gt; 5        27       18 5.397146 5.831117  0.4339703\n#&gt; 6        24       20 5.302660 6.339721  1.0370619\n#&gt; 7        21       23 5.125331 6.607936  1.4826043\n#&gt; 8        21       24 5.036908 6.594808  1.5578999\n#&gt; 9        22       22 5.182703 6.981383  1.7986801\n#&gt; 10       18       27 6.047529 7.820786  1.7732573\n\npsa::loess_plot(ps = lalonde$lr_ps,\n                outcome = log(lalonde$re78 + 1),\n                treatment = lalonde$treat == 1,\n                outcomeTitle = 'log(re78)',\n                \n                plot.strata = 5,\n                points.treat.alpha = 0.5,\n                points.control.alpha = 0.5,\n                percentPoints.treat = 1,\n                percentPoints.control = 1,\n                se = FALSE, \n                method = 'loess')\n\n\n\n\n\n\n\n\nCodePSAgraphics::circ.psa(response = log(lalonde$re78 + 1), \n                      treatment = lalonde$treat == 1, \n                      strata = lalonde$lr_strata5)\n\n\n\n\n\n\n#&gt; $summary.strata\n#&gt;   n.FALSE n.TRUE means.FALSE means.TRUE\n#&gt; A      66     23    6.280406   6.600537\n#&gt; B      61     28    4.409935   5.129193\n#&gt; C      51     38    6.212981   6.455034\n#&gt; D      42     47    4.705981   6.208840\n#&gt; E      40     49    5.783529   7.576461\n#&gt; \n#&gt; $wtd.Mn.FALSE\n#&gt; [1] 5.478567\n#&gt; \n#&gt; $wtd.Mn.TRUE\n#&gt; [1] 6.394013\n#&gt; \n#&gt; $ATE\n#&gt; [1] 0.9154463\n#&gt; \n#&gt; $se.wtd\n#&gt; [1] 0.394155\n#&gt; \n#&gt; $approx.t\n#&gt; [1] 2.322554\n#&gt; \n#&gt; $df\n#&gt; [1] 435\n#&gt; \n#&gt; $CI.95\n#&gt; [1] 0.1407612 1.6901314",
    "crumbs": [
      "倾向性评分",
      "<span class='chapter-number'>23</span>  <span class='chapter-title'>分层（Stratification）</span>"
    ]
  },
  {
    "objectID": "stratification.html#敏感性分析",
    "href": "stratification.html#敏感性分析",
    "title": "\n23  分层（Stratification）\n",
    "section": "\n23.3 敏感性分析",
    "text": "23.3 敏感性分析\n评估该效果的稳健性\n\n23.3.1 估计倾向得分（分类树）\n\nCodelibrary(tree)\ntree_out &lt;- tree::tree(lalonde_formu,\n                       data = lalonde)\n\nplot(tree_out); text(tree_out)\n\n\n\n\n\n\nCode\n\nlalonde$tree_ps &lt;- predict(tree_out)\ntable(lalonde$tree_ps, lalonde$treat, useNA = 'ifany')\n#&gt;                    \n#&gt;                       0   1\n#&gt;   0.332             167  83\n#&gt;   0.344827586206897  19  10\n#&gt;   0.351851851851852  35  19\n#&gt;   0.612903225806452  24  38\n#&gt;   0.659090909090909  15  29\n#&gt;   1                   0   6\nlalonde$tree_strata &lt;- predict(tree_out, type = 'where')\ntable(lalonde$tree_strata, lalonde$treat, useNA = 'ifany')\n#&gt;     \n#&gt;        0   1\n#&gt;   3  167  83\n#&gt;   5   15  29\n#&gt;   6   35  19\n#&gt;   9   24  38\n#&gt;   10  19  10\n#&gt;   11   0   6",
    "crumbs": [
      "倾向性评分",
      "<span class='chapter-number'>23</span>  <span class='chapter-title'>分层（Stratification）</span>"
    ]
  },
  {
    "objectID": "matching.html",
    "href": "matching.html",
    "title": "\n24  匹配（Matching）\n",
    "section": "",
    "text": "24.1 数据来源\nhttps://hbiostat.org/data/\nhttps://hbiostat.org/data/repo/rhc\nCoderhc &lt;- read_csv(\"data/PS/rhc.csv\")\n\nrhc %&gt;% \n    select(age, sex, race, edu, income, ninsclas, cat1,das2d3pc, dnr1, \n           ca, surv2md1, aps1, scoma1, wtkilo1, temp1, meanbp1, resp1,\n           hrt1, pafi1, paco21, ph1, wblc1, hema1, sod1, pot1, crea1,\n           bili1, alb1, resp, card, neuro, gastr, renal, meta, hema,\n           seps, trauma, ortho, cardiohx, chfhx, dementhx, psychhx,\n           chrpulhx, renalhx, liverhx, gibledhx, malighx, immunhx, \n           transhx, amihx, swang1) %&gt;% \n    mutate(\n        across(where(is.character), as.factor),\n        across(ends_with(\"hx\"), as.factor)\n    )-&gt;\n    rhc2\nrhc2 %&gt;% select(where(is.factor)) %&gt;% \n    map(table)\n#&gt; $sex\n#&gt; \n#&gt; Female   Male \n#&gt;   2543   3192 \n#&gt; \n#&gt; $race\n#&gt; \n#&gt; black other white \n#&gt;   920   355  4460 \n#&gt; \n#&gt; $income\n#&gt; \n#&gt;   $11-$25k   $25-$50k     &gt; $50k Under $11k \n#&gt;       1165        893        451       3226 \n#&gt; \n#&gt; $ninsclas\n#&gt; \n#&gt;            Medicaid            Medicare Medicare & Medicaid        No insurance \n#&gt;                 647                1458                 374                 322 \n#&gt;             Private  Private & Medicare \n#&gt;                1698                1236 \n#&gt; \n#&gt; $cat1\n#&gt; \n#&gt;               ARF               CHF         Cirrhosis      Colon Cancer \n#&gt;              2490               456               224                 7 \n#&gt;              Coma              COPD       Lung Cancer MOSF w/Malignancy \n#&gt;               436               457                39               399 \n#&gt;     MOSF w/Sepsis \n#&gt;              1227 \n#&gt; \n#&gt; $dnr1\n#&gt; \n#&gt;   No  Yes \n#&gt; 5081  654 \n#&gt; \n#&gt; $ca\n#&gt; \n#&gt; Metastatic         No        Yes \n#&gt;        384       4379        972 \n#&gt; \n#&gt; $resp\n#&gt; \n#&gt;   No  Yes \n#&gt; 3622 2113 \n#&gt; \n#&gt; $card\n#&gt; \n#&gt;   No  Yes \n#&gt; 3804 1931 \n#&gt; \n#&gt; $neuro\n#&gt; \n#&gt;   No  Yes \n#&gt; 5042  693 \n#&gt; \n#&gt; $gastr\n#&gt; \n#&gt;   No  Yes \n#&gt; 4793  942 \n#&gt; \n#&gt; $renal\n#&gt; \n#&gt;   No  Yes \n#&gt; 5440  295 \n#&gt; \n#&gt; $meta\n#&gt; \n#&gt;   No  Yes \n#&gt; 5470  265 \n#&gt; \n#&gt; $hema\n#&gt; \n#&gt;   No  Yes \n#&gt; 5381  354 \n#&gt; \n#&gt; $seps\n#&gt; \n#&gt;   No  Yes \n#&gt; 4704 1031 \n#&gt; \n#&gt; $trauma\n#&gt; \n#&gt;   No  Yes \n#&gt; 5683   52 \n#&gt; \n#&gt; $ortho\n#&gt; \n#&gt;   No  Yes \n#&gt; 5728    7 \n#&gt; \n#&gt; $cardiohx\n#&gt; \n#&gt;    0    1 \n#&gt; 4722 1013 \n#&gt; \n#&gt; $chfhx\n#&gt; \n#&gt;    0    1 \n#&gt; 4714 1021 \n#&gt; \n#&gt; $dementhx\n#&gt; \n#&gt;    0    1 \n#&gt; 5171  564 \n#&gt; \n#&gt; $psychhx\n#&gt; \n#&gt;    0    1 \n#&gt; 5349  386 \n#&gt; \n#&gt; $chrpulhx\n#&gt; \n#&gt;    0    1 \n#&gt; 4646 1089 \n#&gt; \n#&gt; $renalhx\n#&gt; \n#&gt;    0    1 \n#&gt; 5480  255 \n#&gt; \n#&gt; $liverhx\n#&gt; \n#&gt;    0    1 \n#&gt; 5334  401 \n#&gt; \n#&gt; $gibledhx\n#&gt; \n#&gt;    0    1 \n#&gt; 5550  185 \n#&gt; \n#&gt; $malighx\n#&gt; \n#&gt;    0    1 \n#&gt; 4419 1316 \n#&gt; \n#&gt; $immunhx\n#&gt; \n#&gt;    0    1 \n#&gt; 4192 1543 \n#&gt; \n#&gt; $transhx\n#&gt; \n#&gt;    0    1 \n#&gt; 5073  662 \n#&gt; \n#&gt; $amihx\n#&gt; \n#&gt;    0    1 \n#&gt; 5535  200 \n#&gt; \n#&gt; $swang1\n#&gt; \n#&gt; No RHC    RHC \n#&gt;   3551   2184\n\nrhc2 %&gt;% select(where(is.numeric)) %&gt;% \n    summary()\n#&gt;       age              edu           das2d3pc        surv2md1     \n#&gt;  Min.   : 18.04   Min.   : 0.00   Min.   :11.00   Min.   :0.0000  \n#&gt;  1st Qu.: 50.15   1st Qu.:10.00   1st Qu.:16.06   1st Qu.:0.4709  \n#&gt;  Median : 64.05   Median :12.00   Median :19.75   Median :0.6280  \n#&gt;  Mean   : 61.38   Mean   :11.68   Mean   :20.50   Mean   :0.5925  \n#&gt;  3rd Qu.: 73.93   3rd Qu.:13.00   3rd Qu.:23.43   3rd Qu.:0.7430  \n#&gt;  Max.   :101.85   Max.   :30.00   Max.   :33.00   Max.   :0.9620  \n#&gt;       aps1            scoma1       wtkilo1           temp1      \n#&gt;  Min.   :  3.00   Min.   :  0   Min.   :  0.00   Min.   :27.00  \n#&gt;  1st Qu.: 41.00   1st Qu.:  0   1st Qu.: 56.30   1st Qu.:36.09  \n#&gt;  Median : 54.00   Median :  0   Median : 70.00   Median :38.09  \n#&gt;  Mean   : 54.67   Mean   : 21   Mean   : 67.83   Mean   :37.62  \n#&gt;  3rd Qu.: 67.00   3rd Qu.: 41   3rd Qu.: 83.70   3rd Qu.:39.00  \n#&gt;  Max.   :147.00   Max.   :100   Max.   :244.00   Max.   :43.00  \n#&gt;     meanbp1           resp1             hrt1           pafi1      \n#&gt;  Min.   :  0.00   Min.   :  0.00   Min.   :  0.0   Min.   : 11.6  \n#&gt;  1st Qu.: 50.00   1st Qu.: 14.00   1st Qu.: 97.0   1st Qu.:133.3  \n#&gt;  Median : 63.00   Median : 30.00   Median :124.0   Median :202.5  \n#&gt;  Mean   : 78.52   Mean   : 28.09   Mean   :115.2   Mean   :222.3  \n#&gt;  3rd Qu.:115.00   3rd Qu.: 38.00   3rd Qu.:141.0   3rd Qu.:316.6  \n#&gt;  Max.   :259.00   Max.   :100.00   Max.   :250.0   Max.   :937.5  \n#&gt;      paco21            ph1            wblc1             hema1      \n#&gt;  Min.   :  1.00   Min.   :6.579   Min.   :  0.000   Min.   : 2.00  \n#&gt;  1st Qu.: 31.00   1st Qu.:7.340   1st Qu.:  8.398   1st Qu.:26.10  \n#&gt;  Median : 37.00   Median :7.400   Median : 14.100   Median :30.00  \n#&gt;  Mean   : 38.75   Mean   :7.388   Mean   : 15.645   Mean   :31.87  \n#&gt;  3rd Qu.: 42.00   3rd Qu.:7.460   3rd Qu.: 20.049   3rd Qu.:36.30  \n#&gt;  Max.   :156.00   Max.   :7.770   Max.   :192.000   Max.   :66.19  \n#&gt;       sod1            pot1            crea1              bili1         \n#&gt;  Min.   :101.0   Min.   : 1.100   Min.   : 0.09999   Min.   : 0.09999  \n#&gt;  1st Qu.:132.0   1st Qu.: 3.400   1st Qu.: 1.00000   1st Qu.: 0.79993  \n#&gt;  Median :136.0   Median : 3.800   Median : 1.50000   Median : 1.00977  \n#&gt;  Mean   :136.8   Mean   : 4.067   Mean   : 2.13302   Mean   : 2.26707  \n#&gt;  3rd Qu.:142.0   3rd Qu.: 4.600   3rd Qu.: 2.39990   3rd Qu.: 1.39990  \n#&gt;  Max.   :178.0   Max.   :11.898   Max.   :25.09766   Max.   :58.19531  \n#&gt;       alb1       \n#&gt;  Min.   : 0.300  \n#&gt;  1st Qu.: 2.600  \n#&gt;  Median : 3.500  \n#&gt;  Mean   : 3.093  \n#&gt;  3rd Qu.: 3.500  \n#&gt;  Max.   :29.000\n\n\n\nlibrary(tableone)\n\nCreateTableOne(strata = \"swang1\",\n               data = rhc2\n                ) %&gt;% print(.,showAllLevels = T,smd = T, addOverall = T)\n#&gt;                       Stratified by swang1\n#&gt;                        level               No RHC          RHC            \n#&gt;   n                                          3551            2184         \n#&gt;   age (mean (SD))                           61.76 (17.29)   60.75 (15.63) \n#&gt;   sex (%)              Female                1637 ( 46.1)     906 ( 41.5) \n#&gt;                        Male                  1914 ( 53.9)    1278 ( 58.5) \n#&gt;   race (%)             black                  585 ( 16.5)     335 ( 15.3) \n#&gt;                        other                  213 (  6.0)     142 (  6.5) \n#&gt;                        white                 2753 ( 77.5)    1707 ( 78.2) \n#&gt;   edu (mean (SD))                           11.57 (3.13)    11.86 (3.16)  \n#&gt;   income (%)           $11-$25k               713 ( 20.1)     452 ( 20.7) \n#&gt;                        $25-$50k               500 ( 14.1)     393 ( 18.0) \n#&gt;                        &gt; $50k                 257 (  7.2)     194 (  8.9) \n#&gt;                        Under $11k            2081 ( 58.6)    1145 ( 52.4) \n#&gt;   ninsclas (%)         Medicaid               454 ( 12.8)     193 (  8.8) \n#&gt;                        Medicare               947 ( 26.7)     511 ( 23.4) \n#&gt;                        Medicare & Medicaid    251 (  7.1)     123 (  5.6) \n#&gt;                        No insurance           186 (  5.2)     136 (  6.2) \n#&gt;                        Private                967 ( 27.2)     731 ( 33.5) \n#&gt;                        Private & Medicare     746 ( 21.0)     490 ( 22.4) \n#&gt;   cat1 (%)             ARF                   1581 ( 44.5)     909 ( 41.6) \n#&gt;                        CHF                    247 (  7.0)     209 (  9.6) \n#&gt;                        Cirrhosis              175 (  4.9)      49 (  2.2) \n#&gt;                        Colon Cancer             6 (  0.2)       1 (  0.0) \n#&gt;                        Coma                   341 (  9.6)      95 (  4.3) \n#&gt;                        COPD                   399 ( 11.2)      58 (  2.7) \n#&gt;                        Lung Cancer             34 (  1.0)       5 (  0.2) \n#&gt;                        MOSF w/Malignancy      241 (  6.8)     158 (  7.2) \n#&gt;                        MOSF w/Sepsis          527 ( 14.8)     700 ( 32.1) \n#&gt;   das2d3pc (mean (SD))                      20.37 (5.48)    20.70 (5.03)  \n#&gt;   dnr1 (%)             No                    3052 ( 85.9)    2029 ( 92.9) \n#&gt;                        Yes                    499 ( 14.1)     155 (  7.1) \n#&gt;   ca (%)               Metastatic             261 (  7.4)     123 (  5.6) \n#&gt;                        No                    2652 ( 74.7)    1727 ( 79.1) \n#&gt;                        Yes                    638 ( 18.0)     334 ( 15.3) \n#&gt;   surv2md1 (mean (SD))                       0.61 (0.19)     0.57 (0.20)  \n#&gt;   aps1 (mean (SD))                          50.93 (18.81)   60.74 (20.27) \n#&gt;   scoma1 (mean (SD))                        22.25 (31.37)   18.97 (28.26) \n#&gt;   wtkilo1 (mean (SD))                       65.04 (29.50)   72.36 (27.73) \n#&gt;   temp1 (mean (SD))                         37.63 (1.74)    37.59 (1.83)  \n#&gt;   meanbp1 (mean (SD))                       84.87 (38.87)   68.20 (34.24) \n#&gt;   resp1 (mean (SD))                         28.98 (13.95)   26.65 (14.17) \n#&gt;   hrt1 (mean (SD))                         112.87 (40.94)  118.93 (41.47) \n#&gt;   pafi1 (mean (SD))                        240.63 (116.66) 192.43 (105.54)\n#&gt;   paco21 (mean (SD))                        39.95 (14.24)   36.79 (10.97) \n#&gt;   ph1 (mean (SD))                            7.39 (0.11)     7.38 (0.11)  \n#&gt;   wblc1 (mean (SD))                         15.26 (11.41)   16.27 (12.55) \n#&gt;   hema1 (mean (SD))                         32.70 (8.79)    30.51 (7.42)  \n#&gt;   sod1 (mean (SD))                         137.04 (7.68)   136.33 (7.60)  \n#&gt;   pot1 (mean (SD))                           4.08 (1.04)     4.05 (1.01)  \n#&gt;   crea1 (mean (SD))                          1.92 (2.03)     2.47 (2.05)  \n#&gt;   bili1 (mean (SD))                          2.00 (4.43)     2.71 (5.33)  \n#&gt;   alb1 (mean (SD))                           3.16 (0.67)     2.98 (0.93)  \n#&gt;   resp (%)             No                    2070 ( 58.3)    1552 ( 71.1) \n#&gt;                        Yes                   1481 ( 41.7)     632 ( 28.9) \n#&gt;   card (%)             No                    2544 ( 71.6)    1260 ( 57.7) \n#&gt;                        Yes                   1007 ( 28.4)     924 ( 42.3) \n#&gt;   neuro (%)            No                    2976 ( 83.8)    2066 ( 94.6) \n#&gt;                        Yes                    575 ( 16.2)     118 (  5.4) \n#&gt;   gastr (%)            No                    3029 ( 85.3)    1764 ( 80.8) \n#&gt;                        Yes                    522 ( 14.7)     420 ( 19.2) \n#&gt;   renal (%)            No                    3404 ( 95.9)    2036 ( 93.2) \n#&gt;                        Yes                    147 (  4.1)     148 (  6.8) \n#&gt;   meta (%)             No                    3379 ( 95.2)    2091 ( 95.7) \n#&gt;                        Yes                    172 (  4.8)      93 (  4.3) \n#&gt;   hema (%)             No                    3312 ( 93.3)    2069 ( 94.7) \n#&gt;                        Yes                    239 (  6.7)     115 (  5.3) \n#&gt;   seps (%)             No                    3036 ( 85.5)    1668 ( 76.4) \n#&gt;                        Yes                    515 ( 14.5)     516 ( 23.6) \n#&gt;   trauma (%)           No                    3533 ( 99.5)    2150 ( 98.4) \n#&gt;                        Yes                     18 (  0.5)      34 (  1.6) \n#&gt;   ortho (%)            No                    3548 ( 99.9)    2180 ( 99.8) \n#&gt;                        Yes                      3 (  0.1)       4 (  0.2) \n#&gt;   cardiohx (%)         0                     2984 ( 84.0)    1738 ( 79.6) \n#&gt;                        1                      567 ( 16.0)     446 ( 20.4) \n#&gt;   chfhx (%)            0                     2955 ( 83.2)    1759 ( 80.5) \n#&gt;                        1                      596 ( 16.8)     425 ( 19.5) \n#&gt;   dementhx (%)         0                     3138 ( 88.4)    2033 ( 93.1) \n#&gt;                        1                      413 ( 11.6)     151 (  6.9) \n#&gt;   psychhx (%)          0                     3265 ( 91.9)    2084 ( 95.4) \n#&gt;                        1                      286 (  8.1)     100 (  4.6) \n#&gt;   chrpulhx (%)         0                     2777 ( 78.2)    1869 ( 85.6) \n#&gt;                        1                      774 ( 21.8)     315 ( 14.4) \n#&gt;   renalhx (%)          0                     3402 ( 95.8)    2078 ( 95.1) \n#&gt;                        1                      149 (  4.2)     106 (  4.9) \n#&gt;   liverhx (%)          0                     3286 ( 92.5)    2048 ( 93.8) \n#&gt;                        1                      265 (  7.5)     136 (  6.2) \n#&gt;   gibledhx (%)         0                     3420 ( 96.3)    2130 ( 97.5) \n#&gt;                        1                      131 (  3.7)      54 (  2.5) \n#&gt;   malighx (%)          0                     2679 ( 75.4)    1740 ( 79.7) \n#&gt;                        1                      872 ( 24.6)     444 ( 20.3) \n#&gt;   immunhx (%)          0                     2644 ( 74.5)    1548 ( 70.9) \n#&gt;                        1                      907 ( 25.5)     636 ( 29.1) \n#&gt;   transhx (%)          0                     3216 ( 90.6)    1857 ( 85.0) \n#&gt;                        1                      335 (  9.4)     327 ( 15.0) \n#&gt;   amihx (%)            0                     3446 ( 97.0)    2089 ( 95.7) \n#&gt;                        1                      105 (  3.0)      95 (  4.3) \n#&gt;   swang1 (%)           No RHC                3551 (100.0)       0 (  0.0) \n#&gt;                        RHC                      0 (  0.0)    2184 (100.0) \n#&gt;                       Stratified by swang1\n#&gt;                        p      test SMD   \n#&gt;   n                                      \n#&gt;   age (mean (SD))       0.026       0.061\n#&gt;   sex (%)               0.001       0.093\n#&gt;                                          \n#&gt;   race (%)              0.425       0.036\n#&gt;                                          \n#&gt;                                          \n#&gt;   edu (mean (SD))       0.001       0.091\n#&gt;   income (%)           &lt;0.001       0.142\n#&gt;                                          \n#&gt;                                          \n#&gt;                                          \n#&gt;   ninsclas (%)         &lt;0.001       0.194\n#&gt;                                          \n#&gt;                                          \n#&gt;                                          \n#&gt;                                          \n#&gt;                                          \n#&gt;   cat1 (%)             &lt;0.001       0.583\n#&gt;                                          \n#&gt;                                          \n#&gt;                                          \n#&gt;                                          \n#&gt;                                          \n#&gt;                                          \n#&gt;                                          \n#&gt;                                          \n#&gt;   das2d3pc (mean (SD))  0.023       0.063\n#&gt;   dnr1 (%)             &lt;0.001       0.228\n#&gt;                                          \n#&gt;   ca (%)                0.001       0.107\n#&gt;                                          \n#&gt;                                          \n#&gt;   surv2md1 (mean (SD)) &lt;0.001       0.198\n#&gt;   aps1 (mean (SD))     &lt;0.001       0.501\n#&gt;   scoma1 (mean (SD))   &lt;0.001       0.110\n#&gt;   wtkilo1 (mean (SD))  &lt;0.001       0.256\n#&gt;   temp1 (mean (SD))     0.429       0.021\n#&gt;   meanbp1 (mean (SD))  &lt;0.001       0.455\n#&gt;   resp1 (mean (SD))    &lt;0.001       0.165\n#&gt;   hrt1 (mean (SD))     &lt;0.001       0.147\n#&gt;   pafi1 (mean (SD))    &lt;0.001       0.433\n#&gt;   paco21 (mean (SD))   &lt;0.001       0.249\n#&gt;   ph1 (mean (SD))      &lt;0.001       0.120\n#&gt;   wblc1 (mean (SD))     0.002       0.084\n#&gt;   hema1 (mean (SD))    &lt;0.001       0.269\n#&gt;   sod1 (mean (SD))      0.001       0.092\n#&gt;   pot1 (mean (SD))      0.321       0.027\n#&gt;   crea1 (mean (SD))    &lt;0.001       0.270\n#&gt;   bili1 (mean (SD))    &lt;0.001       0.145\n#&gt;   alb1 (mean (SD))     &lt;0.001       0.230\n#&gt;   resp (%)             &lt;0.001       0.270\n#&gt;                                          \n#&gt;   card (%)             &lt;0.001       0.295\n#&gt;                                          \n#&gt;   neuro (%)            &lt;0.001       0.353\n#&gt;                                          \n#&gt;   gastr (%)            &lt;0.001       0.121\n#&gt;                                          \n#&gt;   renal (%)            &lt;0.001       0.116\n#&gt;                                          \n#&gt;   meta (%)              0.337       0.028\n#&gt;                                          \n#&gt;   hema (%)              0.029       0.062\n#&gt;                                          \n#&gt;   seps (%)             &lt;0.001       0.234\n#&gt;                                          \n#&gt;   trauma (%)           &lt;0.001       0.104\n#&gt;                                          \n#&gt;   ortho (%)             0.516       0.027\n#&gt;                                          \n#&gt;   cardiohx (%)         &lt;0.001       0.116\n#&gt;                                          \n#&gt;   chfhx (%)             0.011       0.070\n#&gt;                                          \n#&gt;   dementhx (%)         &lt;0.001       0.163\n#&gt;                                          \n#&gt;   psychhx (%)          &lt;0.001       0.143\n#&gt;                                          \n#&gt;   chrpulhx (%)         &lt;0.001       0.192\n#&gt;                                          \n#&gt;   renalhx (%)           0.268       0.032\n#&gt;                                          \n#&gt;   liverhx (%)           0.084       0.049\n#&gt;                                          \n#&gt;   gibledhx (%)          0.014       0.070\n#&gt;                                          \n#&gt;   malighx (%)          &lt;0.001       0.101\n#&gt;                                          \n#&gt;   immunhx (%)           0.003       0.080\n#&gt;                                          \n#&gt;   transhx (%)          &lt;0.001       0.170\n#&gt;                                          \n#&gt;   amihx (%)             0.007       0.074\n#&gt;                                          \n#&gt;   swang1 (%)           &lt;0.001         NaN\n#&gt;",
    "crumbs": [
      "倾向性评分",
      "<span class='chapter-number'>24</span>  <span class='chapter-title'>匹配（Matching）</span>"
    ]
  },
  {
    "objectID": "matching.html#数据来源",
    "href": "matching.html#数据来源",
    "title": "\n24  匹配（Matching）\n",
    "section": "",
    "text": "Variable name\nVariable Definition\n\n\nAge\nAge\n\n\nSex\nSex\n\n\nRace\nRace\n\n\nEdu\nYears of education\n\n\nIncome\nIncome\n\n\nNinsclas\nMedical insurance\n\n\nCat1\nPrimary disease category\n\n\nCat2\nSecondary disease category\n\n\nCategories of admission diagnosis:\n \n\n\nResp\nRespiratory Diagnosis\n\n\nCard\nCardiovascular Diagnosis\n\n\nNeuro\nNeurological Diagnosis\n\n\nGastr\nGastrointestinal Diagnosis\n\n\nRenal\nRenal Diagnosis\n\n\nMeta\nMetabolic Diagnosis\n\n\nHema\nHematologic Diagnosis\n\n\nSeps\nSepsis Diagnosis\n\n\nTrauma\nTrauma Diagnosis\n\n\nOrtho\nOrthopedic Diagnosis\n\n\n \n \n\n\nAdld3p\nADL\n\n\nDas2d3pc\nDASI ( Duke Activity Status Index)\n\n\nDnr1\nDNR status on day1\n\n\nCa\nCancer\n\n\nSurv2md1\nSupport model estimate of the prob. of surviving 2 months\n\n\nAps1\nAPACHE score\n\n\nScoma1\nGlasgow Coma Score\n\n\nWtkilo1\nWeight\n\n\nTemp1\nTemperature\n\n\nMeanbp1\nMean blood pressure\n\n\nResp1\nRespiratory rate\n\n\nHrt1\nHeart rate\n\n\nPafi1\nPaO2/FIO2 ratio\n\n\nPaco21\nPaCo2\n\n\nPh1\nPH\n\n\nWblc1\nWBC\n\n\nHema1\nHematocrit\n\n\nSod1\nSodium\n\n\nPot1\nPotassium\n\n\nCrea1\nCreatinine\n\n\nBili1\nBilirubin\n\n\nAlb1\nAlbumin\n\n\nUrin1\nUrine output\n\n\nCategories of comorbidities illness:\n \n\n\nCardiohx\nAcute MI, Peripheral Vascular Disease, Severe Cardiovascular Symptoms (NYHA-Class III), Very Severe Cardiovascular Symptoms (NYHA-Class IV)\n\n\nChfhx\nCongestive Heart Failure\n\n\nDementhx\nDementia, Stroke or Cerebral Infarct, Parkinson�s Disease\n\n\nPsychhx\nPsychiatric History, Active Psychosis or Severe Depression\n\n\nChrpulhx\nChronic Pulmonary Disease, Severe Pulmonary Disease, Very Severe Pulmonary Disease\n\n\nRenalhx\nChronic Renal Disease, Chronic Hemodialysis or Peritoneal Dialysis\n\n\nLiverhx\nCirrhosis, Hepatic Failure\n\n\nGibledhx\nUpper GI Bleeding\n\n\nMalighx\nSolid Tumor, Metastatic Disease, Chronic Leukemia/Myeloma, Acute Leukemia, Lymphoma\n\n\nImmunhx\nImmunosupperssion, Organ Transplant, HIV Positivity, Diabetes Mellitus Without End Organ Damage, Diabetes Mellitus With End Organ Damage, Connective Tissue Disease\n\n\nTranshx\nTransfer (&gt; 24 Hours) from Another Hospital\n\n\nAmihx\nDefinite Myocardial Infarction\n\n\n \n \n\n\nSwang1\nRight Heart Catheterization (rhc2)\n\n\nSadmdte\nStudy Admission Date\n\n\nDthdte\nDate of Death\n\n\nLstctdte\nDate of Last Contact\n\n\nDschdte\nHospital Discharge Date\n\n\nDeath\nDeath at any time up to 180 Days\n\n\nPtid\nPatient ID",
    "crumbs": [
      "倾向性评分",
      "<span class='chapter-number'>24</span>  <span class='chapter-title'>匹配（Matching）</span>"
    ]
  },
  {
    "objectID": "matching.html#估计倾向得分",
    "href": "matching.html#估计倾向得分",
    "title": "\n24  匹配（Matching）\n",
    "section": "\n24.2 估计倾向得分",
    "text": "24.2 估计倾向得分\n\nCode\nlibrary(tidymodels)\nrhc2_formula &lt;- swang1 ~ .\n\n\n\nlogit_ps &lt;- logistic_reg() %&gt;%\n    fit(rhc2_formula, data = rhc2)\n\nsummary(logit_ps$fit)\n#&gt; \n#&gt; Call:\n#&gt; stats::glm(formula = swang1 ~ ., family = stats::binomial, data = data)\n#&gt; \n#&gt; Coefficients:\n#&gt;                               Estimate Std. Error z value Pr(&gt;|z|)    \n#&gt; (Intercept)                 17.2203728  3.1137929   5.530 3.20e-08 ***\n#&gt; age                         -0.0043737  0.0028619  -1.528 0.126457    \n#&gt; sexMale                      0.0478361  0.0679017   0.704 0.481128    \n#&gt; raceother                    0.0238498  0.1519260   0.157 0.875258    \n#&gt; racewhite                   -0.0480662  0.0939149  -0.512 0.608787    \n#&gt; edu                          0.0261939  0.0116913   2.240 0.025061 *  \n#&gt; income$25-$50k               0.0888363  0.1094906   0.811 0.417159    \n#&gt; income&gt; $50k                 0.0312483  0.1382814   0.226 0.821220    \n#&gt; incomeUnder $11k             0.0548697  0.0868242   0.632 0.527411    \n#&gt; ninsclasMedicare             0.2328987  0.1351961   1.723 0.084948 .  \n#&gt; ninsclasMedicare & Medicaid  0.4012458  0.1691375   2.372 0.017677 *  \n#&gt; ninsclasNo insurance         0.5264711  0.1673868   3.145 0.001660 ** \n#&gt; ninsclasPrivate              0.4138771  0.1247856   3.317 0.000911 ***\n#&gt; ninsclasPrivate & Medicare   0.3490696  0.1391972   2.508 0.012151 *  \n#&gt; cat1CHF                      0.7833692  0.1596299   4.907 9.23e-07 ***\n#&gt; cat1Cirrhosis               -1.1607975  0.2378358  -4.881 1.06e-06 ***\n#&gt; cat1Colon Cancer            -0.0864465  1.1193521  -0.077 0.938441    \n#&gt; cat1Coma                    -0.5829321  0.1819159  -3.204 0.001353 ** \n#&gt; cat1COPD                    -0.4719080  0.1901740  -2.481 0.013085 *  \n#&gt; cat1Lung Cancer             -0.4138852  0.5445513  -0.760 0.447226    \n#&gt; cat1MOSF w/Malignancy        0.0143100  0.1614131   0.089 0.929356    \n#&gt; cat1MOSF w/Sepsis            0.5339948  0.0910519   5.865 4.50e-09 ***\n#&gt; das2d3pc                    -0.0020607  0.0066432  -0.310 0.756416    \n#&gt; dnr1Yes                     -0.6777513  0.1166464  -5.810 6.24e-09 ***\n#&gt; caNo                         1.0485967  0.4350633   2.410 0.015943 *  \n#&gt; caYes                        0.2805522  0.1619387   1.732 0.083192 .  \n#&gt; surv2md1                    -1.8855344  0.3535424  -5.333 9.65e-08 ***\n#&gt; aps1                         0.0037687  0.0029458   1.279 0.200771    \n#&gt; scoma1                      -0.0041620  0.0016024  -2.597 0.009396 ** \n#&gt; wtkilo1                      0.0063327  0.0012171   5.203 1.96e-07 ***\n#&gt; temp1                       -0.0284681  0.0197651  -1.440 0.149776    \n#&gt; meanbp1                     -0.0063608  0.0010216  -6.226 4.78e-10 ***\n#&gt; resp1                       -0.0207690  0.0025956  -8.002 1.23e-15 ***\n#&gt; hrt1                         0.0054615  0.0008942   6.108 1.01e-09 ***\n#&gt; pafi1                       -0.0047235  0.0003463 -13.639  &lt; 2e-16 ***\n#&gt; paco21                      -0.0261850  0.0036694  -7.136 9.60e-13 ***\n#&gt; ph1                         -1.6756614  0.3847432  -4.355 1.33e-05 ***\n#&gt; wblc1                        0.0001465  0.0027568   0.053 0.957609    \n#&gt; hema1                       -0.0115223  0.0047296  -2.436 0.014841 *  \n#&gt; sod1                        -0.0108807  0.0043040  -2.528 0.011470 *  \n#&gt; pot1                        -0.1720083  0.0341922  -5.031 4.89e-07 ***\n#&gt; crea1                        0.0523499  0.0218175   2.399 0.016420 *  \n#&gt; bili1                        0.0072293  0.0074332   0.973 0.330766    \n#&gt; alb1                        -0.0964314  0.0481135  -2.004 0.045044 *  \n#&gt; respYes                     -0.2725098  0.0827259  -3.294 0.000987 ***\n#&gt; cardYes                      0.5575983  0.0856700   6.509 7.58e-11 ***\n#&gt; neuroYes                    -0.4873660  0.1343763  -3.627 0.000287 ***\n#&gt; gastrYes                     0.3505067  0.1054000   3.325 0.000883 ***\n#&gt; renalYes                     0.3004368  0.1490678   2.015 0.043859 *  \n#&gt; metaYes                     -0.1129081  0.1554971  -0.726 0.467771    \n#&gt; hemaYes                     -0.5131993  0.1470678  -3.490 0.000484 ***\n#&gt; sepsYes                      0.2844857  0.0919399   3.094 0.001973 ** \n#&gt; traumaYes                    1.2560843  0.3346498   3.753 0.000174 ***\n#&gt; orthoYes                     1.1814997  0.9691723   1.219 0.222813    \n#&gt; cardiohx1                    0.0482934  0.0953604   0.506 0.612554    \n#&gt; chfhx1                       0.0936948  0.1042890   0.898 0.368964    \n#&gt; dementhx1                   -0.4121592  0.1213400  -3.397 0.000682 ***\n#&gt; psychhx1                    -0.3913426  0.1382534  -2.831 0.004646 ** \n#&gt; chrpulhx1                    0.0122390  0.1007226   0.122 0.903286    \n#&gt; renalhx1                    -0.3352647  0.1814102  -1.848 0.064588 .  \n#&gt; liverhx1                    -0.0410152  0.1877313  -0.218 0.827057    \n#&gt; gibledhx1                   -0.1856252  0.2283797  -0.813 0.416337    \n#&gt; malighx1                     0.2298479  0.3846516   0.598 0.550141    \n#&gt; immunhx1                     0.0454368  0.0742516   0.612 0.540584    \n#&gt; transhx1                     0.4716832  0.0994237   4.744 2.09e-06 ***\n#&gt; amihx1                       0.1317831  0.1749886   0.753 0.451392    \n#&gt; ---\n#&gt; Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n#&gt; \n#&gt; (Dispersion parameter for binomial family taken to be 1)\n#&gt; \n#&gt;     Null deviance: 7621.4  on 5734  degrees of freedom\n#&gt; Residual deviance: 5993.2  on 5669  degrees of freedom\n#&gt; AIC: 6125.2\n#&gt; \n#&gt; Number of Fisher Scoring iterations: 5\nrhc2$PS &lt;- fitted(logit_ps$fit)\n\npredict(logit_ps, new_data = rhc2, type = \"prob\") %&gt;% head()\n\n\n\n\n.pred_No RHC\n.pred_RHC\n\n\n\n0.6489847\n0.3510153\n\n\n0.3308540\n0.6691460\n\n\n0.3664559\n0.6335441\n\n\n0.6310644\n0.3689356\n\n\n0.5543195\n0.4456805\n\n\n0.9447431\n0.0552569",
    "crumbs": [
      "倾向性评分",
      "<span class='chapter-number'>24</span>  <span class='chapter-title'>匹配（Matching）</span>"
    ]
  },
  {
    "objectID": "matching.html#匹配方法",
    "href": "matching.html#匹配方法",
    "title": "\n24  匹配（Matching）\n",
    "section": "\n24.3 匹配方法",
    "text": "24.3 匹配方法\n\n24.3.1 Matching\n\n\nCodelibrary(Matching)\ndata(lalonde, package='Matching')\nglimpse(lalonde)\n#&gt; Rows: 445\n#&gt; Columns: 12\n#&gt; $ age     &lt;int&gt; 37, 22, 30, 27, 33, 22, 23, 32, 22, 33, 19, 21, 18, 27, 17, 19…\n#&gt; $ educ    &lt;int&gt; 11, 9, 12, 11, 8, 9, 12, 11, 16, 12, 9, 13, 8, 10, 7, 10, 13, …\n#&gt; $ black   &lt;int&gt; 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,…\n#&gt; $ hisp    &lt;int&gt; 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,…\n#&gt; $ married &lt;int&gt; 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0,…\n#&gt; $ nodegr  &lt;int&gt; 1, 1, 0, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1, 0, 1, 0, 0, 1,…\n#&gt; $ re74    &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,…\n#&gt; $ re75    &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,…\n#&gt; $ re78    &lt;dbl&gt; 9930.05, 3595.89, 24909.50, 7506.15, 289.79, 4056.49, 0.00, 84…\n#&gt; $ u74     &lt;int&gt; 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,…\n#&gt; $ u75     &lt;int&gt; 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,…\n#&gt; $ treat   &lt;int&gt; 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,…\n\nlalonde_formu &lt;- treat ~ age + I(age^2) + educ + I(educ^2) + black +\n    hisp + married + nodegr + re74  + I(re74^2) + re75 + I(re75^2) + u74 + u75\nlr_out &lt;- glm(formula = lalonde_formu,\n              data = lalonde,\n              family = binomial(link = 'logit'))\n\nsummary(lr_out)\n#&gt; \n#&gt; Call:\n#&gt; glm(formula = lalonde_formu, family = binomial(link = \"logit\"), \n#&gt;     data = lalonde)\n#&gt; \n#&gt; Coefficients:\n#&gt;               Estimate Std. Error z value Pr(&gt;|z|)  \n#&gt; (Intercept)  4.269e+00  2.173e+00   1.965   0.0494 *\n#&gt; age          2.143e-02  9.037e-02   0.237   0.8126  \n#&gt; I(age^2)    -3.448e-04  1.484e-03  -0.232   0.8163  \n#&gt; educ        -8.713e-01  4.150e-01  -2.099   0.0358 *\n#&gt; I(educ^2)    4.499e-02  2.330e-02   1.931   0.0535 .\n#&gt; black       -2.613e-01  3.708e-01  -0.705   0.4809  \n#&gt; hisp        -8.974e-01  5.184e-01  -1.731   0.0835 .\n#&gt; married      1.829e-01  2.831e-01   0.646   0.5183  \n#&gt; nodegr      -4.285e-01  3.930e-01  -1.090   0.2756  \n#&gt; re74        -2.168e-05  7.739e-05  -0.280   0.7793  \n#&gt; I(re74^2)   -8.553e-10  2.424e-09  -0.353   0.7242  \n#&gt; re75         6.577e-05  1.025e-04   0.642   0.5210  \n#&gt; I(re75^2)   -1.968e-09  5.042e-09  -0.390   0.6963  \n#&gt; u74         -8.315e-02  4.521e-01  -0.184   0.8541  \n#&gt; u75         -3.060e-01  3.591e-01  -0.852   0.3942  \n#&gt; ---\n#&gt; Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n#&gt; \n#&gt; (Dispersion parameter for binomial family taken to be 1)\n#&gt; \n#&gt;     Null deviance: 604.20  on 444  degrees of freedom\n#&gt; Residual deviance: 580.02  on 430  degrees of freedom\n#&gt; AIC: 610.02\n#&gt; \n#&gt; Number of Fisher Scoring iterations: 4\nlalonde$lr_ps &lt;- fitted(lr_out)\n\n\n\nCodelalonde_match &lt;- Match(\n    Y = lalonde$re78,\n    Tr = lalonde$treat,\n    X = lalonde$lr_ps,\n    M = 1,\n    caliper = 0.1,\n    replace = TRUE,\n    estimand = 'ATE'\n)\n\nsummary(lalonde_match)\n#&gt; \n#&gt; Estimate...  2053.1 \n#&gt; AI SE......  803.05 \n#&gt; T-stat.....  2.5566 \n#&gt; p.val......  0.010569 \n#&gt; \n#&gt; Original number of observations..............  445 \n#&gt; Original number of treated obs...............  185 \n#&gt; Matched number of observations...............  433 \n#&gt; Matched number of observations  (unweighted).  744 \n#&gt; \n#&gt; Caliper (SDs)........................................   0.1 \n#&gt; Number of obs dropped by 'exact' or 'caliper'  12\n\nlalonde_match_df &lt;- data.frame(\n    treated.ps = lalonde[lalonde_match$index.treated, ]$lr_ps,\n    control.ps = lalonde[lalonde_match$index.control, ]$lr_ps,\n    treated.y = 1,\n    control.y = 0\n)\nlalonde_match_df &lt;- lalonde_match_df[order(lalonde_match_df$control.ps), ]\n\n\nrows &lt;- (1:nrow(lalonde_match_df) - 1) %% floor(nrow(lalonde_match_df) / 5) == 0\n\nggplot(lalonde, aes(x = lr_ps, y = treat)) +\n    geom_point(alpha = 0.5) +\n    geom_smooth(\n        method = glm,\n        formula = y ~ x,\n        method.args = list(family = binomial(link = 'logit')),\n        se = FALSE\n    ) +\n    xlim(c(0, 1)) +\n    xlab('Propensity Score') + ylab('Treatment') +\n    geom_segment(\n        data = lalonde_match_df,\n        aes(\n            x = treated.ps,\n            xend = control.ps,\n            y = treated.y,\n            yend = control.y\n        ),\n        color = 'purple',\n        alpha = 0.1\n    )\n\n\n\n\n\n\n\n匹配后，治疗组和对照组应具有非常相似的特征。可以使用简单的回归模型来估计治疗对结果的影响。\n\n24.3.2 一对一匹配ATT\nEstimating the treatment effect on the treated (default is ATT)\n\nCoderr_att &lt;- Match(Y = lalonde$re78, \n                Tr = lalonde$treat, \n                X = lalonde$lr_ps,\n                M = 1,\n                estimand='ATT')\nsummary(rr_att) # The default estimate is ATT here\n#&gt; \n#&gt; Estimate...  2153.3 \n#&gt; AI SE......  825.4 \n#&gt; T-stat.....  2.6088 \n#&gt; p.val......  0.0090858 \n#&gt; \n#&gt; Original number of observations..............  445 \n#&gt; Original number of treated obs...............  185 \n#&gt; Matched number of observations...............  185 \n#&gt; Matched number of observations  (unweighted).  346\n\nrr_att_mb &lt;- psa::MatchBalance(\n    df = lalonde,\n    formu = lalonde_formu,\n    formu.Y = update.formula(lalonde_formu, re78 ~ .),\n    index.treated = rr_att$index.treated,\n    index.control = rr_att$index.control,\n    tolerance = 0.25,\n    M = 1,\n    estimand = 'ATT')\nplot(rr_att_mb)\n\n\n\n\n\n\nCodesummary(rr_att_mb)\n#&gt; Sample sizes and number of matches:\n#&gt;    Group   n n.matched n.percent.matched\n#&gt;  Treated 185       185         1.0000000\n#&gt;  Control 260       173         0.6653846\n#&gt;    Total 445       358         0.8044944\n#&gt; \n#&gt; Covariate importance and t-tests for matched pairs:\n#&gt;           Import.Treat Import.Y Import.Total std.estimate       t p.value\n#&gt; I(educ^2)        1.931   1.5228        3.453     -0.04903 -0.8916  0.3732\n#&gt; educ             2.099   1.2121        3.311     -0.05483 -0.9577  0.3389\n#&gt; black            0.705   1.8424        2.547     -0.02326 -0.5383  0.5907\n#&gt; I(re74^2)        0.353   1.6415        1.994      0.07581  2.0955  0.0369\n#&gt; u75              0.852   0.9435        1.796     -0.06655 -1.8144  0.0705\n#&gt; hisp             1.731   0.0404        1.771      0.02042  0.8161  0.4150\n#&gt; nodegr           1.090   0.5011        1.591      0.03496  1.0914  0.2759\n#&gt; re74             0.280   1.1019        1.382      0.07979  1.7483  0.0813\n#&gt; re75             0.642   0.5903        1.232      0.06147  1.3171  0.1887\n#&gt; age              0.237   0.6729        0.910      0.00896  0.1374  0.8908\n#&gt; married          0.646   0.1406        0.787      0.04627  1.0000  0.3180\n#&gt; I(re75^2)        0.390   0.3817        0.772      0.05125  1.0364  0.3007\n#&gt; I(age^2)         0.232   0.5096        0.742      0.00297  0.0438  0.9651\n#&gt; u74              0.184   0.0702        0.254      0.03913  0.7495  0.4541\n#&gt;             ci.min  ci.max PercentMatched\n#&gt; I(educ^2) -0.15719 0.05913           60.4\n#&gt; educ      -0.16744 0.05778           60.1\n#&gt; black     -0.10826 0.06173           91.0\n#&gt; I(re74^2)  0.00465 0.14696           86.7\n#&gt; u75       -0.13870 0.00559           89.3\n#&gt; hisp      -0.02879 0.06963           98.3\n#&gt; nodegr    -0.02804 0.09797           93.9\n#&gt; re74      -0.00998 0.16956           77.2\n#&gt; re75      -0.03032 0.15326           78.0\n#&gt; age       -0.11922 0.13713           44.8\n#&gt; married   -0.04474 0.13728           89.6\n#&gt; I(re75^2) -0.04602 0.14852           88.7\n#&gt; I(age^2)  -0.13062 0.13656           49.7\n#&gt; u74       -0.06356 0.14183           81.5\n\n\n\n24.3.3 一对一匹配ATE\naverage treatment effect\n\nCoderr.ate &lt;- Match(Y = lalonde$re78, \n                Tr = lalonde$treat, \n                X = lalonde$lr_ps,\n                M = 1,\n                estimand = 'ATE')\nsummary(rr.ate)\n#&gt; \n#&gt; Estimate...  2013.3 \n#&gt; AI SE......  817.76 \n#&gt; T-stat.....  2.4619 \n#&gt; p.val......  0.013819 \n#&gt; \n#&gt; Original number of observations..............  445 \n#&gt; Original number of treated obs...............  185 \n#&gt; Matched number of observations...............  445 \n#&gt; Matched number of observations  (unweighted).  756\n\n\n\n24.3.4 一对多匹配 （ATT）\n\nCoderr2 &lt;- Match(Y = lalonde$re78,      \n             Tr = lalonde$treat, \n             X = lalonde$lr_ps,\n             M = 1, \n             ties = TRUE, \n             replace = TRUE,\n             estimand = 'ATT')\nsummary(rr2) # The default estimate is ATT here\n#&gt; \n#&gt; Estimate...  2153.3 \n#&gt; AI SE......  825.4 \n#&gt; T-stat.....  2.6088 \n#&gt; p.val......  0.0090858 \n#&gt; \n#&gt; Original number of observations..............  445 \n#&gt; Original number of treated obs...............  185 \n#&gt; Matched number of observations...............  185 \n#&gt; Matched number of observations  (unweighted).  346\n\n\n\n24.3.5 MachIt\n\n\nCodeMatchIt::matchit(method = \"nearest\")\nMatchIt::matchit(method = 'optimal')\nMatchIt::matchit(method = 'full')\nMatchIt::matchit(method = 'quick')\nMatchIt::matchit(method = 'genetic')\nMatchIt::matchit(method = 'exact')\nMatchIt::matchit(method = 'subclass')\n\n\n\nCodematchit.out &lt;- MatchIt::matchit(lalonde_formu, data = lalonde )\nsummary(matchit.out)\n#&gt; \n#&gt; Call:\n#&gt; MatchIt::matchit(formula = lalonde_formu, data = lalonde)\n#&gt; \n#&gt; Summary of Balance for All Data:\n#&gt;           Means Treated Means Control Std. Mean Diff. Var. Ratio eCDF Mean\n#&gt; distance         0.4468        0.3936          0.4533     1.2101    0.1340\n#&gt; age             25.8162       25.0538          0.1066     1.0278    0.0254\n#&gt; I(age^2)       717.3946      677.3154          0.0929     1.0115    0.0254\n#&gt; educ            10.3459       10.0885          0.1281     1.5513    0.0287\n#&gt; I(educ^2)      111.0595      104.3731          0.1701     1.6625    0.0287\n#&gt; black            0.8432        0.8269          0.0449          .    0.0163\n#&gt; hisp             0.0595        0.1077         -0.2040          .    0.0482\n#&gt; married          0.1892        0.1538          0.0902          .    0.0353\n#&gt; nodegr           0.7081        0.8346         -0.2783          .    0.1265\n#&gt; re74          2095.5740     2107.0268         -0.0023     0.7381    0.0192\n#&gt; I(re74^2) 28141433.9907 36667413.1577         -0.0747     0.5038    0.0192\n#&gt; re75          1532.0556     1266.9092          0.0824     1.0763    0.0508\n#&gt; I(re75^2) 12654752.6909 11196530.0057          0.0260     1.4609    0.0508\n#&gt; u74              0.7081        0.7500         -0.0921          .    0.0419\n#&gt; u75              0.6000        0.6846         -0.1727          .    0.0846\n#&gt;           eCDF Max\n#&gt; distance    0.2244\n#&gt; age         0.0652\n#&gt; I(age^2)    0.0652\n#&gt; educ        0.1265\n#&gt; I(educ^2)   0.1265\n#&gt; black       0.0163\n#&gt; hisp        0.0482\n#&gt; married     0.0353\n#&gt; nodegr      0.1265\n#&gt; re74        0.0471\n#&gt; I(re74^2)   0.0471\n#&gt; re75        0.1075\n#&gt; I(re75^2)   0.1075\n#&gt; u74         0.0419\n#&gt; u75         0.0846\n#&gt; \n#&gt; Summary of Balance for Matched Data:\n#&gt;           Means Treated Means Control Std. Mean Diff. Var. Ratio eCDF Mean\n#&gt; distance         0.4468        0.4284          0.1571     1.3077    0.0387\n#&gt; age             25.8162       25.1351          0.0952     1.1734    0.0243\n#&gt; I(age^2)       717.3946      675.1676          0.0979     1.1512    0.0243\n#&gt; educ            10.3459       10.2649          0.0403     1.2869    0.0174\n#&gt; I(educ^2)      111.0595      108.4919          0.0653     1.3938    0.0174\n#&gt; black            0.8432        0.8486         -0.0149          .    0.0054\n#&gt; hisp             0.0595        0.0703         -0.0457          .    0.0108\n#&gt; married          0.1892        0.1892          0.0000          .    0.0000\n#&gt; nodegr           0.7081        0.7676         -0.1308          .    0.0595\n#&gt; re74          2095.5740     1741.2109          0.0725     1.5797    0.0146\n#&gt; I(re74^2) 28141433.9907 18066538.6428          0.0883     3.5436    0.0146\n#&gt; re75          1532.0556     1314.8073          0.0675     1.3933    0.0264\n#&gt; I(re75^2) 12654752.6909  9126579.7979          0.0630     3.4873    0.0264\n#&gt; u74              0.7081        0.7243         -0.0357          .    0.0162\n#&gt; u75              0.6000        0.6108         -0.0221          .    0.0108\n#&gt;           eCDF Max Std. Pair Dist.\n#&gt; distance    0.1189          0.1585\n#&gt; age         0.0541          0.8159\n#&gt; I(age^2)    0.0541          0.7701\n#&gt; educ        0.0595          0.7662\n#&gt; I(educ^2)   0.0595          0.7604\n#&gt; black       0.0054          0.5798\n#&gt; hisp        0.0108          0.2286\n#&gt; married     0.0000          0.2378\n#&gt; nodegr      0.0595          0.5588\n#&gt; re74        0.0432          0.6080\n#&gt; I(re74^2)   0.0432          0.3620\n#&gt; re75        0.0649          0.7292\n#&gt; I(re75^2)   0.0649          0.3690\n#&gt; u74         0.0162          0.7728\n#&gt; u75         0.0108          0.7282\n#&gt; \n#&gt; Sample Sizes:\n#&gt;           Control Treated\n#&gt; All           260     185\n#&gt; Matched       185     185\n#&gt; Unmatched      75       0\n#&gt; Discarded       0       0\n\n\n\nCode# Same as above but calculate average treatment effect\nrr.ate &lt;- Match(Y = lalonde$re78, \n                Tr = lalonde$treat, \n                X = lalonde$lr_ps,\n                M = 1,\n                ties = FALSE, \n                replace = FALSE, \n                estimand='ATE')\nsummary(rr.ate) # Here the estimate is ATE\n#&gt; \n#&gt; Estimate...  2036.6 \n#&gt; SE.........  501.71 \n#&gt; T-stat.....  4.0592 \n#&gt; p.val......  4.9233e-05 \n#&gt; \n#&gt; Original number of observations..............  445 \n#&gt; Original number of treated obs...............  185 \n#&gt; Matched number of observations...............  370 \n#&gt; Matched number of observations  (unweighted).  370\n\n\n\nCode## Genetic Matching\nrr.gen &lt;- GenMatch(Tr = lalonde$treat, \n                   X = lalonde$lr_ps, \n                   BalanceMatrix = lalonde[,all.vars(lalonde_formu)[-1]],\n                   estimand = 'ATE', \n                   M = 1, \n                   pop.size = 16,\n                   print.level = 0)\nrr.gen.mout &lt;- Match(Y = lalonde$re78, \n                     Tr = lalonde$treat, \n                     X = lalonde$lr_ps,\n                     estimand = 'ATE',\n                     Weight.matrix = rr.gen)\nsummary(rr.gen.mout)\n#&gt; \n#&gt; Estimate...  2086.5 \n#&gt; AI SE......  815.65 \n#&gt; T-stat.....  2.5581 \n#&gt; p.val......  0.010524 \n#&gt; \n#&gt; Original number of observations..............  445 \n#&gt; Original number of treated obs...............  185 \n#&gt; Matched number of observations...............  445 \n#&gt; Matched number of observations  (unweighted).  671\n\n\n\nCode## Partial exact matching\nrr2 &lt;- Matchby(Y = lalonde$re78, \n               Tr = lalonde$treat, \n               X = lalonde$lr_ps, \n               by = factor(lalonde$nodegr),\n               print.level = 0)\nsummary(rr2)\n#&gt; \n#&gt; Estimate...  2014.4 \n#&gt; SE.........  702.05 \n#&gt; T-stat.....  2.8693 \n#&gt; p.val......  0.0041132 \n#&gt; \n#&gt; Original number of observations..............  445 \n#&gt; Original number of treated obs...............  185 \n#&gt; Matched number of observations...............  185 \n#&gt; Matched number of observations  (unweighted).  185\n\n\n\nCode## Partial exact matching on two covariates\nrr3 &lt;- Matchby(Y = lalonde$re78, \n               Tr = lalonde$treat, \n               X = lalonde$lr_ps, \n               by = lalonde[,c('nodegr','married')],\n               print.level = 0)\nsummary(rr3)\n#&gt; \n#&gt; Estimate...  1894 \n#&gt; SE.........  705.3 \n#&gt; T-stat.....  2.6853 \n#&gt; p.val......  0.0072455 \n#&gt; \n#&gt; Original number of observations..............  445 \n#&gt; Original number of treated obs...............  185 \n#&gt; Matched number of observations...............  185 \n#&gt; Matched number of observations  (unweighted).  185",
    "crumbs": [
      "倾向性评分",
      "<span class='chapter-number'>24</span>  <span class='chapter-title'>匹配（Matching）</span>"
    ]
  },
  {
    "objectID": "matching.html#示例",
    "href": "matching.html#示例",
    "title": "\n24  匹配（Matching）\n",
    "section": "\n24.4 示例",
    "text": "24.4 示例\n\n\n变量名\n描述\n\n\n\nage\n年龄\n\n\neduc\n受教育年限\n\n\nblack\n分类变量，1为黑人\n\n\nhisp\n分类变量，1为西班牙裔\n\n\nmarried\n分类变量，1为已婚\n\n\nnodegr\n分类变量，1为有高中学历证书\n\n\nre74\n1974年的收入\n\n\nre75\n1975年的收入\n\n\nre78\n1978年的收入\n\n\nu74\n分类变量，1为1974年收入为零\n\n\nu75\n分类变量，1为1975年收入为零\n\n\ntreat\n分类变量，1为实验组\n\n\n\n\n24.4.1 估计倾向值分数\n\nCodeattach(lalonde)\nglm_ps &lt;- glm(\n    formula = treat ~ age + educ + black + hisp + married + nodegr + re74  + re75,\n    family = binomial(link = 'logit')\n)\n\npsm1 &lt;- Match(Y=re78,\n             Tr = treat,\n             X=glm_ps$fitted.values,\n             estimand = \"ATT\",\n             M=1,\n             replace = TRUE)\nsummary(psm1)\n#&gt; \n#&gt; Estimate...  2624.3 \n#&gt; AI SE......  802.19 \n#&gt; T-stat.....  3.2714 \n#&gt; p.val......  0.0010702 \n#&gt; \n#&gt; Original number of observations..............  445 \n#&gt; Original number of treated obs...............  185 \n#&gt; Matched number of observations...............  185 \n#&gt; Matched number of observations  (unweighted).  344\n\n\n如上所示，使用1对1样本可替代匹配法，实验组平均效应为2624.3，因果效应的标准误为803.19，t值为3.2714，p值为0.0010702&lt;0.05，表明估计的实验组平均处理效应有统计学差异。\n\nCodepsm2 &lt;- Match(Y=re78,\n             Tr = treat,\n             X=glm_ps$fitted.values,\n             estimand = \"ATT\",\n             M=1,\n             replace = FALSE)\nsummary(psm2)\n#&gt; \n#&gt; Estimate...  1996.3 \n#&gt; SE.........  643.88 \n#&gt; T-stat.....  3.1005 \n#&gt; p.val......  0.0019319 \n#&gt; \n#&gt; Original number of observations..............  445 \n#&gt; Original number of treated obs...............  185 \n#&gt; Matched number of observations...............  185 \n#&gt; Matched number of observations  (unweighted).  185\n\n\n\n24.4.2 检验平衡\n受试者个体同质性，是否随机分配\n协变量分布是否平衡，是否重合：\n以age 为例，实验组匹配前25.816匹配后25.816，对照组匹配前25.054匹配后25.692 ，匹配后实验组与对照组更接近了；T-test p-value &gt; 0.05 ，表示匹配前后age 均值无统计学差异；KS Bootstrap p-value &gt; 0.05 ，表示匹配前后age 分布无统计学差异\n***** (V1) age *****                Before Matching          After Matching \n\nmean   treatment........          25.816             25.816  \nmean control..........     25.054            25.692 \nstd mean diff.........     10.655            1.7342 \n\nmean raw eQQ diff.....    0.94054           0.73837  \nmed  raw eQQ diff.....          1                 0  \nmax  raw eQQ diff.....          7                 9   \n\nmean eCDF diff........   0.025364          0.021893  \nmed  eCDF diff........   0.022193          0.020349  \nmax  eCDF diff........   0.065177          0.061047   \n\nvar ratio (Tr/Co).....     1.0278             1.083  \nT-test p-value........    0.26594           0.84975  \nKS Bootstrap p-value..      0.526             0.355  \nKS Naive p-value......     0.7481           0.54314  \nKS Statistic..........   0.065177          0.061047 \n\nCodecheck_balance &lt;- MatchBalance(\n    formul = treat ~ age + educ + black + hisp + married + nodegr + re74  + re75,\n    match.out = psm1,\n    nboots = 1000,data = lalonde\n)\n#&gt; \n#&gt; ***** (V1) age *****\n#&gt;                        Before Matching        After Matching\n#&gt; mean treatment........     25.816             25.816 \n#&gt; mean control..........     25.054             25.692 \n#&gt; std mean diff.........     10.655             1.7342 \n#&gt; \n#&gt; mean raw eQQ diff.....    0.94054            0.73837 \n#&gt; med  raw eQQ diff.....          1                  0 \n#&gt; max  raw eQQ diff.....          7                  9 \n#&gt; \n#&gt; mean eCDF diff........   0.025364           0.021893 \n#&gt; med  eCDF diff........   0.022193           0.020349 \n#&gt; max  eCDF diff........   0.065177           0.061047 \n#&gt; \n#&gt; var ratio (Tr/Co).....     1.0278              1.083 \n#&gt; T-test p-value........    0.26594            0.84975 \n#&gt; KS Bootstrap p-value..      0.514              0.364 \n#&gt; KS Naive p-value......     0.7481            0.54314 \n#&gt; KS Statistic..........   0.065177           0.061047 \n#&gt; \n#&gt; \n#&gt; ***** (V2) educ *****\n#&gt;                        Before Matching        After Matching\n#&gt; mean treatment........     10.346             10.346 \n#&gt; mean control..........     10.088             10.146 \n#&gt; std mean diff.........     12.806             9.9664 \n#&gt; \n#&gt; mean raw eQQ diff.....    0.40541            0.23256 \n#&gt; med  raw eQQ diff.....          0                  0 \n#&gt; max  raw eQQ diff.....          2                  2 \n#&gt; \n#&gt; mean eCDF diff........   0.028698           0.016611 \n#&gt; med  eCDF diff........   0.012682           0.010174 \n#&gt; max  eCDF diff........    0.12651           0.061047 \n#&gt; \n#&gt; var ratio (Tr/Co).....     1.5513             1.2344 \n#&gt; T-test p-value........    0.15017             0.1842 \n#&gt; KS Bootstrap p-value..      0.003              0.183 \n#&gt; KS Naive p-value......   0.062873            0.54314 \n#&gt; KS Statistic..........    0.12651           0.061047 \n#&gt; \n#&gt; \n#&gt; ***** (V3) black *****\n#&gt;                        Before Matching        After Matching\n#&gt; mean treatment........    0.84324            0.84324 \n#&gt; mean control..........    0.82692            0.86847 \n#&gt; std mean diff.........     4.4767            -6.9194 \n#&gt; \n#&gt; mean raw eQQ diff.....   0.016216           0.026163 \n#&gt; med  raw eQQ diff.....          0                  0 \n#&gt; max  raw eQQ diff.....          1                  1 \n#&gt; \n#&gt; mean eCDF diff........  0.0081601           0.013081 \n#&gt; med  eCDF diff........  0.0081601           0.013081 \n#&gt; max  eCDF diff........    0.01632           0.026163 \n#&gt; \n#&gt; var ratio (Tr/Co).....    0.92503             1.1572 \n#&gt; T-test p-value........    0.64736            0.40214 \n#&gt; \n#&gt; \n#&gt; ***** (V4) hisp *****\n#&gt;                        Before Matching        After Matching\n#&gt; mean treatment........   0.059459           0.059459 \n#&gt; mean control..........    0.10769            0.04955 \n#&gt; std mean diff.........    -20.341             4.1792 \n#&gt; \n#&gt; mean raw eQQ diff.....   0.048649           0.011628 \n#&gt; med  raw eQQ diff.....          0                  0 \n#&gt; max  raw eQQ diff.....          1                  1 \n#&gt; \n#&gt; mean eCDF diff........   0.024116           0.005814 \n#&gt; med  eCDF diff........   0.024116           0.005814 \n#&gt; max  eCDF diff........   0.048233           0.011628 \n#&gt; \n#&gt; var ratio (Tr/Co).....    0.58288             1.1875 \n#&gt; T-test p-value........   0.064043            0.46063 \n#&gt; \n#&gt; \n#&gt; ***** (V5) married *****\n#&gt;                        Before Matching        After Matching\n#&gt; mean treatment........    0.18919            0.18919 \n#&gt; mean control..........    0.15385            0.18423 \n#&gt; std mean diff.........     8.9995             1.2617 \n#&gt; \n#&gt; mean raw eQQ diff.....   0.037838           0.026163 \n#&gt; med  raw eQQ diff.....          0                  0 \n#&gt; max  raw eQQ diff.....          1                  1 \n#&gt; \n#&gt; mean eCDF diff........   0.017672           0.013081 \n#&gt; med  eCDF diff........   0.017672           0.013081 \n#&gt; max  eCDF diff........   0.035343           0.026163 \n#&gt; \n#&gt; var ratio (Tr/Co).....     1.1802             1.0207 \n#&gt; T-test p-value........    0.33425            0.89497 \n#&gt; \n#&gt; \n#&gt; ***** (V6) nodegr *****\n#&gt;                        Before Matching        After Matching\n#&gt; mean treatment........    0.70811            0.70811 \n#&gt; mean control..........    0.83462            0.76757 \n#&gt; std mean diff.........    -27.751            -13.043 \n#&gt; \n#&gt; mean raw eQQ diff.....    0.12432           0.043605 \n#&gt; med  raw eQQ diff.....          0                  0 \n#&gt; max  raw eQQ diff.....          1                  1 \n#&gt; \n#&gt; mean eCDF diff........   0.063254           0.021802 \n#&gt; med  eCDF diff........   0.063254           0.021802 \n#&gt; max  eCDF diff........    0.12651           0.043605 \n#&gt; \n#&gt; var ratio (Tr/Co).....     1.4998             1.1585 \n#&gt; T-test p-value........  0.0020368          0.0071385 \n#&gt; \n#&gt; \n#&gt; ***** (V7) re74 *****\n#&gt;                        Before Matching        After Matching\n#&gt; mean treatment........     2095.6             2095.6 \n#&gt; mean control..........       2107             2193.3 \n#&gt; std mean diff.........   -0.23437            -2.0004 \n#&gt; \n#&gt; mean raw eQQ diff.....     487.98             869.16 \n#&gt; med  raw eQQ diff.....          0                  0 \n#&gt; max  raw eQQ diff.....       8413              10305 \n#&gt; \n#&gt; mean eCDF diff........   0.019223           0.054701 \n#&gt; med  eCDF diff........     0.0158           0.050872 \n#&gt; max  eCDF diff........   0.047089            0.12209 \n#&gt; \n#&gt; var ratio (Tr/Co).....     0.7381            0.75054 \n#&gt; T-test p-value........    0.98186            0.84996 \n#&gt; KS Bootstrap p-value..      0.575         &lt; 2.22e-16 \n#&gt; KS Naive p-value......    0.97023           0.011858 \n#&gt; KS Statistic..........   0.047089            0.12209 \n#&gt; \n#&gt; \n#&gt; ***** (V8) re75 *****\n#&gt;                        Before Matching        After Matching\n#&gt; mean treatment........     1532.1             1532.1 \n#&gt; mean control..........     1266.9             2179.9 \n#&gt; std mean diff.........     8.2363            -20.125 \n#&gt; \n#&gt; mean raw eQQ diff.....     367.61             590.34 \n#&gt; med  raw eQQ diff.....          0                  0 \n#&gt; max  raw eQQ diff.....     2110.2             8092.9 \n#&gt; \n#&gt; mean eCDF diff........   0.050834           0.050338 \n#&gt; med  eCDF diff........   0.061954           0.049419 \n#&gt; max  eCDF diff........    0.10748           0.098837 \n#&gt; \n#&gt; var ratio (Tr/Co).....     1.0763            0.56563 \n#&gt; T-test p-value........    0.38527           0.079002 \n#&gt; KS Bootstrap p-value..      0.049               0.01 \n#&gt; KS Naive p-value......    0.16449           0.069435 \n#&gt; KS Statistic..........    0.10748           0.098837 \n#&gt; \n#&gt; \n#&gt; Before Matching Minimum p.value: 0.0020368 \n#&gt; Variable Name(s): nodegr  Number(s): 6 \n#&gt; \n#&gt; After Matching Minimum p.value: &lt; 2.22e-16 \n#&gt; Variable Name(s): re74  Number(s): 7\n\n\n\nCode# age 变平衡了\nqqplot(lalonde$age[psm1$index.control],lalonde$age[psm1$index.treated])\nabline(a=0,b=1)\n\n\n\n\n\n\nCode\n# re74 更不平衡了\nqqplot(lalonde$re74[psm1$index.control],lalonde$re74[psm1$index.treated])\nabline(a=0,b=1)\n\n\n\n\n\n\n\n\nCode# # The covariates we want to match on\nx &lt;- cbind(age , educ , black , hisp , married , nodegr , re74  , re75)\n\n# The covariates we want to obtain balance on\nBalanceMatrix = x\nset.seed(100)\n\n\n\n# Genetic Matching 自动适配平衡\ngen_match &lt;- GenMatch(Tr=treat,\n                      X=glm_ps$fitted.values,\n                      BalanceMatrix = x,\n                      estimand = \"ATT\")\n#&gt; \n#&gt; \n#&gt; Sat Aug 31 15:02:33 2024\n#&gt; Domains:\n#&gt;  0.000000e+00   &lt;=  X1   &lt;=    1.000000e+03 \n#&gt; \n#&gt; Data Type: Floating Point\n#&gt; Operators (code number, name, population) \n#&gt;  (1) Cloning...........................  15\n#&gt;  (2) Uniform Mutation..................  12\n#&gt;  (3) Boundary Mutation.................  12\n#&gt;  (4) Non-Uniform Mutation..............  12\n#&gt;  (5) Polytope Crossover................  12\n#&gt;  (6) Simple Crossover..................  12\n#&gt;  (7) Whole Non-Uniform Mutation........  12\n#&gt;  (8) Heuristic Crossover...............  12\n#&gt;  (9) Local-Minimum Crossover...........  0\n#&gt; \n#&gt; SOFT Maximum Number of Generations: 100\n#&gt; Maximum Nonchanging Generations: 4\n#&gt; Population size       : 100\n#&gt; Convergence Tolerance: 1.000000e-03\n#&gt; \n#&gt; Not Using the BFGS Derivative Based Optimizer on the Best Individual Each Generation.\n#&gt; Not Checking Gradients before Stopping.\n#&gt; Using Out of Bounds Individuals.\n#&gt; \n#&gt; Maximization Problem.\n#&gt; GENERATION: 0 (initializing the population)\n#&gt; Lexical Fit..... 1.180299e-02  1.180299e-02  1.155612e-01  1.186261e-01  1.822343e-01  3.842491e-01  3.842491e-01  4.144313e-01  4.144313e-01  4.610718e-01  5.977650e-01  7.731052e-01  7.731052e-01  8.523060e-01  9.184104e-01  9.749549e-01  \n#&gt; #unique......... 100, #Total UniqueCount: 100\n#&gt; var 1:\n#&gt; best............ 3.729259e+01\n#&gt; mean............ 4.810920e+02\n#&gt; variance........ 7.636997e+04\n#&gt; \n#&gt; GENERATION: 1\n#&gt; Lexical Fit..... 1.180299e-02  1.180299e-02  1.155612e-01  1.186261e-01  1.822343e-01  3.842491e-01  3.842491e-01  4.144313e-01  4.144313e-01  4.610718e-01  5.977650e-01  7.731052e-01  7.731052e-01  8.523060e-01  9.184104e-01  9.749549e-01  \n#&gt; #unique......... 61, #Total UniqueCount: 161\n#&gt; var 1:\n#&gt; best............ 3.729259e+01\n#&gt; mean............ 2.015230e+02\n#&gt; variance........ 6.039634e+04\n#&gt; \n#&gt; GENERATION: 2\n#&gt; Lexical Fit..... 1.180299e-02  1.180299e-02  1.155612e-01  1.186261e-01  1.822343e-01  3.842491e-01  3.842491e-01  4.144313e-01  4.144313e-01  4.610718e-01  5.977650e-01  7.731052e-01  7.731052e-01  8.523060e-01  9.184104e-01  9.749549e-01  \n#&gt; #unique......... 56, #Total UniqueCount: 217\n#&gt; var 1:\n#&gt; best............ 3.729259e+01\n#&gt; mean............ 9.873041e+01\n#&gt; variance........ 3.291501e+04\n#&gt; \n#&gt; GENERATION: 3\n#&gt; Lexical Fit..... 1.180299e-02  1.180299e-02  1.155612e-01  1.186261e-01  1.822343e-01  3.842491e-01  3.842491e-01  4.144313e-01  4.144313e-01  4.610718e-01  5.977650e-01  7.731052e-01  7.731052e-01  8.523060e-01  9.184104e-01  9.749549e-01  \n#&gt; #unique......... 56, #Total UniqueCount: 273\n#&gt; var 1:\n#&gt; best............ 3.729259e+01\n#&gt; mean............ 1.042351e+02\n#&gt; variance........ 2.899583e+04\n#&gt; \n#&gt; GENERATION: 4\n#&gt; Lexical Fit..... 1.180299e-02  1.180299e-02  1.155612e-01  1.186261e-01  1.822343e-01  3.842491e-01  3.842491e-01  4.144313e-01  4.144313e-01  4.610718e-01  5.977650e-01  7.731052e-01  7.731052e-01  8.523060e-01  9.184104e-01  9.749549e-01  \n#&gt; #unique......... 58, #Total UniqueCount: 331\n#&gt; var 1:\n#&gt; best............ 3.729259e+01\n#&gt; mean............ 1.050645e+02\n#&gt; variance........ 2.721152e+04\n#&gt; \n#&gt; GENERATION: 5\n#&gt; Lexical Fit..... 1.541148e-02  2.397991e-02  2.418950e-02  2.418950e-02  1.729273e-01  1.956942e-01  3.942807e-01  3.942807e-01  6.059370e-01  6.059370e-01  6.074259e-01  6.137460e-01  8.414918e-01  8.538318e-01  9.621995e-01  9.621995e-01  \n#&gt; #unique......... 58, #Total UniqueCount: 389\n#&gt; var 1:\n#&gt; best............ 2.941808e-01\n#&gt; mean............ 8.418536e+01\n#&gt; variance........ 1.578216e+04\n#&gt; \n#&gt; GENERATION: 6\n#&gt; Lexical Fit..... 4.145421e-02  4.145421e-02  4.499068e-02  4.499068e-02  1.608408e-01  1.806532e-01  2.764640e-01  4.729068e-01  4.729068e-01  6.940013e-01  6.940013e-01  7.762162e-01  8.635587e-01  8.667712e-01  8.667712e-01  9.507460e-01  \n#&gt; #unique......... 62, #Total UniqueCount: 451\n#&gt; var 1:\n#&gt; best............ 7.310932e-02\n#&gt; mean............ 9.403781e+01\n#&gt; variance........ 2.447312e+04\n#&gt; \n#&gt; GENERATION: 7\n#&gt; Lexical Fit..... 4.177047e-02  4.177047e-02  4.419097e-02  6.248288e-02  1.198352e-01  2.880778e-01  3.513309e-01  4.150287e-01  4.150287e-01  8.316757e-01  8.316757e-01  8.667712e-01  8.667712e-01  8.836843e-01  8.920699e-01  8.920699e-01  \n#&gt; #unique......... 61, #Total UniqueCount: 512\n#&gt; var 1:\n#&gt; best............ 8.760968e-02\n#&gt; mean............ 1.016562e+02\n#&gt; variance........ 4.437002e+04\n#&gt; \n#&gt; GENERATION: 8\n#&gt; Lexical Fit..... 4.177047e-02  4.177047e-02  4.559074e-02  6.427954e-02  1.215371e-01  2.846955e-01  3.519026e-01  4.150287e-01  4.150287e-01  8.316757e-01  8.316757e-01  8.667712e-01  8.667712e-01  8.794500e-01  8.948772e-01  8.948772e-01  \n#&gt; #unique......... 60, #Total UniqueCount: 572\n#&gt; var 1:\n#&gt; best............ 8.627748e-02\n#&gt; mean............ 7.473970e+01\n#&gt; variance........ 2.676016e+04\n#&gt; \n#&gt; GENERATION: 9\n#&gt; Lexical Fit..... 4.177047e-02  4.177047e-02  4.559074e-02  6.427954e-02  1.215371e-01  2.846955e-01  3.519026e-01  4.150287e-01  4.150287e-01  8.316757e-01  8.316757e-01  8.667712e-01  8.667712e-01  8.794500e-01  8.948772e-01  8.948772e-01  \n#&gt; #unique......... 55, #Total UniqueCount: 627\n#&gt; var 1:\n#&gt; best............ 8.627748e-02\n#&gt; mean............ 4.192386e+01\n#&gt; variance........ 1.737331e+04\n#&gt; \n#&gt; GENERATION: 10\n#&gt; Lexical Fit..... 4.177047e-02  4.177047e-02  4.559074e-02  6.427954e-02  1.215371e-01  2.846955e-01  3.519026e-01  4.150287e-01  4.150287e-01  8.316757e-01  8.316757e-01  8.667712e-01  8.667712e-01  8.794500e-01  8.948772e-01  8.948772e-01  \n#&gt; #unique......... 51, #Total UniqueCount: 678\n#&gt; var 1:\n#&gt; best............ 8.627748e-02\n#&gt; mean............ 6.242257e+01\n#&gt; variance........ 2.722981e+04\n#&gt; \n#&gt; GENERATION: 11\n#&gt; Lexical Fit..... 4.177047e-02  4.177047e-02  4.559074e-02  6.427954e-02  1.215371e-01  2.846955e-01  3.519026e-01  4.150287e-01  4.150287e-01  8.316757e-01  8.316757e-01  8.667712e-01  8.667712e-01  8.794500e-01  8.948772e-01  8.948772e-01  \n#&gt; #unique......... 49, #Total UniqueCount: 727\n#&gt; var 1:\n#&gt; best............ 8.627748e-02\n#&gt; mean............ 5.280735e+01\n#&gt; variance........ 1.784927e+04\n#&gt; \n#&gt; GENERATION: 12\n#&gt; Lexical Fit..... 4.177047e-02  4.177047e-02  4.559074e-02  6.427954e-02  1.215371e-01  2.846955e-01  3.519026e-01  4.150287e-01  4.150287e-01  8.316757e-01  8.316757e-01  8.667712e-01  8.667712e-01  8.794500e-01  8.948772e-01  8.948772e-01  \n#&gt; #unique......... 50, #Total UniqueCount: 777\n#&gt; var 1:\n#&gt; best............ 8.627748e-02\n#&gt; mean............ 5.682777e+01\n#&gt; variance........ 2.131922e+04\n#&gt; \n#&gt; GENERATION: 13\n#&gt; Lexical Fit..... 4.177047e-02  4.177047e-02  4.559074e-02  6.427954e-02  1.215371e-01  2.846955e-01  3.519026e-01  4.150287e-01  4.150287e-01  8.316757e-01  8.316757e-01  8.667712e-01  8.667712e-01  8.794500e-01  8.948772e-01  8.948772e-01  \n#&gt; #unique......... 53, #Total UniqueCount: 830\n#&gt; var 1:\n#&gt; best............ 8.627748e-02\n#&gt; mean............ 3.877940e+01\n#&gt; variance........ 1.599211e+04\n#&gt; \n#&gt; 'wait.generations' limit reached.\n#&gt; No significant improvement in 4 generations.\n#&gt; \n#&gt; Solution Lexical Fitness Value:\n#&gt; 4.177047e-02  4.177047e-02  4.559074e-02  6.427954e-02  1.215371e-01  2.846955e-01  3.519026e-01  4.150287e-01  4.150287e-01  8.316757e-01  8.316757e-01  8.667712e-01  8.667712e-01  8.794500e-01  8.948772e-01  8.948772e-01  \n#&gt; \n#&gt; Parameters at the Solution:\n#&gt; \n#&gt;  X[ 1] : 8.627748e-02\n#&gt; \n#&gt; Solution Found Generation 8\n#&gt; Number of Generations Run 13\n#&gt; \n#&gt; Sat Aug 31 15:02:38 2024\n#&gt; Total run time : 0 hours 0 minutes and 5 seconds\n\nPSM &lt;-  Match(Y=re78,\n             Tr = treat,\n             X=glm_ps$fitted.values,\n             estimand = \"ATT\",\n             Weight.matrix = gen_match,\n             replace = TRUE,)\nsummary(PSM)\n#&gt; \n#&gt; Estimate...  2439.3 \n#&gt; AI SE......  813.4 \n#&gt; T-stat.....  2.9989 \n#&gt; p.val......  0.0027099 \n#&gt; \n#&gt; Original number of observations..............  445 \n#&gt; Original number of treated obs...............  185 \n#&gt; Matched number of observations...............  185 \n#&gt; Matched number of observations  (unweighted).  489\n\ncheck_balance2 &lt;- MatchBalance(\n    formul = treat ~ age + educ + black + hisp + married + nodegr + re74  + re75,\n    match.out = PSM,\n    nboots = 1000,data = lalonde\n)\n#&gt; \n#&gt; ***** (V1) age *****\n#&gt;                        Before Matching        After Matching\n#&gt; mean treatment........     25.816             25.816 \n#&gt; mean control..........     25.054             25.217 \n#&gt; std mean diff.........     10.655             8.3769 \n#&gt; \n#&gt; mean raw eQQ diff.....    0.94054            0.46217 \n#&gt; med  raw eQQ diff.....          1                  0 \n#&gt; max  raw eQQ diff.....          7                  9 \n#&gt; \n#&gt; mean eCDF diff........   0.025364           0.012952 \n#&gt; med  eCDF diff........   0.022193           0.010225 \n#&gt; max  eCDF diff........   0.065177            0.03681 \n#&gt; \n#&gt; var ratio (Tr/Co).....     1.0278             1.2224 \n#&gt; T-test p-value........    0.26594             0.3519 \n#&gt; KS Bootstrap p-value..      0.503              0.734 \n#&gt; KS Naive p-value......     0.7481            0.89488 \n#&gt; KS Statistic..........   0.065177            0.03681 \n#&gt; \n#&gt; \n#&gt; ***** (V2) educ *****\n#&gt;                        Before Matching        After Matching\n#&gt; mean treatment........     10.346             10.346 \n#&gt; mean control..........     10.088             10.188 \n#&gt; std mean diff.........     12.806             7.8605 \n#&gt; \n#&gt; mean raw eQQ diff.....    0.40541            0.17587 \n#&gt; med  raw eQQ diff.....          0                  0 \n#&gt; max  raw eQQ diff.....          2                  2 \n#&gt; \n#&gt; mean eCDF diff........   0.028698           0.012562 \n#&gt; med  eCDF diff........   0.012682           0.010225 \n#&gt; max  eCDF diff........    0.12651            0.03681 \n#&gt; \n#&gt; var ratio (Tr/Co).....     1.5513             1.2791 \n#&gt; T-test p-value........    0.15017             0.2847 \n#&gt; KS Bootstrap p-value..      0.011              0.456 \n#&gt; KS Naive p-value......   0.062873            0.89488 \n#&gt; KS Statistic..........    0.12651            0.03681 \n#&gt; \n#&gt; \n#&gt; ***** (V3) black *****\n#&gt;                        Before Matching        After Matching\n#&gt; mean treatment........    0.84324            0.84324 \n#&gt; mean control..........    0.82692              0.868 \n#&gt; std mean diff.........     4.4767            -6.7917 \n#&gt; \n#&gt; mean raw eQQ diff.....   0.016216           0.034765 \n#&gt; med  raw eQQ diff.....          0                  0 \n#&gt; max  raw eQQ diff.....          1                  1 \n#&gt; \n#&gt; mean eCDF diff........  0.0081601           0.017382 \n#&gt; med  eCDF diff........  0.0081601           0.017382 \n#&gt; max  eCDF diff........    0.01632           0.034765 \n#&gt; \n#&gt; var ratio (Tr/Co).....    0.92503             1.1537 \n#&gt; T-test p-value........    0.64736            0.41503 \n#&gt; \n#&gt; \n#&gt; ***** (V4) hisp *****\n#&gt;                        Before Matching        After Matching\n#&gt; mean treatment........   0.059459           0.059459 \n#&gt; mean control..........    0.10769           0.057132 \n#&gt; std mean diff.........    -20.341            0.98148 \n#&gt; \n#&gt; mean raw eQQ diff.....   0.048649            0.00818 \n#&gt; med  raw eQQ diff.....          0                  0 \n#&gt; max  raw eQQ diff.....          1                  1 \n#&gt; \n#&gt; mean eCDF diff........   0.024116            0.00409 \n#&gt; med  eCDF diff........   0.024116            0.00409 \n#&gt; max  eCDF diff........   0.048233            0.00818 \n#&gt; \n#&gt; var ratio (Tr/Co).....    0.58288             1.0382 \n#&gt; T-test p-value........   0.064043            0.86677 \n#&gt; \n#&gt; \n#&gt; ***** (V5) married *****\n#&gt;                        Before Matching        After Matching\n#&gt; mean treatment........    0.18919            0.18919 \n#&gt; mean control..........    0.15385            0.18101 \n#&gt; std mean diff.........     8.9995             2.0837 \n#&gt; \n#&gt; mean raw eQQ diff.....   0.037838           0.018405 \n#&gt; med  raw eQQ diff.....          0                  0 \n#&gt; max  raw eQQ diff.....          1                  1 \n#&gt; \n#&gt; mean eCDF diff........   0.017672          0.0092025 \n#&gt; med  eCDF diff........   0.017672          0.0092025 \n#&gt; max  eCDF diff........   0.035343           0.018405 \n#&gt; \n#&gt; var ratio (Tr/Co).....     1.1802             1.0348 \n#&gt; T-test p-value........    0.33425            0.83168 \n#&gt; \n#&gt; \n#&gt; ***** (V6) nodegr *****\n#&gt;                        Before Matching        After Matching\n#&gt; mean treatment........    0.70811            0.70811 \n#&gt; mean control..........    0.83462            0.75333 \n#&gt; std mean diff.........    -27.751            -9.9207 \n#&gt; \n#&gt; mean raw eQQ diff.....    0.12432           0.034765 \n#&gt; med  raw eQQ diff.....          0                  0 \n#&gt; max  raw eQQ diff.....          1                  1 \n#&gt; \n#&gt; mean eCDF diff........   0.063254           0.017382 \n#&gt; med  eCDF diff........   0.063254           0.017382 \n#&gt; max  eCDF diff........    0.12651           0.034765 \n#&gt; \n#&gt; var ratio (Tr/Co).....     1.4998             1.1123 \n#&gt; T-test p-value........  0.0020368            0.04177 \n#&gt; \n#&gt; \n#&gt; ***** (V7) re74 *****\n#&gt;                        Before Matching        After Matching\n#&gt; mean treatment........     2095.6             2095.6 \n#&gt; mean control..........       2107             2018.1 \n#&gt; std mean diff.........   -0.23437             1.5857 \n#&gt; \n#&gt; mean raw eQQ diff.....     487.98             648.91 \n#&gt; med  raw eQQ diff.....          0                  0 \n#&gt; max  raw eQQ diff.....       8413              10305 \n#&gt; \n#&gt; mean eCDF diff........   0.019223           0.037077 \n#&gt; med  eCDF diff........     0.0158           0.033742 \n#&gt; max  eCDF diff........   0.047089           0.087935 \n#&gt; \n#&gt; var ratio (Tr/Co).....     0.7381            0.86668 \n#&gt; T-test p-value........    0.98186            0.87945 \n#&gt; KS Bootstrap p-value..      0.555              0.002 \n#&gt; KS Naive p-value......    0.97023           0.045591 \n#&gt; KS Statistic..........   0.047089           0.087935 \n#&gt; \n#&gt; \n#&gt; ***** (V8) re75 *****\n#&gt;                        Before Matching        After Matching\n#&gt; mean treatment........     1532.1             1532.1 \n#&gt; mean control..........     1266.9             2079.5 \n#&gt; std mean diff.........     8.2363            -17.005 \n#&gt; \n#&gt; mean raw eQQ diff.....     367.61             532.46 \n#&gt; med  raw eQQ diff.....          0                  0 \n#&gt; max  raw eQQ diff.....     2110.2             8092.9 \n#&gt; \n#&gt; mean eCDF diff........   0.050834           0.040137 \n#&gt; med  eCDF diff........   0.061954             0.0409 \n#&gt; max  eCDF diff........    0.10748           0.083845 \n#&gt; \n#&gt; var ratio (Tr/Co).....     1.0763            0.64518 \n#&gt; T-test p-value........    0.38527            0.12154 \n#&gt; KS Bootstrap p-value..      0.038               0.02 \n#&gt; KS Naive p-value......    0.16449            0.06428 \n#&gt; KS Statistic..........    0.10748           0.083845 \n#&gt; \n#&gt; \n#&gt; Before Matching Minimum p.value: 0.0020368 \n#&gt; Variable Name(s): nodegr  Number(s): 6 \n#&gt; \n#&gt; After Matching Minimum p.value: 0.002 \n#&gt; Variable Name(s): re74  Number(s): 7\n\n# age 变平衡了\nqqplot(lalonde$age[PSM$index.control],lalonde$age[PSM$index.treated])\nabline(a=0,b=1)\n\n\n\n\n\n\nCode\n# re74 也变平衡了\nqqplot(lalonde$re74[PSM$index.control],lalonde$re74[PSM$index.treated])\nabline(a=0,b=1)\n\n\n\n\n\n\n\n\n24.4.3 敏感性分析\n\nCodelibrary(rbounds)\npsens(x =lalonde[PSM$index.treated,\"re78\"],\n      y =lalonde[PSM$index.control,\"re78\"] ,\n      Gamma = 2,\n      GammaInc = 0.1)\n#&gt; \n#&gt;  Rosenbaum Sensitivity Test for Wilcoxon Signed Rank P-Value \n#&gt;  \n#&gt; Unconfounded estimate ....  1e-04 \n#&gt; \n#&gt;  Gamma Lower bound Upper bound\n#&gt;    1.0       1e-04      0.0001\n#&gt;    1.1       0e+00      0.0015\n#&gt;    1.2       0e+00      0.0142\n#&gt;    1.3       0e+00      0.0693\n#&gt;    1.4       0e+00      0.2048\n#&gt;    1.5       0e+00      0.4152\n#&gt;    1.6       0e+00      0.6393\n#&gt;    1.7       0e+00      0.8140\n#&gt;    1.8       0e+00      0.9191\n#&gt;    1.9       0e+00      0.9699\n#&gt;    2.0       0e+00      0.9903\n#&gt; \n#&gt;  Note: Gamma is Odds of Differential Assignment To\n#&gt;  Treatment Due to Unobserved Factors \n#&gt; \n# psens\n\n\n对PSM（Y=re78）使用psens()进行Wilcoxon 符合秩检验，当τ=1.3，p值就大于0.05了，说明处理发生比为1.3时，就可以改变原先对于处理效应的结论，也就是说，这个隐藏性偏差不必太大就可以改变原来的结论，因此分析结果对隐藏性排除的影响非常敏感，结论不可靠。\n对 PSM（Y=re78）使用Hodges-Lehmann点估计检验法 hlsens() ，当τ=1.5，其95%置信区间包含零，说明此时处理效应是无效的。说明处理发生比为1.5时，隐藏性偏差就可以改变原来的结论，因此匹配后的结论不可靠。\n\nCodex = lalonde[PSM$index.treated, \"re78\"]\ny = lalonde[PSM$index.control, \"re78\"]\nhlsens(x, y,Gamma = 2,GammaInc = 0.1)\n#&gt; \n#&gt;  Rosenbaum Sensitivity Test for Hodges-Lehmann Point Estimate \n#&gt;  \n#&gt; Unconfounded estimate ....  1527.95 \n#&gt; \n#&gt;  Gamma Lower bound Upper bound\n#&gt;    1.0 1527.900000      1527.9\n#&gt;    1.1  917.250000      1580.2\n#&gt;    1.2  608.050000      1918.7\n#&gt;    1.3  338.450000      2141.0\n#&gt;    1.4  114.850000      2407.3\n#&gt;    1.5   -0.050046      2631.4\n#&gt;    1.6 -154.050000      2850.3\n#&gt;    1.7 -378.150000      3072.7\n#&gt;    1.8 -545.350000      3258.1\n#&gt;    1.9 -706.350000      3474.2\n#&gt;    2.0 -867.650000      3678.9\n#&gt; \n#&gt;  Note: Gamma is Odds of Differential Assignment To\n#&gt;  Treatment Due to Unobserved Factors \n#&gt; \n\n\n共同支持域的查验\n\nCodesum(glm_ps$fitted.values[lalonde$treat==1]&gt; \n        max(glm_ps$fitted.values[lalonde$treat==0]))\n#&gt; [1] 4\n\nsum(glm_ps$fitted.values[lalonde$treat==1]&lt; \n        min(glm_ps$fitted.values[lalonde$treat==0]))\n#&gt; [1] 0\n\n\n丢弃的实验组样本共有4个。185-181\n\nCodeattach(lalonde)\nsummary(PSM)\n#&gt; \n#&gt; Estimate...  2439.3 \n#&gt; AI SE......  813.4 \n#&gt; T-stat.....  2.9989 \n#&gt; p.val......  0.0027099 \n#&gt; \n#&gt; Original number of observations..............  445 \n#&gt; Original number of treated obs...............  185 \n#&gt; Matched number of observations...............  185 \n#&gt; Matched number of observations  (unweighted).  489\nPSM_CS &lt;-  Match(Y=re78,\n             Tr = treat,\n             X=glm_ps$fitted.values,\n             estimand = \"ATT\",\n             Weight.matrix = gen_match,\n             replace = TRUE,\n             CommonSupport = TRUE)\nsummary(PSM_CS)\n#&gt; \n#&gt; Estimate...  2330 \n#&gt; AI SE......  821.6 \n#&gt; T-stat.....  2.836 \n#&gt; p.val......  0.0045684 \n#&gt; \n#&gt; Original number of observations..............  430 \n#&gt; Original number of treated obs...............  181 \n#&gt; Matched number of observations...............  181 \n#&gt; Matched number of observations  (unweighted).  468\ndetach(lalonde)\n\n\n有查验共同支持域的ATT（2330），与无查验共同支持域（2439.3）存在差异，因此必须重新改进倾向值分析。\n\n24.4.4 MatchIt\n\n24.4.4.1 匹配数据\n\nCodelibrary(MatchIt)\nNM &lt;- MatchIt::matchit(\n    formula = treat ~ age + educ + black + hisp + married + nodegr + re74  + re75,\n    data = lalonde,\n    method = \"nearest\", # 最近邻匹配\n    ratio = 1, # 1:1\n    replace = FALSE\n)\nsummary(NM)\n#&gt; \n#&gt; Call:\n#&gt; MatchIt::matchit(formula = treat ~ age + educ + black + hisp + \n#&gt;     married + nodegr + re74 + re75, data = lalonde, method = \"nearest\", \n#&gt;     replace = FALSE, ratio = 1)\n#&gt; \n#&gt; Summary of Balance for All Data:\n#&gt;          Means Treated Means Control Std. Mean Diff. Var. Ratio eCDF Mean\n#&gt; distance        0.4377        0.4001          0.3935     1.0471    0.1117\n#&gt; age            25.8162       25.0538          0.1066     1.0278    0.0254\n#&gt; educ           10.3459       10.0885          0.1281     1.5513    0.0287\n#&gt; black           0.8432        0.8269          0.0449          .    0.0163\n#&gt; hisp            0.0595        0.1077         -0.2040          .    0.0482\n#&gt; married         0.1892        0.1538          0.0902          .    0.0353\n#&gt; nodegr          0.7081        0.8346         -0.2783          .    0.1265\n#&gt; re74         2095.5740     2107.0268         -0.0023     0.7381    0.0192\n#&gt; re75         1532.0556     1266.9092          0.0824     1.0763    0.0508\n#&gt;          eCDF Max\n#&gt; distance   0.2140\n#&gt; age        0.0652\n#&gt; educ       0.1265\n#&gt; black      0.0163\n#&gt; hisp       0.0482\n#&gt; married    0.0353\n#&gt; nodegr     0.1265\n#&gt; re74       0.0471\n#&gt; re75       0.1075\n#&gt; \n#&gt; Summary of Balance for Matched Data:\n#&gt;          Means Treated Means Control Std. Mean Diff. Var. Ratio eCDF Mean\n#&gt; distance        0.4377        0.4267          0.1152     1.0987    0.0298\n#&gt; age            25.8162       25.8757         -0.0083     0.9551    0.0121\n#&gt; educ           10.3459       10.1459          0.0995     1.3748    0.0220\n#&gt; black           0.8432        0.8486         -0.0149          .    0.0054\n#&gt; hisp            0.0595        0.0649         -0.0229          .    0.0054\n#&gt; married         0.1892        0.2000         -0.0276          .    0.0108\n#&gt; nodegr          0.7081        0.7730         -0.1427          .    0.0649\n#&gt; re74         2095.5740     1659.5326          0.0892     1.1752    0.0351\n#&gt; re75         1532.0556     1359.6980          0.0535     0.9270    0.0502\n#&gt;          eCDF Max Std. Pair Dist.\n#&gt; distance   0.1027          0.1302\n#&gt; age        0.0432          0.8711\n#&gt; educ       0.0757          0.6533\n#&gt; black      0.0054          0.4906\n#&gt; hisp       0.0054          0.2057\n#&gt; married    0.0108          0.7177\n#&gt; nodegr     0.0649          0.2378\n#&gt; re74       0.0865          0.6297\n#&gt; re75       0.1081          0.7019\n#&gt; \n#&gt; Sample Sizes:\n#&gt;           Control Treated\n#&gt; All           260     185\n#&gt; Matched       185     185\n#&gt; Unmatched      75       0\n#&gt; Discarded       0       0\n\n\n\n24.4.4.2 评估质量\n\nCode# 散点图展示了匹配后实验组和对照组样本倾向值的分布，凸显了分布平衡与不平衡，分布缺乏重合\nplot(NM,type = \"jitter\")\n\n\n\n\n\n\n#&gt; To identify the units, use first mouse button; to stop, use second.\n\n\nCode# QQ图 展示了 匹配前（All）匹配后（Matched）的平衡情况\nplot(NM,type = \"QQ\")\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCode\n# 直方图展示了匹配前后倾向值的分布\nplot(NM,type = \"hist\")\n\n\n\n\n\n\n\n\nCode# 标准化平衡统计值，Std. Mean Diff.\nsummary(NM,standardize = TRUE)\n#&gt; \n#&gt; Call:\n#&gt; MatchIt::matchit(formula = treat ~ age + educ + black + hisp + \n#&gt;     married + nodegr + re74 + re75, data = lalonde, method = \"nearest\", \n#&gt;     replace = FALSE, ratio = 1)\n#&gt; \n#&gt; Summary of Balance for All Data:\n#&gt;          Means Treated Means Control Std. Mean Diff. Var. Ratio eCDF Mean\n#&gt; distance        0.4377        0.4001          0.3935     1.0471    0.1117\n#&gt; age            25.8162       25.0538          0.1066     1.0278    0.0254\n#&gt; educ           10.3459       10.0885          0.1281     1.5513    0.0287\n#&gt; black           0.8432        0.8269          0.0449          .    0.0163\n#&gt; hisp            0.0595        0.1077         -0.2040          .    0.0482\n#&gt; married         0.1892        0.1538          0.0902          .    0.0353\n#&gt; nodegr          0.7081        0.8346         -0.2783          .    0.1265\n#&gt; re74         2095.5740     2107.0268         -0.0023     0.7381    0.0192\n#&gt; re75         1532.0556     1266.9092          0.0824     1.0763    0.0508\n#&gt;          eCDF Max\n#&gt; distance   0.2140\n#&gt; age        0.0652\n#&gt; educ       0.1265\n#&gt; black      0.0163\n#&gt; hisp       0.0482\n#&gt; married    0.0353\n#&gt; nodegr     0.1265\n#&gt; re74       0.0471\n#&gt; re75       0.1075\n#&gt; \n#&gt; Summary of Balance for Matched Data:\n#&gt;          Means Treated Means Control Std. Mean Diff. Var. Ratio eCDF Mean\n#&gt; distance        0.4377        0.4267          0.1152     1.0987    0.0298\n#&gt; age            25.8162       25.8757         -0.0083     0.9551    0.0121\n#&gt; educ           10.3459       10.1459          0.0995     1.3748    0.0220\n#&gt; black           0.8432        0.8486         -0.0149          .    0.0054\n#&gt; hisp            0.0595        0.0649         -0.0229          .    0.0054\n#&gt; married         0.1892        0.2000         -0.0276          .    0.0108\n#&gt; nodegr          0.7081        0.7730         -0.1427          .    0.0649\n#&gt; re74         2095.5740     1659.5326          0.0892     1.1752    0.0351\n#&gt; re75         1532.0556     1359.6980          0.0535     0.9270    0.0502\n#&gt;          eCDF Max Std. Pair Dist.\n#&gt; distance   0.1027          0.1302\n#&gt; age        0.0432          0.8711\n#&gt; educ       0.0757          0.6533\n#&gt; black      0.0054          0.4906\n#&gt; hisp       0.0054          0.2057\n#&gt; married    0.0108          0.7177\n#&gt; nodegr     0.0649          0.2378\n#&gt; re74       0.0865          0.6297\n#&gt; re75       0.1081          0.7019\n#&gt; \n#&gt; Sample Sizes:\n#&gt;           Control Treated\n#&gt; All           260     185\n#&gt; Matched       185     185\n#&gt; Unmatched      75       0\n#&gt; Discarded       0       0\n\n\n继续改进，调整模型和协变量\n\n24.4.4.3 计算平均处理效应\n为了简化步骤，以当前的结果进行匹配后分析。\n\nCode\n# 提取匹配后的样本\nmData &lt;- match.data(NM,group = \"all\")\nmData_trt &lt;- match.data(NM,group = \"treat\")\nmData_ctrl &lt;- match.data(NM,group = \"control\")\n \n# 包从CRAN剔除了\n\n\n\nCodelibrary(rbounds)\npsens(x =mData_trt$re78,\n      y =mData_ctrl$re78 ,Gamma = 2,GammaInc = 0.1)\n#&gt; \n#&gt;  Rosenbaum Sensitivity Test for Wilcoxon Signed Rank P-Value \n#&gt;  \n#&gt; Unconfounded estimate ....  0.0199 \n#&gt; \n#&gt;  Gamma Lower bound Upper bound\n#&gt;    1.0      0.0199      0.0199\n#&gt;    1.1      0.0048      0.0639\n#&gt;    1.2      0.0010      0.1491\n#&gt;    1.3      0.0002      0.2749\n#&gt;    1.4      0.0000      0.4248\n#&gt;    1.5      0.0000      0.5755\n#&gt;    1.6      0.0000      0.7076\n#&gt;    1.7      0.0000      0.8108\n#&gt;    1.8      0.0000      0.8844\n#&gt;    1.9      0.0000      0.9328\n#&gt;    2.0      0.0000      0.9627\n#&gt; \n#&gt;  Note: Gamma is Odds of Differential Assignment To\n#&gt;  Treatment Due to Unobserved Factors \n#&gt; \n\nhlsens(x =mData_trt$re78,\n      y =mData_ctrl$re78 ,Gamma = 2,GammaInc = 0.1)\n#&gt; \n#&gt;  Rosenbaum Sensitivity Test for Hodges-Lehmann Point Estimate \n#&gt;  \n#&gt; Unconfounded estimate ....  1435.08 \n#&gt; \n#&gt;  Gamma Lower bound Upper bound\n#&gt;    1.0  1.4351e+03      1435.1\n#&gt;    1.1  8.0828e+02      1515.9\n#&gt;    1.2  4.6298e+02      1809.0\n#&gt;    1.3  1.8238e+02      2178.1\n#&gt;    1.4 -2.0266e-02      2439.4\n#&gt;    1.5 -2.4892e+02      2678.5\n#&gt;    1.6 -4.5162e+02      2937.5\n#&gt;    1.7 -6.7212e+02      3184.0\n#&gt;    1.8 -8.9732e+02      3462.6\n#&gt;    1.9 -1.1328e+03      3651.1\n#&gt;    2.0 -1.3022e+03      3848.9\n#&gt; \n#&gt;  Note: Gamma is Odds of Differential Assignment To\n#&gt;  Treatment Due to Unobserved Factors \n#&gt;",
    "crumbs": [
      "倾向性评分",
      "<span class='chapter-number'>24</span>  <span class='chapter-title'>匹配（Matching）</span>"
    ]
  },
  {
    "objectID": "diagnostic_test.html",
    "href": "diagnostic_test.html",
    "title": "\n25  诊断性测试\n",
    "section": "",
    "text": "25.1 基本特征",
    "crumbs": [
      "研究设计",
      "<span class='chapter-number'>25</span>  <span class='chapter-title'>诊断性测试</span>"
    ]
  },
  {
    "objectID": "diagnostic_test.html#基本特征",
    "href": "diagnostic_test.html#基本特征",
    "title": "\n25  诊断性测试\n",
    "section": "",
    "text": "25.1.1 灵敏度（Sensitivity）\n真阳性率：指在所有真实状况为阳性的样本中，被正确识别出阳性的比例。\n\\[\nSe=\\frac{TP}{TP+FN}\n\\]\n其中TP 是真阳性的数量，FN 是假阴性的数量。\n假阴性率(FNR) /漏诊率\n\\[\nFNR=1-Se\n\\]\n\n25.1.2 特异度（Specificity）\n真阴性率：指在所有真实状况为阴性的样本中，被正确识别出阴性的比例。\n\\[\nSp=\\frac{TN}{TN+FP}\n\\]\n其中 TN 是真阴性的数量，FP 是假阳性的数量。\n假阳性率(FPR) /误诊率\n\\[ FPR=1-Sp \\]\n\n\n\n\n\nCode# 构建列联表\nobserved_sensitivity &lt;- matrix(c(28, 11, 37, 2), nrow = 2, byrow = TRUE,\n                   dimnames = list('检验方式' = c('尿糖检验', '血糖检验'),\n                                   '结果' = c('检出阳性', '未检出阳性')))\nobserved_sensitivity\n#&gt;           结果\n#&gt; 检验方式 检出阳性 未检出阳性\n#&gt;   尿糖检验       28         11\n#&gt;   血糖检验       37          2\n# 进行卡方检验\ns &lt;- chisq.test(observed_sensitivity,correct = F)\n\n# 输出结果\ns\n#&gt; \n#&gt;  Pearson's Chi-squared test\n#&gt; \n#&gt; data:  observed_sensitivity\n#&gt; X-squared = 7.4769, df = 1, p-value = 0.006249\n\n\n# 构建列联表\nobserved_accuracy &lt;- matrix(c(29, 11, 38, 2), nrow = 2, byrow = TRUE,\n                            dimnames = list('检验方式' = c('尿糖检验', '血糖检验'),\n                                            '结果' = c('检准', '不准')))\n\n# 进行卡方检验\naccuracy &lt;- chisq.test(observed_accuracy,correct = F)\n\n# 输出结果\naccuracy\n#&gt; \n#&gt;  Pearson's Chi-squared test\n#&gt; \n#&gt; data:  observed_accuracy\n#&gt; X-squared = 7.4397, df = 1, p-value = 0.00638\n\n\n\n25.1.3 Youden’s Index\n\\[\nJ=Se-FPR =Se+Sp-1,J[1,-1]\n\\]\n\nJ 越大诊断有效性越高\nJ=1 表示完美的诊断性能，因为Se，Sp都是1。\nJ≤0 表示没有诊断价值\n\n25.1.4 Likelihood Ratio\n正似然比\n\\[\nLR+=\\frac{Se}{FPR}=\\frac{Se}{1-Sp}\n\\]\n\nLR+越大表示患病测出阳性结果的优势越大\nLR+=1表示诊断无效\n\n负似然比\n\\[\nLR-=\\frac{FNR}{Sp}=\\frac{1-Sp}{Sp}\n\\]\n\nLR-越小表示患病测出阴性结果的优势越小\nLR-=1表示诊断无效\n\n25.1.5 预测值\n\nCodem\n#&gt;        truth\n#&gt; predict +    -   \n#&gt;       + \"TP\" \"FP\"\n#&gt;       - \"FN\" \"TN\"\n\n\n阳性预测值（Positive Predictive Value, PPV）：在所有被测试为阳性的样本中，真正的阳性比例。\n\\[\nPPV=\\frac{TP}{TP+NP}\n\\]\n阴性预测值（Negative Predictive Value, NPV）：在所有被测试为阴性的样本中，真正的阴性比例。\n\\[\nPPV=\\frac{TN}{TN+FN}\n\\]\n配对样本设计\n\\(\\chi^2\\)配对检验\n完全随机设计\n\\(\\chi^2\\)检验",
    "crumbs": [
      "研究设计",
      "<span class='chapter-number'>25</span>  <span class='chapter-title'>诊断性测试</span>"
    ]
  },
  {
    "objectID": "diagnostic_test.html#一致性agreement",
    "href": "diagnostic_test.html#一致性agreement",
    "title": "\n25  诊断性测试\n",
    "section": "\n25.2 一致性agreement",
    "text": "25.2 一致性agreement\n准确度（Accuracy）：指测试正确地分类（阳性或阴性）的样本占总样本的比例。\n\\[\nAccuracy=\\frac{TP+TN}{N}\n\\]\nkappa 系数\n\\[\n\\kappa =\\frac{Accuracy-[(a+b)(a+c)+(c+d)(b+d)]/N^2}{1-[(a+b)(a+c)+(c+d)(b+d)]/N^2}\n\\]\n\nκ=1表示完全一致\nκ=-1表示完全不一致\nκ=0表示一致性与偶然一致性Pe相同\n\n通常κ＞0.7即可以认为两种诊断方法有较好的一致性",
    "crumbs": [
      "研究设计",
      "<span class='chapter-number'>25</span>  <span class='chapter-title'>诊断性测试</span>"
    ]
  },
  {
    "objectID": "diagnostic_test.html#roc曲线receiver-operating-characteristic-curve",
    "href": "diagnostic_test.html#roc曲线receiver-operating-characteristic-curve",
    "title": "\n25  诊断性测试\n",
    "section": "\n25.3 ROC曲线（Receiver Operating Characteristic Curve）",
    "text": "25.3 ROC曲线（Receiver Operating Characteristic Curve）\nROC曲线（Receiver Operating Characteristic Curve）：是一个图形工具，用于展示不同阈值下灵敏度和特异度之间的关系。曲线下面积（AUC）越接近1，表示测试的性能越好。\n\nCodelibrary(pROC)\n\nroc_data &lt;- aSAH %&gt;%\n    dplyr::filter(gender == \"Female\") %&gt;%\n    roc(outcome, s100b)\n\n\n\n# 绘制ROC曲线\nplot(roc_data, print.thres = \"best\", print.thres.pattern = \"Best cutoff: %.2f\", main = \"ROC Curve\")\n\n\n\n\n\n\nCode\n\n# 计算AUC\nauc_value &lt;- auc(roc_data)\nprint(paste(\"AUC:\", auc_value))\n#&gt; [1] \"AUC: 0.72\"\n\n\n\n25.3.1 AUC\n$ A=P(X&gt;Y) $\n\\[\nS(X,Y)=\n\\begin{cases}\n1,\\ \\ \\ \\  X&gt;Y\\\\\n1/2,X=Y\\\\\n0,\\ \\ \\ \\ X&lt;Y\\\\\n\\end{cases}\n\\]\n$ A=_1^{n_1}_1^{n_0}S(X,Y) $\n\n25.3.2 分组AUC的比较\n完全随机设计\n\\[\nZ=\\frac{\\hat A_1-\\hat A_2}{\\sqrt{Var(\\hat A_1)+Var(\\hat A_2)}}\n\\]\n配对样本设计\n\\[\nZ=\\frac{\\hat A_1-\\hat A_2}{\\sqrt{Var(\\hat A_1)+Var(\\hat A_2)-2Cov(\\hat A_1,\\hat A_2)}}\n\\]",
    "crumbs": [
      "研究设计",
      "<span class='chapter-number'>25</span>  <span class='chapter-title'>诊断性测试</span>"
    ]
  }
]