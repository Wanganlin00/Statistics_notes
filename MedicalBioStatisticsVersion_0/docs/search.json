[
  {
    "objectID": "multiple_linear_regression.html",
    "href": "multiple_linear_regression.html",
    "title": "\n17  多元线性回归\n",
    "section": "",
    "text": "17.1 多元回归\nShow the codelibrary(tidymodels)\nlibrary(patchwork)\nlibrary(ggfortify)\n\n# 检测变量相关关系\nad &lt;- advertising %&gt;% select(-1)\ncor(ad)\n#&gt;                   TV      radio  newspaper     sales\n#&gt; TV        1.00000000 0.05480866 0.05664787 0.7822244\n#&gt; radio     0.05480866 1.00000000 0.35410375 0.5762226\n#&gt; newspaper 0.05664787 0.35410375 1.00000000 0.2282990\n#&gt; sales     0.78222442 0.57622257 0.22829903 1.0000000",
    "crumbs": [
      "推断统计模型",
      "<span class='chapter-number'>17</span>  <span class='chapter-title'>多元线性回归</span>"
    ]
  },
  {
    "objectID": "multiple_linear_regression.html#多元回归",
    "href": "multiple_linear_regression.html#多元回归",
    "title": "\n17  多元线性回归\n",
    "section": "",
    "text": "17.1.1 rms::ols()\n\n\nShow the code\nols_mlm &lt;- rms::ols(sales~TV+radio+newspaper,data = advertising)\nols_mlm \n#&gt; Linear Regression Model\n#&gt; \n#&gt; rms::ols(formula = sales ~ TV + radio + newspaper, data = advertising)\n#&gt; \n#&gt;                 Model Likelihood    Discrimination    \n#&gt;                       Ratio Test           Indexes    \n#&gt; Obs     200    LR chi2    455.01    R2       0.897    \n#&gt; sigma1.6855    d.f.            3    R2 adj   0.896    \n#&gt; d.f.    196    Pr(&gt; chi2) 0.0000    g        5.685    \n#&gt; \n#&gt; Residuals\n#&gt; \n#&gt;     Min      1Q  Median      3Q     Max \n#&gt; -8.8277 -0.8908  0.2418  1.1893  2.8292 \n#&gt; \n#&gt; \n#&gt;           Coef    S.E.   t     Pr(&gt;|t|)\n#&gt; Intercept  2.9389 0.3119  9.42 &lt;0.0001 \n#&gt; TV         0.0458 0.0014 32.81 &lt;0.0001 \n#&gt; radio      0.1885 0.0086 21.89 &lt;0.0001 \n#&gt; newspaper -0.0010 0.0059 -0.18 0.8599\ntexreg::texreg(ols_mlm)\n#&gt; \n#&gt; \\begin{table}\n#&gt; \\begin{center}\n#&gt; \\begin{tabular}{l c}\n#&gt; \\hline\n#&gt;  & Model 1 \\\\\n#&gt; \\hline\n#&gt; Intercept  & $2.94^{***}$ \\\\\n#&gt;            & $(0.31)$     \\\\\n#&gt; TV         & $0.05^{***}$ \\\\\n#&gt;            & $(0.00)$     \\\\\n#&gt; radio      & $0.19^{***}$ \\\\\n#&gt;            & $(0.01)$     \\\\\n#&gt; newspaper  & $-0.00$      \\\\\n#&gt;            & $(0.01)$     \\\\\n#&gt; \\hline\n#&gt; Num. obs.  & $200$        \\\\\n#&gt; R$^2$      & $0.90$       \\\\\n#&gt; Adj. R$^2$ & $0.90$       \\\\\n#&gt; L.R.       & $455.01$     \\\\\n#&gt; \\hline\n#&gt; \\multicolumn{2}{l}{\\scriptsize{$^{***}p&lt;0.001$; $^{**}p&lt;0.01$; $^{*}p&lt;0.05$}}\n#&gt; \\end{tabular}\n#&gt; \\caption{Statistical models}\n#&gt; \\label{table:coefficients}\n#&gt; \\end{center}\n#&gt; \\end{table}\n\ncar::vif(ols_mlm)\n#&gt;        TV     radio newspaper \n#&gt;  3.966283  3.970266  3.410504\nanova(ols_mlm)\n#&gt;                 Analysis of Variance          Response: sales \n#&gt; \n#&gt;  Factor     d.f. Partial SS   MS           F       P     \n#&gt;  TV           1  3.058010e+03 3.058010e+03 1076.41 &lt;.0001\n#&gt;  radio        1  1.361737e+03 1.361737e+03  479.33 &lt;.0001\n#&gt;  newspaper    1  8.871717e-02 8.871717e-02    0.03 0.8599\n#&gt;  REGRESSION   3  4.860323e+03 1.620108e+03  570.27 &lt;.0001\n#&gt;  ERROR      196  5.568253e+02 2.840945e+00\n\n\n\n17.1.2 lm()\n\n\nShow the code# 多元线性回归\nlm_spec &lt;-linear_reg() %&gt;%\n  set_mode(\"regression\") %&gt;%\n  set_engine(\"lm\")  \nlm_spec\n#&gt; Linear Regression Model Specification (regression)\n#&gt; \n#&gt; Computational engine: lm\nlm_sales_multi&lt;- lm_spec %&gt;% fit(sales~TV+radio+newspaper,data = advertising)\nsummary(lm_sales_multi$fit)\n#&gt; \n#&gt; Call:\n#&gt; stats::lm(formula = sales ~ TV + radio + newspaper, data = data)\n#&gt; \n#&gt; Residuals:\n#&gt;     Min      1Q  Median      3Q     Max \n#&gt; -8.8277 -0.8908  0.2418  1.1893  2.8292 \n#&gt; \n#&gt; Coefficients:\n#&gt;              Estimate Std. Error t value Pr(&gt;|t|)    \n#&gt; (Intercept)  2.938889   0.311908   9.422   &lt;2e-16 ***\n#&gt; TV           0.045765   0.001395  32.809   &lt;2e-16 ***\n#&gt; radio        0.188530   0.008611  21.893   &lt;2e-16 ***\n#&gt; newspaper   -0.001037   0.005871  -0.177     0.86    \n#&gt; ---\n#&gt; Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n#&gt; \n#&gt; Residual standard error: 1.686 on 196 degrees of freedom\n#&gt; Multiple R-squared:  0.8972, Adjusted R-squared:  0.8956 \n#&gt; F-statistic: 570.3 on 3 and 196 DF,  p-value: &lt; 2.2e-16\n\ntidy(lm_sales_multi)\n\n\n\n\nterm\nestimate\nstd.error\nstatistic\np.value\n\n\n\n(Intercept)\n2.9388894\n0.3119082\n9.4222884\n0.0000000\n\n\nTV\n0.0457646\n0.0013949\n32.8086244\n0.0000000\n\n\nradio\n0.1885300\n0.0086112\n21.8934961\n0.0000000\n\n\nnewspaper\n-0.0010375\n0.0058710\n-0.1767146\n0.8599151\n\n\n\n\n\nShow the codeglance(lm_sales_multi)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nr.squared\nadj.r.squared\nsigma\nstatistic\np.value\ndf\nlogLik\nAIC\nBIC\ndeviance\ndf.residual\nnobs\n\n\n0.8972106\n0.8956373\n1.68551\n570.2707\n0\n3\n-386.1811\n782.3622\n798.8538\n556.8253\n196\n200\n\n\n\n\nShow the code\nlogLik(lm_sales_multi$fit)\n#&gt; 'log Lik.' -386.1811 (df=5)\ncar::vif(lm_sales_multi$fit)\n#&gt;        TV     radio newspaper \n#&gt;  1.004611  1.144952  1.145187\n\n\n\n17.1.3 线性组合\n我们经常希望对回归系数的线性组合进行推断，特别是对于多个类别的分类变量。例如，对于分类变量，回归系数表示其中一个组与参考类别之间的平均差异\n\nShow the codelm_multiple &lt;- lm(sales~TV+radio+newspaper,data = advertising)\nlm_multiple\n#&gt; \n#&gt; Call:\n#&gt; lm(formula = sales ~ TV + radio + newspaper, data = advertising)\n#&gt; \n#&gt; Coefficients:\n#&gt; (Intercept)           TV        radio    newspaper  \n#&gt;    2.938889     0.045765     0.188530    -0.001037\nlibrary(multcomp, quietly = T)\nconfint(lm_multiple)\n#&gt;                   2.5 %     97.5 %\n#&gt; (Intercept)  2.32376228 3.55401646\n#&gt; TV           0.04301371 0.04851558\n#&gt; radio        0.17154745 0.20551259\n#&gt; newspaper   -0.01261595 0.01054097\n# 在 R 中，我们通过首先指定一个矩阵来执行此计算，该矩阵指定要进行的比较。此处的矩阵必须具有与回归方程中的回归系数相同的列数\ncomparison &lt;- matrix(c(0,3,1,1), nrow=1)\n\nlincom &lt;- glht(lm_multiple, linfct = comparison)\nsummary(lincom)\n#&gt; \n#&gt;   Simultaneous Tests for General Linear Hypotheses\n#&gt; \n#&gt; Fit: lm(formula = sales ~ TV + radio + newspaper, data = advertising)\n#&gt; \n#&gt; Linear Hypotheses:\n#&gt;        Estimate Std. Error t value Pr(&gt;|t|)    \n#&gt; 1 == 0 0.324786   0.009268   35.05   &lt;2e-16 ***\n#&gt; ---\n#&gt; Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n#&gt; (Adjusted p values reported -- single-step method)\nconfint(lincom)\n#&gt; \n#&gt;   Simultaneous Confidence Intervals\n#&gt; \n#&gt; Fit: lm(formula = sales ~ TV + radio + newspaper, data = advertising)\n#&gt; \n#&gt; Quantile = 1.9721\n#&gt; 95% family-wise confidence level\n#&gt;  \n#&gt; \n#&gt; Linear Hypotheses:\n#&gt;        Estimate lwr    upr   \n#&gt; 1 == 0 0.3248   0.3065 0.3431",
    "crumbs": [
      "推断统计模型",
      "<span class='chapter-number'>17</span>  <span class='chapter-title'>多元线性回归</span>"
    ]
  },
  {
    "objectID": "multiple_linear_regression.html#交互项",
    "href": "multiple_linear_regression.html#交互项",
    "title": "\n17  多元线性回归\n",
    "section": "\n17.2 交互项",
    "text": "17.2 交互项\n\nShow the codelm_interact&lt;- lm_spec %&gt;%  fit(sales ~ .+ TV:radio, data = advertising)\n\nlm_interact\n#&gt; parsnip model object\n#&gt; \n#&gt; \n#&gt; Call:\n#&gt; stats::lm(formula = sales ~ . + TV:radio, data = data)\n#&gt; \n#&gt; Coefficients:\n#&gt; (Intercept)           id           TV        radio    newspaper     TV:radio  \n#&gt;   6.7912439   -0.0005502    0.0190783    0.0278567    0.0012488    0.0010873",
    "crumbs": [
      "推断统计模型",
      "<span class='chapter-number'>17</span>  <span class='chapter-title'>多元线性回归</span>"
    ]
  },
  {
    "objectID": "multiple_linear_regression.html#变换",
    "href": "multiple_linear_regression.html#变换",
    "title": "\n17  多元线性回归\n",
    "section": "\n17.3 变换",
    "text": "17.3 变换\n\n17.3.1 多项式\n\nShow the coderec_spec_square &lt;- recipe(sales ~ TV, data = advertising) %&gt;%  \n  step_mutate(`TV^2` = TV^2)  \nrec_spec_square\n\nlm_wf_square &lt;- workflow() %&gt;%  \n  add_model(lm_spec) %&gt;%  \n  add_recipe(rec_spec_square)  \n\nlm_wf_square %&gt;%\n  fit(advertising)\n#&gt; ══ Workflow [trained] ══════════════════════════════════════════════════════════\n#&gt; Preprocessor: Recipe\n#&gt; Model: linear_reg()\n#&gt; \n#&gt; ── Preprocessor ────────────────────────────────────────────────────────────────\n#&gt; 1 Recipe Step\n#&gt; \n#&gt; • step_mutate()\n#&gt; \n#&gt; ── Model ───────────────────────────────────────────────────────────────────────\n#&gt; \n#&gt; Call:\n#&gt; stats::lm(formula = ..y ~ ., data = data)\n#&gt; \n#&gt; Coefficients:\n#&gt; (Intercept)           TV       `TV^2`  \n#&gt;   6.114e+00    6.727e-02   -6.847e-05\n\nlm(sales ~ TV+ I(TV^2),data = advertising)\n#&gt; \n#&gt; Call:\n#&gt; lm(formula = sales ~ TV + I(TV^2), data = advertising)\n#&gt; \n#&gt; Coefficients:\n#&gt; (Intercept)           TV      I(TV^2)  \n#&gt;   6.114e+00    6.727e-02   -6.847e-05\n\n\n\n17.3.2 对数变换\n\nShow the coderec_spec_log &lt;- recipe(sales ~ TV, data = advertising) %&gt;%  \n  step_log(TV)  \n\nlm_wf_log &lt;- workflow() %&gt;% \n  add_model(lm_spec) %&gt;%  \n  add_recipe(rec_spec_log) \n\nlm_wf_log %&gt;%\n  fit(advertising)\n#&gt; ══ Workflow [trained] ══════════════════════════════════════════════════════════\n#&gt; Preprocessor: Recipe\n#&gt; Model: linear_reg()\n#&gt; \n#&gt; ── Preprocessor ────────────────────────────────────────────────────────────────\n#&gt; 1 Recipe Step\n#&gt; \n#&gt; • step_log()\n#&gt; \n#&gt; ── Model ───────────────────────────────────────────────────────────────────────\n#&gt; \n#&gt; Call:\n#&gt; stats::lm(formula = ..y ~ ., data = data)\n#&gt; \n#&gt; Coefficients:\n#&gt; (Intercept)           TV  \n#&gt;      -4.203        3.901\n\nlm(sales ~ log(TV),data = advertising)\n#&gt; \n#&gt; Call:\n#&gt; lm(formula = sales ~ log(TV), data = advertising)\n#&gt; \n#&gt; Coefficients:\n#&gt; (Intercept)      log(TV)  \n#&gt;      -4.203        3.901",
    "crumbs": [
      "推断统计模型",
      "<span class='chapter-number'>17</span>  <span class='chapter-title'>多元线性回归</span>"
    ]
  },
  {
    "objectID": "multiple_linear_regression.html#回归诊断",
    "href": "multiple_linear_regression.html#回归诊断",
    "title": "\n17  多元线性回归\n",
    "section": "\n17.4 回归诊断",
    "text": "17.4 回归诊断\nhttps://www.statmethods.net/stats/rdiagnostics.html\n\nShow the codelibrary(car)\ncar::scatterplotMatrix(ad)  # 多重共线性\n\n\n\n\n\n\nShow the codeconfint(lm_sales_multi$fit)  # 95%置信区间\n#&gt;                   2.5 %     97.5 %\n#&gt; (Intercept)  2.32376228 3.55401646\n#&gt; TV           0.04301371 0.04851558\n#&gt; radio        0.17154745 0.20551259\n#&gt; newspaper   -0.01261595 0.01054097\nplot(lm_sales_multi$fit)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nShow the codeautoplot(lm_sales_multi) #回归诊断图\n\n\n\n\n\n\n\n\n17.4.1 线性假设\n残差图， 成分残差图\n\nShow the codeplot(lm_sales_multi$fit,1)  \n\n\n\n\n\n\nShow the codecrPlots(lm_sales_multi$fit)\n\n\n\n\n\n\n\n\n17.4.2 正态性假设Q-Q图\nStandardized Residuals\n\nShow the codeplot(lm_sales_multi$fit,2) \n\n\n\n\n\n\nShow the codesummary(powerTransform(lm_sales_multi$fit))  \n#&gt; bcPower Transformation to Normality \n#&gt;    Est Power Rounded Pwr Wald Lwr Bnd Wald Upr Bnd\n#&gt; Y1    0.9074           1       0.7569       1.0578\n#&gt; \n#&gt; Likelihood ratio test that transformation parameter is equal to 0\n#&gt;  (log transformation)\n#&gt;                            LRT df       pval\n#&gt; LR test, lambda = (0) 147.1578  1 &lt; 2.22e-16\n#&gt; \n#&gt; Likelihood ratio test that no transformation is needed\n#&gt;                           LRT df    pval\n#&gt; LR test, lambda = (1) 1.41991  1 0.23342\n\n\n\nShow the codeplot(lm_sales_multi$fit,3)\n\n\n\n\n\n\n\n\n17.4.3 误差相关性\n\nShow the codedurbinWatsonTest(lm_sales_multi$fit)      #结果表明rho=0\n#&gt;  lag Autocorrelation D-W Statistic p-value\n#&gt;    1     -0.04687792      2.083648   0.554\n#&gt;  Alternative hypothesis: rho != 0\n\n\n\n17.4.4 误差项的方差齐性\n\nShow the codencvTest(lm_sales_multi$fit)\n#&gt; Non-constant Variance Score Test \n#&gt; Variance formula: ~ fitted.values \n#&gt; Chisquare = 5.355982, Df = 1, p = 0.020651\nspreadLevelPlot(lm_sales_multi$fit)\n\n\n\n\n\n\n#&gt; \n#&gt; Suggested power transformation:  1.499852\n\n\nShow the codetibble(\n    abs_studentized_residuals=abs(rstudent(lm_sales_multi$fit)),\n    fitted_values=lm_sales_multi$fit$model$sales\n) %&gt;% ggplot(aes(fitted_values,abs_studentized_residuals))+\n    geom_point(pch=21)+\n    geom_smooth()\n\n\n\n\n\n\n\n\n17.4.5 异常观测点\n\nShow the code# studentized residual Plot\nresidplot&lt;-function(fit,nbreaks=10){\n  z&lt;-rstudent(fit)\n  hist(z,breaks=nbreaks,freq=FALSE)     #密度直方图\n  title(xlab=\"Studentized Residual\")\n  rug(z,col=\"brown\")                    #轴须图\n  curve(dnorm(x,mean=mean(z),sd=sd(z)),add=TRUE,col=\"blue\",lwd=2) #正态密度曲线\n  lines(density(z)$x,density(z)$y,col=\"red\",lwd=2)       #样本密度曲线\n  legend(\"topright\",c(\"Normal Curve\",\"Kernel Density Curve\"),#图例\n  lty = c(3,2),pch = c(21,22),col=c(\"blue\",\"red\"),cex=.7)\n}\nresidplot(lm_sales_multi$fit)\n\n\n\n\n\n\n\n\nShow the code#######################################################################\nlibrary(car)\noutlierTest(lm_sales_multi$fit)            #离群点\n#高杠杆值点\nhat.plot&lt;-function(fit){\n  p&lt;-length(coefficients(fit)) #模型估计的参数数目（包含截距项）\n  n&lt;-length(fitted(fit))       #样本量\n  plot(hatvalues(fit),main=\"Index Plot of Hat Values\")#帽子值\n  abline(h=c(2,3)*p/n,col=\"red\",lty=2)  #大于帽子均值p/n的2或3倍被认为是高杠杆值\n  identity(1:n,hatvalues(fit),names(hatvalues(fit)))\n}\nhat.plot(lm_sales_multi$fit)\n####强影响点\n#Cook's D图形    大于4/(n-k-1)  k为预测变量数目\ncutoff&lt;-4/(nrow(advertising)-length(lm_sales_multi$fit$coefficients)-2)\n{plot(lm_sales_multi$fit,which=4,cook.levels=cutoff)\nabline(h=cutoff,lty=2,col=\"red\")}\n#变量添加图\navPlots(lm_sales_multi$fit,ask=FALSE,id.method=\"identity\")\n\n###\ninfluencePlot(lm_sales_multi$fit,id.method=\"identity\",main=\"Influence Plot\")\n\n\n\n17.4.6 多重共线性\n\nShow the codevif(lm_sales_multi$fit)\n#&gt;        TV     radio newspaper \n#&gt;  1.004611  1.144952  1.145187\n\nsqrt(vif(lm_sales_multi$fit))&gt;=2       #vif平方根 ≥2 存在\n#&gt;        TV     radio newspaper \n#&gt;     FALSE     FALSE     FALSE",
    "crumbs": [
      "推断统计模型",
      "<span class='chapter-number'>17</span>  <span class='chapter-title'>多元线性回归</span>"
    ]
  },
  {
    "objectID": "multiple_linear_regression.html#逐步回归",
    "href": "multiple_linear_regression.html#逐步回归",
    "title": "\n17  多元线性回归\n",
    "section": "\n17.5 逐步回归",
    "text": "17.5 逐步回归\n逐步回归是筛选变量，有向前、向后和两个方向同时进行三个方法。\n\ndirection = \"both\"双向\ndirection = \"backward\"向后\ndirection = \"forward\"向前\n\n\nShow the codestep_full &lt;- lm(sales~ . ,data = advertising[-1])\nstep_lm_0 &lt;- lm(sales~ 1 ,data = advertising[-1])\n\nstep_forward &lt;- stats::step(step_lm_0,scope =formula(step_full),  \n                            direction = \"forward\")\n#&gt; Start:  AIC=661.8\n#&gt; sales ~ 1\n#&gt; \n#&gt;             Df Sum of Sq    RSS    AIC\n#&gt; + TV         1    3314.6 2102.5 474.52\n#&gt; + radio      1    1798.7 3618.5 583.10\n#&gt; + newspaper  1     282.3 5134.8 653.10\n#&gt; &lt;none&gt;                   5417.1 661.80\n#&gt; \n#&gt; Step:  AIC=474.52\n#&gt; sales ~ TV\n#&gt; \n#&gt;             Df Sum of Sq     RSS    AIC\n#&gt; + radio      1   1545.62  556.91 210.82\n#&gt; + newspaper  1    183.97 1918.56 458.20\n#&gt; &lt;none&gt;                   2102.53 474.52\n#&gt; \n#&gt; Step:  AIC=210.82\n#&gt; sales ~ TV + radio\n#&gt; \n#&gt;             Df Sum of Sq    RSS    AIC\n#&gt; &lt;none&gt;                   556.91 210.82\n#&gt; + newspaper  1  0.088717 556.83 212.79\nsummary(step_forward)\n#&gt; \n#&gt; Call:\n#&gt; lm(formula = sales ~ TV + radio, data = advertising[-1])\n#&gt; \n#&gt; Residuals:\n#&gt;     Min      1Q  Median      3Q     Max \n#&gt; -8.7977 -0.8752  0.2422  1.1708  2.8328 \n#&gt; \n#&gt; Coefficients:\n#&gt;             Estimate Std. Error t value Pr(&gt;|t|)    \n#&gt; (Intercept)  2.92110    0.29449   9.919   &lt;2e-16 ***\n#&gt; TV           0.04575    0.00139  32.909   &lt;2e-16 ***\n#&gt; radio        0.18799    0.00804  23.382   &lt;2e-16 ***\n#&gt; ---\n#&gt; Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n#&gt; \n#&gt; Residual standard error: 1.681 on 197 degrees of freedom\n#&gt; Multiple R-squared:  0.8972, Adjusted R-squared:  0.8962 \n#&gt; F-statistic: 859.6 on 2 and 197 DF,  p-value: &lt; 2.2e-16\n\n\n\nstep_backward &lt;- stats::step(object = step_full,#scope = formula(step_lm_0) ,\n                         direction = \"backward\")\n#&gt; Start:  AIC=212.79\n#&gt; sales ~ TV + radio + newspaper\n#&gt; \n#&gt;             Df Sum of Sq    RSS    AIC\n#&gt; - newspaper  1      0.09  556.9 210.82\n#&gt; &lt;none&gt;                    556.8 212.79\n#&gt; - radio      1   1361.74 1918.6 458.20\n#&gt; - TV         1   3058.01 3614.8 584.90\n#&gt; \n#&gt; Step:  AIC=210.82\n#&gt; sales ~ TV + radio\n#&gt; \n#&gt;         Df Sum of Sq    RSS    AIC\n#&gt; &lt;none&gt;                556.9 210.82\n#&gt; - radio  1    1545.6 2102.5 474.52\n#&gt; - TV     1    3061.6 3618.5 583.10\nsummary(step_backward )\n#&gt; \n#&gt; Call:\n#&gt; lm(formula = sales ~ TV + radio, data = advertising[-1])\n#&gt; \n#&gt; Residuals:\n#&gt;     Min      1Q  Median      3Q     Max \n#&gt; -8.7977 -0.8752  0.2422  1.1708  2.8328 \n#&gt; \n#&gt; Coefficients:\n#&gt;             Estimate Std. Error t value Pr(&gt;|t|)    \n#&gt; (Intercept)  2.92110    0.29449   9.919   &lt;2e-16 ***\n#&gt; TV           0.04575    0.00139  32.909   &lt;2e-16 ***\n#&gt; radio        0.18799    0.00804  23.382   &lt;2e-16 ***\n#&gt; ---\n#&gt; Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n#&gt; \n#&gt; Residual standard error: 1.681 on 197 degrees of freedom\n#&gt; Multiple R-squared:  0.8972, Adjusted R-squared:  0.8962 \n#&gt; F-statistic: 859.6 on 2 and 197 DF,  p-value: &lt; 2.2e-16\n\nstep_both&lt;- stats::step(object = step_lm_0, scope = formula(step_full) ,\n                         direction = \"both\")\n#&gt; Start:  AIC=661.8\n#&gt; sales ~ 1\n#&gt; \n#&gt;             Df Sum of Sq    RSS    AIC\n#&gt; + TV         1    3314.6 2102.5 474.52\n#&gt; + radio      1    1798.7 3618.5 583.10\n#&gt; + newspaper  1     282.3 5134.8 653.10\n#&gt; &lt;none&gt;                   5417.1 661.80\n#&gt; \n#&gt; Step:  AIC=474.52\n#&gt; sales ~ TV\n#&gt; \n#&gt;             Df Sum of Sq    RSS    AIC\n#&gt; + radio      1    1545.6  556.9 210.82\n#&gt; + newspaper  1     184.0 1918.6 458.20\n#&gt; &lt;none&gt;                   2102.5 474.52\n#&gt; - TV         1    3314.6 5417.1 661.80\n#&gt; \n#&gt; Step:  AIC=210.82\n#&gt; sales ~ TV + radio\n#&gt; \n#&gt;             Df Sum of Sq    RSS    AIC\n#&gt; &lt;none&gt;                    556.9 210.82\n#&gt; + newspaper  1      0.09  556.8 212.79\n#&gt; - radio      1   1545.62 2102.5 474.52\n#&gt; - TV         1   3061.57 3618.5 583.10\nsummary(step_both)\n#&gt; \n#&gt; Call:\n#&gt; lm(formula = sales ~ TV + radio, data = advertising[-1])\n#&gt; \n#&gt; Residuals:\n#&gt;     Min      1Q  Median      3Q     Max \n#&gt; -8.7977 -0.8752  0.2422  1.1708  2.8328 \n#&gt; \n#&gt; Coefficients:\n#&gt;             Estimate Std. Error t value Pr(&gt;|t|)    \n#&gt; (Intercept)  2.92110    0.29449   9.919   &lt;2e-16 ***\n#&gt; TV           0.04575    0.00139  32.909   &lt;2e-16 ***\n#&gt; radio        0.18799    0.00804  23.382   &lt;2e-16 ***\n#&gt; ---\n#&gt; Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n#&gt; \n#&gt; Residual standard error: 1.681 on 197 degrees of freedom\n#&gt; Multiple R-squared:  0.8972, Adjusted R-squared:  0.8962 \n#&gt; F-statistic: 859.6 on 2 and 197 DF,  p-value: &lt; 2.2e-16",
    "crumbs": [
      "推断统计模型",
      "<span class='chapter-number'>17</span>  <span class='chapter-title'>多元线性回归</span>"
    ]
  },
  {
    "objectID": "multiple_linear_regression.html#模型选择和优化",
    "href": "multiple_linear_regression.html#模型选择和优化",
    "title": "\n17  多元线性回归\n",
    "section": "\n17.6 模型选择和优化",
    "text": "17.6 模型选择和优化\n\n\nn是观测值的数量，p是模型的参数数（等于回归系数的数量）\n\n\n\\(\\mathcal{L}\\)是模型拟合的最大似然值\n\nShow the code########################两模型比较\nlm1 &lt;- lm_spec %&gt;% fit(sales~TV+radio+newspaper,data = advertising)\nlm2 &lt;- lm_spec %&gt;% fit(sales~TV*radio*newspaper,data = advertising[-1])\n\nanova(lm2$fit,lm1$fit) #anova() 嵌套模型\n\n\n\n\nRes.Df\nRSS\nDf\nSum of Sq\nF\nPr(&gt;F)\n\n\n\n192\n169.8597\nNA\nNA\nNA\nNA\n\n\n196\n556.8253\n-4\n-386.9656\n109.3511\n0\n\n\n\n\n\nShow the code\n\n##########################################            AIC \nAIC(lm2$fit,lm1$fit)  # 赤池信息准则  AIC值小的优先选择\n\n\n\n\n\ndf\nAIC\n\n\nlm2\\(fit |  9| 552.9065|\n|lm1\\)fit\n5\n782.3622\n\n\n\n\nShow the code#BIC\n\n\n####################################相对重要性##################################\nad &lt;- scale(advertising[-1])\nad\n#&gt;                 TV        radio    newspaper        sales\n#&gt;   [1,]  0.96742460  0.979065591  1.774492530  1.548168135\n#&gt;   [2,] -1.19437904  1.080097401  0.667902716 -0.694303815\n#&gt;   [3,] -1.51235985  1.524637364  1.779084189 -0.905134512\n#&gt;   [4,]  0.05191939  1.214806480  1.283185019  0.858176766\n#&gt;   [5,]  0.39319551 -0.839506984  1.278593360 -0.215143142\n#&gt;   [6,] -1.61136487  1.726700983  2.040808751 -1.307629477\n#&gt;   [7,] -1.04295960  0.642292892 -0.323895625 -0.425973838\n#&gt;   [8,] -0.31265202 -0.246787034 -0.870303044 -0.157643861\n#&gt;   [9,] -1.61252963 -1.425491481 -1.357018896 -1.767623723\n#&gt;  [10,]  0.61450084 -1.391814211 -0.429503781 -0.655970962\n#&gt;  [11,] -0.94278982 -1.176279684 -0.291754012 -1.039299500\n#&gt;  [12,]  0.78805080  0.049572941 -1.219269126  0.647346069\n#&gt;  [13,] -1.43548537  0.797208333  1.622967784 -0.924300938\n#&gt;  [14,] -0.57705364 -1.055041512 -1.072336039 -0.828468804\n#&gt;  [15,]  0.66458573  0.649028346  0.709227646  0.954008900\n#&gt;  [16,]  0.56325118  1.645875535  1.026052116  1.605667416\n#&gt;  [17,] -0.92298882  0.898240143  3.831555755 -0.291808850\n#&gt;  [18,]  1.56494899  1.100303763  1.159210227  1.988995954\n#&gt;  [19,] -0.90668211 -0.186167948 -0.562661892 -0.521805973\n#&gt;  [20,]  0.00299927  0.042837487 -0.525928620  0.110686115\n#&gt;  [21,]  0.83114711  0.298784739  1.049010411  0.762344631\n#&gt;  [22,]  1.05245243 -1.223427861 -0.323895625 -0.291808850\n#&gt;  [23,] -1.55895045 -0.495998831  0.874527370 -1.614292308\n#&gt;  [24,]  0.94645883 -0.428644291 -0.199920832  0.283183958\n#&gt;  [25,] -0.98705089 -0.718268813 -0.562661892 -0.828468804\n#&gt;  [26,]  1.34946748 -1.331195125 -0.507561984 -0.387640985\n#&gt;  [27,] -0.04825039  0.406552002 -0.824386454  0.187351823\n#&gt;  [28,]  1.08390109 -0.442115199 -0.351445579  0.359849666\n#&gt;  [29,]  1.18523563  0.258372015 -0.351445579  0.934842473\n#&gt;  [30,] -0.89037540 -0.489263377  0.470461379 -0.675137388\n#&gt;  [31,]  1.69889695  0.339197463  0.580661195  1.414003146\n#&gt;  [32,] -0.39767985 -0.394967022  0.369444882 -0.406807411\n#&gt;  [33,] -0.58054794 -1.465904205 -0.025437791 -0.847635231\n#&gt;  [34,]  1.38091613 -0.219845218 -1.389160509  0.647346069\n#&gt;  [35,] -0.59801941 -1.472639659 -1.063152721 -0.866801658\n#&gt;  [36,]  1.67327212 -1.290782401 -1.012644472 -0.234309569\n#&gt;  [37,]  1.39605808  1.383192830 -1.173352536  2.180660223\n#&gt;  [38,] -0.84262004  1.760378253  0.695452669  0.129852542\n#&gt;  [39,] -1.21068574  0.231430199  0.208736817 -0.751803096\n#&gt;  [40,]  0.94296453  0.972330137  0.066395389  1.433169573\n#&gt;  [41,]  0.64594949 -0.064929776  0.048028753  0.494014654\n#&gt;  [42,]  0.34893444  0.682705616  0.374036541  0.589846789\n#&gt;  [43,]  1.70705030  0.298784739 -1.320285624  1.279838158\n#&gt;  [44,]  0.69719914 -1.001157880 -0.190737514 -0.215143142\n#&gt;  [45,] -1.42034342  0.164075659  0.585252854 -1.058465927\n#&gt;  [46,]  0.32680391 -0.051458868  0.043437094  0.168185396\n#&gt;  [47,] -0.66790531 -0.900126070  0.236286771 -0.655970962\n#&gt;  [48,]  1.08157156  1.228277388 -0.553478574  1.758998831\n#&gt;  [49,]  0.93364642 -0.502734285  0.888302347  0.149018969\n#&gt;  [50,] -0.93347170 -0.778887899  0.286795020 -0.828468804\n#&gt;  [51,]  0.61450084 -1.358136941  0.185778522 -0.502639546\n#&gt;  [52,] -0.54327546 -0.920332432 -1.237635762 -0.636804535\n#&gt;  [53,]  0.80785181  1.241748296  0.415361472  1.644000269\n#&gt;  [54,]  0.41416128  1.544843726  1.292368337  1.375670293\n#&gt;  [55,]  1.34713795  0.372874732 -0.672861707  1.184006023\n#&gt;  [56,]  0.60401795  1.760378253  1.352059904  1.854830966\n#&gt;  [57,] -1.62767157  0.325726555  0.498011333 -1.633458735\n#&gt;  [58,] -0.12628963 -0.273728850 -0.640720094 -0.157643861\n#&gt;  [59,]  0.74262497  1.773849161  0.328119951  1.873997393\n#&gt;  [60,]  0.74146021  0.420022910 -0.975911200  0.839010339\n#&gt;  [61,] -1.08955020 -1.432226935 -0.420320463 -1.135131635\n#&gt;  [62,]  1.33083124  1.309102836  1.108701978  1.950663100\n#&gt;  [63,]  1.07458297 -0.522940647 -0.149412583  0.321516812\n#&gt;  [64,] -0.51648587  0.426758364 -1.017236131 -0.004312446\n#&gt;  [65,] -0.18569264  1.315838290 -0.075946040  0.762344631\n#&gt;  [66,] -0.90901164 -0.940538794 -1.361610555 -0.905134512\n#&gt;  [67,] -1.34579847  0.089985665 -1.301918988 -0.866801658\n#&gt;  [68,] -0.09018192 -0.590295187 -0.934586269 -0.119311008\n#&gt;  [69,]  1.05245243  0.285313831 -0.897852997  0.934842473\n#&gt;  [70,]  0.81251087  1.389928284 -0.154004242  1.586500989\n#&gt;  [71,]  0.60634748  0.494112904  0.374036541  0.819843912\n#&gt;  [72,] -0.43378756 -0.603766095  0.052620412 -0.310975277\n#&gt;  [73,] -1.40054242  0.655763800 -0.516745302 -1.000966646\n#&gt;  [74,] -0.20549365 -1.183015138  0.034253776 -0.579305254\n#&gt;  [75,]  0.77290886  0.089985665 -0.801428159  0.570680362\n#&gt;  [76,] -1.51585415  1.376457376  2.702007645 -1.020133073\n#&gt;  [77,] -1.39238907 -1.459168751 -0.452462076 -1.365128758\n#&gt;  [78,] -0.30915772  0.352668371 -0.750919910  0.034020408\n#&gt;  [79,] -1.64980211  0.446964726 -0.971319541 -1.671791589\n#&gt;  [80,] -0.36157214 -1.048306058 -0.342262261 -0.579305254\n#&gt;  [81,] -0.82281904  0.231430199 -0.378995532 -0.425973838\n#&gt;  [82,]  1.08040679 -1.290782401  0.291386679 -0.330141704\n#&gt;  [83,] -0.83563145 -0.199638856  0.089353684 -0.521805973\n#&gt;  [84,] -0.91600023  1.430341008  0.231695112 -0.080978154\n#&gt;  [85,]  0.77407363  1.329309198  0.149045251  1.471502427\n#&gt;  [86,]  0.53762635 -0.327612482  1.613784466  0.225684677\n#&gt;  [87,] -0.82398380  0.285313831 -0.668270048 -0.387640985\n#&gt;  [88,] -0.42330468  1.167658302  1.498992991  0.379016092\n#&gt;  [89,] -0.68421201  0.150604751  1.967342208 -0.215143142\n#&gt;  [90,] -0.43378756  1.652610989  0.957177231  0.513181081\n#&gt;  [91,] -0.14842017 -1.236898769 -0.975911200 -0.540972400\n#&gt;  [92,] -1.37957665 -1.465904205  0.112311979 -1.288463050\n#&gt;  [93,]  0.82299375  0.689441070  1.306143314  1.030674608\n#&gt;  [94,]  1.20969569  0.891504689  1.916833959  1.567334562\n#&gt;  [95,] -0.46174192 -0.623972457 -0.902444656 -0.483473119\n#&gt;  [96,]  0.18936165  0.561467444  1.026052116  0.551513935\n#&gt;  [97,]  0.58887601 -1.331195125 -1.132027606 -0.445140265\n#&gt;  [98,]  0.44095087 -0.152490678 -0.392770509  0.283183958\n#&gt;  [99,]  1.66162447  1.282161020  0.947993914  2.180660223\n#&gt; [100,] -0.13793728  1.241748296  0.704635987  0.609013216\n#&gt; [101,]  0.87773770 -1.277311493  0.883710688 -0.445140265\n#&gt; [102,]  1.73966372  0.878033781  3.230048428  1.873997393\n#&gt; [103,]  1.55097181 -0.886655162 -0.420320463  0.149018969\n#&gt; [104,]  0.47589381 -0.408437930 -0.581028528  0.129852542\n#&gt; [105,]  1.06177055  0.743324702 -1.159577559  1.279838158\n#&gt; [106,] -0.10648863  1.558314633  1.306143314  0.992341754\n#&gt; [107,] -1.42150819 -0.826036076 -0.039212768 -1.307629477\n#&gt; [108,] -0.65975195 -1.546729653 -0.337670602 -1.020133073\n#&gt; [109,] -1.56011521 -1.539994199 -0.227470786 -1.671791589\n#&gt; [110,]  1.26211011  0.244901107 -1.150394241  1.107340316\n#&gt; [111,]  0.91733971 -1.014628788  1.191351840 -0.119311008\n#&gt; [112,]  1.10253732  0.992536499 -0.337670602  1.490668854\n#&gt; [113,]  0.33379250 -0.529676101 -1.292735670  0.014853981\n#&gt; [114,]  0.72864780 -0.179432494 -0.911627974  0.359849666\n#&gt; [115,] -0.80185327  1.585256449  0.181186863  0.110686115\n#&gt; [116,] -0.83796098  0.790472879  1.016868798 -0.272642423\n#&gt; [117,] -0.09134669 -0.603766095 -0.227470786 -0.349308131\n#&gt; [118,] -0.82281904 -1.513052383 -0.723369956 -0.885968085\n#&gt; [119,] -0.24858995  0.918446505  2.233658429  0.359849666\n#&gt; [120,] -1.48673502 -0.489263377 -0.378995532 -1.422628038\n#&gt; [121,] -0.06688662  0.238165653  0.718410964  0.283183958\n#&gt; [122,] -1.49372361 -0.105342500  0.911260642 -1.345962331\n#&gt; [123,]  0.89637394 -1.405285119 -0.686636684 -0.464306692\n#&gt; [124,] -0.27887383  0.763531064 -0.833569772  0.225684677\n#&gt; [125,]  0.96043601  0.608615622  2.004075480  1.088173889\n#&gt; [126,] -0.69702443 -0.772152445 -0.213695809 -0.655970962\n#&gt; [127,] -1.62184775  1.053155585  0.920443960 -1.422628038\n#&gt; [128,] -0.77855797 -1.566936015 -0.980502859 -1.000966646\n#&gt; [129,]  0.85327764  1.733436437 -1.256002398  2.046495235\n#&gt; [130,] -1.01849954 -0.758681537  0.576069536 -0.828468804\n#&gt; [131,] -1.70454606  1.100303763 -1.003461154 -2.380949385\n#&gt; [132,]  1.37625707 -1.371607849  0.571477877 -0.253475996\n#&gt; [133,] -1.61485916  0.265107469 -1.306510647 -1.595125881\n#&gt; [134,]  0.84745381  0.689441070  0.667902716  1.069007462\n#&gt; [135,] -1.28290117  1.032949223  1.609192807 -0.617638108\n#&gt; [136,] -1.15011797  1.598727357 -1.012644472 -0.464306692\n#&gt; [137,] -1.41451960  1.059891039 -0.975911200 -0.866801658\n#&gt; [138,]  1.47526209  0.379610186  1.338284927  1.299004585\n#&gt; [139,] -1.21185051  0.177546567 -0.461645394 -0.847635231\n#&gt; [140,]  0.44095087  1.389928284 -1.324877283  1.279838158\n#&gt; [141,] -0.85776198 -0.421908837 -0.810611477 -0.598471681\n#&gt; [142,]  0.54345018  0.817414695  2.068358705  0.992341754\n#&gt; [143,]  0.85560717  0.669234708  0.337303269  1.164839596\n#&gt; [144,] -0.49435534 -1.183015138  0.176595204 -0.694303815\n#&gt; [145,] -0.59219559 -0.570088825  0.383219859 -0.502639546\n#&gt; [146,] -0.07853427 -1.438962389 -0.989686177 -0.713470242\n#&gt; [147,]  1.08390109 -1.075247874 -1.003461154 -0.157643861\n#&gt; [148,]  1.12000880  1.733436437  0.631169444  2.180660223\n#&gt; [149,] -1.27008875  1.147451941 -0.856528067 -0.598471681\n#&gt; [150,] -1.19204951  0.170811113 -0.457053735 -0.751803096\n#&gt; [151,]  1.55679563 -0.630707911  0.295978338  0.398182519\n#&gt; [152,] -0.30333390 -1.001157880  0.833202439 -0.464306692\n#&gt; [153,]  0.58887601  0.002424763 -0.750919910  0.494014654\n#&gt; [154,]  0.28254284  1.107039217  0.328119951  0.954008900\n#&gt; [155,]  0.47472905 -0.145755224 -0.966727882  0.302350385\n#&gt; [156,] -1.66494405 -0.785623353 -1.141210924 -2.074286554\n#&gt; [157,] -0.61898518  1.362986468  0.915852301  0.244851104\n#&gt; [158,]  0.03211839 -1.479375113 -0.287162353 -0.751803096\n#&gt; [159,] -1.57642192  0.918446505  0.672494375 -1.288463050\n#&gt; [160,] -0.17870405 -0.327612482  0.185778522 -0.215143142\n#&gt; [161,]  0.29652002 -0.347818844  0.006703822  0.072353262\n#&gt; [162,] -0.71449590  0.844356511  0.860752393 -0.138477435\n#&gt; [163,]  0.48171764 -0.347818844 -0.227470786  0.168185396\n#&gt; [164,]  0.19169118  0.911711051 -1.063152721  0.762344631\n#&gt; [165,] -0.34759496 -0.576824279 -1.154985900 -0.406807411\n#&gt; [166,]  1.01867425 -1.337930579  2.490791332 -0.406807411\n#&gt; [167,] -1.50420650  0.965594683 -0.411137145 -1.154298062\n#&gt; [168,]  0.69603438 -1.216692407 -0.512153643 -0.349308131\n#&gt; [169,]  0.79620416  0.022631125  1.241860088  0.589846789\n#&gt; [170,]  1.59872717 -0.852977892 -1.109069311  0.187351823\n#&gt; [171,] -1.13031697 -0.785623353 -0.558070233 -1.077632354\n#&gt; [172,]  0.20333883 -0.159226132  0.773510872  0.091519689\n#&gt; [173,] -1.48440549 -0.213109764 -0.622353458 -1.230963769\n#&gt; [174,]  0.24876466 -1.088718782 -0.815203136 -0.445140265\n#&gt; [175,]  0.87773770 -1.337930579 -0.801428159 -0.483473119\n#&gt; [176,]  1.51253457  1.726700983  0.516377969  2.487323054\n#&gt; [177,]  1.18057657  0.467171088 -0.470828712  1.184006023\n#&gt; [178,]  0.26973043 -1.041570604  0.213328476 -0.445140265\n#&gt; [179,]  1.51020504 -1.412020573 -0.314712307 -0.425973838\n#&gt; [180,]  0.21615124 -0.893390616 -0.594803505 -0.272642423\n#&gt; [181,]  0.11132240 -1.391814211 -1.021827790 -0.675137388\n#&gt; [182,]  0.83231187 -1.203221500 -0.144820924 -0.349308131\n#&gt; [183,] -1.05810154 -1.183015138 -0.039212768 -1.020133073\n#&gt; [184,]  1.63716441  1.329309198  1.893875664  2.333991639\n#&gt; [185,]  1.24347388 -0.132284316 -0.025437791  0.685678923\n#&gt; [186,]  0.67506861  1.470753732 -0.502970325  1.644000269\n#&gt; [187,] -0.08785239 -1.425491481 -0.181554196 -0.713470242\n#&gt; [188,]  0.51316629  0.366139279 -0.567253551  0.628179642\n#&gt; [189,]  1.61852817 -0.630707911 -1.233044103  0.359849666\n#&gt; [190,] -1.49488838 -0.751946083 -0.328487284 -1.403461612\n#&gt; [191,] -1.25261728  1.201335572 -1.136619265 -0.617638108\n#&gt; [192,] -0.83330192 -0.839506984 -1.127435947 -0.790135950\n#&gt; [193,] -1.51235985 -1.290782401  0.048028753 -1.556793027\n#&gt; [194,]  0.23012842  1.261954658 -1.237635762  1.069007462\n#&gt; [195,]  0.03095363  0.830885603 -1.127435947  0.628179642\n#&gt; [196,] -1.26775922 -1.317724217 -0.769286546 -1.230963769\n#&gt; [197,] -0.61549089 -1.236898769 -1.031011108 -0.828468804\n#&gt; [198,]  0.34893444 -0.940538794 -1.109069311 -0.234309569\n#&gt; [199,]  1.59057381  1.261954658  1.636742761  2.199826650\n#&gt; [200,]  0.99071990 -0.987686972 -1.003461154 -0.119311008\n#&gt; attr(,\"scaled:center\")\n#&gt;        TV     radio newspaper     sales \n#&gt;  147.0425   23.2640   30.5540   14.0225 \n#&gt; attr(,\"scaled:scale\")\n#&gt;        TV     radio newspaper     sales \n#&gt; 85.854236 14.846809 21.778621  5.217457\n#R平方贡献率  #相对权重 \nrelweights&lt;-function(fit,...){\n  R&lt;-cor(fit$model)\n  nvar&lt;-ncol(R)\n  rxx&lt;-R[2:nvar,2:nvar]\n  rxy&lt;-R[2:nvar,1]\n  svd&lt;-eigen(rxx)\n  evec&lt;-svd$vectors\n  ev&lt;-svd$values\n  delta&lt;-diag(sqrt(ev))\n  lambda&lt;-evec %*%delta %*% t(evec)\n  lambdaasq&lt;-lambda^2\n  beta&lt;-solve(lambda) %*% rxy\n  r2&lt;-colSums(beta^2)\n  rawwgt&lt;-lambdaasq%*%beta^2\n  import&lt;-(rawwgt/r2)*100            #计算相对权重\n  import&lt;-data.frame(Weights=import)  #数据框化\n  row.names(import)&lt;-names(fit$model[2:nvar])\n  import&lt;-import[order(import$Weights),1,drop=FALSE] #升序排序\n  dotchart(import$Weights,labels=row.names(import),   #点图\n           xlab = \"% of R-Square\",pch=19,\n           main=\"Relative Importiance of Predictor Variables \",\n           sub=paste(\"Total R-Square =\",round(r2,digits = 3)),\n  ...)\nreturn(import)\n}\nrelweights(lm1$fit,col=\"blue\")\n\n\n\n\n\n\n\n\n\n\n\nWeights\n\n\n\nnewspaper\n2.468097\n\n\nradio\n32.198236\n\n\nTV\n65.333667",
    "crumbs": [
      "推断统计模型",
      "<span class='chapter-number'>17</span>  <span class='chapter-title'>多元线性回归</span>"
    ]
  },
  {
    "objectID": "multiple_linear_regression.html#线性可加模型",
    "href": "multiple_linear_regression.html#线性可加模型",
    "title": "\n17  多元线性回归\n",
    "section": "\n17.7 线性可加模型",
    "text": "17.7 线性可加模型\nadditive model\n\\[\nY_i=\\beta_0+ \\beta_1 X_i+  \\beta_2 X_i^2+\\epsilon_i\n\\]\n\\[\nY_i=\\beta_0+ \\beta_1\\times \\log(X_i)+\\epsilon_i\n\\]\n\\[\nY_i=\\beta_0+ \\beta_1 (X_i\\times W_i)+\\epsilon_i\n\\]\n\\[\nY_i=\\beta_0+ \\beta_1\\times \\exp(X_i)+\\epsilon_i\n\\]\n\\[\nY_i=\\beta_0+ \\beta_1\\times \\sin(X_i)+\\epsilon_i\n\\]",
    "crumbs": [
      "推断统计模型",
      "<span class='chapter-number'>17</span>  <span class='chapter-title'>多元线性回归</span>"
    ]
  },
  {
    "objectID": "GLM.html",
    "href": "GLM.html",
    "title": "\n19  广义线性模型\n",
    "section": "",
    "text": "19.1 GLM 组件\n广义线性模型是对线性模型的扩展，适用于非正态分布的数据，假设观测值之间是独立的，不能处理组内相关性。模型形式为：\n\\[\ng(E(Y))=\\mathbf{X} \\beta\n\\]\n\\[\n\\eta = \\mathbf{X} \\beta\n\\]\n\\[\nE(y)=\\mu\n\\]\n\\[\n\\eta =g(\\mu)=g(E(y))\n\\]\n\\[\nE(y)=g^{-1}(\\eta)\n\\]\n典型链接函数",
    "crumbs": [
      "推断统计模型",
      "<span class='chapter-number'>19</span>  <span class='chapter-title'>广义线性模型</span>"
    ]
  },
  {
    "objectID": "GLM.html#glm-组件",
    "href": "GLM.html#glm-组件",
    "title": "\n19  广义线性模型\n",
    "section": "",
    "text": "线性预测子：\n\n\n\n因变量的期望值与线性预测函数的关系：\n\n\n\n链接函数 g(.) ：\n\n\n\n反链接函数g-1 (.)：\n\n\n\n\ny 的方差：\n\\[\nVar(y)=f(\\mu)=f(g^{-1}(\\mathbf{X}\\beta))\n\\]\n\n\n\n\n\nY的分布\n名称\n链接函数\n均值函数\n\n\n\n正态\n恒等\n\n\n\n\n\n指数 / Gamma\n倒数\n\n\n\n\n泊松\n自然对数\n\n\n\n\n\n二项式\n多项式\n\nLogit",
    "crumbs": [
      "推断统计模型",
      "<span class='chapter-number'>19</span>  <span class='chapter-title'>广义线性模型</span>"
    ]
  },
  {
    "objectID": "GLM.html#广义线性回归",
    "href": "GLM.html#广义线性回归",
    "title": "\n18  广义线性模型\n",
    "section": "\n18.2 广义线性回归",
    "text": "18.2 广义线性回归\n高斯线性回归是一种简单的线性回归模型，其中假设响应变量服从正态分布，并且使用恒等连接函数（identity link function）。t-statistic\n\nCodelibrary(tidymodels)\nlibrary(patchwork)\nlibrary(ggfortify)\n# 使用 glm() 函数进行高斯线性回归\nglm1 &lt;- linear_reg() %&gt;% \n  set_engine(\"glm\", family = stats::gaussian(link = \"identity\")) %&gt;% \n  fit(Fertility ~ Agriculture + Education + Catholic + Infant.Mortality,\n      data = swiss)\n\n# 查看模型的系数\ntidy(glm1)\n\n\n\n\nterm\nestimate\nstd.error\nstatistic\np.value\n\n\n\n(Intercept)\n62.1013116\n9.6048861\n6.465596\n0.0000001\n\n\nAgriculture\n-0.1546175\n0.0681899\n-2.267454\n0.0285697\n\n\nEducation\n-0.9802638\n0.1481367\n-6.617293\n0.0000001\n\n\nCatholic\n0.1246664\n0.0288935\n4.314686\n0.0000950\n\n\nInfant.Mortality\n1.0784422\n0.3818662\n2.824136\n0.0072204\n\n\n\n\n\nCode\n# 查看模型的 AIC 和 Deviance\nglance(glm1) %&gt;% dplyr::select(AIC, deviance)\n\n\n\n\nAIC\ndeviance\n\n\n325.2408\n2158.069\n\n\n\n\nCode\n\n# Change the theme and colour\nautoplot(glm1, which = 1:6, ncol = 2, label.size = 3,\n         colour = \"steelblue\") + theme_bw()",
    "crumbs": [
      "推断统计模型",
      "<span class='chapter-number'>18</span>  <span class='chapter-title'>广义线性模型</span>"
    ]
  },
  {
    "objectID": "GLM.html#逻辑回归",
    "href": "GLM.html#逻辑回归",
    "title": "\n19  广义线性模型\n",
    "section": "\n19.4 逻辑回归",
    "text": "19.4 逻辑回归\n逻辑回归用于处理分类问题。其模型假设响应变量的对数优势（log odds）服从线性模型。\nSigmoid 激活函数：\n\\[\nf(x)=\\frac{1}{1+e^{-x}}=\\frac{e^x}{1+e^x}\n\\]\n\nShow the codesigmoid &lt;- tibble(\n    x=seq(-6,6,length.out=1000),\n    y=1/(1+exp(-x)),\n)\nggplot(sigmoid,aes(x,y))+\n    geom_line()\n\n\n\n\n\n\n\n逻辑回归( logistic regression )的一般表达式：\n\\[\n\\pi(Y=k|X=(X_1,X_2,...,X_p)=\\frac{e^{\\beta_{k0}+\\beta_{k1}X_1+\\beta_{k2}X_2+...+\\beta_{kp}X_p}}{1+\\sum_{l=1}^{K-1} e^{\\beta_{l0}+\\beta_{l1}X_1+\\beta_{l2}X_2+...+\\beta_{lp}X_p}}\n\\] 其中\\(\\pi\\) 是成功概率，\\(k=1,2,...,K-1\\)是因变量的第k个水平，共K 个水平，\\(p\\) 是自变量个数。\nlogit link function\nz-statistic\n\n19.4.1 二分类Binary\n\n\n当\\(K=2\\)时，\\(k=l=p=1\\)即二分类逻辑回归，一般需要引入虚拟变量（哑变量，dummy variable），通常取值为 0或1。\n极大似然法（maximum likelihood），likelihood function：\n\\[\n\\ell (\\beta_0,\\beta_1)=\\prod_{i:y_i=1}\\pi(x_i)\\prod_{i':y_{i'}=0}(1-\\pi(x_{i'}))\n\\]\n\n\n\nShow the codelogit_spec &lt;- logistic_reg() %&gt;%\n  set_engine(\"glm\",family= binomial(link = \"logit\")) \n\n\nlogit_binary_y &lt;- logit_spec %&gt;% fit(default~balance,data=df)\n\nlogit_binary_y %&gt;% glance()\n#&gt; # A tibble: 1 × 8\n#&gt;   null.deviance df.null logLik   AIC   BIC deviance df.residual  nobs\n#&gt;           &lt;dbl&gt;   &lt;int&gt;  &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;    &lt;dbl&gt;       &lt;int&gt; &lt;int&gt;\n#&gt; 1         2921.    9999  -798. 1600. 1615.    1596.        9998 10000\n\ntidy(logit_binary_y,  conf.int = TRUE) %&gt;% \n    mutate(\n        z_value = estimate/std.error,\n        Wald_ChiSquare=z_value^2, #  Wald卡方值可以用来检验各个变量系数是否显著 不同于零。 它是通过系数估计的平方除以其标准误差的平方来计算的。即 z值的平方\n        OR = exp(estimate),\n        `OR 95% CI`= sprintf(\"%.3f ~ %3.f\",exp(conf.low),exp(conf.high)),\n    )\n#&gt; # A tibble: 2 × 11\n#&gt;   term         estimate std.error statistic   p.value conf.low conf.high z_value\n#&gt;   &lt;chr&gt;           &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt;     &lt;dbl&gt;   &lt;dbl&gt;\n#&gt; 1 (Intercept) -10.7      0.361        -29.5 3.62e-191 -1.14e+1  -9.97      -29.5\n#&gt; 2 balance       0.00550  0.000220      25.0 1.98e-137  5.08e-3   0.00594    25.0\n#&gt; # ℹ 3 more variables: Wald_ChiSquare &lt;dbl&gt;, OR &lt;dbl&gt;, `OR 95% CI` &lt;chr&gt;\n\n\nggplot(df,aes(balance,as.numeric(default)-1))+\n  geom_point(color=\"orange\",size=1.25)+\n  geom_smooth(method = \"glm\",\n              method.args=list(family=binomial(link = \"logit\")),se=FALSE)+\n  geom_hline(yintercept = c(0,1),linetype=2)+\n  ggtitle(\"binary logistic regression with continuous x\")\n\n\n\n\n\n\n\n\nShow the codelogit_binary_x &lt;- logit_spec %&gt;%fit(default ~ student, data = df)\n\ntidy(logit_binary_x)\n#&gt; # A tibble: 2 × 5\n#&gt;   term        estimate std.error statistic  p.value\n#&gt;   &lt;chr&gt;          &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt;\n#&gt; 1 (Intercept)   -3.50     0.0707    -49.6  0       \n#&gt; 2 student1       0.405    0.115       3.52 0.000431\n\n\nggplot(df,aes(student,as.numeric(default)-1))+\n  geom_point(color=\"orange\",size=1.25)+\n  geom_smooth(method = \"glm\",\n              method.args=list(family=binomial(link = \"logit\")),se=FALSE)+\n  geom_hline(yintercept = c(0,1),linetype=2)+\n    scale_y_continuous(\"default\", breaks = c(0,1))+\n  ggtitle(\"binary logistic regression with binary x\")\n\n\n\n\n\n\n\n\n19.4.2 二分类多元逻辑回归\n\n\n当\\(K=2\\)时，\\(k=l=1,p&gt;1\\)即多元逻辑回归（multiple logistic regression）。\n优势（odds）\n\\[\nOdds=\\frac{\\pi(X)}{1-\\pi(X)}=e^{\\beta_0+\\beta_1X_1+\\beta_2X_2+...+\\beta_pX_p}\n\\]\nlog odds (logit)\n\\[\nlogit(\\pi(X))=\\ln (\\frac{\\pi(X)}{1-\\pi(X)})=\\beta_0+\\beta_1X_1+\\beta_2X_2+...+\\beta_pX_p\n\\]\n\n\n\nShow the codelogit_multiple&lt;-logit_spec %&gt;% fit(default~balance+income+student,data=df)\n\ntidy(logit_multiple)\n\n\n\n\nterm\nestimate\nstd.error\nstatistic\np.value\n\n\n\n(Intercept)\n-10.8690452\n0.4922555\n-22.080088\n0.0000000\n\n\nbalance\n0.0057365\n0.0002319\n24.737563\n0.0000000\n\n\nincome\n0.0000030\n0.0000082\n0.369815\n0.7115203\n\n\nstudent1\n-0.6467758\n0.2362525\n-2.737646\n0.0061881\n\n\n\n\n\nShow the code\n# confusion matrix 混淆矩阵\naugment(logit_multiple, new_data = df) %&gt;%\n  conf_mat(truth = default, estimate = .pred_class) %&gt;% \n    autoplot(type = \"heatmap\")\n\n\n\n\n\n\nShow the code\n#准确性 \n(9627+105)/(9627+105+40+228)\n#&gt; [1] 0.9732\naugment(logit_multiple, new_data = df) %&gt;%\n  accuracy(truth = default, estimate = .pred_class)\n\n\n\n\n.metric\n.estimator\n.estimate\n\n\naccuracy\nbinary\n0.9732\n\n\n\n\n\n\nShow the codedf_new &lt;- tibble(\n  balance = c(1000, 2000), \n  income = c(14144,24141),\n  student = factor(c(1, 0)),)\npredict(logit_multiple, new_data = df_new,type=\"class\")\n#&gt; # A tibble: 2 × 1\n#&gt;   .pred_class\n#&gt;   &lt;fct&gt;      \n#&gt; 1 0          \n#&gt; 2 1\npredict(logit_multiple, new_data = df_new, type = \"prob\")\n#&gt; # A tibble: 2 × 2\n#&gt;   .pred_0 .pred_1\n#&gt;     &lt;dbl&gt;   &lt;dbl&gt;\n#&gt; 1   0.997 0.00322\n#&gt; 2   0.337 0.663\n\n\n\n19.4.3 似然比检验\nlikelihood ratio tests (LRT)\n比较两个嵌套模型，log-likelihood (logLL)\n\n相应的p-value 源自具有 个自由度的 卡方 分布（即模型中测试的参数数量之差）。\n\nShow the codelogit_binary_y\n#&gt; parsnip model object\n#&gt; \n#&gt; \n#&gt; Call:  stats::glm(formula = default ~ balance, family = ~binomial(link = \"logit\"), \n#&gt;     data = data)\n#&gt; \n#&gt; Coefficients:\n#&gt; (Intercept)      balance  \n#&gt;  -10.651331     0.005499  \n#&gt; \n#&gt; Degrees of Freedom: 9999 Total (i.e. Null);  9998 Residual\n#&gt; Null Deviance:       2921 \n#&gt; Residual Deviance: 1596  AIC: 1600\nlogit_multiple\n#&gt; parsnip model object\n#&gt; \n#&gt; \n#&gt; Call:  stats::glm(formula = default ~ balance + income + student, family = ~binomial(link = \"logit\"), \n#&gt;     data = data)\n#&gt; \n#&gt; Coefficients:\n#&gt; (Intercept)      balance       income     student1  \n#&gt;  -1.087e+01    5.737e-03    3.033e-06   -6.468e-01  \n#&gt; \n#&gt; Degrees of Freedom: 9999 Total (i.e. Null);  9996 Residual\n#&gt; Null Deviance:       2921 \n#&gt; Residual Deviance: 1572  AIC: 1580\n\n\nLRT=2*(logLik(logit_multiple$fit)-logLik(logit_binary_y$fit))\nLRT\n#&gt; 'log Lik.' 24.90686 (df=4)\n\npval=1-pchisq(LRT,2)\npval\n#&gt; 'log Lik.' 3.904316e-06 (df=4)\n\nout&lt;-anova(logit_binary_y$fit, logit_multiple$fit)\nout\n#&gt; Analysis of Deviance Table\n#&gt; \n#&gt; Model 1: default ~ balance\n#&gt; Model 2: default ~ balance + income + student\n#&gt;   Resid. Df Resid. Dev Df Deviance  Pr(&gt;Chi)    \n#&gt; 1      9998     1596.5                          \n#&gt; 2      9996     1571.5  2   24.907 3.904e-06 ***\n#&gt; ---\n#&gt; Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n1-pchisq(out$Deviance[2],2)\n#&gt; [1] 3.904316e-06\n\n\n\n19.4.4 K&gt;2 多分类逻辑回归\n用于处理具有多于两个类别的响应变量的情况。例如，分类问题中的三个或更多类别。\n\n\n当\\(K&gt;2\\)时，\\(k,l,p&gt;1\\)即多项逻辑回归（multinomial logistic regression）。\n\\[\n\\ln (\\frac{P(Y=k|X=x)}{P(Y=K|X=x)})=\\beta_{k0}+\\beta_{k1}X_1+\\beta_{k2}X_2+...+\\beta_{kp}X_p\n\\]\n\n\n\n19.4.4.1 nnet::multinom()\n\n\nShow the codemn_spec &lt;- multinom_reg(mode = \"classification\", engine = \"nnet\")\n\niris_mnlogit &lt;- mn_spec %&gt;% \n    fit(Species ~ ., data = iris)\n\niris_mnlogit %&gt;% glance()\n#&gt; # A tibble: 1 × 4\n#&gt;     edf deviance   AIC  nobs\n#&gt;   &lt;dbl&gt;    &lt;dbl&gt; &lt;dbl&gt; &lt;int&gt;\n#&gt; 1    10     11.9  31.9   150\niris_mnlogit %&gt;% tidy()\n#&gt; # A tibble: 10 × 6\n#&gt;    y.level    term         estimate std.error statistic p.value\n#&gt;    &lt;chr&gt;      &lt;chr&gt;           &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;   &lt;dbl&gt;\n#&gt;  1 versicolor (Intercept)     18.7       35.0    0.534    0.593\n#&gt;  2 versicolor Sepal.Length    -5.46      89.9   -0.0607   0.952\n#&gt;  3 versicolor Sepal.Width     -8.71     157.    -0.0554   0.956\n#&gt;  4 versicolor Petal.Length    14.2       60.2    0.237    0.813\n#&gt;  5 versicolor Petal.Width     -3.10      45.5   -0.0681   0.946\n#&gt;  6 virginica  (Intercept)    -23.8       35.8   -0.666    0.505\n#&gt;  7 virginica  Sepal.Length    -7.92      89.9   -0.0881   0.930\n#&gt;  8 virginica  Sepal.Width    -15.4      157.    -0.0978   0.922\n#&gt;  9 virginica  Petal.Length    23.7       60.5    0.391    0.696\n#&gt; 10 virginica  Petal.Width     15.1       45.9    0.330    0.742\n\n\naugment(iris_mnlogit, new_data = iris) %&gt;%\n    conf_mat(truth = Species, estimate = .pred_class) %&gt;%\n    autoplot(type = \"heatmap\")\n\n\n\n\n\n\n\n\n19.4.4.2 glmnet::glmnet()\n\n\nShow the codelibrary(glmnet) # 多项回归\niris_glmnet &lt;- glmnet(x = iris[, -5], y = iris[, 5], family = \"multinomial\")\niris_glmnet\n#&gt; \n#&gt; Call:  glmnet(x = iris[, -5], y = iris[, 5], family = \"multinomial\") \n#&gt; \n#&gt;     Df  %Dev  Lambda\n#&gt; 1    0  0.00 0.43500\n#&gt; 2    1  6.56 0.39640\n#&gt; 3    1 12.05 0.36110\n#&gt; 4    1 16.73 0.32910\n#&gt; 5    1 20.78 0.29980\n#&gt; 6    2 25.37 0.27320\n#&gt; 7    2 29.66 0.24890\n#&gt; 8    2 33.54 0.22680\n#&gt; 9    2 37.10 0.20670\n#&gt; 10   2 40.40 0.18830\n#&gt; 11   2 43.47 0.17160\n#&gt; 12   3 46.47 0.15630\n#&gt; 13   3 49.57 0.14240\n#&gt; 14   3 52.38 0.12980\n#&gt; 15   3 54.97 0.11830\n#&gt; 16   3 57.36 0.10780\n#&gt; 17   3 59.60 0.09818\n#&gt; 18   3 61.71 0.08946\n#&gt; 19   3 63.72 0.08151\n#&gt; 20   3 65.70 0.07427\n#&gt; 21   3 67.65 0.06767\n#&gt; 22   3 69.54 0.06166\n#&gt; 23   3 71.38 0.05618\n#&gt; 24   3 73.12 0.05119\n#&gt; 25   3 74.71 0.04664\n#&gt; 26   3 76.24 0.04250\n#&gt; 27   3 77.67 0.03872\n#&gt; 28   3 78.99 0.03528\n#&gt; 29   3 80.21 0.03215\n#&gt; 30   3 81.33 0.02929\n#&gt; 31   3 82.36 0.02669\n#&gt; 32   3 83.31 0.02432\n#&gt; 33   3 84.18 0.02216\n#&gt; 34   3 84.99 0.02019\n#&gt; 35   3 85.73 0.01840\n#&gt; 36   3 86.53 0.01676\n#&gt; 37   3 87.34 0.01527\n#&gt; 38   3 88.06 0.01392\n#&gt; 39   3 88.73 0.01268\n#&gt; 40   3 89.34 0.01155\n#&gt; 41   3 89.89 0.01053\n#&gt; 42   3 90.40 0.00959\n#&gt; 43   4 90.87 0.00874\n#&gt; 44   4 91.34 0.00796\n#&gt; 45   4 91.77 0.00726\n#&gt; 46   4 92.16 0.00661\n#&gt; 47   4 92.52 0.00602\n#&gt; 48   4 92.85 0.00549\n#&gt; 49   4 93.16 0.00500\n#&gt; 50   4 93.44 0.00456\n#&gt; 51   4 93.69 0.00415\n#&gt; 52   4 93.92 0.00378\n#&gt; 53   4 94.14 0.00345\n#&gt; 54   4 94.34 0.00314\n#&gt; 55   4 94.52 0.00286\n#&gt; 56   4 94.68 0.00261\n#&gt; 57   4 94.83 0.00238\n#&gt; 58   4 94.97 0.00216\n#&gt; 59   4 95.10 0.00197\n#&gt; 60   4 95.22 0.00180\n#&gt; 61   4 95.33 0.00164\n#&gt; 62   4 95.43 0.00149\n#&gt; 63   4 95.52 0.00136\n#&gt; 64   4 95.60 0.00124\n#&gt; 65   4 95.68 0.00113\n#&gt; 66   4 95.75 0.00103\n#&gt; 67   4 95.81 0.00094\n#&gt; 68   4 95.87 0.00085\n#&gt; 69   4 95.92 0.00078\n#&gt; 70   4 95.97 0.00071\n#&gt; 71   4 96.01 0.00065\n#&gt; 72   4 96.05 0.00059\n#&gt; 73   4 96.09 0.00054\n#&gt; 74   4 96.12 0.00049\n#&gt; 75   4 96.15 0.00045\n#&gt; 76   4 96.18 0.00041\n#&gt; 77   4 96.20 0.00037\n#&gt; 78   4 96.22 0.00034\n#&gt; 79   4 96.24 0.00031\n#&gt; 80   4 96.26 0.00028\n#&gt; 81   4 96.27 0.00025\n#&gt; 82   4 96.29 0.00023\n#&gt; 83   4 96.30 0.00021\n#&gt; 84   4 96.31 0.00019\n#&gt; 85   4 96.32 0.00018\n#&gt; 86   4 96.33 0.00016\n#&gt; 87   4 96.33 0.00015\n#&gt; 88   4 96.34 0.00013\n#&gt; 89   4 96.35 0.00012\n#&gt; 90   4 96.35 0.00011\n#&gt; 91   4 96.35 0.00010\n#&gt; 92   4 96.36 0.00009\n#&gt; 93   4 96.36 0.00008\n#&gt; 94   4 96.36 0.00008\n#&gt; 95   4 96.37 0.00007\n#&gt; 96   4 96.37 0.00006\n#&gt; 97   4 96.37 0.00006\n#&gt; 98   4 96.37 0.00005\n#&gt; 99   4 96.38 0.00005\n#&gt; 100  4 96.38 0.00004\nsummary(iris_glmnet )\n#&gt;            Length Class  Mode     \n#&gt; a0         300    -none- numeric  \n#&gt; beta         3    -none- list     \n#&gt; dfmat      300    -none- numeric  \n#&gt; df         100    -none- numeric  \n#&gt; dim          2    -none- numeric  \n#&gt; lambda     100    -none- numeric  \n#&gt; dev.ratio  100    -none- numeric  \n#&gt; nulldev      1    -none- numeric  \n#&gt; npasses      1    -none- numeric  \n#&gt; jerr         1    -none- numeric  \n#&gt; offset       1    -none- logical  \n#&gt; classnames   3    -none- character\n#&gt; grouped      1    -none- logical  \n#&gt; call         4    -none- call     \n#&gt; nobs         1    -none- numeric\nplot(iris_glmnet)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nShow the codeplot(iris_glmnet$lambda,\n  ylab = expression(lambda), xlab = \"迭代次数\", main = \"惩罚系数的迭代路径\"\n)\n\n\n\n\n\n\nShow the code\n# 选择一个迭代趋于稳定时的 lambda，比如 iris_glmnet$lambda[80]\ncoef(iris_glmnet, s = 0.0002796185)\n#&gt; $setosa\n#&gt; 5 x 1 sparse Matrix of class \"dgCMatrix\"\n#&gt;                      1\n#&gt; (Intercept)  17.015429\n#&gt; Sepal.Length  .       \n#&gt; Sepal.Width   4.486992\n#&gt; Petal.Length -3.250342\n#&gt; Petal.Width  -3.315393\n#&gt; \n#&gt; $versicolor\n#&gt; 5 x 1 sparse Matrix of class \"dgCMatrix\"\n#&gt;                     1\n#&gt; (Intercept)  8.132656\n#&gt; Sepal.Length 2.123980\n#&gt; Sepal.Width  .       \n#&gt; Petal.Length .       \n#&gt; Petal.Width  .       \n#&gt; \n#&gt; $virginica\n#&gt; 5 x 1 sparse Matrix of class \"dgCMatrix\"\n#&gt;                       1\n#&gt; (Intercept)  -25.148085\n#&gt; Sepal.Length   .       \n#&gt; Sepal.Width   -5.176029\n#&gt; Petal.Length   7.536940\n#&gt; Petal.Width   14.481524\n\niris_pred_glmnet &lt;- predict(\n  object = iris_glmnet, newx = as.matrix(iris[, -5]),\n  s = 0.0002796185, type = \"class\"\n)\n\n\n\nShow the codemn_spec &lt;- multinom_reg(mode = \"classification\", engine = \"glmnet\" ,penalty = tune())\n\niris_mnlogit &lt;- mn_spec %&gt;% \n    fit(Species ~ ., data = iris)\niris_mnlogit %&gt;% glance()\n#&gt; # A tibble: 1 × 3\n#&gt;   nulldev npasses  nobs\n#&gt;     &lt;dbl&gt;   &lt;int&gt; &lt;int&gt;\n#&gt; 1    330.    6546   150\niris_mnlogit$fit %&gt;% tidy() %&gt;% DT::datatable()\n\n\n\n\n\n\n19.4.5 有序逻辑回归\n\\[\n    \\ln \\left(\\frac{P(Y\\le k|X=x)}{1-P(Y\\le k|X=x)}\\right)\n\\]\n\nShow the codeacl &lt;- read_rds(\"data/icpsr/advanced_acl_data.rds\")\nacl$PhysActCat_W1 &lt;- factor(acl$PhysActCat_W1,ordered = T)\nstr(acl$PhysActCat_W1)\n#&gt;  Ord.factor w/ 5 levels \"(1) Low_5th\"&lt;..: 1 3 5 3 2 2 3 1 4 5 ...\n\nordered_logit &lt;- MASS::polr(PhysActCat_W1 ~ SelfEfficacy_W1, data = acl,\n                            method = \"logistic\")\nordered_logit %&gt;% summary()\n#&gt; Call:\n#&gt; MASS::polr(formula = PhysActCat_W1 ~ SelfEfficacy_W1, data = acl, \n#&gt;     method = \"logistic\")\n#&gt; \n#&gt; Coefficients:\n#&gt;                  Value Std. Error t value\n#&gt; SelfEfficacy_W1 0.2431    0.02893   8.404\n#&gt; \n#&gt; Intercepts:\n#&gt;                           Value    Std. Error t value \n#&gt; (1) Low_5th|(2) 2Low_5th   -0.9332   0.0371   -25.1533\n#&gt; (2) 2Low_5th|(3) 3Low_5th  -0.2688   0.0338    -7.9606\n#&gt; (3) 3Low_5th|(4) 4Low_5th   0.8470   0.0364    23.2527\n#&gt; (4) 4Low_5th|(5) Hi_5th     1.5298   0.0435    35.1647\n#&gt; \n#&gt; Residual Deviance: 11196.86 \n#&gt; AIC: 11206.86\n\npredict(ordered_logit ,acl ,type = \"prob\") %&gt;% \n    as_tibble() %&gt;% \n    DT::datatable()\n\n\n\n\nShow the code\npredict(ordered_logit ,acl ,type = \"class\") %&gt;% \n    as_tibble() %&gt;% \n    DT::datatable()",
    "crumbs": [
      "推断统计模型",
      "<span class='chapter-number'>19</span>  <span class='chapter-title'>广义线性模型</span>"
    ]
  },
  {
    "objectID": "GLM.html#泊松回归",
    "href": "GLM.html#泊松回归",
    "title": "\n19  广义线性模型\n",
    "section": "\n19.5 泊松回归",
    "text": "19.5 泊松回归\n泊松回归用于计数数据，假设响应变量服从泊松分布，并使用对数链接函数（log link function），z-statistic\nfamily=poisson(link = \"log\")\nfamily = quasipoisson(link = \"log\"))\n\\[\nP(X=x;\\lambda)=\\frac{e^{-\\lambda}\\lambda ^x}{x!}\n\\]\n\nShow the codeggplot(tibble(x=0:20,\n              y1=dpois(x,lambda = 2),\n              y2=dpois(x,lambda = 6),\n              ),\n       aes(x)\n       )+\n    geom_col(aes(y=y1),fill = \"lightblue\")+\n    geom_col(aes(y=y2),fill = \"yellow\",alpha=.3)+\n    ylab(\"Poisson Density\")\n\n\n\n\n\n\n\n\nShow the codelibrary(poissonreg)\ndf2 &lt;- read_csv(\"data/ISLR/Bikeshare.csv\")\n\n\n\nShow the code# 泊松回归模型\npois_spec &lt;- poisson_reg() %&gt;% \n  set_mode(\"regression\") %&gt;% \n  set_engine(\"glm\",family=poisson(link = \"log\"))\n\npois_rec_spec &lt;- recipe(bikers ~ mnth + hr + workingday + temp + weathersit, data = df2) %&gt;% \n    step_dummy(all_nominal_predictors()) # 虚拟变量\n\npois_wf &lt;- workflow() %&gt;% \n  add_recipe(pois_rec_spec) %&gt;% \n  add_model(pois_spec)\n\npois_fit &lt;- pois_wf %&gt;% fit(data = df2)\n\n\ntidy(pois_fit)\n#&gt; # A tibble: 18 × 5\n#&gt;    term                       estimate std.error statistic   p.value\n#&gt;    &lt;chr&gt;                         &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;\n#&gt;  1 (Intercept)                 3.01     0.00632     477.   0        \n#&gt;  2 hr                          0.0507   0.000144    352.   0        \n#&gt;  3 workingday                 -0.0128   0.00195      -6.57 4.91e- 11\n#&gt;  4 temp                        2.56     0.00995     258.   0        \n#&gt;  5 mnth_Aug                   -0.229    0.00470     -48.7  0        \n#&gt;  6 mnth_Dec                    0.298    0.00501      59.5  0        \n#&gt;  7 mnth_Feb                   -0.102    0.00592     -17.2  5.28e- 66\n#&gt;  8 mnth_Jan                   -0.145    0.00678     -21.4  1.74e-101\n#&gt;  9 mnth_July                  -0.378    0.00496     -76.2  0        \n#&gt; 10 mnth_June                  -0.150    0.00462     -32.5  1.32e-231\n#&gt; 11 mnth_March                 -0.0312   0.00534      -5.83 5.44e-  9\n#&gt; 12 mnth_May                    0.0508   0.00434      11.7  1.43e- 31\n#&gt; 13 mnth_Nov                    0.285    0.00461      61.8  0        \n#&gt; 14 mnth_Oct                    0.267    0.00432      61.7  0        \n#&gt; 15 mnth_Sept                  -0.00653  0.00443      -1.47 1.41e-  1\n#&gt; 16 weathersit_cloudy.misty    -0.0308   0.00216     -14.2  5.70e- 46\n#&gt; 17 weathersit_heavy.rain.snow -0.646    0.167        -3.87 1.08e-  4\n#&gt; 18 weathersit_light.rain.snow -0.473    0.00404    -117.   0\n\n\n# 绘制实际值与预测值的关系图\naugment(pois_fit, new_data = df2, type = \"response\") %&gt;%\n    ggplot(aes(bikers, .pred)) +\n    geom_point(alpha = 0.1) +\n    geom_abline(slope = 1,\n                linewidth = 1,\n                color = \"grey40\") +\n    labs(title = \"Predicting the number of bikers per hour using Poission Regression\", x = \"Actual\", y = \"Predicted\")\n\n\n\n\n\n\n\n\nShow the codepois_fit_coef_mnths &lt;- \n  tidy(pois_fit) %&gt;% \n  dplyr::filter(grepl(\"^mnth\", term)) %&gt;% \n  mutate(\n    term = stringr::str_replace(term, \"mnth_\", \"\"),\n    term = forcats::fct_inorder(term)\n  ) \n\npois_fit_coef_mnths %&gt;% \n  ggplot(aes(term, estimate)) +\n  geom_line(group = 1,na.rm = TRUE) +\n  geom_point(shape = 21, size = 3, stroke = 1.5, \n             fill = \"black\", color = \"white\",na.rm = TRUE) +\n  labs(title = \"Coefficient value from Poission Regression\",\n       x = \"Month\", y = \"Coefficient\")\n\n\n\n\n\n\n\n\nShow the codepois_acl &lt;- pois_spec %&gt;% \n    fit(NChronic12_W1 ~ SelfEfficacy_W1,data = acl)\n\npois_acl %&gt;% glance()\n#&gt; # A tibble: 1 × 8\n#&gt;   null.deviance df.null logLik    AIC    BIC deviance df.residual  nobs\n#&gt;           &lt;dbl&gt;   &lt;int&gt;  &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;    &lt;dbl&gt;       &lt;int&gt; &lt;int&gt;\n#&gt; 1         5217.    3616 -5161. 10327. 10339.    5114.        3615  3617\n\npois_acl %&gt;% tidy()\n#&gt; # A tibble: 2 × 5\n#&gt;   term            estimate std.error statistic  p.value\n#&gt;   &lt;chr&gt;              &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt;\n#&gt; 1 (Intercept)       0.0713    0.0162      4.40 1.06e- 5\n#&gt; 2 SelfEfficacy_W1  -0.150     0.0144    -10.4  3.97e-25\n\nAIC(pois_acl$fit)\n#&gt; [1] 10326.52\nBIC(pois_acl$fit)\n#&gt; [1] 10338.9",
    "crumbs": [
      "推断统计模型",
      "<span class='chapter-number'>19</span>  <span class='chapter-title'>广义线性模型</span>"
    ]
  },
  {
    "objectID": "GLM.html#负二项回归",
    "href": "GLM.html#负二项回归",
    "title": "\n19  广义线性模型\n",
    "section": "\n19.6 负二项回归",
    "text": "19.6 负二项回归\n负二项回归用于处理计数数据且存在过度离散（overdispersion）的问题即当均值不等于方差。\nlog link function，z-statistic\nprobability mass function ：\n\\[\nP(X=x;\\lambda,\\nu)=\\binom{x+\\nu - 1}{ x} \\left ( \\frac{\\lambda}{\\lambda +\\nu} \\right)^x \\left ( \\frac{\\nu}{\\nu + \\lambda} \\right)^{\\nu}\n\\]\n负二项分布的均值是 \\(\\lambda\\) ，\n方差是 \\(\\lambda + \\frac{\\lambda ^2}{\\nu}\\) 。\n\nShow the codelibrary(MASS)\n# 负二项回归模型\nnb_spec &lt;- linear_reg() %&gt;% \n  set_engine(\"glm\", family = MASS::negative.binomial(theta = 1, link = \"log\"))\n\nnb_acl &lt;- nb_spec %&gt;% \n  fit(NChronic12_W1 ~ SelfEfficacy_W1, data = acl)\n\n# 查看模型结果\nnb_acl %&gt;% glance()\n#&gt; # A tibble: 1 × 8\n#&gt;   null.deviance df.null logLik    AIC    BIC deviance df.residual  nobs\n#&gt;           &lt;dbl&gt;   &lt;int&gt;  &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;    &lt;dbl&gt;       &lt;int&gt; &lt;int&gt;\n#&gt; 1         2946.    3616 -5220. 10443. 10456.    2898.        3615  3617\nnb_acl %&gt;% tidy()\n#&gt; # A tibble: 2 × 5\n#&gt;   term            estimate std.error statistic  p.value\n#&gt;   &lt;chr&gt;              &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt;\n#&gt; 1 (Intercept)       0.0715    0.0181      3.95 8.10e- 5\n#&gt; 2 SelfEfficacy_W1  -0.148     0.0169     -8.75 3.18e-18\n\n\nAIC(nb_acl$fit)\n#&gt; [1] 10443.43\nBIC(nb_acl$fit)\n#&gt; [1] 10455.82\n\n# MASS::glm.nb()",
    "crumbs": [
      "推断统计模型",
      "<span class='chapter-number'>19</span>  <span class='chapter-title'>广义线性模型</span>"
    ]
  },
  {
    "objectID": "GLM.html#正则化广义线性模型",
    "href": "GLM.html#正则化广义线性模型",
    "title": "\n19  广义线性模型\n",
    "section": "\n19.8 正则化广义线性模型",
    "text": "19.8 正则化广义线性模型\nRidge、Lasso\n\nShow the codelibrary(glmnet)\ndata(QuickStartExample)\nfit &lt;- glmnet::glmnet(x = QuickStartExample$x, y = QuickStartExample$y)\nautoplot(fit)\n\n\n\n\n\n\nShow the code\nfit &lt;- glmnet::cv.glmnet(x = QuickStartExample$x, y = QuickStartExample$y)\nautoplot(fit, colour = 'blue')",
    "crumbs": [
      "推断统计模型",
      "<span class='chapter-number'>19</span>  <span class='chapter-title'>广义线性模型</span>"
    ]
  },
  {
    "objectID": "LME.html",
    "href": "LME.html",
    "title": "\n19  线性混合模型\n",
    "section": "",
    "text": "19.1 lme4::lmer()\nCodelme4::lmer\n#&gt; function (formula, data = NULL, REML = TRUE, control = lmerControl(), \n#&gt;     start = NULL, verbose = 0L, subset, weights, na.action, offset, \n#&gt;     contrasts = NULL, devFunOnly = FALSE) \n#&gt; {\n#&gt;     mc &lt;- mcout &lt;- match.call()\n#&gt;     missCtrl &lt;- missing(control)\n#&gt;     if (!missCtrl && !inherits(control, \"lmerControl\")) {\n#&gt;         if (!is.list(control)) \n#&gt;             stop(\"'control' is not a list; use lmerControl()\")\n#&gt;         warning(\"passing control as list is deprecated: please use lmerControl() instead\", \n#&gt;             immediate. = TRUE)\n#&gt;         control &lt;- do.call(lmerControl, control)\n#&gt;     }\n#&gt;     mc$control &lt;- control\n#&gt;     mc[[1]] &lt;- quote(lme4::lFormula)\n#&gt;     lmod &lt;- eval(mc, parent.frame(1L))\n#&gt;     mcout$formula &lt;- lmod$formula\n#&gt;     lmod$formula &lt;- NULL\n#&gt;     if (is.matrix(y &lt;- model.response(lmod$fr)) && ncol(y) &gt; \n#&gt;         1) {\n#&gt;         stop(\"can't handle matrix-valued responses: consider using refit()\")\n#&gt;     }\n#&gt;     devfun &lt;- do.call(mkLmerDevfun, c(lmod, list(start = start, \n#&gt;         verbose = verbose, control = control)))\n#&gt;     if (devFunOnly) \n#&gt;         return(devfun)\n#&gt;     if (identical(control$optimizer, \"none\")) \n#&gt;         stop(\"deprecated use of optimizer=='none'; use NULL instead\")\n#&gt;     opt &lt;- if (length(control$optimizer) == 0) {\n#&gt;         s &lt;- getStart(start, environment(devfun)$pp)\n#&gt;         list(par = s, fval = devfun(s), conv = 1000, message = \"no optimization\")\n#&gt;     }\n#&gt;     else {\n#&gt;         optimizeLmer(devfun, optimizer = control$optimizer, restart_edge = control$restart_edge, \n#&gt;             boundary.tol = control$boundary.tol, control = control$optCtrl, \n#&gt;             verbose = verbose, start = start, calc.derivs = control$calc.derivs, \n#&gt;             use.last.params = control$use.last.params)\n#&gt;     }\n#&gt;     cc &lt;- checkConv(attr(opt, \"derivs\"), opt$par, ctrl = control$checkConv, \n#&gt;         lbound = environment(devfun)$lower)\n#&gt;     mkMerMod(environment(devfun), opt, lmod$reTrms, fr = lmod$fr, \n#&gt;         mc = mcout, lme4conv = cc)\n#&gt; }\n#&gt; &lt;bytecode: 0x0000021bb56bef28&gt;\n#&gt; &lt;environment: namespace:lme4&gt;\nlmer() 的表达式如下：\n\\[\nlmer (data,formual= DV ~ Fixed\\_Factor + (Random\\_intercept + Random\\_slope | Random\\_Factor))\n\\]\n截距中，1表示随机截距，0表示固定截距，默认截距为1。",
    "crumbs": [
      "推断统计模型",
      "<span class='chapter-number'>19</span>  <span class='chapter-title'>线性混合模型</span>"
    ]
  },
  {
    "objectID": "LME.html#lme4lmer",
    "href": "LME.html#lme4lmer",
    "title": "\n19  线性混合模型\n",
    "section": "",
    "text": "LME\n表达式\n简写\n\n\n\n随机截距+随机斜率\ny~x+( 1+x | id )\ny~x+( x | id )\n\n\n随机截距+固定斜率\ny~x+( 1+1 | id )\ny~x+( 1 | id )\n\n\n固定截距+随机斜率\ny~x+( 0+x | id )\nNA\n\n\n线性模型：固定截距+固定斜率\ny~x\nNA",
    "crumbs": [
      "推断统计模型",
      "<span class='chapter-number'>19</span>  <span class='chapter-title'>线性混合模型</span>"
    ]
  },
  {
    "objectID": "LME.html#nlmelme",
    "href": "LME.html#nlmelme",
    "title": "\n19  线性混合模型\n",
    "section": "\n19.2 nlme::lme()\n",
    "text": "19.2 nlme::lme()\n\n\nCodenlme::nlme\n#&gt; function (model, data = sys.frame(sys.parent()), fixed, random = fixed, \n#&gt;     groups, start, correlation = NULL, weights = NULL, subset, \n#&gt;     method = c(\"ML\", \"REML\"), na.action = na.fail, naPattern, \n#&gt;     control = list(), verbose = FALSE) \n#&gt; {\n#&gt;     UseMethod(\"nlme\")\n#&gt; }\n#&gt; &lt;bytecode: 0x0000021bb8b7b550&gt;\n#&gt; &lt;environment: namespace:nlme&gt;",
    "crumbs": [
      "推断统计模型",
      "<span class='chapter-number'>19</span>  <span class='chapter-title'>线性混合模型</span>"
    ]
  },
  {
    "objectID": "LME.html#随机截距随机斜率",
    "href": "LME.html#随机截距随机斜率",
    "title": "\n19  线性混合模型\n",
    "section": "\n19.3 随机截距+随机斜率",
    "text": "19.3 随机截距+随机斜率\n\nCodedf_long &lt;- read_delim(\"data/AED/RIKZ.txt\")\ndf_long$Beach &lt;- factor(df_long$Beach)\ndf_long$Exposure &lt;- factor(df_long$Exposure)\nhead(df_long)\n\n\n\n\nSample\nRichness\nExposure\nNAP\nBeach\n\n\n\n1\n11\n10\n0.045\n1\n\n\n2\n10\n10\n-1.036\n1\n\n\n3\n13\n10\n-1.336\n1\n\n\n4\n11\n10\n0.616\n1\n\n\n5\n10\n10\n-0.684\n1\n\n\n6\n8\n8\n1.190\n2\n\n\n\n\n\n\n\\[\n\\eta_{(nrow \\times 1)} = \\mathbf{X}_{nrow \\times 1} \\beta_{1 \\times 1} + \\mathbf{Z}_{nrow \\times 2n_{subjects}} \\mathbf{\\gamma}_{2n_{subjects} \\times 1} + \\epsilon_i\n\\]\nZ有两倍于受试者数量的列，每个受试者的随机截距和随机斜率\n\nCodelibrary(lme4)\nlme1 &lt;- lmer(Richness ~ 1 + NAP * Exposure+ (1 +NAP |Beach) ,data = df_long)\nsummary(lme1)\n#&gt; Linear mixed model fit by REML ['lmerMod']\n#&gt; Formula: Richness ~ 1 + NAP * Exposure + (1 + NAP | Beach)\n#&gt;    Data: df_long\n#&gt; \n#&gt; REML criterion at convergence: 207.2\n#&gt; \n#&gt; Scaled residuals: \n#&gt;      Min       1Q   Median       3Q      Max \n#&gt; -1.92384 -0.36066 -0.13343  0.09819  2.84228 \n#&gt; \n#&gt; Random effects:\n#&gt;  Groups   Name        Variance Std.Dev. Corr \n#&gt;  Beach    (Intercept) 3.758    1.938         \n#&gt;           NAP         2.837    1.684    -1.00\n#&gt;  Residual             6.535    2.556         \n#&gt; Number of obs: 45, groups:  Beach, 9\n#&gt; \n#&gt; Fixed effects:\n#&gt;                Estimate Std. Error t value\n#&gt; (Intercept)     13.3457     2.2784   5.858\n#&gt; NAP             -4.1753     2.1243  -1.965\n#&gt; Exposure10      -5.3273     2.5556  -2.085\n#&gt; Exposure11      -9.7660     2.5653  -3.807\n#&gt; NAP:Exposure10   0.1646     2.3621   0.070\n#&gt; NAP:Exposure11   2.7273     2.3715   1.150\n#&gt; \n#&gt; Correlation of Fixed Effects:\n#&gt;             (Intr) NAP    Exps10 Exps11 NAP:E10\n#&gt; NAP         -0.770                             \n#&gt; Exposure10  -0.892  0.686                      \n#&gt; Exposure11  -0.888  0.683  0.792               \n#&gt; NAP:Expsr10  0.692 -0.899 -0.775 -0.615        \n#&gt; NAP:Expsr11  0.689 -0.896 -0.615 -0.779  0.806 \n#&gt; optimizer (nloptwrap) convergence code: 0 (OK)\n#&gt; boundary (singular) fit: see help('isSingular')\nAIC(lme1)\n#&gt; [1] 227.1558\nBIC(lme1)\n#&gt; [1] 245.2224\nlogLik(lme1)\n#&gt; 'log Lik.' -103.5779 (df=10)\n\n2*(1-pt(-3.914605,35,lower.tail = F))\n#&gt; [1] 0.0003993968\n\nlibrary(nlme)\n\nnlme1 &lt;- lme(Richness ~ 1 + NAP * Exposure,\n             random = ~ 1 + NAP | Beach ,\n             data = df_long,\n             control = lmeControl(opt = \"optim\", msMaxIter = 100, msMaxEval = 5000))\nsummary(nlme1)\n#&gt; Linear mixed-effects model fit by REML\n#&gt;   Data: df_long \n#&gt;        AIC      BIC    logLik\n#&gt;   227.2046 243.8402 -103.6023\n#&gt; \n#&gt; Random effects:\n#&gt;  Formula: ~1 + NAP | Beach\n#&gt;  Structure: General positive-definite, Log-Cholesky parametrization\n#&gt;             StdDev   Corr  \n#&gt; (Intercept) 1.939709 (Intr)\n#&gt; NAP         1.689580 -0.996\n#&gt; Residual    2.554676       \n#&gt; \n#&gt; Fixed effects:  Richness ~ 1 + NAP * Exposure \n#&gt;                    Value Std.Error DF   t-value p-value\n#&gt; (Intercept)    13.345694  2.278989 33  5.855970  0.0000\n#&gt; NAP            -4.175271  2.128084 33 -1.961986  0.0582\n#&gt; Exposure10     -5.323695  2.556406  6 -2.082492  0.0825\n#&gt; Exposure11     -9.765613  2.566035  6 -3.805720  0.0089\n#&gt; NAP:Exposure10  0.167146  2.366467 33  0.070631  0.9441\n#&gt; NAP:Exposure11  2.726865  2.375786 33  1.147774  0.2593\n#&gt;  Correlation: \n#&gt;                (Intr) NAP    Exps10 Exps11 NAP:E10\n#&gt; NAP            -0.767                             \n#&gt; Exposure10     -0.891  0.684                      \n#&gt; Exposure11     -0.888  0.682  0.792               \n#&gt; NAP:Exposure10  0.690 -0.899 -0.772 -0.613        \n#&gt; NAP:Exposure11  0.687 -0.896 -0.613 -0.777  0.806 \n#&gt; \n#&gt; Standardized Within-Group Residuals:\n#&gt;        Min         Q1        Med         Q3        Max \n#&gt; -1.9251786 -0.3608959 -0.1327685  0.0992999  2.8420571 \n#&gt; \n#&gt; Number of Observations: 45\n#&gt; Number of Groups: 9\n\n\n这个模型的公式可以分解为：\n\n固定效应部分：Richness 的预测由截距、NAP（数值变量）和 Exposure（分类变量，包含 Exposure10 和 Exposure11）及其交互项构成。\n随机效应部分：Beach 作为随机因子，包含随机截距和随机斜率（NAP）。\n\n\nCode# 标准化模型残差分布\nquantile(residuals(lme1,type=\"pearson\",scaled=T))\n#&gt;         0%        25%        50%        75%       100% \n#&gt; -1.9238372 -0.3606612 -0.1334336  0.0981939  2.8422803\n\n# 随机因子随机效应和显著性检验\nranef(lme1)\n#&gt; $Beach\n#&gt;     (Intercept)           NAP\n#&gt; 1 -4.274356e-02  3.713708e-02\n#&gt; 2 -2.709479e-14  2.354089e-14\n#&gt; 3  3.819348e-03 -3.318381e-03\n#&gt; 4 -2.741786e-01  2.382158e-01\n#&gt; 5  3.269522e+00 -2.840673e+00\n#&gt; 6  2.736093e-01 -2.377212e-01\n#&gt; 7 -3.250033e-03  2.823741e-03\n#&gt; 8 -2.148947e+00  1.867079e+00\n#&gt; 9 -1.077831e+00  9.364564e-01\n#&gt; \n#&gt; with conditional variances for \"Beach\"\nlmerTest::ranova(lme1)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nnpar\nlogLik\nAIC\nLRT\nDf\nPr(&gt;Chisq)\n\n\n\n\n10\n-103.5779\n227.1558\nNA\nNA\nNA\n\n\nNAP in (1 + NAP | Beach)\n8\n-105.6747\n227.3493\n4.193538\n2\n0.1228527\n\n\n\n\n\nCode\n# 查看固定效应和显著性检验\ncoef(lme1)\n#&gt; $Beach\n#&gt;   (Intercept)       NAP Exposure10 Exposure11 NAP:Exposure10 NAP:Exposure11\n#&gt; 1    13.30295 -4.138134  -5.327265  -9.766048      0.1646123       2.727307\n#&gt; 2    13.34569 -4.175271  -5.327265  -9.766048      0.1646123       2.727307\n#&gt; 3    13.34951 -4.178590  -5.327265  -9.766048      0.1646123       2.727307\n#&gt; 4    13.07152 -3.937055  -5.327265  -9.766048      0.1646123       2.727307\n#&gt; 5    16.61522 -7.015944  -5.327265  -9.766048      0.1646123       2.727307\n#&gt; 6    13.61930 -4.412992  -5.327265  -9.766048      0.1646123       2.727307\n#&gt; 7    13.34244 -4.172447  -5.327265  -9.766048      0.1646123       2.727307\n#&gt; 8    11.19675 -2.308192  -5.327265  -9.766048      0.1646123       2.727307\n#&gt; 9    12.26786 -3.238815  -5.327265  -9.766048      0.1646123       2.727307\n#&gt; \n#&gt; attr(,\"class\")\n#&gt; [1] \"coef.mer\"\nanova(lme1)\n\n\n\n\n\nnpar\nSum Sq\nMean Sq\nF value\n\n\n\nNAP\n1\n124.27890\n124.27890\n19.017821\n\n\nExposure\n2\n142.98343\n71.49172\n10.940045\n\n\nNAP:Exposure\n2\n22.30791\n11.15395\n1.706838\n\n\n\n\n\nCode\n#  查看 类和方法\nclass(lme1)\n#&gt; [1] \"lmerMod\"\n#&gt; attr(,\"package\")\n#&gt; [1] \"lme4\"\n# methods(class = \"lmerMod\")\n\n# confint(lme1,level = 0.95)",
    "crumbs": [
      "推断统计模型",
      "<span class='chapter-number'>19</span>  <span class='chapter-title'>线性混合模型</span>"
    ]
  },
  {
    "objectID": "LME.html#随机截距固定斜率",
    "href": "LME.html#随机截距固定斜率",
    "title": "\n19  线性混合模型\n",
    "section": "\n19.4 随机截距+固定斜率",
    "text": "19.4 随机截距+固定斜率\n\\[\n\\eta_{(nrow \\ \\times 1)}=\\mathbf{X_{nrow×1}}\\beta_{1\\times1} +Z_{nrow\\times n_{subjects}} \\mathbf{\\gamma}_{n_{subjects}\\times 1}+\\epsilon_i\n\\]\nZ有一倍于受试者数量的列，每个受试者的随机截距。\n\nCodelme2 &lt;- lmer(Richness ~ 1 + NAP+ (1 |Beach) ,data = df_long)\nsummary(lme2)\n#&gt; Linear mixed model fit by REML ['lmerMod']\n#&gt; Formula: Richness ~ 1 + NAP + (1 | Beach)\n#&gt;    Data: df_long\n#&gt; \n#&gt; REML criterion at convergence: 239.5\n#&gt; \n#&gt; Scaled residuals: \n#&gt;     Min      1Q  Median      3Q     Max \n#&gt; -1.4227 -0.4848 -0.1576  0.2519  3.9794 \n#&gt; \n#&gt; Random effects:\n#&gt;  Groups   Name        Variance Std.Dev.\n#&gt;  Beach    (Intercept) 8.668    2.944   \n#&gt;  Residual             9.362    3.060   \n#&gt; Number of obs: 45, groups:  Beach, 9\n#&gt; \n#&gt; Fixed effects:\n#&gt;             Estimate Std. Error t value\n#&gt; (Intercept)   6.5819     1.0958   6.007\n#&gt; NAP          -2.5684     0.4947  -5.192\n#&gt; \n#&gt; Correlation of Fixed Effects:\n#&gt;     (Intr)\n#&gt; NAP -0.157\nAIC(lme2)\n#&gt; [1] 247.4802\nBIC(lme2)\n#&gt; [1] 254.7069\nlogLik(lme2)\n#&gt; 'log Lik.' -119.7401 (df=4)\n\n2*(1-pt(6.007,35,lower.tail = T))\n#&gt; [1] 7.558855e-07\n\n\n\nnlme2 &lt;- lme(Richness ~ 1 + NAP * Exposure,random= ~ 1 |Beach ,data = df_long)\nsummary(nlme2)\n#&gt; Linear mixed-effects model fit by REML\n#&gt;   Data: df_long \n#&gt;        AIC      BIC    logLik\n#&gt;   227.3493 240.6578 -105.6747\n#&gt; \n#&gt; Random effects:\n#&gt;  Formula: ~1 | Beach\n#&gt;         (Intercept) Residual\n#&gt; StdDev:   0.5138683 2.971793\n#&gt; \n#&gt; Fixed effects:  Richness ~ 1 + NAP * Exposure \n#&gt;                    Value Std.Error DF   t-value p-value\n#&gt; (Intercept)    13.345694  1.483557 33  8.995739  0.0000\n#&gt; NAP            -4.175271  1.505110 33 -2.774063  0.0090\n#&gt; Exposure10     -5.544983  1.657659  6 -3.345069  0.0155\n#&gt; Exposure11     -9.730595  1.670518  6 -5.824898  0.0011\n#&gt; NAP:Exposure10  0.671731  1.643864 33  0.408629  0.6855\n#&gt; NAP:Exposure11  2.688806  1.656743 33  1.622947  0.1141\n#&gt;  Correlation: \n#&gt;                (Intr) NAP    Exps10 Exps11 NAP:E10\n#&gt; NAP            -0.278                             \n#&gt; Exposure10     -0.895  0.249                      \n#&gt; Exposure11     -0.888  0.247  0.795               \n#&gt; NAP:Exposure10  0.255 -0.916 -0.276 -0.226        \n#&gt; NAP:Exposure11  0.253 -0.908 -0.226 -0.296  0.832 \n#&gt; \n#&gt; Standardized Within-Group Residuals:\n#&gt;        Min         Q1        Med         Q3        Max \n#&gt; -1.5652904 -0.4386841 -0.1164805  0.1783113  4.1098230 \n#&gt; \n#&gt; Number of Observations: 45\n#&gt; Number of Groups: 9",
    "crumbs": [
      "推断统计模型",
      "<span class='chapter-number'>19</span>  <span class='chapter-title'>线性混合模型</span>"
    ]
  },
  {
    "objectID": "LME.html#固定截距随机斜率",
    "href": "LME.html#固定截距随机斜率",
    "title": "\n19  线性混合模型\n",
    "section": "\n19.5 固定截距+随机斜率",
    "text": "19.5 固定截距+随机斜率\n\\[\n\\eta_{(nrow \\times 1)} = \\mathbf{X}_{nrow \\times 1} \\beta_{1 \\times 1} + \\mathbf{Z}_{nrow \\times n_{subjects}} \\mathbf{\\gamma}_{n_{subjects} \\times 1} + \\epsilon_i\n\\]\nZ 有一倍于受试者数量的列，每个受试者的随机斜率。\n\nCodelme3 &lt;- lmer(Richness ~ 1 +  NAP+ (0 + NAP |Beach) ,data = df_long)\nsummary(lme3)\n#&gt; Linear mixed model fit by REML ['lmerMod']\n#&gt; Formula: Richness ~ 1 + NAP + (0 + NAP | Beach)\n#&gt;    Data: df_long\n#&gt; \n#&gt; REML criterion at convergence: 252.2\n#&gt; \n#&gt; Scaled residuals: \n#&gt;     Min      1Q  Median      3Q     Max \n#&gt; -1.2182 -0.6636 -0.1930  0.3253  3.3347 \n#&gt; \n#&gt; Random effects:\n#&gt;  Groups   Name Variance Std.Dev.\n#&gt;  Beach    NAP   0.00    0.00    \n#&gt;  Residual      17.31    4.16    \n#&gt; Number of obs: 45, groups:  Beach, 9\n#&gt; \n#&gt; Fixed effects:\n#&gt;             Estimate Std. Error t value\n#&gt; (Intercept)   6.6857     0.6578  10.164\n#&gt; NAP          -2.8669     0.6307  -4.545\n#&gt; \n#&gt; Correlation of Fixed Effects:\n#&gt;     (Intr)\n#&gt; NAP -0.333\n#&gt; optimizer (nloptwrap) convergence code: 0 (OK)\n#&gt; boundary (singular) fit: see help('isSingular')\n\nnlme3 &lt;- lme(Richness ~ 1 + NAP,random= ~ 0+NAP |Beach ,data = df_long)\nsummary(nlme3)\n#&gt; Linear mixed-effects model fit by REML\n#&gt;   Data: df_long \n#&gt;       AIC      BIC    logLik\n#&gt;   260.201 267.2458 -126.1005\n#&gt; \n#&gt; Random effects:\n#&gt;  Formula: ~0 + NAP | Beach\n#&gt;                  NAP Residual\n#&gt; StdDev: 0.0001127408 4.159929\n#&gt; \n#&gt; Fixed effects:  Richness ~ 1 + NAP \n#&gt;                 Value Std.Error DF   t-value p-value\n#&gt; (Intercept)  6.685662 0.6577579 35 10.164320   0e+00\n#&gt; NAP         -2.866853 0.6307186 35 -4.545376   1e-04\n#&gt;  Correlation: \n#&gt;     (Intr)\n#&gt; NAP -0.333\n#&gt; \n#&gt; Standardized Within-Group Residuals:\n#&gt;        Min         Q1        Med         Q3        Max \n#&gt; -1.2181663 -0.6636488 -0.1930031  0.3253447  3.3347473 \n#&gt; \n#&gt; Number of Observations: 45\n#&gt; Number of Groups: 9",
    "crumbs": [
      "推断统计模型",
      "<span class='chapter-number'>19</span>  <span class='chapter-title'>线性混合模型</span>"
    ]
  },
  {
    "objectID": "LME.html#随机效应模型",
    "href": "LME.html#随机效应模型",
    "title": "\n19  线性混合模型\n",
    "section": "\n19.6 随机效应模型",
    "text": "19.6 随机效应模型\n\nCode\nlme4 &lt;- lmer(Richness ~ 1 + (1|Beach) ,data = df_long)\nsummary(lme4)\n#&gt; Linear mixed model fit by REML ['lmerMod']\n#&gt; Formula: Richness ~ 1 + (1 | Beach)\n#&gt;    Data: df_long\n#&gt; \n#&gt; REML criterion at convergence: 261.1\n#&gt; \n#&gt; Scaled residuals: \n#&gt;     Min      1Q  Median      3Q     Max \n#&gt; -1.7797 -0.5070 -0.0980  0.2547  3.8063 \n#&gt; \n#&gt; Random effects:\n#&gt;  Groups   Name        Variance Std.Dev.\n#&gt;  Beach    (Intercept) 10.48    3.237   \n#&gt;  Residual             15.51    3.938   \n#&gt; Number of obs: 45, groups:  Beach, 9\n#&gt; \n#&gt; Fixed effects:\n#&gt;             Estimate Std. Error t value\n#&gt; (Intercept)    5.689      1.228   4.631\n\nnlme4 &lt;- lme(Richness ~ 1 ,random= ~ 1 |Beach ,data = df_long)\nsummary(nlme4)\n#&gt; Linear mixed-effects model fit by REML\n#&gt;   Data: df_long \n#&gt;        AIC      BIC    logLik\n#&gt;   267.1142 272.4668 -130.5571\n#&gt; \n#&gt; Random effects:\n#&gt;  Formula: ~1 | Beach\n#&gt;         (Intercept) Residual\n#&gt; StdDev:    3.237112 3.938415\n#&gt; \n#&gt; Fixed effects:  Richness ~ 1 \n#&gt;                Value Std.Error DF  t-value p-value\n#&gt; (Intercept) 5.688889  1.228419 36 4.631066       0\n#&gt; \n#&gt; Standardized Within-Group Residuals:\n#&gt;         Min          Q1         Med          Q3         Max \n#&gt; -1.77968689 -0.50704111 -0.09795286  0.25468670  3.80631705 \n#&gt; \n#&gt; Number of Observations: 45\n#&gt; Number of Groups: 9",
    "crumbs": [
      "推断统计模型",
      "<span class='chapter-number'>19</span>  <span class='chapter-title'>线性混合模型</span>"
    ]
  },
  {
    "objectID": "LME.html#线性模型固定截距-固定斜率",
    "href": "LME.html#线性模型固定截距-固定斜率",
    "title": "\n19  线性混合模型\n",
    "section": "\n19.7 线性模型：固定截距+ 固定斜率",
    "text": "19.7 线性模型：固定截距+ 固定斜率\n\nCodelm &lt;- lm(Richness ~ 1 + NAP ,data = df_long)\nlm\n#&gt; \n#&gt; Call:\n#&gt; lm(formula = Richness ~ 1 + NAP, data = df_long)\n#&gt; \n#&gt; Coefficients:\n#&gt; (Intercept)          NAP  \n#&gt;       6.686       -2.867",
    "crumbs": [
      "推断统计模型",
      "<span class='chapter-number'>19</span>  <span class='chapter-title'>线性混合模型</span>"
    ]
  },
  {
    "objectID": "LME.html#模型选择",
    "href": "LME.html#模型选择",
    "title": "\n19  线性混合模型\n",
    "section": "\n19.8 模型选择",
    "text": "19.8 模型选择\n限制最大似然法REML\n\n\n赤池信息准则（AIC）\n\\[ kIC=−2log(\\mathcal{L})+2k\\]\n其中：\n\n\\(\\mathcal{L}\\) 是似然函数。\n\\(k\\) 是模型参数的数量。\n\n\n\n贝叶斯信息准则（BIC）\n\\[ BIC=−2log(\\mathcal{L})+klog(n) \\]\n其中：\n\n\n\\(n\\) 是样本量。\n\n\n\n\nCode\nplot_lme &lt;- function(model, title) {\n    ggplot(df_long, aes(NAP, Richness, group = Beach, color = Beach)) +\n        geom_point() +\n        geom_line(\n            data =  bind_cols(df_long, .pred = predict(model, df_long)),\n            mapping = aes(y = .pred),\n            linewidth = 1\n        ) +\n        labs(title = title)+\n        scale_x_continuous(expand = (mult=c(0,.1)))+\n        scale_y_continuous(expand = (mult=c(0,.1)))+\n    ggsci::scale_color_jco() +\n        ggpubr::theme_pubr() +\n        theme(legend.position = \"right\",\n              plot.title = element_text(hjust = .5))\n}\n\n\nlme_plot &lt;- map2(list(lme1,lme2,lme3,lm),list(\"随机截距+随机斜率\",\"随机截距+固定斜率\",\"固定截距+随机斜率\",\"固定截距+固定斜率\"),plot_lme)\n\n\nlme_plot\n#&gt; [[1]]\n\n\n\n\n\n\n#&gt; \n#&gt; [[2]]\n\n\n\n\n\n\n#&gt; \n#&gt; [[3]]\n\n\n\n\n\n\n#&gt; \n#&gt; [[4]]\n\n\n\n\n\n\n\n\nCodeanova(lme1,lme2,lme3)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nnpar\nAIC\nBIC\nlogLik\ndeviance\nChisq\nDf\nPr(&gt;Chisq)\n\n\n\nlme2\n4\n249.8291\n257.0557\n-120.9145\n241.8291\nNA\nNA\nNA\n\n\nlme3\n4\n261.9535\n269.1801\n-126.9767\n253.9535\n0.00000\n0\nNA\n\n\nlme1\n10\n238.1993\n256.2660\n-109.0997\n218.1993\n35.75415\n6\n3.1e-06\n\n\n\n\n\nCodeanova(lme1,lme2,lme3,lme4,lm)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nnpar\nAIC\nBIC\nlogLik\ndeviance\nChisq\nDf\nPr(&gt;Chisq)\n\n\n\nlme4\n3\n269.3035\n274.7235\n-131.6518\n263.3035\nNA\nNA\nNA\n\n\nlm\n3\n259.9535\n265.3735\n-126.9767\n253.9535\n9.350043\n0\nNA\n\n\nlme2\n4\n249.8291\n257.0557\n-120.9145\n241.8291\n12.124401\n1\n0.0004977\n\n\nlme3\n4\n261.9535\n269.1801\n-126.9767\n253.9535\n0.000000\n0\nNA\n\n\nlme1\n10\n238.1993\n256.2660\n-109.0997\n218.1993\n35.754147\n6\n0.0000031\n\n\n\n\n\nCode\n# p小于0.05,说明全模型与简化后模型存在差异，最终采用lme1,AIC",
    "crumbs": [
      "推断统计模型",
      "<span class='chapter-number'>19</span>  <span class='chapter-title'>线性混合模型</span>"
    ]
  },
  {
    "objectID": "LME.html#模型诊断",
    "href": "LME.html#模型诊断",
    "title": "\n19  线性混合模型\n",
    "section": "\n19.9 模型诊断",
    "text": "19.9 模型诊断\nsleepstudy\n\nCode# 拟合线性混合模型\nmodel &lt;- lme1\n# 1. 残差图\nresiduals &lt;- resid(model)\nfitted &lt;- fitted(model)\nggplot(data.frame(fitted, residuals), aes(fitted, residuals)) +\n  geom_point() +\n  geom_smooth(method = \"loess\", se = FALSE) +\n  labs(title = \"Residuals vs Fitted\", x = \"Fitted values\", y = \"Residuals\")\n\n\n\n\n\n\nCode\n# 2. QQ图\nqqnorm(residuals)\nqqline(residuals)\n\n\n\n\n\n\nCode\n# 3. Cook's 距离\ncooksd &lt;- cooks.distance(model)\nplot(cooksd, type = \"h\", main = \"Cook's Distance\")\n\n\n\n\n\n\nCode\n# 4. 随机效应的分布\nrand_dist &lt;- ranef(model)\n\nqqnorm(rand_dist$Beach$NAP)\nqqline(rand_dist$Beach$NAP)",
    "crumbs": [
      "推断统计模型",
      "<span class='chapter-number'>19</span>  <span class='chapter-title'>线性混合模型</span>"
    ]
  },
  {
    "objectID": "GEE.html",
    "href": "GEE.html",
    "title": "\n20  广义估计方程\n",
    "section": "",
    "text": "20.1 数据集处理\n数据集 Analyzing ecological data\nShow the coderfb &lt;- read_delim(\"data/AED/RiceFieldBirds.txt\")\nrfb$richness &lt;- rowSums(rfb[, 8:56] &gt; 0)\nrfb |&gt; mutate(\n    FIELD = factor(FIELD),\n    SPTREAT = factor(SPTREAT),\n    log_AREA = log(rfb$AREA),\n    DEPTH2 = DEPTH ^ 2,\n    .after = 4\n) -&gt; rfb\n\n\nggplot(rfb, aes(Time, richness)) +\n    geom_point(pch = 21) +\n    geom_smooth(method = \"loess\", se = F) +\n    facet_wrap(vars(FIELD), labeller = \"label_both\")\nShow the codeowls &lt;- read_delim(\"data/AED/Owls.txt\")\n\nowls |&gt;\n    mutate(NCalls = SiblingNegotiation, log_broodsize = log(BroodSize), ) -&gt;\n    owls\nShow the codede &lt;- read_delim(\"data/AED/DeerEcervi.txt\")\n\nde |&gt;\n    mutate(\n        Ecervi_binary = if_else(Ecervi &gt; 0, 1, Ecervi),\n        Sex = factor(Sex),\n        Length_center = scale(Length, center = T , scale = F),\n    ) -&gt; de",
    "crumbs": [
      "推断统计模型",
      "<span class='chapter-number'>20</span>  <span class='chapter-title'>广义估计方程</span>"
    ]
  },
  {
    "objectID": "GEE.html#glm-连接函数",
    "href": "GEE.html#glm-连接函数",
    "title": "\n20  广义估计方程\n",
    "section": "\n20.2 GLM 连接函数",
    "text": "20.2 GLM 连接函数\nGLM的形式如下：\n\\[ g(\\mu_{ij})=\\beta_0+\\beta_1x_{ij_1}+\\beta_2x_{ij_2}+...+\\beta_px_{ij_p} \\]\n其中，g() 是一个连接函数，用于将自变量的线性组合与因变量的均值联系起来。常见的连接函数包括恒等连接函数（identity）、logistic连接函数（logit）、逆正弦连接函数（inverse sine）函数等。i 表示观测对象的索引，j 表示时间点或相关性结构的索引，uij 表示因变量的均值，β 表示待估计的系数，Xij 表示自变量。\n\\[\n\\eta = \\beta  \\mathbf{X}+ \\alpha\n\\]\n\\[\nE(y)=g^{-1}(\\eta)\n\\]\n对于计数数据：\n\\[\nE(y)=e^{\\eta}=e^{\\beta \\mathbf{X} +\\alpha}, 此时g(\\mu)=\\ln(\\mu)=\\mathbf{X}\\beta\n\\]\n\nShow the coderfb_glm &lt;- glm(richness ~ offset(log_AREA) +SPTREAT + DEPTH +DEPTH2,\n            family = quasipoisson(link = \"log\"),\n            data = rfb)\n\nowls_glm &lt;- glm(\n    NCalls ~ offset(log_broodsize) + SexParent * FoodTreatment + SexParent *\n        ArrivalTime,\n    family = poisson(link = \"log\"),\n    data = owls\n)\n\n\n对于二分类数据：\n\\[\nE(y)=\\frac{e^{\\beta \\mathbf{X} +\\alpha}}{1+e^{\\beta\\mathbf{X}+\\alpha}}, 此时g(\\mu)=\\ln(\\frac{\\mu}{1-\\mu})=logit(\\mu)\n\\]\n\nShow the codede_glm &lt;- glm(Ecervi_binary ~ Length_center *Sex,\n              family = binomial(link = \"logit\"),\n              data = de)\nsummary(de_glm)\n#&gt; \n#&gt; Call:\n#&gt; glm(formula = Ecervi_binary ~ Length_center * Sex, family = binomial(link = \"logit\"), \n#&gt;     data = de)\n#&gt; \n#&gt; Coefficients:\n#&gt;                    Estimate Std. Error z value Pr(&gt;|z|)    \n#&gt; (Intercept)        0.652409   0.109602   5.953 2.64e-09 ***\n#&gt; Length_center      0.025112   0.005576   4.504 6.68e-06 ***\n#&gt; Sex2               0.163873   0.174235   0.941   0.3469    \n#&gt; Length_center:Sex2 0.020109   0.009722   2.068   0.0386 *  \n#&gt; ---\n#&gt; Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n#&gt; \n#&gt; (Dispersion parameter for binomial family taken to be 1)\n#&gt; \n#&gt;     Null deviance: 1073.1  on 825  degrees of freedom\n#&gt; Residual deviance: 1003.7  on 822  degrees of freedom\n#&gt; AIC: 1011.7\n#&gt; \n#&gt; Number of Fisher Scoring iterations: 4",
    "crumbs": [
      "推断统计模型",
      "<span class='chapter-number'>20</span>  <span class='chapter-title'>广义估计方程</span>"
    ]
  },
  {
    "objectID": "GEE.html#方差",
    "href": "GEE.html#方差",
    "title": "\n20  广义估计方程\n",
    "section": "\n20.3 方差",
    "text": "20.3 方差\n\\[\nvar(Y_{is}|X_{is})=\\Phi × \\nu(\\mu_{is})\n\\]\n其中，Φ 是scale parameter （overdispersion），v() 是方差函数。",
    "crumbs": [
      "推断统计模型",
      "<span class='chapter-number'>20</span>  <span class='chapter-title'>广义估计方程</span>"
    ]
  },
  {
    "objectID": "GEE.html#相关性结构",
    "href": "GEE.html#相关性结构",
    "title": "\n20  广义估计方程\n",
    "section": "\n20.4 相关性结构",
    "text": "20.4 相关性结构\nR(α)\n\n非结构化相关：cor(Yis,Yit)=αst\n自回归相关：cor(Yis,Yit)=α|s-t|\nexchangeable 等相关：cor(Yis,Yit)=α\nindependence，独立，cor(Yis,Yit)=I",
    "crumbs": [
      "推断统计模型",
      "<span class='chapter-number'>20</span>  <span class='chapter-title'>广义估计方程</span>"
    ]
  },
  {
    "objectID": "GEE.html#gee",
    "href": "GEE.html#gee",
    "title": "\n20  广义估计方程\n",
    "section": "\n20.5 GEE",
    "text": "20.5 GEE\nGLM的期望和方差：\n\\[ E(Y_{ij})=b'(\\theta_{ij})\\\\ Var(Y_{ij})=b''(\\theta_{ij})\\ \\Phi \\]\n假定潜在的随机成分Vi ：\n\\[\nV_i=A_i^{1/2}R(\\alpha)A_i^{1/2}\\ \\Phi\n\\]\n其中，Ai =diag（b''(θi1)，...，b''(θij)） 。\nGEE的形式如下：\n\\[\nU(\\beta)=\\sum_{i=1}^{n} D'_iV_i^{-1}(y_i-\\mu_i)=0\n\\]\n其中，$U(β) $是一个包含待估计参数的函数，quasi-deviance \\(D'_i = \\left(\\frac{\\partial \\mu_i}{\\partial \\beta}\\right)'\\)，\\(V_i\\) 是方差-协方差矩阵，\\(R(\\alpha)\\) 是相关性结构矩阵，y 是观测数据，μ 是模型的均值预测值。采用迭代重复加权最小二乘法（iteratively reweighted least squares ，IWLS)），偏微分方程估计参数。",
    "crumbs": [
      "推断统计模型",
      "<span class='chapter-number'>20</span>  <span class='chapter-title'>广义估计方程</span>"
    ]
  },
  {
    "objectID": "GEE.html#gee-1",
    "href": "GEE.html#gee-1",
    "title": "\n20  广义估计方程\n",
    "section": "\n20.6 gee\n",
    "text": "20.6 gee\n\nhttps://www.statsmodels.org/stable//gee.html\n\nShow the codedata(epil,package = \"MASS\")\nOxboys |&gt; head(n=18)\n\n\n\n\nSubject\nage\nheight\nOccasion\n\n\n\n1\n-1.0000\n140.5\n1\n\n\n1\n-0.7479\n143.4\n2\n\n\n1\n-0.4630\n144.8\n3\n\n\n1\n-0.1643\n147.1\n4\n\n\n1\n-0.0027\n147.7\n5\n\n\n1\n0.2466\n150.2\n6\n\n\n1\n0.5562\n151.7\n7\n\n\n1\n0.7781\n153.3\n8\n\n\n1\n0.9945\n155.8\n9\n\n\n2\n-1.0000\n136.9\n1\n\n\n2\n-0.7479\n139.1\n2\n\n\n2\n-0.4630\n140.1\n3\n\n\n2\n-0.1643\n142.6\n4\n\n\n2\n-0.0027\n143.2\n5\n\n\n2\n0.2466\n144.0\n6\n\n\n2\n0.5562\n145.8\n7\n\n\n2\n0.7781\n146.8\n8\n\n\n2\n0.9945\n148.3\n9\n\n\n\n\n\nShow the code\n\ndf_long &lt;- Oxboys\n\n\n\nShow the codelibrary(gee)\n\ng1 &lt;- gee(height~age,data = df_long ,id = Subject,corstr = \"AR-M\",Mv = 1)\n#&gt; (Intercept)         age \n#&gt;  149.371801    6.521022\ng1\n#&gt; \n#&gt;  GEE:  GENERALIZED LINEAR MODELS FOR DEPENDENT DATA\n#&gt;  gee S-function, version 4.13 modified 98/01/27 (1998) \n#&gt; \n#&gt; Model:\n#&gt;  Link:                      Identity \n#&gt;  Variance to Mean Relation: Gaussian \n#&gt;  Correlation Structure:     AR-M , M = 1 \n#&gt; \n#&gt; Call:\n#&gt; gee(formula = height ~ age, id = Subject, data = df_long, corstr = \"AR-M\", \n#&gt;     Mv = 1)\n#&gt; \n#&gt; Number of observations :  234 \n#&gt; \n#&gt; Maximum cluster size   :  9 \n#&gt; \n#&gt; \n#&gt; Coefficients:\n#&gt; (Intercept)         age \n#&gt;  149.719096    6.547328 \n#&gt; \n#&gt; Estimated Scale Parameter:  65.41743\n#&gt; Number of Iterations:  2\n#&gt; \n#&gt; Working Correlation[1:4,1:4]\n#&gt;           [,1]      [,2]      [,3]      [,4]\n#&gt; [1,] 1.0000000 0.9892949 0.9787045 0.9682274\n#&gt; [2,] 0.9892949 1.0000000 0.9892949 0.9787045\n#&gt; [3,] 0.9787045 0.9892949 1.0000000 0.9892949\n#&gt; [4,] 0.9682274 0.9787045 0.9892949 1.0000000\n#&gt; \n#&gt; \n#&gt; Returned Error Value:\n#&gt; [1] 0\nsummary(g1)\n#&gt; \n#&gt;  GEE:  GENERALIZED LINEAR MODELS FOR DEPENDENT DATA\n#&gt;  gee S-function, version 4.13 modified 98/01/27 (1998) \n#&gt; \n#&gt; Model:\n#&gt;  Link:                      Identity \n#&gt;  Variance to Mean Relation: Gaussian \n#&gt;  Correlation Structure:     AR-M , M = 1 \n#&gt; \n#&gt; Call:\n#&gt; gee(formula = height ~ age, id = Subject, data = df_long, corstr = \"AR-M\", \n#&gt;     Mv = 1)\n#&gt; \n#&gt; Summary of Residuals:\n#&gt;         Min          1Q      Median          3Q         Max \n#&gt; -22.0304139  -5.4912438   0.1324571   4.3822174  18.5695861 \n#&gt; \n#&gt; \n#&gt; Coefficients:\n#&gt;               Estimate Naive S.E.  Naive z Robust S.E. Robust z\n#&gt; (Intercept) 149.719096  1.5531285 96.39840   1.5847569 94.47449\n#&gt; age           6.547328  0.3177873 20.60286   0.3042478 21.51972\n#&gt; \n#&gt; Estimated Scale Parameter:  65.41743\n#&gt; Number of Iterations:  2\n#&gt; \n#&gt; Working Correlation\n#&gt;            [,1]      [,2]      [,3]      [,4]      [,5]      [,6]      [,7]\n#&gt;  [1,] 1.0000000 0.9892949 0.9787045 0.9682274 0.9578625 0.9476085 0.9374643\n#&gt;  [2,] 0.9892949 1.0000000 0.9892949 0.9787045 0.9682274 0.9578625 0.9476085\n#&gt;  [3,] 0.9787045 0.9892949 1.0000000 0.9892949 0.9787045 0.9682274 0.9578625\n#&gt;  [4,] 0.9682274 0.9787045 0.9892949 1.0000000 0.9892949 0.9787045 0.9682274\n#&gt;  [5,] 0.9578625 0.9682274 0.9787045 0.9892949 1.0000000 0.9892949 0.9787045\n#&gt;  [6,] 0.9476085 0.9578625 0.9682274 0.9787045 0.9892949 1.0000000 0.9892949\n#&gt;  [7,] 0.9374643 0.9476085 0.9578625 0.9682274 0.9787045 0.9892949 1.0000000\n#&gt;  [8,] 0.9274287 0.9374643 0.9476085 0.9578625 0.9682274 0.9787045 0.9892949\n#&gt;  [9,] 0.9175005 0.9274287 0.9374643 0.9476085 0.9578625 0.9682274 0.9787045\n#&gt;            [,8]      [,9]\n#&gt;  [1,] 0.9274287 0.9175005\n#&gt;  [2,] 0.9374643 0.9274287\n#&gt;  [3,] 0.9476085 0.9374643\n#&gt;  [4,] 0.9578625 0.9476085\n#&gt;  [5,] 0.9682274 0.9578625\n#&gt;  [6,] 0.9787045 0.9682274\n#&gt;  [7,] 0.9892949 0.9787045\n#&gt;  [8,] 1.0000000 0.9892949\n#&gt;  [9,] 0.9892949 1.0000000\n\n\ngee1 &lt;- gee(y ~ age + trt + base,id=subject,data = epil,family = poisson,corstr =\"exchangeable\" )\n#&gt;  (Intercept)          age trtprogabide         base \n#&gt;   0.57304359   0.02234757  -0.15188049   0.02263524\nsummary(gee1)\n#&gt; \n#&gt;  GEE:  GENERALIZED LINEAR MODELS FOR DEPENDENT DATA\n#&gt;  gee S-function, version 4.13 modified 98/01/27 (1998) \n#&gt; \n#&gt; Model:\n#&gt;  Link:                      Logarithm \n#&gt;  Variance to Mean Relation: Poisson \n#&gt;  Correlation Structure:     Exchangeable \n#&gt; \n#&gt; Call:\n#&gt; gee(formula = y ~ age + trt + base, id = subject, data = epil, \n#&gt;     family = poisson, corstr = \"exchangeable\")\n#&gt; \n#&gt; Summary of Residuals:\n#&gt;        Min         1Q     Median         3Q        Max \n#&gt; -15.742906  -3.318756  -1.186874   1.295122  63.957902 \n#&gt; \n#&gt; \n#&gt; Coefficients:\n#&gt;                 Estimate  Naive S.E.   Naive z Robust S.E.   Robust z\n#&gt; (Intercept)   0.57304359 0.451797966  1.268362 0.360726141  1.5885835\n#&gt; age           0.02234757 0.013412798  1.666138 0.011400956  1.9601489\n#&gt; trtprogabide -0.15188049 0.159304397 -0.953398 0.171051111 -0.8879246\n#&gt; base          0.02263524 0.001696439 13.342795 0.001226748 18.4514092\n#&gt; \n#&gt; Estimated Scale Parameter:  5.087384\n#&gt; Number of Iterations:  1\n#&gt; \n#&gt; Working Correlation\n#&gt;           [,1]      [,2]      [,3]      [,4]\n#&gt; [1,] 1.0000000 0.3933815 0.3933815 0.3933815\n#&gt; [2,] 0.3933815 1.0000000 0.3933815 0.3933815\n#&gt; [3,] 0.3933815 0.3933815 1.0000000 0.3933815\n#&gt; [4,] 0.3933815 0.3933815 0.3933815 1.0000000",
    "crumbs": [
      "推断统计模型",
      "<span class='chapter-number'>20</span>  <span class='chapter-title'>广义估计方程</span>"
    ]
  },
  {
    "objectID": "GEE.html#geepack",
    "href": "GEE.html#geepack",
    "title": "\n20  广义估计方程\n",
    "section": "\n20.7 geepack\n",
    "text": "20.7 geepack\n\n\nShow the codelibrary(geepack)\n\nrfb_gee &lt;- geeglm(richness ~ offset(log_AREA) +SPTREAT + DEPTH +DEPTH2,\n            family = poisson(link = \"log\"),\n            data = rfb,\n            id=FIELD,\n            corstr = \"ar1\")\n\nsummary(rfb_gee)\n#&gt; \n#&gt; Call:\n#&gt; geeglm(formula = richness ~ offset(log_AREA) + SPTREAT + DEPTH + \n#&gt;     DEPTH2, family = poisson(link = \"log\"), data = rfb, id = FIELD, \n#&gt;     corstr = \"ar1\")\n#&gt; \n#&gt;  Coefficients:\n#&gt;                Estimate    Std.err  Wald Pr(&gt;|W|)   \n#&gt; (Intercept)  -0.6782034  0.2610088 6.752  0.00937 **\n#&gt; SPTREATrlfld -0.5223137  0.2287644 5.213  0.02242 * \n#&gt; DEPTH         0.0498238  0.0193149 6.654  0.00989 **\n#&gt; DEPTH2       -0.0011411  0.0004908 5.406  0.02007 * \n#&gt; ---\n#&gt; Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n#&gt; \n#&gt; Correlation structure = ar1 \n#&gt; Estimated Scale Parameters:\n#&gt; \n#&gt;             Estimate Std.err\n#&gt; (Intercept)    2.334  0.2927\n#&gt;   Link = identity \n#&gt; \n#&gt; Estimated Correlation Parameters:\n#&gt;       Estimate Std.err\n#&gt; alpha   0.4215 0.09034\n#&gt; Number of clusters:   11  Maximum cluster size: 10\nrfb_gee2 &lt;- geeglm(richness ~ offset(log_AREA) +SPTREAT ,\n            family = poisson(link = \"log\"),\n            data = rfb,\n            id=FIELD,\n            corstr = \"ar1\")\n\n# Wald's Test\nanova(rfb_gee,rfb_gee2)\n\n\n\n\nDf\nX2\nP(&gt;|Chi|)\n\n\n2\n6.885\n0.032\n\n\n\n\n\n\\[\nE(Y_{is})=\\mu_{is}=e^{-0.678+0.0498×DEPTH-0.001×DEPTH^2-0.522×SPTREAT_{is}}\\\\\nvar(Y_{is})= 2.33 × \\mu_{is} \\\\\ncor(Y_{is},Y_{it})=0.422^{|s-t|}\n\\]\n作业相关矩阵 corstr ，比较QIC，一般越小越好。\n\nShow the codeQIC(rfb_gee)\n#&gt;       QIC      QICu Quasi Lik       CIC    params      QICC \n#&gt;  -467.536  -471.921   239.961     6.193     4.000  -455.536\nQIC(rfb_gee2)\n#&gt;       QIC      QICu Quasi Lik       CIC    params      QICC \n#&gt;  -451.065  -457.436   230.718     5.185     2.000  -447.637\n\n\n\n20.7.1 示例\n\nShow the codedf &lt;- read_delim(\"data/麻醉诱导时相.txt\")\ndf_long &lt;- df |&gt; pivot_longer(\n    cols = starts_with(\"t\"),\n    names_to = \"time\",\n    values_to = \"SBP\"\n)\n\n\n\nShow the codeg3 &lt;- geeglm(SBP~ group * time,data = df_long ,id = id,corstr = \"ar1\")\n\ng3\n#&gt; \n#&gt; Call:\n#&gt; geeglm(formula = SBP ~ group * time, data = df_long, id = id, \n#&gt;     corstr = \"ar1\")\n#&gt; \n#&gt; Coefficients:\n#&gt;   (Intercept)        groupB        groupC        timet1        timet2 \n#&gt;         121.0           0.2           5.2          -8.6          -2.6 \n#&gt;        timet3        timet4 groupB:timet1 groupC:timet1 groupB:timet2 \n#&gt;           4.8          -0.2           7.2           5.4          -0.6 \n#&gt; groupC:timet2 groupB:timet3 groupC:timet3 groupB:timet4 groupC:timet4 \n#&gt;          -5.0           2.2          11.6          14.2           4.6 \n#&gt; \n#&gt; Degrees of Freedom: 75 Total (i.e. Null);  60 Residual\n#&gt; \n#&gt; Scale Link:                   identity\n#&gt; Estimated Scale Parameters:  [1] 16.13\n#&gt; \n#&gt; Correlation:  Structure = ar1    Link = identity \n#&gt; Estimated Correlation Parameters:\n#&gt;  alpha \n#&gt; 0.8464 \n#&gt; \n#&gt; Number of clusters:   15   Maximum cluster size: 5\nsummary(g3)\n#&gt; \n#&gt; Call:\n#&gt; geeglm(formula = SBP ~ group * time, data = df_long, id = id, \n#&gt;     corstr = \"ar1\")\n#&gt; \n#&gt;  Coefficients:\n#&gt;               Estimate Std.err    Wald Pr(&gt;|W|)    \n#&gt; (Intercept)    121.000   1.414 7320.50  &lt; 2e-16 ***\n#&gt; groupB           0.200   2.234    0.01  0.92867    \n#&gt; groupC           5.200   2.028    6.58  0.01034 *  \n#&gt; timet1          -8.600   0.921   87.22  &lt; 2e-16 ***\n#&gt; timet2          -2.600   1.315    3.91  0.04794 *  \n#&gt; timet3           4.800   1.180   16.55  4.7e-05 ***\n#&gt; timet4          -0.200   1.213    0.03  0.86907    \n#&gt; groupB:timet1    7.200   1.173   37.67  8.4e-10 ***\n#&gt; groupC:timet1    5.400   2.191    6.08  0.01371 *  \n#&gt; groupB:timet2   -0.600   1.470    0.17  0.68309    \n#&gt; groupC:timet2   -5.000   1.943    6.62  0.01008 *  \n#&gt; groupB:timet3    2.200   1.397    2.48  0.11534    \n#&gt; groupC:timet3   11.600   3.098   14.02  0.00018 ***\n#&gt; groupB:timet4   14.200   1.425   99.23  &lt; 2e-16 ***\n#&gt; groupC:timet4    4.600   2.498    3.39  0.06555 .  \n#&gt; ---\n#&gt; Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n#&gt; \n#&gt; Correlation structure = ar1 \n#&gt; Estimated Scale Parameters:\n#&gt; \n#&gt;             Estimate Std.err\n#&gt; (Intercept)     16.1    4.44\n#&gt;   Link = identity \n#&gt; \n#&gt; Estimated Correlation Parameters:\n#&gt;       Estimate Std.err\n#&gt; alpha    0.846  0.0661\n#&gt; Number of clusters:   15  Maximum cluster size: 5\nQIC(g3)\n#&gt;       QIC      QICu Quasi Lik       CIC    params      QICC \n#&gt;      1240      1240      -605        15        15       968",
    "crumbs": [
      "推断统计模型",
      "<span class='chapter-number'>20</span>  <span class='chapter-title'>广义估计方程</span>"
    ]
  },
  {
    "objectID": "SurvivalAnalysis.html",
    "href": "SurvivalAnalysis.html",
    "title": "\n21  生存分析\n",
    "section": "",
    "text": "21.1 生存函数\n\\[\nS(t)=P(T&gt;t)=1-F(t)=\\int_{t}^{+\\infty}f(x)dx\n\\]\n其中S(t)是累计生存概率或生存率，量化了生存时间大于t的概率。f(x)是密度函数，呈右偏态分布，反映了任意时间点 t 终点事件的瞬时发生率。F(t)=P(T&lt;t)是f(t)在区间[0,t]的累计形式，也称为分布函数或累积函数。",
    "crumbs": [
      "生存分析",
      "<span class='chapter-number'>21</span>  <span class='chapter-title'>生存分析</span>"
    ]
  },
  {
    "objectID": "SurvivalAnalysis.html#风险函数",
    "href": "SurvivalAnalysis.html#风险函数",
    "title": "\n21  生存分析\n",
    "section": "\n21.2 风险函数",
    "text": "21.2 风险函数\n\\[\n\\begin{aligned}\nh(t)=&\\lim_{\\Delta t\\to 0}\\frac{P(t\\le T&lt;t+\\Delta t|T\\ge t)}{\\Delta t}\\\\\n=&\\lim_{\\Delta t\\to 0}\\frac{P(t\\le T&lt;t+\\Delta t\\ \\&\\ T\\ge t)}{\\Delta t·P(T\\ge t) }\\\\\n=&\\lim_{\\Delta t\\to 0}\\frac{S(t)- S(t+\\Delta t)}{\\Delta t·S(t)}\\\\\n=&-\\frac{d(\\ln S(t))}{dt}\n\\end{aligned}\n\\]\n\\[S(t)=e^{-\\int_0^t h(u)du} \\]\n\\[\n\\begin{aligned}\nh(t)\\Delta t=&P(t\\le T&lt;t+\\Delta t|T\\ge t)\n=\\frac{P(t\\le T&lt;t+\\Delta t\\ \\&\\ T\\ge t)}{P(T\\ge t) }\\\\\n=&\\frac{P(t\\le T&lt;t+\\Delta t)}{P(T\\ge t) }\\\\\n=&\\frac{f(t)\\Delta t}{S(t)}\n\\end{aligned}\n\\]\n\\(f(t)=h(t)S(t)\\)",
    "crumbs": [
      "生存分析",
      "<span class='chapter-number'>21</span>  <span class='chapter-title'>生存分析</span>"
    ]
  },
  {
    "objectID": "SurvivalAnalysis.html#乘积极限法",
    "href": "SurvivalAnalysis.html#乘积极限法",
    "title": "\n21  生存分析\n",
    "section": "\n21.3 乘积极限法",
    "text": "21.3 乘积极限法\nproduct limit method 也称为Kaplan-Meier 法。\n\\(t_1&lt;t_2&lt;t_3&lt;...&lt;t_n\\)，样本量大小n，ti 代表个体i发生终点事件或右删失的时间。由于一些个体有相同的生存时间，它们被称为 tied 观测时间，生存时间的个数小于样本量n。\n\n21.3.1 点估计S(t)\n\\(n_1&gt;n_2&gt;n_3&gt;...&gt;n_n\\) ,ni d代表在时间点ti 暴露于特定事件风险的幸存者数量。\n\\(d_i\\) 代表在时间点ti 发生终点事件的数量。（如果没有 tie，di=1或0）\n生存率的KM估计计算公式：\n\\[\n\\hat S(t)=\\prod_{t_i\\le t}\\frac{n_i-d_i}{n_i}\n\\tag{21.1}\\]\nEquation 21.1 包括了删失情况，如果从ti-1 到ti 发生了删失，但没有终点事件，di =0，条件概率等于1。\n\n21.3.2 区间估计S(t)\n(1-α)×100% CI \\([\\hat S(t)-z_{1-\\alpha/2}\\sqrt{Var\\left [\\hat S(t)  \\right]},\\hat S(t)+z_{1-\\alpha/2}\\sqrt{Var\\left [\\hat S(t)  \\right]}]\\)\n其中\\(Var\\left [\\hat S(t)  \\right]=\\hat S(t)^2\\sum_{t_i\\le t}\\frac{d_i}{n_i(n_i-d_i)}\\) (Greenwood method )\n\nCodedf_raw &lt;- tibble(\n    id=1:5,\n    sex=factor(c(\"Male\",\"Male\",\"Female\",\"Male\",\"Female\")),\n    age_years=c(53,62,75,73,61),\n    outcome=c(\"Loss to follow-up\",\"Death\",\"Death\",\"Relapse\",\"Survival\"),\n    time=c(\"37.5+\",44.3,25.3,18.1,\"56.7+\")\n)\ndf &lt;- df_raw |&gt; arrange(time) |&gt; select(id,outcome,time) |&gt; \n    mutate(\n        d_i=if_else(outcome==\"Relapse\"|outcome==\"Death\",1,0),\n        time=parse_number(time),\n    )\ndf\n\n\n\n\nid\noutcome\ntime\nd_i\n\n\n\n4\nRelapse\n18.1\n1\n\n\n3\nDeath\n25.3\n1\n\n\n1\nLoss to follow-up\n37.5\n0\n\n\n2\nDeath\n44.3\n1\n\n\n5\nSurvival\n56.7\n0\n\n\n\n\n\nCode\nlibrary(survminer)\nlibrary(survival)\n\nkm_fit&lt;-survfit(Surv(time,d_i)~1,data=df)\n# t_i\nkm_fit$time\n#&gt; [1] 18.1 25.3 37.5 44.3 56.7\n# d_i\nkm_fit$n.event\n#&gt; [1] 1 1 0 1 0\n# cnesored\nkm_fit$n.censor\n#&gt; [1] 0 0 1 0 1\n# n_i\nkm_fit$n.risk\n#&gt; [1] 5 4 3 2 1\n\n# 生存率\nkm_fit$surv\n#&gt; [1] 0.8 0.6 0.6 0.3 0.3\n\nsummary(km_fit)\n#&gt; Call: survfit(formula = Surv(time, d_i) ~ 1, data = df)\n#&gt; \n#&gt;  time n.risk n.event survival std.err lower 95% CI upper 95% CI\n#&gt;  18.1      5       1      0.8   0.179       0.5161            1\n#&gt;  25.3      4       1      0.6   0.219       0.2933            1\n#&gt;  44.3      2       1      0.3   0.239       0.0631            1",
    "crumbs": [
      "生存分析",
      "<span class='chapter-number'>21</span>  <span class='chapter-title'>生存分析</span>"
    ]
  },
  {
    "objectID": "SurvivalAnalysis.html#单因素分组生存曲线的比较",
    "href": "SurvivalAnalysis.html#单因素分组生存曲线的比较",
    "title": "\n21  生存分析\n",
    "section": "\n21.4 单因素分组生存曲线的比较",
    "text": "21.4 单因素分组生存曲线的比较\n\n\n检验方法\n权重\n\n\n\nlog-rank test\n1\n\n\nWilcoxon test\nnj\n\n\n\nTarone-Ware test\n\\(\\sqrt{n_j}\\)\n\n\nPeto test\n\\(\\hat S(t_j)\\)\n\n\n\n\\[\n\\chi^2=\\frac{\\left(\\sum_jw(t_j)(m_{ij}-e_{ij})\\right)^2}{\\hat {Var}\\left(\\sum_jw(t_j)(m_{ij}-e_{ij})\\right)}\n\\]\n\n21.4.1 log-rank test\n\nH0 :两总体的生存曲线是相同的。\n\n计算当第j次发生终点事件各组终点事件的期望值（e1j ,e2j ）\n\\(e_{1j}=\\left ( \\frac{n_{1j}}{n_{1j}+n_{2j}}\\right)\\times (m_{1j}+m_{2j})\\)\n\\(e_{2j}=\\left ( \\frac{n_{2j}}{n_{1j}+n_{2j}}\\right)\\times (m_{1j}+m_{2j})\\)\n其中mij 表示在第 j 个时间点第 i 组终点事件的数量，nij 表示在第 j 个时间点第 i 组初始观测的数量\n\n\n对所有时间点对终点事件的观测值和期望值的差异求和\n\\(O_i-Ei=\\sum_j(m_{ij}-e_{ij})\\ \\ \\ (i=1,2)\\)\n计算其方差估计值\n\\(\\hat{Var}=\\sum_j\\frac{n_{1j}n_{2j}(m_{1j}+m_{2j})(n_{1j}+n_{2j}-m_{1j}-m_{2j})}{(n_{1j}+n_{2j})^2(n_{1j}+n_{2j}-1)}\\ \\ \\ (i=1,2)\\)\n\n\n计算log-rank test 的检验统计量\n\\[\n\\chi^2=\\frac{(O_1-E_1)^2}{\\hat{Var}(O_1-E_1)} \\ 或者 \\ \\chi^2=\\frac{(O_2-E_2)^2}{\\hat{Var}(O_2-E_2)}\n\\]\n也可以近似估计为\n\\[\n\\chi^2=\\sum_{i=1}^2\\frac{(O_i-E_i)^2}{E_i} \\sim \\chi^2(\\nu=1)\n\\]\n\n\n\nCodedf &lt;- read_csv(\"data/log-rank-survival.csv\")\n\n# 使用 Kaplan-Meier 方法创建一个Surv对象\nsurv_formula &lt;- Surv(Days,status)~treatment\n\nkm&lt;-survfit(surv_formula,data=df)\nsummary(km)\n#&gt; Call: survfit(formula = surv_formula, data = df)\n#&gt; \n#&gt;                 treatment=CON \n#&gt;  time n.risk n.event survival std.err lower 95% CI upper 95% CI\n#&gt;    11     14       1   0.9286  0.0688       0.8030        1.000\n#&gt;    13     13       1   0.8571  0.0935       0.6921        1.000\n#&gt;    14     12       2   0.7143  0.1207       0.5129        0.995\n#&gt;    15     10       1   0.6429  0.1281       0.4351        0.950\n#&gt;    17      9       3   0.4286  0.1323       0.2341        0.785\n#&gt;    20      6       2   0.2857  0.1207       0.1248        0.654\n#&gt;    21      4       2   0.1429  0.0935       0.0396        0.515\n#&gt;    25      2       1   0.0714  0.0688       0.0108        0.472\n#&gt;    27      1       1   0.0000     NaN           NA           NA\n#&gt; \n#&gt;                 treatment=DPVB \n#&gt;  time n.risk n.event survival std.err lower 95% CI upper 95% CI\n#&gt;    20     14       1    0.929  0.0688        0.803        1.000\n#&gt;    23     13       1    0.857  0.0935        0.692        1.000\n#&gt;    27     12       1    0.786  0.1097        0.598        1.000\n#&gt;    28     11       1    0.714  0.1207        0.513        0.995\n#&gt;    30     10       1    0.643  0.1281        0.435        0.950\n#&gt;    32      9       1    0.571  0.1323        0.363        0.899\n#&gt;    38      8       1    0.500  0.1336        0.296        0.844\n#&gt;    39      7       1    0.429  0.1323        0.234        0.785\n#&gt;    45      6       1    0.357  0.1281        0.177        0.721\n#&gt; \n#&gt;                 treatment=LDRT \n#&gt;  time n.risk n.event survival std.err lower 95% CI upper 95% CI\n#&gt;    13     14       2   0.8571  0.0935       0.6921        1.000\n#&gt;    15     12       1   0.7857  0.1097       0.5977        1.000\n#&gt;    16     11       1   0.7143  0.1207       0.5129        0.995\n#&gt;    18     10       1   0.6429  0.1281       0.4351        0.950\n#&gt;    19      9       2   0.5000  0.1336       0.2961        0.844\n#&gt;    20      7       3   0.2857  0.1207       0.1248        0.654\n#&gt;    24      4       1   0.2143  0.1097       0.0786        0.584\n#&gt;    25      3       1   0.1429  0.0935       0.0396        0.515\n#&gt;    27      2       1   0.0714  0.0688       0.0108        0.472\n#&gt;    30      1       1   0.0000     NaN           NA           NA\n#&gt; \n#&gt;                 treatment=LR_DPVB \n#&gt;  time n.risk n.event survival std.err lower 95% CI upper 95% CI\n#&gt;    30     14       1    0.929  0.0688        0.803            1\n#&gt;    40     13       1    0.857  0.0935        0.692            1\n\n# 执行Log-rank检验\nlogrank_test &lt;- survdiff(surv_formula,data = df,subset = T,na.action = \"na.omit\")\nlogrank_test$chisq\n#&gt; [1] 58.43627\nlogrank_test$pvalue\n#&gt; [1] 1.268397e-12",
    "crumbs": [
      "生存分析",
      "<span class='chapter-number'>21</span>  <span class='chapter-title'>生存分析</span>"
    ]
  },
  {
    "objectID": "CoxProportionalHazardsModel.html",
    "href": "CoxProportionalHazardsModel.html",
    "title": "\n22  Cox比例风险模型\n",
    "section": "",
    "text": "22.1 风险函数\n\\[\n\\begin{aligned} h(t)=&\\lim_{\\Delta t\\to 0}\\frac{P(t\\le T&lt;t+\\Delta t|T\\ge t)}{\\Delta t}\\\\ =&\\lim_{\\Delta t\\to 0}\\frac{P(t\\le T&lt;t+\\Delta t\\ \\&\\ T\\ge t)}{\\Delta t·P(T\\ge t) }\\\\ =&\\lim_{\\Delta t\\to 0}\\frac{S(t)- S(t+\\Delta t)}{\\Delta t·S(t)}\\\\ =&-\\frac{d(\\ln S(t))}{dt} \\end{aligned}\n\\]",
    "crumbs": [
      "生存分析",
      "<span class='chapter-number'>22</span>  <span class='chapter-title'>Cox比例风险模型</span>"
    ]
  },
  {
    "objectID": "CoxProportionalHazardsModel.html#风险率",
    "href": "CoxProportionalHazardsModel.html#风险率",
    "title": "\n22  Cox比例风险模型\n",
    "section": "\n22.2 风险率",
    "text": "22.2 风险率\n对于有风险因子\\(x_1,x_2,...,x_k\\) 的个体在时间 t 的风险率\\(h(t|x_1,x_2,...,x_k)\\)\n\\[ h(t|x_1,x_2,...,x_k)=h_0(t)g(x_1,x_2,...,x_k)=h_0(t)exp(\\sum_{j=1}^k\\beta_jx_j) \\]\n其中\n\n\\(h0 (t)\\)是给定所有风险因子（协变量）为零的随时间变化的基线风险函数。\n\\(g(X)\\)是k个独立风险因子的集合函数，代表变量的风险效应。\n\\(β_j\\)是部分回归系数，表示风险比的比例变化。",
    "crumbs": [
      "生存分析",
      "<span class='chapter-number'>22</span>  <span class='chapter-title'>Cox比例风险模型</span>"
    ]
  },
  {
    "objectID": "CoxProportionalHazardsModel.html#比例风险假设",
    "href": "CoxProportionalHazardsModel.html#比例风险假设",
    "title": "\n22  Cox比例风险模型\n",
    "section": "\n22.3 比例风险假设",
    "text": "22.3 比例风险假设\n（proportional hazards assumption）\n\\[ \\frac{h(t)}{h_0(t)}=exp(\\sum_{j=1}^k\\beta_jx_j) \\]",
    "crumbs": [
      "生存分析",
      "<span class='chapter-number'>22</span>  <span class='chapter-title'>Cox比例风险模型</span>"
    ]
  },
  {
    "objectID": "CoxProportionalHazardsModel.html#风险比hazard-ratio",
    "href": "CoxProportionalHazardsModel.html#风险比hazard-ratio",
    "title": "\n22  Cox比例风险模型\n",
    "section": "\n22.4 风险比（hazard ratio）",
    "text": "22.4 风险比（hazard ratio）\n假设有两个个体，分别具有独立变量，两个个体的风险函数之比称为风险比\n\\[ HR=\\frac{h(t|x_1,x_2,...,x_k)}{h(t|x_1^*,x_2^*,...,x_k^*)}=exp(\\sum_{j=1}^k\\beta_j(x_j-x_j^*)) \\]\n\nCodedf &lt;- read_csv(\"data/log-rank-survival.csv\")\n\n\nlibrary(survminer)\nlibrary(survival)\n# 使用 Kaplan-Meier 方法创建一个Surv对象\nsurv_formula &lt;- Surv(Days,status)~treatment\n\n# 拟合Cox比例风险模型 \ncox_model &lt;- coxph(surv_formula, data = df)  \n# 查看模型结果 \nsummary(cox_model)  \n#&gt; Call:\n#&gt; coxph(formula = surv_formula, data = df)\n#&gt; \n#&gt;   n= 56, number of events= 39 \n#&gt; \n#&gt;                       coef exp(coef)  se(coef)      z Pr(&gt;|z|)    \n#&gt; treatmentDPVB    -2.740141  0.064561  0.580664 -4.719 2.37e-06 ***\n#&gt; treatmentLDRT    -0.383558  0.681432  0.387499 -0.990    0.322    \n#&gt; treatmentLR_DPVB -4.632850  0.009727  0.878661 -5.273 1.34e-07 ***\n#&gt; ---\n#&gt; Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n#&gt; \n#&gt;                  exp(coef) exp(-coef) lower .95 upper .95\n#&gt; treatmentDPVB     0.064561     15.489  0.020688   0.20148\n#&gt; treatmentLDRT     0.681432      1.467  0.318848   1.45634\n#&gt; treatmentLR_DPVB  0.009727    102.807  0.001738   0.05444\n#&gt; \n#&gt; Concordance= 0.822  (se = 0.025 )\n#&gt; Likelihood ratio test= 61.41  on 3 df,   p=3e-13\n#&gt; Wald test            = 36.01  on 3 df,   p=7e-08\n#&gt; Score (logrank) test = 60.47  on 3 df,   p=5e-13\n# 检查比例风险假设 \ncox.zph(cox_model)\n#&gt;           chisq df    p\n#&gt; treatment 0.833  3 0.84\n#&gt; GLOBAL    0.833  3 0.84\n\n\n\n22.4.1 模型系数的估计\n条件死亡概率和局部似然函数方法\n\\[ \\ln L_p(\\beta)=\\sum_{i=1}^{d}\\left[ \\sum_{j=1}^k\\beta_jx_{ij}-\\ln\\sum_{m\\in R_i}exp( \\sum_{j=1}^k\\beta_jx_{mj})         \\right] \\]\nNewton-Raphson iterative method\n\\[  \\begin{cases}  \\frac{\\partial \\ln L_p(\\beta)}{\\partial \\beta_1}=0\\\\ \\frac{\\partial \\ln L_p(\\beta)}{\\partial \\beta_2}=0\\\\ \\vdots\\\\ \\frac{\\partial \\ln L_p(\\beta)}{\\partial \\beta_k}=0\\\\ \\end{cases} \\]\n\n22.4.2 模型系数的假设检验\n\n\nWald‘s test\n检验是否有独立变量需要被消除，统计量\\(Z=b_j/S_{b_j}\\)\n当样本量足够大时，Z服从标准正态分布，Z2 服从自由度为1 的\\(\\chi^2\\) 分布\n\\[ \\chi^2_W=(b_j/S_{b_j})^2\\sim \\chi^2(1) \\]\n\n\nPartial likelihood Ratio test\n主要用于非显著性变量的消除，新变量的引入和模型的比较。\n\\[ \\chi^2_{LR}=2\\left[ \\ln L_p(\\beta_k)-\\ln L_p(\\beta_{k-1}) \\right]\\sim\\chi^2(1) \\]\n其中分别是包含 k 个和 k-1 个（不包含要检验的第 j 个变量）独立变量的对数局部似然函数",
    "crumbs": [
      "生存分析",
      "<span class='chapter-number'>22</span>  <span class='chapter-title'>Cox比例风险模型</span>"
    ]
  },
  {
    "objectID": "PropensityScore.html",
    "href": "PropensityScore.html",
    "title": "倾向性评分",
    "section": "",
    "text": "加权（Weighting）\n……",
    "crumbs": [
      "倾向性评分"
    ]
  },
  {
    "objectID": "PropensityScore.html#回归",
    "href": "PropensityScore.html#回归",
    "title": "倾向性评分",
    "section": "回归",
    "text": "回归\n……",
    "crumbs": [
      "倾向性评分"
    ]
  },
  {
    "objectID": "PropensityScore.html#psapsa_shiny",
    "href": "PropensityScore.html#psapsa_shiny",
    "title": "倾向性评分",
    "section": "psa::psa_shiny()",
    "text": "psa::psa_shiny()\n\nShow the codepsa::psa_shiny()",
    "crumbs": [
      "倾向性评分"
    ]
  },
  {
    "objectID": "stratification.html",
    "href": "stratification.html",
    "title": "\n23  分层（Stratification）\n",
    "section": "",
    "text": "23.1 估计倾向得分（逻辑回归）\nCodedata(lalonde, package='Matching')\nglimpse(lalonde)\n#&gt; Rows: 445\n#&gt; Columns: 12\n#&gt; $ age     &lt;int&gt; 37, 22, 30, 27, 33, 22, 23, 32, 22, 33, 19, 21, 18, 27, 17, 19…\n#&gt; $ educ    &lt;int&gt; 11, 9, 12, 11, 8, 9, 12, 11, 16, 12, 9, 13, 8, 10, 7, 10, 13, …\n#&gt; $ black   &lt;int&gt; 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,…\n#&gt; $ hisp    &lt;int&gt; 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,…\n#&gt; $ married &lt;int&gt; 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0,…\n#&gt; $ nodegr  &lt;int&gt; 1, 1, 0, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1, 0, 1, 0, 0, 1,…\n#&gt; $ re74    &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,…\n#&gt; $ re75    &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,…\n#&gt; $ re78    &lt;dbl&gt; 9930.05, 3595.89, 24909.50, 7506.15, 289.79, 4056.49, 0.00, 84…\n#&gt; $ u74     &lt;int&gt; 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,…\n#&gt; $ u75     &lt;int&gt; 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,…\n#&gt; $ treat   &lt;int&gt; 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,…\n\nlalonde_formu &lt;- treat ~ age + I(age^2) + educ + I(educ^2) + black +\n    hisp + married + nodegr + re74  + I(re74^2) + re75 + I(re75^2)\nlr_out &lt;- glm(formula = lalonde_formu,\n              data = lalonde,\n              family = binomial(link = 'logit'))\n倾向性得分就是模型的拟合值，检查倾向得分的分布，以确保我们有良好的重叠\nCodelalonde$lr_ps &lt;- fitted(lr_out)\n\nggplot(lalonde, aes(x = lr_ps, color = as.logical(treat))) + \n    geom_density() +\n    xlab('Propensity Score')",
    "crumbs": [
      "倾向性评分",
      "<span class='chapter-number'>23</span>  <span class='chapter-title'>分层（Stratification）</span>"
    ]
  },
  {
    "objectID": "stratification.html#估计倾向得分逻辑回归",
    "href": "stratification.html#估计倾向得分逻辑回归",
    "title": "\n23  分层（Stratification）\n",
    "section": "",
    "text": "23.1.1 分层\n根据倾向分数使用五分位数进行分层\n\nCodebreaks5 &lt;- psa::get_strata_breaks(lalonde$lr_ps)\nstr(breaks5)\n#&gt; List of 2\n#&gt;  $ breaks: Named num [1:6] 0.0849 0.3403 0.3594 0.408 0.5112 ...\n#&gt;   ..- attr(*, \"names\")= chr [1:6] \"0%\" \"20%\" \"40%\" \"60%\" ...\n#&gt;  $ labels:'data.frame':  5 obs. of  4 variables:\n#&gt;   ..$ strata: chr [1:5] \"A\" \"B\" \"C\" \"D\" ...\n#&gt;   ..$ xmin  : num [1:5] 0.0849 0.3403 0.3594 0.408 0.5112\n#&gt;   ..$ xmax  : num [1:5] 0.34 0.359 0.408 0.511 0.83\n#&gt;   ..$ xmid  : num [1:5] 0.213 0.35 0.384 0.46 0.671\n\nlalonde$lr_strata5 &lt;- cut(x = lalonde$lr_ps, \n                          breaks = breaks5$breaks, \n                          include.lowest = TRUE, \n                          labels = breaks5$labels$strata)\ntable(lalonde$treat, lalonde$lr_strata5)\n#&gt;    \n#&gt;      A  B  C  D  E\n#&gt;   0 66 61 51 42 40\n#&gt;   1 23 28 38 47 49\n\n\n\nCodeggplot(lalonde, aes(x = lr_ps, color = as.logical(treat))) + \n    geom_density(aes(fill = as.logical(treat)), alpha = 0.2) +\n    geom_vline(xintercept = breaks5$breaks, alpha = 0.5) +\n    geom_text(data = breaks5$labels, \n              aes(x = xmid, y = 0, label = strata),\n              color = 'black', vjust = 1) +\n    xlab('Propensity Score') + ylab('Density') +\n    xlim(c(0, 1))\n\n\n\n\n\n\n\n\nCodeggplot() +\n    geom_vline(xintercept = breaks5$breaks) +\n    geom_point(data = lalonde, aes(x = lr_ps, y = log(re78 + 1), color = as.logical(treat)), alpha = 0.5) +\n    geom_text(data = breaks5$labels, aes(x = xmid, y = 0, label = strata), color = 'black', vjust = 1) +\n    xlab('Propensity Score')\n\n\n\n\n\n\n\n\n23.1.2 查看平衡混杂效应\n\nCodecovars &lt;- all.vars(lalonde_formu)\ncovars &lt;- lalonde[,covars[-1]]\nPSAgraphics::cv.bal.psa(covariates = covars, \n                        treatment = lalonde$treat,\n                        propensity = lalonde$lr_ps,\n                        strata = lalonde$lr_strata)\n\n\n\n\n\n\n\n\n23.1.2.1 数值变量的协变量平衡图\n\nCodePSAgraphics::box.psa(continuous = lalonde$age, \n                     treatment = lalonde$treat, \n                     strata = lalonde$lr_strata,\n                     xlab = \"Strata\", \n                     balance = FALSE,\n                     main = 'Covariate: age')\n\n\n\n\n\n\n\n\n23.1.2.2 分类变量的协变量平衡图\n\nCodePSAgraphics::cat.psa(categorical = lalonde$nodegr, \n                     treatment = lalonde$treat, \n                     strata = lalonde$lr_strata, \n                     xlab = 'Strata',\n                     balance = FALSE,\n                     main = 'Covariate: nodegr')\n\n\n\n\n\n\n#&gt; $`treatment:stratum.proportions`\n#&gt;   0:A 1:A 0:B   1:B   0:C 1:C   0:D   1:D   0:E   1:E\n#&gt; 0   0   0   0 0.036 0.039   0 0.333 0.383 0.675 0.714\n#&gt; 1   1   1   1 0.964 0.961   1 0.667 0.617 0.325 0.286",
    "crumbs": [
      "倾向性评分",
      "<span class='chapter-number'>23</span>  <span class='chapter-title'>分层（Stratification）</span>"
    ]
  },
  {
    "objectID": "stratification.html#估计因果效应",
    "href": "stratification.html#估计因果效应",
    "title": "\n23  分层（Stratification）\n",
    "section": "\n23.2 估计因果效应",
    "text": "23.2 估计因果效应\n\nCodePSAgraphics::loess.psa(response = log(lalonde$re78 + 1),\n                       treatment = lalonde$treat,\n                       propensity = lalonde$lr_ps)\n\n\n\n\n\n\n#&gt; $ATE\n#&gt; [1] 0.9008386\n#&gt; \n#&gt; $se.wtd\n#&gt; [1] 0.3913399\n#&gt; \n#&gt; $CI95\n#&gt; [1] 0.1181588 1.6835185\n#&gt; \n#&gt; $summary.strata\n#&gt;    counts.0 counts.1  means.0  means.1 diff.means\n#&gt; 1        34       11 6.268705 6.474912  0.2062076\n#&gt; 2        32       12 5.491717 5.659280  0.1675631\n#&gt; 3        31       14 5.467712 5.703584  0.2358722\n#&gt; 4        30       14 5.425593 5.747613  0.3220194\n#&gt; 5        27       18 5.397146 5.831117  0.4339703\n#&gt; 6        24       20 5.302660 6.339721  1.0370619\n#&gt; 7        21       23 5.125331 6.607936  1.4826043\n#&gt; 8        21       24 5.036908 6.594808  1.5578999\n#&gt; 9        22       22 5.182703 6.981383  1.7986801\n#&gt; 10       18       27 6.047529 7.820786  1.7732573\n\npsa::loess_plot(ps = lalonde$lr_ps,\n                outcome = log(lalonde$re78 + 1),\n                treatment = lalonde$treat == 1,\n                outcomeTitle = 'log(re78)',\n                \n                plot.strata = 5,\n                points.treat.alpha = 0.5,\n                points.control.alpha = 0.5,\n                percentPoints.treat = 1,\n                percentPoints.control = 1,\n                se = FALSE, \n                method = 'loess')\n\n\n\n\n\n\n\n\nCodePSAgraphics::circ.psa(response = log(lalonde$re78 + 1), \n                      treatment = lalonde$treat == 1, \n                      strata = lalonde$lr_strata5)\n\n\n\n\n\n\n#&gt; $summary.strata\n#&gt;   n.FALSE n.TRUE means.FALSE means.TRUE\n#&gt; A      66     23    6.280406   6.600537\n#&gt; B      61     28    4.409935   5.129193\n#&gt; C      51     38    6.212981   6.455034\n#&gt; D      42     47    4.705981   6.208840\n#&gt; E      40     49    5.783529   7.576461\n#&gt; \n#&gt; $wtd.Mn.FALSE\n#&gt; [1] 5.478567\n#&gt; \n#&gt; $wtd.Mn.TRUE\n#&gt; [1] 6.394013\n#&gt; \n#&gt; $ATE\n#&gt; [1] 0.9154463\n#&gt; \n#&gt; $se.wtd\n#&gt; [1] 0.394155\n#&gt; \n#&gt; $approx.t\n#&gt; [1] 2.322554\n#&gt; \n#&gt; $df\n#&gt; [1] 435\n#&gt; \n#&gt; $CI.95\n#&gt; [1] 0.1407612 1.6901314",
    "crumbs": [
      "倾向性评分",
      "<span class='chapter-number'>23</span>  <span class='chapter-title'>分层（Stratification）</span>"
    ]
  },
  {
    "objectID": "stratification.html#敏感性分析",
    "href": "stratification.html#敏感性分析",
    "title": "\n23  分层（Stratification）\n",
    "section": "\n23.3 敏感性分析",
    "text": "23.3 敏感性分析\n评估该效果的稳健性\n\n23.3.1 估计倾向得分（分类树）\n\nCodelibrary(tree)\ntree_out &lt;- tree::tree(lalonde_formu,\n                       data = lalonde)\n\nplot(tree_out); text(tree_out)\n\n\n\n\n\n\nCode\n\nlalonde$tree_ps &lt;- predict(tree_out)\ntable(lalonde$tree_ps, lalonde$treat, useNA = 'ifany')\n#&gt;                    \n#&gt;                       0   1\n#&gt;   0.332             167  83\n#&gt;   0.344827586206897  19  10\n#&gt;   0.351851851851852  35  19\n#&gt;   0.612903225806452  24  38\n#&gt;   0.659090909090909  15  29\n#&gt;   1                   0   6\nlalonde$tree_strata &lt;- predict(tree_out, type = 'where')\ntable(lalonde$tree_strata, lalonde$treat, useNA = 'ifany')\n#&gt;     \n#&gt;        0   1\n#&gt;   3  167  83\n#&gt;   5   15  29\n#&gt;   6   35  19\n#&gt;   9   24  38\n#&gt;   10  19  10\n#&gt;   11   0   6",
    "crumbs": [
      "倾向性评分",
      "<span class='chapter-number'>23</span>  <span class='chapter-title'>分层（Stratification）</span>"
    ]
  },
  {
    "objectID": "matching.html",
    "href": "matching.html",
    "title": "\n24  匹配（Matching）\n",
    "section": "",
    "text": "24.1 数据来源\nhttps://hbiostat.org/data/\nhttps://hbiostat.org/data/repo/rhc\nCoderhc &lt;- read_csv(\"data/PS/rhc.csv\")\n\nrhc %&gt;% \n    select(age, sex, race, edu, income, ninsclas, cat1,das2d3pc, dnr1, \n           ca, surv2md1, aps1, scoma1, wtkilo1, temp1, meanbp1, resp1,\n           hrt1, pafi1, paco21, ph1, wblc1, hema1, sod1, pot1, crea1,\n           bili1, alb1, resp, card, neuro, gastr, renal, meta, hema,\n           seps, trauma, ortho, cardiohx, chfhx, dementhx, psychhx,\n           chrpulhx, renalhx, liverhx, gibledhx, malighx, immunhx, \n           transhx, amihx, swang1) %&gt;% \n    mutate(\n        across(where(is.character), as.factor),\n        across(ends_with(\"hx\"), as.factor)\n    )-&gt;\n    rhc2\nrhc2 %&gt;% select(where(is.factor)) %&gt;% \n    map(table)\n#&gt; $sex\n#&gt; \n#&gt; Female   Male \n#&gt;   2543   3192 \n#&gt; \n#&gt; $race\n#&gt; \n#&gt; black other white \n#&gt;   920   355  4460 \n#&gt; \n#&gt; $income\n#&gt; \n#&gt;   $11-$25k   $25-$50k     &gt; $50k Under $11k \n#&gt;       1165        893        451       3226 \n#&gt; \n#&gt; $ninsclas\n#&gt; \n#&gt;            Medicaid            Medicare Medicare & Medicaid        No insurance \n#&gt;                 647                1458                 374                 322 \n#&gt;             Private  Private & Medicare \n#&gt;                1698                1236 \n#&gt; \n#&gt; $cat1\n#&gt; \n#&gt;               ARF               CHF         Cirrhosis      Colon Cancer \n#&gt;              2490               456               224                 7 \n#&gt;              Coma              COPD       Lung Cancer MOSF w/Malignancy \n#&gt;               436               457                39               399 \n#&gt;     MOSF w/Sepsis \n#&gt;              1227 \n#&gt; \n#&gt; $dnr1\n#&gt; \n#&gt;   No  Yes \n#&gt; 5081  654 \n#&gt; \n#&gt; $ca\n#&gt; \n#&gt; Metastatic         No        Yes \n#&gt;        384       4379        972 \n#&gt; \n#&gt; $resp\n#&gt; \n#&gt;   No  Yes \n#&gt; 3622 2113 \n#&gt; \n#&gt; $card\n#&gt; \n#&gt;   No  Yes \n#&gt; 3804 1931 \n#&gt; \n#&gt; $neuro\n#&gt; \n#&gt;   No  Yes \n#&gt; 5042  693 \n#&gt; \n#&gt; $gastr\n#&gt; \n#&gt;   No  Yes \n#&gt; 4793  942 \n#&gt; \n#&gt; $renal\n#&gt; \n#&gt;   No  Yes \n#&gt; 5440  295 \n#&gt; \n#&gt; $meta\n#&gt; \n#&gt;   No  Yes \n#&gt; 5470  265 \n#&gt; \n#&gt; $hema\n#&gt; \n#&gt;   No  Yes \n#&gt; 5381  354 \n#&gt; \n#&gt; $seps\n#&gt; \n#&gt;   No  Yes \n#&gt; 4704 1031 \n#&gt; \n#&gt; $trauma\n#&gt; \n#&gt;   No  Yes \n#&gt; 5683   52 \n#&gt; \n#&gt; $ortho\n#&gt; \n#&gt;   No  Yes \n#&gt; 5728    7 \n#&gt; \n#&gt; $cardiohx\n#&gt; \n#&gt;    0    1 \n#&gt; 4722 1013 \n#&gt; \n#&gt; $chfhx\n#&gt; \n#&gt;    0    1 \n#&gt; 4714 1021 \n#&gt; \n#&gt; $dementhx\n#&gt; \n#&gt;    0    1 \n#&gt; 5171  564 \n#&gt; \n#&gt; $psychhx\n#&gt; \n#&gt;    0    1 \n#&gt; 5349  386 \n#&gt; \n#&gt; $chrpulhx\n#&gt; \n#&gt;    0    1 \n#&gt; 4646 1089 \n#&gt; \n#&gt; $renalhx\n#&gt; \n#&gt;    0    1 \n#&gt; 5480  255 \n#&gt; \n#&gt; $liverhx\n#&gt; \n#&gt;    0    1 \n#&gt; 5334  401 \n#&gt; \n#&gt; $gibledhx\n#&gt; \n#&gt;    0    1 \n#&gt; 5550  185 \n#&gt; \n#&gt; $malighx\n#&gt; \n#&gt;    0    1 \n#&gt; 4419 1316 \n#&gt; \n#&gt; $immunhx\n#&gt; \n#&gt;    0    1 \n#&gt; 4192 1543 \n#&gt; \n#&gt; $transhx\n#&gt; \n#&gt;    0    1 \n#&gt; 5073  662 \n#&gt; \n#&gt; $amihx\n#&gt; \n#&gt;    0    1 \n#&gt; 5535  200 \n#&gt; \n#&gt; $swang1\n#&gt; \n#&gt; No RHC    RHC \n#&gt;   3551   2184\n\nrhc2 %&gt;% select(where(is.numeric)) %&gt;% \n    summary()\n#&gt;       age              edu           das2d3pc        surv2md1     \n#&gt;  Min.   : 18.04   Min.   : 0.00   Min.   :11.00   Min.   :0.0000  \n#&gt;  1st Qu.: 50.15   1st Qu.:10.00   1st Qu.:16.06   1st Qu.:0.4709  \n#&gt;  Median : 64.05   Median :12.00   Median :19.75   Median :0.6280  \n#&gt;  Mean   : 61.38   Mean   :11.68   Mean   :20.50   Mean   :0.5925  \n#&gt;  3rd Qu.: 73.93   3rd Qu.:13.00   3rd Qu.:23.43   3rd Qu.:0.7430  \n#&gt;  Max.   :101.85   Max.   :30.00   Max.   :33.00   Max.   :0.9620  \n#&gt;       aps1            scoma1       wtkilo1           temp1      \n#&gt;  Min.   :  3.00   Min.   :  0   Min.   :  0.00   Min.   :27.00  \n#&gt;  1st Qu.: 41.00   1st Qu.:  0   1st Qu.: 56.30   1st Qu.:36.09  \n#&gt;  Median : 54.00   Median :  0   Median : 70.00   Median :38.09  \n#&gt;  Mean   : 54.67   Mean   : 21   Mean   : 67.83   Mean   :37.62  \n#&gt;  3rd Qu.: 67.00   3rd Qu.: 41   3rd Qu.: 83.70   3rd Qu.:39.00  \n#&gt;  Max.   :147.00   Max.   :100   Max.   :244.00   Max.   :43.00  \n#&gt;     meanbp1           resp1             hrt1           pafi1      \n#&gt;  Min.   :  0.00   Min.   :  0.00   Min.   :  0.0   Min.   : 11.6  \n#&gt;  1st Qu.: 50.00   1st Qu.: 14.00   1st Qu.: 97.0   1st Qu.:133.3  \n#&gt;  Median : 63.00   Median : 30.00   Median :124.0   Median :202.5  \n#&gt;  Mean   : 78.52   Mean   : 28.09   Mean   :115.2   Mean   :222.3  \n#&gt;  3rd Qu.:115.00   3rd Qu.: 38.00   3rd Qu.:141.0   3rd Qu.:316.6  \n#&gt;  Max.   :259.00   Max.   :100.00   Max.   :250.0   Max.   :937.5  \n#&gt;      paco21            ph1            wblc1             hema1      \n#&gt;  Min.   :  1.00   Min.   :6.579   Min.   :  0.000   Min.   : 2.00  \n#&gt;  1st Qu.: 31.00   1st Qu.:7.340   1st Qu.:  8.398   1st Qu.:26.10  \n#&gt;  Median : 37.00   Median :7.400   Median : 14.100   Median :30.00  \n#&gt;  Mean   : 38.75   Mean   :7.388   Mean   : 15.645   Mean   :31.87  \n#&gt;  3rd Qu.: 42.00   3rd Qu.:7.460   3rd Qu.: 20.049   3rd Qu.:36.30  \n#&gt;  Max.   :156.00   Max.   :7.770   Max.   :192.000   Max.   :66.19  \n#&gt;       sod1            pot1            crea1              bili1         \n#&gt;  Min.   :101.0   Min.   : 1.100   Min.   : 0.09999   Min.   : 0.09999  \n#&gt;  1st Qu.:132.0   1st Qu.: 3.400   1st Qu.: 1.00000   1st Qu.: 0.79993  \n#&gt;  Median :136.0   Median : 3.800   Median : 1.50000   Median : 1.00977  \n#&gt;  Mean   :136.8   Mean   : 4.067   Mean   : 2.13302   Mean   : 2.26707  \n#&gt;  3rd Qu.:142.0   3rd Qu.: 4.600   3rd Qu.: 2.39990   3rd Qu.: 1.39990  \n#&gt;  Max.   :178.0   Max.   :11.898   Max.   :25.09766   Max.   :58.19531  \n#&gt;       alb1       \n#&gt;  Min.   : 0.300  \n#&gt;  1st Qu.: 2.600  \n#&gt;  Median : 3.500  \n#&gt;  Mean   : 3.093  \n#&gt;  3rd Qu.: 3.500  \n#&gt;  Max.   :29.000\n\n\n\nlibrary(tableone)\n\nCreateTableOne(strata = \"swang1\",\n               data = rhc2\n                ) %&gt;% print(.,showAllLevels = T,smd = T, addOverall = T)\n#&gt;                       Stratified by swang1\n#&gt;                        level               No RHC          RHC            \n#&gt;   n                                          3551            2184         \n#&gt;   age (mean (SD))                           61.76 (17.29)   60.75 (15.63) \n#&gt;   sex (%)              Female                1637 ( 46.1)     906 ( 41.5) \n#&gt;                        Male                  1914 ( 53.9)    1278 ( 58.5) \n#&gt;   race (%)             black                  585 ( 16.5)     335 ( 15.3) \n#&gt;                        other                  213 (  6.0)     142 (  6.5) \n#&gt;                        white                 2753 ( 77.5)    1707 ( 78.2) \n#&gt;   edu (mean (SD))                           11.57 (3.13)    11.86 (3.16)  \n#&gt;   income (%)           $11-$25k               713 ( 20.1)     452 ( 20.7) \n#&gt;                        $25-$50k               500 ( 14.1)     393 ( 18.0) \n#&gt;                        &gt; $50k                 257 (  7.2)     194 (  8.9) \n#&gt;                        Under $11k            2081 ( 58.6)    1145 ( 52.4) \n#&gt;   ninsclas (%)         Medicaid               454 ( 12.8)     193 (  8.8) \n#&gt;                        Medicare               947 ( 26.7)     511 ( 23.4) \n#&gt;                        Medicare & Medicaid    251 (  7.1)     123 (  5.6) \n#&gt;                        No insurance           186 (  5.2)     136 (  6.2) \n#&gt;                        Private                967 ( 27.2)     731 ( 33.5) \n#&gt;                        Private & Medicare     746 ( 21.0)     490 ( 22.4) \n#&gt;   cat1 (%)             ARF                   1581 ( 44.5)     909 ( 41.6) \n#&gt;                        CHF                    247 (  7.0)     209 (  9.6) \n#&gt;                        Cirrhosis              175 (  4.9)      49 (  2.2) \n#&gt;                        Colon Cancer             6 (  0.2)       1 (  0.0) \n#&gt;                        Coma                   341 (  9.6)      95 (  4.3) \n#&gt;                        COPD                   399 ( 11.2)      58 (  2.7) \n#&gt;                        Lung Cancer             34 (  1.0)       5 (  0.2) \n#&gt;                        MOSF w/Malignancy      241 (  6.8)     158 (  7.2) \n#&gt;                        MOSF w/Sepsis          527 ( 14.8)     700 ( 32.1) \n#&gt;   das2d3pc (mean (SD))                      20.37 (5.48)    20.70 (5.03)  \n#&gt;   dnr1 (%)             No                    3052 ( 85.9)    2029 ( 92.9) \n#&gt;                        Yes                    499 ( 14.1)     155 (  7.1) \n#&gt;   ca (%)               Metastatic             261 (  7.4)     123 (  5.6) \n#&gt;                        No                    2652 ( 74.7)    1727 ( 79.1) \n#&gt;                        Yes                    638 ( 18.0)     334 ( 15.3) \n#&gt;   surv2md1 (mean (SD))                       0.61 (0.19)     0.57 (0.20)  \n#&gt;   aps1 (mean (SD))                          50.93 (18.81)   60.74 (20.27) \n#&gt;   scoma1 (mean (SD))                        22.25 (31.37)   18.97 (28.26) \n#&gt;   wtkilo1 (mean (SD))                       65.04 (29.50)   72.36 (27.73) \n#&gt;   temp1 (mean (SD))                         37.63 (1.74)    37.59 (1.83)  \n#&gt;   meanbp1 (mean (SD))                       84.87 (38.87)   68.20 (34.24) \n#&gt;   resp1 (mean (SD))                         28.98 (13.95)   26.65 (14.17) \n#&gt;   hrt1 (mean (SD))                         112.87 (40.94)  118.93 (41.47) \n#&gt;   pafi1 (mean (SD))                        240.63 (116.66) 192.43 (105.54)\n#&gt;   paco21 (mean (SD))                        39.95 (14.24)   36.79 (10.97) \n#&gt;   ph1 (mean (SD))                            7.39 (0.11)     7.38 (0.11)  \n#&gt;   wblc1 (mean (SD))                         15.26 (11.41)   16.27 (12.55) \n#&gt;   hema1 (mean (SD))                         32.70 (8.79)    30.51 (7.42)  \n#&gt;   sod1 (mean (SD))                         137.04 (7.68)   136.33 (7.60)  \n#&gt;   pot1 (mean (SD))                           4.08 (1.04)     4.05 (1.01)  \n#&gt;   crea1 (mean (SD))                          1.92 (2.03)     2.47 (2.05)  \n#&gt;   bili1 (mean (SD))                          2.00 (4.43)     2.71 (5.33)  \n#&gt;   alb1 (mean (SD))                           3.16 (0.67)     2.98 (0.93)  \n#&gt;   resp (%)             No                    2070 ( 58.3)    1552 ( 71.1) \n#&gt;                        Yes                   1481 ( 41.7)     632 ( 28.9) \n#&gt;   card (%)             No                    2544 ( 71.6)    1260 ( 57.7) \n#&gt;                        Yes                   1007 ( 28.4)     924 ( 42.3) \n#&gt;   neuro (%)            No                    2976 ( 83.8)    2066 ( 94.6) \n#&gt;                        Yes                    575 ( 16.2)     118 (  5.4) \n#&gt;   gastr (%)            No                    3029 ( 85.3)    1764 ( 80.8) \n#&gt;                        Yes                    522 ( 14.7)     420 ( 19.2) \n#&gt;   renal (%)            No                    3404 ( 95.9)    2036 ( 93.2) \n#&gt;                        Yes                    147 (  4.1)     148 (  6.8) \n#&gt;   meta (%)             No                    3379 ( 95.2)    2091 ( 95.7) \n#&gt;                        Yes                    172 (  4.8)      93 (  4.3) \n#&gt;   hema (%)             No                    3312 ( 93.3)    2069 ( 94.7) \n#&gt;                        Yes                    239 (  6.7)     115 (  5.3) \n#&gt;   seps (%)             No                    3036 ( 85.5)    1668 ( 76.4) \n#&gt;                        Yes                    515 ( 14.5)     516 ( 23.6) \n#&gt;   trauma (%)           No                    3533 ( 99.5)    2150 ( 98.4) \n#&gt;                        Yes                     18 (  0.5)      34 (  1.6) \n#&gt;   ortho (%)            No                    3548 ( 99.9)    2180 ( 99.8) \n#&gt;                        Yes                      3 (  0.1)       4 (  0.2) \n#&gt;   cardiohx (%)         0                     2984 ( 84.0)    1738 ( 79.6) \n#&gt;                        1                      567 ( 16.0)     446 ( 20.4) \n#&gt;   chfhx (%)            0                     2955 ( 83.2)    1759 ( 80.5) \n#&gt;                        1                      596 ( 16.8)     425 ( 19.5) \n#&gt;   dementhx (%)         0                     3138 ( 88.4)    2033 ( 93.1) \n#&gt;                        1                      413 ( 11.6)     151 (  6.9) \n#&gt;   psychhx (%)          0                     3265 ( 91.9)    2084 ( 95.4) \n#&gt;                        1                      286 (  8.1)     100 (  4.6) \n#&gt;   chrpulhx (%)         0                     2777 ( 78.2)    1869 ( 85.6) \n#&gt;                        1                      774 ( 21.8)     315 ( 14.4) \n#&gt;   renalhx (%)          0                     3402 ( 95.8)    2078 ( 95.1) \n#&gt;                        1                      149 (  4.2)     106 (  4.9) \n#&gt;   liverhx (%)          0                     3286 ( 92.5)    2048 ( 93.8) \n#&gt;                        1                      265 (  7.5)     136 (  6.2) \n#&gt;   gibledhx (%)         0                     3420 ( 96.3)    2130 ( 97.5) \n#&gt;                        1                      131 (  3.7)      54 (  2.5) \n#&gt;   malighx (%)          0                     2679 ( 75.4)    1740 ( 79.7) \n#&gt;                        1                      872 ( 24.6)     444 ( 20.3) \n#&gt;   immunhx (%)          0                     2644 ( 74.5)    1548 ( 70.9) \n#&gt;                        1                      907 ( 25.5)     636 ( 29.1) \n#&gt;   transhx (%)          0                     3216 ( 90.6)    1857 ( 85.0) \n#&gt;                        1                      335 (  9.4)     327 ( 15.0) \n#&gt;   amihx (%)            0                     3446 ( 97.0)    2089 ( 95.7) \n#&gt;                        1                      105 (  3.0)      95 (  4.3) \n#&gt;   swang1 (%)           No RHC                3551 (100.0)       0 (  0.0) \n#&gt;                        RHC                      0 (  0.0)    2184 (100.0) \n#&gt;                       Stratified by swang1\n#&gt;                        p      test SMD   \n#&gt;   n                                      \n#&gt;   age (mean (SD))       0.026       0.061\n#&gt;   sex (%)               0.001       0.093\n#&gt;                                          \n#&gt;   race (%)              0.425       0.036\n#&gt;                                          \n#&gt;                                          \n#&gt;   edu (mean (SD))       0.001       0.091\n#&gt;   income (%)           &lt;0.001       0.142\n#&gt;                                          \n#&gt;                                          \n#&gt;                                          \n#&gt;   ninsclas (%)         &lt;0.001       0.194\n#&gt;                                          \n#&gt;                                          \n#&gt;                                          \n#&gt;                                          \n#&gt;                                          \n#&gt;   cat1 (%)             &lt;0.001       0.583\n#&gt;                                          \n#&gt;                                          \n#&gt;                                          \n#&gt;                                          \n#&gt;                                          \n#&gt;                                          \n#&gt;                                          \n#&gt;                                          \n#&gt;   das2d3pc (mean (SD))  0.023       0.063\n#&gt;   dnr1 (%)             &lt;0.001       0.228\n#&gt;                                          \n#&gt;   ca (%)                0.001       0.107\n#&gt;                                          \n#&gt;                                          \n#&gt;   surv2md1 (mean (SD)) &lt;0.001       0.198\n#&gt;   aps1 (mean (SD))     &lt;0.001       0.501\n#&gt;   scoma1 (mean (SD))   &lt;0.001       0.110\n#&gt;   wtkilo1 (mean (SD))  &lt;0.001       0.256\n#&gt;   temp1 (mean (SD))     0.429       0.021\n#&gt;   meanbp1 (mean (SD))  &lt;0.001       0.455\n#&gt;   resp1 (mean (SD))    &lt;0.001       0.165\n#&gt;   hrt1 (mean (SD))     &lt;0.001       0.147\n#&gt;   pafi1 (mean (SD))    &lt;0.001       0.433\n#&gt;   paco21 (mean (SD))   &lt;0.001       0.249\n#&gt;   ph1 (mean (SD))      &lt;0.001       0.120\n#&gt;   wblc1 (mean (SD))     0.002       0.084\n#&gt;   hema1 (mean (SD))    &lt;0.001       0.269\n#&gt;   sod1 (mean (SD))      0.001       0.092\n#&gt;   pot1 (mean (SD))      0.321       0.027\n#&gt;   crea1 (mean (SD))    &lt;0.001       0.270\n#&gt;   bili1 (mean (SD))    &lt;0.001       0.145\n#&gt;   alb1 (mean (SD))     &lt;0.001       0.230\n#&gt;   resp (%)             &lt;0.001       0.270\n#&gt;                                          \n#&gt;   card (%)             &lt;0.001       0.295\n#&gt;                                          \n#&gt;   neuro (%)            &lt;0.001       0.353\n#&gt;                                          \n#&gt;   gastr (%)            &lt;0.001       0.121\n#&gt;                                          \n#&gt;   renal (%)            &lt;0.001       0.116\n#&gt;                                          \n#&gt;   meta (%)              0.337       0.028\n#&gt;                                          \n#&gt;   hema (%)              0.029       0.062\n#&gt;                                          \n#&gt;   seps (%)             &lt;0.001       0.234\n#&gt;                                          \n#&gt;   trauma (%)           &lt;0.001       0.104\n#&gt;                                          \n#&gt;   ortho (%)             0.516       0.027\n#&gt;                                          \n#&gt;   cardiohx (%)         &lt;0.001       0.116\n#&gt;                                          \n#&gt;   chfhx (%)             0.011       0.070\n#&gt;                                          \n#&gt;   dementhx (%)         &lt;0.001       0.163\n#&gt;                                          \n#&gt;   psychhx (%)          &lt;0.001       0.143\n#&gt;                                          \n#&gt;   chrpulhx (%)         &lt;0.001       0.192\n#&gt;                                          \n#&gt;   renalhx (%)           0.268       0.032\n#&gt;                                          \n#&gt;   liverhx (%)           0.084       0.049\n#&gt;                                          \n#&gt;   gibledhx (%)          0.014       0.070\n#&gt;                                          \n#&gt;   malighx (%)          &lt;0.001       0.101\n#&gt;                                          \n#&gt;   immunhx (%)           0.003       0.080\n#&gt;                                          \n#&gt;   transhx (%)          &lt;0.001       0.170\n#&gt;                                          \n#&gt;   amihx (%)             0.007       0.074\n#&gt;                                          \n#&gt;   swang1 (%)           &lt;0.001         NaN\n#&gt;",
    "crumbs": [
      "倾向性评分",
      "<span class='chapter-number'>24</span>  <span class='chapter-title'>匹配（Matching）</span>"
    ]
  },
  {
    "objectID": "matching.html#数据来源",
    "href": "matching.html#数据来源",
    "title": "\n24  匹配（Matching）\n",
    "section": "",
    "text": "Variable name\nVariable Definition\n\n\nAge\nAge\n\n\nSex\nSex\n\n\nRace\nRace\n\n\nEdu\nYears of education\n\n\nIncome\nIncome\n\n\nNinsclas\nMedical insurance\n\n\nCat1\nPrimary disease category\n\n\nCat2\nSecondary disease category\n\n\nCategories of admission diagnosis:\n \n\n\nResp\nRespiratory Diagnosis\n\n\nCard\nCardiovascular Diagnosis\n\n\nNeuro\nNeurological Diagnosis\n\n\nGastr\nGastrointestinal Diagnosis\n\n\nRenal\nRenal Diagnosis\n\n\nMeta\nMetabolic Diagnosis\n\n\nHema\nHematologic Diagnosis\n\n\nSeps\nSepsis Diagnosis\n\n\nTrauma\nTrauma Diagnosis\n\n\nOrtho\nOrthopedic Diagnosis\n\n\n \n \n\n\nAdld3p\nADL\n\n\nDas2d3pc\nDASI ( Duke Activity Status Index)\n\n\nDnr1\nDNR status on day1\n\n\nCa\nCancer\n\n\nSurv2md1\nSupport model estimate of the prob. of surviving 2 months\n\n\nAps1\nAPACHE score\n\n\nScoma1\nGlasgow Coma Score\n\n\nWtkilo1\nWeight\n\n\nTemp1\nTemperature\n\n\nMeanbp1\nMean blood pressure\n\n\nResp1\nRespiratory rate\n\n\nHrt1\nHeart rate\n\n\nPafi1\nPaO2/FIO2 ratio\n\n\nPaco21\nPaCo2\n\n\nPh1\nPH\n\n\nWblc1\nWBC\n\n\nHema1\nHematocrit\n\n\nSod1\nSodium\n\n\nPot1\nPotassium\n\n\nCrea1\nCreatinine\n\n\nBili1\nBilirubin\n\n\nAlb1\nAlbumin\n\n\nUrin1\nUrine output\n\n\nCategories of comorbidities illness:\n \n\n\nCardiohx\nAcute MI, Peripheral Vascular Disease, Severe Cardiovascular Symptoms (NYHA-Class III), Very Severe Cardiovascular Symptoms (NYHA-Class IV)\n\n\nChfhx\nCongestive Heart Failure\n\n\nDementhx\nDementia, Stroke or Cerebral Infarct, Parkinson�s Disease\n\n\nPsychhx\nPsychiatric History, Active Psychosis or Severe Depression\n\n\nChrpulhx\nChronic Pulmonary Disease, Severe Pulmonary Disease, Very Severe Pulmonary Disease\n\n\nRenalhx\nChronic Renal Disease, Chronic Hemodialysis or Peritoneal Dialysis\n\n\nLiverhx\nCirrhosis, Hepatic Failure\n\n\nGibledhx\nUpper GI Bleeding\n\n\nMalighx\nSolid Tumor, Metastatic Disease, Chronic Leukemia/Myeloma, Acute Leukemia, Lymphoma\n\n\nImmunhx\nImmunosupperssion, Organ Transplant, HIV Positivity, Diabetes Mellitus Without End Organ Damage, Diabetes Mellitus With End Organ Damage, Connective Tissue Disease\n\n\nTranshx\nTransfer (&gt; 24 Hours) from Another Hospital\n\n\nAmihx\nDefinite Myocardial Infarction\n\n\n \n \n\n\nSwang1\nRight Heart Catheterization (rhc2)\n\n\nSadmdte\nStudy Admission Date\n\n\nDthdte\nDate of Death\n\n\nLstctdte\nDate of Last Contact\n\n\nDschdte\nHospital Discharge Date\n\n\nDeath\nDeath at any time up to 180 Days\n\n\nPtid\nPatient ID",
    "crumbs": [
      "倾向性评分",
      "<span class='chapter-number'>24</span>  <span class='chapter-title'>匹配（Matching）</span>"
    ]
  },
  {
    "objectID": "matching.html#估计倾向得分",
    "href": "matching.html#估计倾向得分",
    "title": "\n24  匹配（Matching）\n",
    "section": "\n24.2 估计倾向得分",
    "text": "24.2 估计倾向得分\n\nCode\nlibrary(tidymodels)\nrhc2_formula &lt;- swang1 ~ .\n\n\n\nlogit_ps &lt;- logistic_reg() %&gt;%\n    fit(rhc2_formula, data = rhc2)\n\nsummary(logit_ps$fit)\n#&gt; \n#&gt; Call:\n#&gt; stats::glm(formula = swang1 ~ ., family = stats::binomial, data = data)\n#&gt; \n#&gt; Coefficients:\n#&gt;                               Estimate Std. Error z value Pr(&gt;|z|)    \n#&gt; (Intercept)                 17.2203728  3.1137929   5.530 3.20e-08 ***\n#&gt; age                         -0.0043737  0.0028619  -1.528 0.126457    \n#&gt; sexMale                      0.0478361  0.0679017   0.704 0.481128    \n#&gt; raceother                    0.0238498  0.1519260   0.157 0.875258    \n#&gt; racewhite                   -0.0480662  0.0939149  -0.512 0.608787    \n#&gt; edu                          0.0261939  0.0116913   2.240 0.025061 *  \n#&gt; income$25-$50k               0.0888363  0.1094906   0.811 0.417159    \n#&gt; income&gt; $50k                 0.0312483  0.1382814   0.226 0.821220    \n#&gt; incomeUnder $11k             0.0548697  0.0868242   0.632 0.527411    \n#&gt; ninsclasMedicare             0.2328987  0.1351961   1.723 0.084948 .  \n#&gt; ninsclasMedicare & Medicaid  0.4012458  0.1691375   2.372 0.017677 *  \n#&gt; ninsclasNo insurance         0.5264711  0.1673868   3.145 0.001660 ** \n#&gt; ninsclasPrivate              0.4138771  0.1247856   3.317 0.000911 ***\n#&gt; ninsclasPrivate & Medicare   0.3490696  0.1391972   2.508 0.012151 *  \n#&gt; cat1CHF                      0.7833692  0.1596299   4.907 9.23e-07 ***\n#&gt; cat1Cirrhosis               -1.1607975  0.2378358  -4.881 1.06e-06 ***\n#&gt; cat1Colon Cancer            -0.0864465  1.1193521  -0.077 0.938441    \n#&gt; cat1Coma                    -0.5829321  0.1819159  -3.204 0.001353 ** \n#&gt; cat1COPD                    -0.4719080  0.1901740  -2.481 0.013085 *  \n#&gt; cat1Lung Cancer             -0.4138852  0.5445513  -0.760 0.447226    \n#&gt; cat1MOSF w/Malignancy        0.0143100  0.1614131   0.089 0.929356    \n#&gt; cat1MOSF w/Sepsis            0.5339948  0.0910519   5.865 4.50e-09 ***\n#&gt; das2d3pc                    -0.0020607  0.0066432  -0.310 0.756416    \n#&gt; dnr1Yes                     -0.6777513  0.1166464  -5.810 6.24e-09 ***\n#&gt; caNo                         1.0485967  0.4350633   2.410 0.015943 *  \n#&gt; caYes                        0.2805522  0.1619387   1.732 0.083192 .  \n#&gt; surv2md1                    -1.8855344  0.3535424  -5.333 9.65e-08 ***\n#&gt; aps1                         0.0037687  0.0029458   1.279 0.200771    \n#&gt; scoma1                      -0.0041620  0.0016024  -2.597 0.009396 ** \n#&gt; wtkilo1                      0.0063327  0.0012171   5.203 1.96e-07 ***\n#&gt; temp1                       -0.0284681  0.0197651  -1.440 0.149776    \n#&gt; meanbp1                     -0.0063608  0.0010216  -6.226 4.78e-10 ***\n#&gt; resp1                       -0.0207690  0.0025956  -8.002 1.23e-15 ***\n#&gt; hrt1                         0.0054615  0.0008942   6.108 1.01e-09 ***\n#&gt; pafi1                       -0.0047235  0.0003463 -13.639  &lt; 2e-16 ***\n#&gt; paco21                      -0.0261850  0.0036694  -7.136 9.60e-13 ***\n#&gt; ph1                         -1.6756614  0.3847432  -4.355 1.33e-05 ***\n#&gt; wblc1                        0.0001465  0.0027568   0.053 0.957609    \n#&gt; hema1                       -0.0115223  0.0047296  -2.436 0.014841 *  \n#&gt; sod1                        -0.0108807  0.0043040  -2.528 0.011470 *  \n#&gt; pot1                        -0.1720083  0.0341922  -5.031 4.89e-07 ***\n#&gt; crea1                        0.0523499  0.0218175   2.399 0.016420 *  \n#&gt; bili1                        0.0072293  0.0074332   0.973 0.330766    \n#&gt; alb1                        -0.0964314  0.0481135  -2.004 0.045044 *  \n#&gt; respYes                     -0.2725098  0.0827259  -3.294 0.000987 ***\n#&gt; cardYes                      0.5575983  0.0856700   6.509 7.58e-11 ***\n#&gt; neuroYes                    -0.4873660  0.1343763  -3.627 0.000287 ***\n#&gt; gastrYes                     0.3505067  0.1054000   3.325 0.000883 ***\n#&gt; renalYes                     0.3004368  0.1490678   2.015 0.043859 *  \n#&gt; metaYes                     -0.1129081  0.1554971  -0.726 0.467771    \n#&gt; hemaYes                     -0.5131993  0.1470678  -3.490 0.000484 ***\n#&gt; sepsYes                      0.2844857  0.0919399   3.094 0.001973 ** \n#&gt; traumaYes                    1.2560843  0.3346498   3.753 0.000174 ***\n#&gt; orthoYes                     1.1814997  0.9691723   1.219 0.222813    \n#&gt; cardiohx1                    0.0482934  0.0953604   0.506 0.612554    \n#&gt; chfhx1                       0.0936948  0.1042890   0.898 0.368964    \n#&gt; dementhx1                   -0.4121592  0.1213400  -3.397 0.000682 ***\n#&gt; psychhx1                    -0.3913426  0.1382534  -2.831 0.004646 ** \n#&gt; chrpulhx1                    0.0122390  0.1007226   0.122 0.903286    \n#&gt; renalhx1                    -0.3352647  0.1814102  -1.848 0.064588 .  \n#&gt; liverhx1                    -0.0410152  0.1877313  -0.218 0.827057    \n#&gt; gibledhx1                   -0.1856252  0.2283797  -0.813 0.416337    \n#&gt; malighx1                     0.2298479  0.3846516   0.598 0.550141    \n#&gt; immunhx1                     0.0454368  0.0742516   0.612 0.540584    \n#&gt; transhx1                     0.4716832  0.0994237   4.744 2.09e-06 ***\n#&gt; amihx1                       0.1317831  0.1749886   0.753 0.451392    \n#&gt; ---\n#&gt; Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n#&gt; \n#&gt; (Dispersion parameter for binomial family taken to be 1)\n#&gt; \n#&gt;     Null deviance: 7621.4  on 5734  degrees of freedom\n#&gt; Residual deviance: 5993.2  on 5669  degrees of freedom\n#&gt; AIC: 6125.2\n#&gt; \n#&gt; Number of Fisher Scoring iterations: 5\nrhc2$PS &lt;- fitted(logit_ps$fit)\n\npredict(logit_ps, new_data = rhc2, type = \"prob\") %&gt;% head()\n\n\n\n\n.pred_No RHC\n.pred_RHC\n\n\n\n0.6489847\n0.3510153\n\n\n0.3308540\n0.6691460\n\n\n0.3664559\n0.6335441\n\n\n0.6310644\n0.3689356\n\n\n0.5543195\n0.4456805\n\n\n0.9447431\n0.0552569",
    "crumbs": [
      "倾向性评分",
      "<span class='chapter-number'>24</span>  <span class='chapter-title'>匹配（Matching）</span>"
    ]
  },
  {
    "objectID": "matching.html#匹配方法",
    "href": "matching.html#匹配方法",
    "title": "\n24  匹配（Matching）\n",
    "section": "\n24.3 匹配方法",
    "text": "24.3 匹配方法\n\n24.3.1 Matching\n\n\nCodelibrary(Matching)\ndata(lalonde, package='Matching')\nglimpse(lalonde)\n#&gt; Rows: 445\n#&gt; Columns: 12\n#&gt; $ age     &lt;int&gt; 37, 22, 30, 27, 33, 22, 23, 32, 22, 33, 19, 21, 18, 27, 17, 19…\n#&gt; $ educ    &lt;int&gt; 11, 9, 12, 11, 8, 9, 12, 11, 16, 12, 9, 13, 8, 10, 7, 10, 13, …\n#&gt; $ black   &lt;int&gt; 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,…\n#&gt; $ hisp    &lt;int&gt; 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,…\n#&gt; $ married &lt;int&gt; 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0,…\n#&gt; $ nodegr  &lt;int&gt; 1, 1, 0, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1, 0, 1, 0, 0, 1,…\n#&gt; $ re74    &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,…\n#&gt; $ re75    &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,…\n#&gt; $ re78    &lt;dbl&gt; 9930.05, 3595.89, 24909.50, 7506.15, 289.79, 4056.49, 0.00, 84…\n#&gt; $ u74     &lt;int&gt; 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,…\n#&gt; $ u75     &lt;int&gt; 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,…\n#&gt; $ treat   &lt;int&gt; 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,…\n\nlalonde_formu &lt;- treat ~ age + I(age^2) + educ + I(educ^2) + black +\n    hisp + married + nodegr + re74  + I(re74^2) + re75 + I(re75^2) + u74 + u75\nlr_out &lt;- glm(formula = lalonde_formu,\n              data = lalonde,\n              family = binomial(link = 'logit'))\n\nsummary(lr_out)\n#&gt; \n#&gt; Call:\n#&gt; glm(formula = lalonde_formu, family = binomial(link = \"logit\"), \n#&gt;     data = lalonde)\n#&gt; \n#&gt; Coefficients:\n#&gt;               Estimate Std. Error z value Pr(&gt;|z|)  \n#&gt; (Intercept)  4.269e+00  2.173e+00   1.965   0.0494 *\n#&gt; age          2.143e-02  9.037e-02   0.237   0.8126  \n#&gt; I(age^2)    -3.448e-04  1.484e-03  -0.232   0.8163  \n#&gt; educ        -8.713e-01  4.150e-01  -2.099   0.0358 *\n#&gt; I(educ^2)    4.499e-02  2.330e-02   1.931   0.0535 .\n#&gt; black       -2.613e-01  3.708e-01  -0.705   0.4809  \n#&gt; hisp        -8.974e-01  5.184e-01  -1.731   0.0835 .\n#&gt; married      1.829e-01  2.831e-01   0.646   0.5183  \n#&gt; nodegr      -4.285e-01  3.930e-01  -1.090   0.2756  \n#&gt; re74        -2.168e-05  7.739e-05  -0.280   0.7793  \n#&gt; I(re74^2)   -8.553e-10  2.424e-09  -0.353   0.7242  \n#&gt; re75         6.577e-05  1.025e-04   0.642   0.5210  \n#&gt; I(re75^2)   -1.968e-09  5.042e-09  -0.390   0.6963  \n#&gt; u74         -8.315e-02  4.521e-01  -0.184   0.8541  \n#&gt; u75         -3.060e-01  3.591e-01  -0.852   0.3942  \n#&gt; ---\n#&gt; Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n#&gt; \n#&gt; (Dispersion parameter for binomial family taken to be 1)\n#&gt; \n#&gt;     Null deviance: 604.20  on 444  degrees of freedom\n#&gt; Residual deviance: 580.02  on 430  degrees of freedom\n#&gt; AIC: 610.02\n#&gt; \n#&gt; Number of Fisher Scoring iterations: 4\nlalonde$lr_ps &lt;- fitted(lr_out)\n\n\n\nCodelalonde_match &lt;- Match(\n    Y = lalonde$re78,\n    Tr = lalonde$treat,\n    X = lalonde$lr_ps,\n    M = 1,\n    caliper = 0.1,\n    replace = TRUE,\n    estimand = 'ATE'\n)\n\nsummary(lalonde_match)\n#&gt; \n#&gt; Estimate...  2053.1 \n#&gt; AI SE......  803.05 \n#&gt; T-stat.....  2.5566 \n#&gt; p.val......  0.010569 \n#&gt; \n#&gt; Original number of observations..............  445 \n#&gt; Original number of treated obs...............  185 \n#&gt; Matched number of observations...............  433 \n#&gt; Matched number of observations  (unweighted).  744 \n#&gt; \n#&gt; Caliper (SDs)........................................   0.1 \n#&gt; Number of obs dropped by 'exact' or 'caliper'  12\n\nlalonde_match_df &lt;- data.frame(\n    treated.ps = lalonde[lalonde_match$index.treated, ]$lr_ps,\n    control.ps = lalonde[lalonde_match$index.control, ]$lr_ps,\n    treated.y = 1,\n    control.y = 0\n)\nlalonde_match_df &lt;- lalonde_match_df[order(lalonde_match_df$control.ps), ]\n\n\nrows &lt;- (1:nrow(lalonde_match_df) - 1) %% floor(nrow(lalonde_match_df) / 5) == 0\n\nggplot(lalonde, aes(x = lr_ps, y = treat)) +\n    geom_point(alpha = 0.5) +\n    geom_smooth(\n        method = glm,\n        formula = y ~ x,\n        method.args = list(family = binomial(link = 'logit')),\n        se = FALSE\n    ) +\n    xlim(c(0, 1)) +\n    xlab('Propensity Score') + ylab('Treatment') +\n    geom_segment(\n        data = lalonde_match_df,\n        aes(\n            x = treated.ps,\n            xend = control.ps,\n            y = treated.y,\n            yend = control.y\n        ),\n        color = 'purple',\n        alpha = 0.1\n    )\n\n\n\n\n\n\n\n匹配后，治疗组和对照组应具有非常相似的特征。可以使用简单的回归模型来估计治疗对结果的影响。\n\n24.3.2 一对一匹配ATT\nEstimating the treatment effect on the treated (default is ATT)\n\nCoderr_att &lt;- Match(Y = lalonde$re78, \n                Tr = lalonde$treat, \n                X = lalonde$lr_ps,\n                M = 1,\n                estimand='ATT')\nsummary(rr_att) # The default estimate is ATT here\n#&gt; \n#&gt; Estimate...  2153.3 \n#&gt; AI SE......  825.4 \n#&gt; T-stat.....  2.6088 \n#&gt; p.val......  0.0090858 \n#&gt; \n#&gt; Original number of observations..............  445 \n#&gt; Original number of treated obs...............  185 \n#&gt; Matched number of observations...............  185 \n#&gt; Matched number of observations  (unweighted).  346\n\nrr_att_mb &lt;- psa::MatchBalance(\n    df = lalonde,\n    formu = lalonde_formu,\n    formu.Y = update.formula(lalonde_formu, re78 ~ .),\n    index.treated = rr_att$index.treated,\n    index.control = rr_att$index.control,\n    tolerance = 0.25,\n    M = 1,\n    estimand = 'ATT')\nplot(rr_att_mb)\n\n\n\n\n\n\nCodesummary(rr_att_mb)\n#&gt; Sample sizes and number of matches:\n#&gt;    Group   n n.matched n.percent.matched\n#&gt;  Treated 185       185         1.0000000\n#&gt;  Control 260       173         0.6653846\n#&gt;    Total 445       358         0.8044944\n#&gt; \n#&gt; Covariate importance and t-tests for matched pairs:\n#&gt;           Import.Treat Import.Y Import.Total std.estimate       t p.value\n#&gt; I(educ^2)        1.931   1.5228        3.453     -0.04903 -0.8916  0.3732\n#&gt; educ             2.099   1.2121        3.311     -0.05483 -0.9577  0.3389\n#&gt; black            0.705   1.8424        2.547     -0.02326 -0.5383  0.5907\n#&gt; I(re74^2)        0.353   1.6415        1.994      0.07581  2.0955  0.0369\n#&gt; u75              0.852   0.9435        1.796     -0.06655 -1.8144  0.0705\n#&gt; hisp             1.731   0.0404        1.771      0.02042  0.8161  0.4150\n#&gt; nodegr           1.090   0.5011        1.591      0.03496  1.0914  0.2759\n#&gt; re74             0.280   1.1019        1.382      0.07979  1.7483  0.0813\n#&gt; re75             0.642   0.5903        1.232      0.06147  1.3171  0.1887\n#&gt; age              0.237   0.6729        0.910      0.00896  0.1374  0.8908\n#&gt; married          0.646   0.1406        0.787      0.04627  1.0000  0.3180\n#&gt; I(re75^2)        0.390   0.3817        0.772      0.05125  1.0364  0.3007\n#&gt; I(age^2)         0.232   0.5096        0.742      0.00297  0.0438  0.9651\n#&gt; u74              0.184   0.0702        0.254      0.03913  0.7495  0.4541\n#&gt;             ci.min  ci.max PercentMatched\n#&gt; I(educ^2) -0.15719 0.05913           60.4\n#&gt; educ      -0.16744 0.05778           60.1\n#&gt; black     -0.10826 0.06173           91.0\n#&gt; I(re74^2)  0.00465 0.14696           86.7\n#&gt; u75       -0.13870 0.00559           89.3\n#&gt; hisp      -0.02879 0.06963           98.3\n#&gt; nodegr    -0.02804 0.09797           93.9\n#&gt; re74      -0.00998 0.16956           77.2\n#&gt; re75      -0.03032 0.15326           78.0\n#&gt; age       -0.11922 0.13713           44.8\n#&gt; married   -0.04474 0.13728           89.6\n#&gt; I(re75^2) -0.04602 0.14852           88.7\n#&gt; I(age^2)  -0.13062 0.13656           49.7\n#&gt; u74       -0.06356 0.14183           81.5\n\n\n\n24.3.3 一对一匹配ATE\naverage treatment effect\n\nCoderr.ate &lt;- Match(Y = lalonde$re78, \n                Tr = lalonde$treat, \n                X = lalonde$lr_ps,\n                M = 1,\n                estimand = 'ATE')\nsummary(rr.ate)\n#&gt; \n#&gt; Estimate...  2013.3 \n#&gt; AI SE......  817.76 \n#&gt; T-stat.....  2.4619 \n#&gt; p.val......  0.013819 \n#&gt; \n#&gt; Original number of observations..............  445 \n#&gt; Original number of treated obs...............  185 \n#&gt; Matched number of observations...............  445 \n#&gt; Matched number of observations  (unweighted).  756\n\n\n\n24.3.4 一对多匹配 （ATT）\n\nCoderr2 &lt;- Match(Y = lalonde$re78,      \n             Tr = lalonde$treat, \n             X = lalonde$lr_ps,\n             M = 1, \n             ties = TRUE, \n             replace = TRUE,\n             estimand = 'ATT')\nsummary(rr2) # The default estimate is ATT here\n#&gt; \n#&gt; Estimate...  2153.3 \n#&gt; AI SE......  825.4 \n#&gt; T-stat.....  2.6088 \n#&gt; p.val......  0.0090858 \n#&gt; \n#&gt; Original number of observations..............  445 \n#&gt; Original number of treated obs...............  185 \n#&gt; Matched number of observations...............  185 \n#&gt; Matched number of observations  (unweighted).  346\n\n\n\n24.3.5 MachIt\n\n\nCodeMatchIt::matchit(method = \"nearest\")\nMatchIt::matchit(method = 'optimal')\nMatchIt::matchit(method = 'full')\nMatchIt::matchit(method = 'quick')\nMatchIt::matchit(method = 'genetic')\nMatchIt::matchit(method = 'exact')\nMatchIt::matchit(method = 'subclass')\n\n\n\nCodematchit.out &lt;- MatchIt::matchit(lalonde_formu, data = lalonde )\nsummary(matchit.out)\n#&gt; \n#&gt; Call:\n#&gt; MatchIt::matchit(formula = lalonde_formu, data = lalonde)\n#&gt; \n#&gt; Summary of Balance for All Data:\n#&gt;           Means Treated Means Control Std. Mean Diff. Var. Ratio eCDF Mean\n#&gt; distance         0.4468        0.3936          0.4533     1.2101    0.1340\n#&gt; age             25.8162       25.0538          0.1066     1.0278    0.0254\n#&gt; I(age^2)       717.3946      677.3154          0.0929     1.0115    0.0254\n#&gt; educ            10.3459       10.0885          0.1281     1.5513    0.0287\n#&gt; I(educ^2)      111.0595      104.3731          0.1701     1.6625    0.0287\n#&gt; black            0.8432        0.8269          0.0449          .    0.0163\n#&gt; hisp             0.0595        0.1077         -0.2040          .    0.0482\n#&gt; married          0.1892        0.1538          0.0902          .    0.0353\n#&gt; nodegr           0.7081        0.8346         -0.2783          .    0.1265\n#&gt; re74          2095.5740     2107.0268         -0.0023     0.7381    0.0192\n#&gt; I(re74^2) 28141433.9907 36667413.1577         -0.0747     0.5038    0.0192\n#&gt; re75          1532.0556     1266.9092          0.0824     1.0763    0.0508\n#&gt; I(re75^2) 12654752.6909 11196530.0057          0.0260     1.4609    0.0508\n#&gt; u74              0.7081        0.7500         -0.0921          .    0.0419\n#&gt; u75              0.6000        0.6846         -0.1727          .    0.0846\n#&gt;           eCDF Max\n#&gt; distance    0.2244\n#&gt; age         0.0652\n#&gt; I(age^2)    0.0652\n#&gt; educ        0.1265\n#&gt; I(educ^2)   0.1265\n#&gt; black       0.0163\n#&gt; hisp        0.0482\n#&gt; married     0.0353\n#&gt; nodegr      0.1265\n#&gt; re74        0.0471\n#&gt; I(re74^2)   0.0471\n#&gt; re75        0.1075\n#&gt; I(re75^2)   0.1075\n#&gt; u74         0.0419\n#&gt; u75         0.0846\n#&gt; \n#&gt; Summary of Balance for Matched Data:\n#&gt;           Means Treated Means Control Std. Mean Diff. Var. Ratio eCDF Mean\n#&gt; distance         0.4468        0.4284          0.1571     1.3077    0.0387\n#&gt; age             25.8162       25.1351          0.0952     1.1734    0.0243\n#&gt; I(age^2)       717.3946      675.1676          0.0979     1.1512    0.0243\n#&gt; educ            10.3459       10.2649          0.0403     1.2869    0.0174\n#&gt; I(educ^2)      111.0595      108.4919          0.0653     1.3938    0.0174\n#&gt; black            0.8432        0.8486         -0.0149          .    0.0054\n#&gt; hisp             0.0595        0.0703         -0.0457          .    0.0108\n#&gt; married          0.1892        0.1892          0.0000          .    0.0000\n#&gt; nodegr           0.7081        0.7676         -0.1308          .    0.0595\n#&gt; re74          2095.5740     1741.2109          0.0725     1.5797    0.0146\n#&gt; I(re74^2) 28141433.9907 18066538.6428          0.0883     3.5436    0.0146\n#&gt; re75          1532.0556     1314.8073          0.0675     1.3933    0.0264\n#&gt; I(re75^2) 12654752.6909  9126579.7979          0.0630     3.4873    0.0264\n#&gt; u74              0.7081        0.7243         -0.0357          .    0.0162\n#&gt; u75              0.6000        0.6108         -0.0221          .    0.0108\n#&gt;           eCDF Max Std. Pair Dist.\n#&gt; distance    0.1189          0.1585\n#&gt; age         0.0541          0.8159\n#&gt; I(age^2)    0.0541          0.7701\n#&gt; educ        0.0595          0.7662\n#&gt; I(educ^2)   0.0595          0.7604\n#&gt; black       0.0054          0.5798\n#&gt; hisp        0.0108          0.2286\n#&gt; married     0.0000          0.2378\n#&gt; nodegr      0.0595          0.5588\n#&gt; re74        0.0432          0.6080\n#&gt; I(re74^2)   0.0432          0.3620\n#&gt; re75        0.0649          0.7292\n#&gt; I(re75^2)   0.0649          0.3690\n#&gt; u74         0.0162          0.7728\n#&gt; u75         0.0108          0.7282\n#&gt; \n#&gt; Sample Sizes:\n#&gt;           Control Treated\n#&gt; All           260     185\n#&gt; Matched       185     185\n#&gt; Unmatched      75       0\n#&gt; Discarded       0       0\n\n\n\nCode# Same as above but calculate average treatment effect\nrr.ate &lt;- Match(Y = lalonde$re78, \n                Tr = lalonde$treat, \n                X = lalonde$lr_ps,\n                M = 1,\n                ties = FALSE, \n                replace = FALSE, \n                estimand='ATE')\nsummary(rr.ate) # Here the estimate is ATE\n#&gt; \n#&gt; Estimate...  2036.6 \n#&gt; SE.........  501.71 \n#&gt; T-stat.....  4.0592 \n#&gt; p.val......  4.9233e-05 \n#&gt; \n#&gt; Original number of observations..............  445 \n#&gt; Original number of treated obs...............  185 \n#&gt; Matched number of observations...............  370 \n#&gt; Matched number of observations  (unweighted).  370\n\n\n\nCode## Genetic Matching\nrr.gen &lt;- GenMatch(Tr = lalonde$treat, \n                   X = lalonde$lr_ps, \n                   BalanceMatrix = lalonde[,all.vars(lalonde_formu)[-1]],\n                   estimand = 'ATE', \n                   M = 1, \n                   pop.size = 16,\n                   print.level = 0)\nrr.gen.mout &lt;- Match(Y = lalonde$re78, \n                     Tr = lalonde$treat, \n                     X = lalonde$lr_ps,\n                     estimand = 'ATE',\n                     Weight.matrix = rr.gen)\nsummary(rr.gen.mout)\n#&gt; \n#&gt; Estimate...  2086.5 \n#&gt; AI SE......  815.65 \n#&gt; T-stat.....  2.5581 \n#&gt; p.val......  0.010524 \n#&gt; \n#&gt; Original number of observations..............  445 \n#&gt; Original number of treated obs...............  185 \n#&gt; Matched number of observations...............  445 \n#&gt; Matched number of observations  (unweighted).  671\n\n\n\nCode## Partial exact matching\nrr2 &lt;- Matchby(Y = lalonde$re78, \n               Tr = lalonde$treat, \n               X = lalonde$lr_ps, \n               by = factor(lalonde$nodegr),\n               print.level = 0)\nsummary(rr2)\n#&gt; \n#&gt; Estimate...  2014.4 \n#&gt; SE.........  702.05 \n#&gt; T-stat.....  2.8693 \n#&gt; p.val......  0.0041132 \n#&gt; \n#&gt; Original number of observations..............  445 \n#&gt; Original number of treated obs...............  185 \n#&gt; Matched number of observations...............  185 \n#&gt; Matched number of observations  (unweighted).  185\n\n\n\nCode## Partial exact matching on two covariates\nrr3 &lt;- Matchby(Y = lalonde$re78, \n               Tr = lalonde$treat, \n               X = lalonde$lr_ps, \n               by = lalonde[,c('nodegr','married')],\n               print.level = 0)\nsummary(rr3)\n#&gt; \n#&gt; Estimate...  1894 \n#&gt; SE.........  705.3 \n#&gt; T-stat.....  2.6853 \n#&gt; p.val......  0.0072455 \n#&gt; \n#&gt; Original number of observations..............  445 \n#&gt; Original number of treated obs...............  185 \n#&gt; Matched number of observations...............  185 \n#&gt; Matched number of observations  (unweighted).  185",
    "crumbs": [
      "倾向性评分",
      "<span class='chapter-number'>24</span>  <span class='chapter-title'>匹配（Matching）</span>"
    ]
  },
  {
    "objectID": "matching.html#示例",
    "href": "matching.html#示例",
    "title": "\n24  匹配（Matching）\n",
    "section": "\n24.4 示例",
    "text": "24.4 示例\n\n\n变量名\n描述\n\n\n\nage\n年龄\n\n\neduc\n受教育年限\n\n\nblack\n分类变量，1为黑人\n\n\nhisp\n分类变量，1为西班牙裔\n\n\nmarried\n分类变量，1为已婚\n\n\nnodegr\n分类变量，1为有高中学历证书\n\n\nre74\n1974年的收入\n\n\nre75\n1975年的收入\n\n\nre78\n1978年的收入\n\n\nu74\n分类变量，1为1974年收入为零\n\n\nu75\n分类变量，1为1975年收入为零\n\n\ntreat\n分类变量，1为实验组\n\n\n\n\n24.4.1 估计倾向值分数\n\nCodeattach(lalonde)\nglm_ps &lt;- glm(\n    formula = treat ~ age + educ + black + hisp + married + nodegr + re74  + re75,\n    family = binomial(link = 'logit')\n)\n\npsm1 &lt;- Match(Y=re78,\n             Tr = treat,\n             X=glm_ps$fitted.values,\n             estimand = \"ATT\",\n             M=1,\n             replace = TRUE)\nsummary(psm1)\n#&gt; \n#&gt; Estimate...  2624.3 \n#&gt; AI SE......  802.19 \n#&gt; T-stat.....  3.2714 \n#&gt; p.val......  0.0010702 \n#&gt; \n#&gt; Original number of observations..............  445 \n#&gt; Original number of treated obs...............  185 \n#&gt; Matched number of observations...............  185 \n#&gt; Matched number of observations  (unweighted).  344\n\n\n如上所示，使用1对1样本可替代匹配法，实验组平均效应为2624.3，因果效应的标准误为803.19，t值为3.2714，p值为0.0010702&lt;0.05，表明估计的实验组平均处理效应有统计学差异。\n\nCodepsm2 &lt;- Match(Y=re78,\n             Tr = treat,\n             X=glm_ps$fitted.values,\n             estimand = \"ATT\",\n             M=1,\n             replace = FALSE)\nsummary(psm2)\n#&gt; \n#&gt; Estimate...  1996.3 \n#&gt; SE.........  643.88 \n#&gt; T-stat.....  3.1005 \n#&gt; p.val......  0.0019319 \n#&gt; \n#&gt; Original number of observations..............  445 \n#&gt; Original number of treated obs...............  185 \n#&gt; Matched number of observations...............  185 \n#&gt; Matched number of observations  (unweighted).  185\n\n\n\n24.4.2 检验平衡\n受试者个体同质性，是否随机分配\n协变量分布是否平衡，是否重合：\n以age 为例，实验组匹配前25.816匹配后25.816，对照组匹配前25.054匹配后25.692 ，匹配后实验组与对照组更接近了；T-test p-value &gt; 0.05 ，表示匹配前后age 均值无统计学差异；KS Bootstrap p-value &gt; 0.05 ，表示匹配前后age 分布无统计学差异\n***** (V1) age *****                Before Matching          After Matching \n\nmean   treatment........          25.816             25.816  \nmean control..........     25.054            25.692 \nstd mean diff.........     10.655            1.7342 \n\nmean raw eQQ diff.....    0.94054           0.73837  \nmed  raw eQQ diff.....          1                 0  \nmax  raw eQQ diff.....          7                 9   \n\nmean eCDF diff........   0.025364          0.021893  \nmed  eCDF diff........   0.022193          0.020349  \nmax  eCDF diff........   0.065177          0.061047   \n\nvar ratio (Tr/Co).....     1.0278             1.083  \nT-test p-value........    0.26594           0.84975  \nKS Bootstrap p-value..      0.526             0.355  \nKS Naive p-value......     0.7481           0.54314  \nKS Statistic..........   0.065177          0.061047 \n\nCodecheck_balance &lt;- MatchBalance(\n    formul = treat ~ age + educ + black + hisp + married + nodegr + re74  + re75,\n    match.out = psm1,\n    nboots = 1000,data = lalonde\n)\n#&gt; \n#&gt; ***** (V1) age *****\n#&gt;                        Before Matching        After Matching\n#&gt; mean treatment........     25.816             25.816 \n#&gt; mean control..........     25.054             25.692 \n#&gt; std mean diff.........     10.655             1.7342 \n#&gt; \n#&gt; mean raw eQQ diff.....    0.94054            0.73837 \n#&gt; med  raw eQQ diff.....          1                  0 \n#&gt; max  raw eQQ diff.....          7                  9 \n#&gt; \n#&gt; mean eCDF diff........   0.025364           0.021893 \n#&gt; med  eCDF diff........   0.022193           0.020349 \n#&gt; max  eCDF diff........   0.065177           0.061047 \n#&gt; \n#&gt; var ratio (Tr/Co).....     1.0278              1.083 \n#&gt; T-test p-value........    0.26594            0.84975 \n#&gt; KS Bootstrap p-value..      0.514              0.364 \n#&gt; KS Naive p-value......     0.7481            0.54314 \n#&gt; KS Statistic..........   0.065177           0.061047 \n#&gt; \n#&gt; \n#&gt; ***** (V2) educ *****\n#&gt;                        Before Matching        After Matching\n#&gt; mean treatment........     10.346             10.346 \n#&gt; mean control..........     10.088             10.146 \n#&gt; std mean diff.........     12.806             9.9664 \n#&gt; \n#&gt; mean raw eQQ diff.....    0.40541            0.23256 \n#&gt; med  raw eQQ diff.....          0                  0 \n#&gt; max  raw eQQ diff.....          2                  2 \n#&gt; \n#&gt; mean eCDF diff........   0.028698           0.016611 \n#&gt; med  eCDF diff........   0.012682           0.010174 \n#&gt; max  eCDF diff........    0.12651           0.061047 \n#&gt; \n#&gt; var ratio (Tr/Co).....     1.5513             1.2344 \n#&gt; T-test p-value........    0.15017             0.1842 \n#&gt; KS Bootstrap p-value..      0.003              0.183 \n#&gt; KS Naive p-value......   0.062873            0.54314 \n#&gt; KS Statistic..........    0.12651           0.061047 \n#&gt; \n#&gt; \n#&gt; ***** (V3) black *****\n#&gt;                        Before Matching        After Matching\n#&gt; mean treatment........    0.84324            0.84324 \n#&gt; mean control..........    0.82692            0.86847 \n#&gt; std mean diff.........     4.4767            -6.9194 \n#&gt; \n#&gt; mean raw eQQ diff.....   0.016216           0.026163 \n#&gt; med  raw eQQ diff.....          0                  0 \n#&gt; max  raw eQQ diff.....          1                  1 \n#&gt; \n#&gt; mean eCDF diff........  0.0081601           0.013081 \n#&gt; med  eCDF diff........  0.0081601           0.013081 \n#&gt; max  eCDF diff........    0.01632           0.026163 \n#&gt; \n#&gt; var ratio (Tr/Co).....    0.92503             1.1572 \n#&gt; T-test p-value........    0.64736            0.40214 \n#&gt; \n#&gt; \n#&gt; ***** (V4) hisp *****\n#&gt;                        Before Matching        After Matching\n#&gt; mean treatment........   0.059459           0.059459 \n#&gt; mean control..........    0.10769            0.04955 \n#&gt; std mean diff.........    -20.341             4.1792 \n#&gt; \n#&gt; mean raw eQQ diff.....   0.048649           0.011628 \n#&gt; med  raw eQQ diff.....          0                  0 \n#&gt; max  raw eQQ diff.....          1                  1 \n#&gt; \n#&gt; mean eCDF diff........   0.024116           0.005814 \n#&gt; med  eCDF diff........   0.024116           0.005814 \n#&gt; max  eCDF diff........   0.048233           0.011628 \n#&gt; \n#&gt; var ratio (Tr/Co).....    0.58288             1.1875 \n#&gt; T-test p-value........   0.064043            0.46063 \n#&gt; \n#&gt; \n#&gt; ***** (V5) married *****\n#&gt;                        Before Matching        After Matching\n#&gt; mean treatment........    0.18919            0.18919 \n#&gt; mean control..........    0.15385            0.18423 \n#&gt; std mean diff.........     8.9995             1.2617 \n#&gt; \n#&gt; mean raw eQQ diff.....   0.037838           0.026163 \n#&gt; med  raw eQQ diff.....          0                  0 \n#&gt; max  raw eQQ diff.....          1                  1 \n#&gt; \n#&gt; mean eCDF diff........   0.017672           0.013081 \n#&gt; med  eCDF diff........   0.017672           0.013081 \n#&gt; max  eCDF diff........   0.035343           0.026163 \n#&gt; \n#&gt; var ratio (Tr/Co).....     1.1802             1.0207 \n#&gt; T-test p-value........    0.33425            0.89497 \n#&gt; \n#&gt; \n#&gt; ***** (V6) nodegr *****\n#&gt;                        Before Matching        After Matching\n#&gt; mean treatment........    0.70811            0.70811 \n#&gt; mean control..........    0.83462            0.76757 \n#&gt; std mean diff.........    -27.751            -13.043 \n#&gt; \n#&gt; mean raw eQQ diff.....    0.12432           0.043605 \n#&gt; med  raw eQQ diff.....          0                  0 \n#&gt; max  raw eQQ diff.....          1                  1 \n#&gt; \n#&gt; mean eCDF diff........   0.063254           0.021802 \n#&gt; med  eCDF diff........   0.063254           0.021802 \n#&gt; max  eCDF diff........    0.12651           0.043605 \n#&gt; \n#&gt; var ratio (Tr/Co).....     1.4998             1.1585 \n#&gt; T-test p-value........  0.0020368          0.0071385 \n#&gt; \n#&gt; \n#&gt; ***** (V7) re74 *****\n#&gt;                        Before Matching        After Matching\n#&gt; mean treatment........     2095.6             2095.6 \n#&gt; mean control..........       2107             2193.3 \n#&gt; std mean diff.........   -0.23437            -2.0004 \n#&gt; \n#&gt; mean raw eQQ diff.....     487.98             869.16 \n#&gt; med  raw eQQ diff.....          0                  0 \n#&gt; max  raw eQQ diff.....       8413              10305 \n#&gt; \n#&gt; mean eCDF diff........   0.019223           0.054701 \n#&gt; med  eCDF diff........     0.0158           0.050872 \n#&gt; max  eCDF diff........   0.047089            0.12209 \n#&gt; \n#&gt; var ratio (Tr/Co).....     0.7381            0.75054 \n#&gt; T-test p-value........    0.98186            0.84996 \n#&gt; KS Bootstrap p-value..      0.575         &lt; 2.22e-16 \n#&gt; KS Naive p-value......    0.97023           0.011858 \n#&gt; KS Statistic..........   0.047089            0.12209 \n#&gt; \n#&gt; \n#&gt; ***** (V8) re75 *****\n#&gt;                        Before Matching        After Matching\n#&gt; mean treatment........     1532.1             1532.1 \n#&gt; mean control..........     1266.9             2179.9 \n#&gt; std mean diff.........     8.2363            -20.125 \n#&gt; \n#&gt; mean raw eQQ diff.....     367.61             590.34 \n#&gt; med  raw eQQ diff.....          0                  0 \n#&gt; max  raw eQQ diff.....     2110.2             8092.9 \n#&gt; \n#&gt; mean eCDF diff........   0.050834           0.050338 \n#&gt; med  eCDF diff........   0.061954           0.049419 \n#&gt; max  eCDF diff........    0.10748           0.098837 \n#&gt; \n#&gt; var ratio (Tr/Co).....     1.0763            0.56563 \n#&gt; T-test p-value........    0.38527           0.079002 \n#&gt; KS Bootstrap p-value..      0.049               0.01 \n#&gt; KS Naive p-value......    0.16449           0.069435 \n#&gt; KS Statistic..........    0.10748           0.098837 \n#&gt; \n#&gt; \n#&gt; Before Matching Minimum p.value: 0.0020368 \n#&gt; Variable Name(s): nodegr  Number(s): 6 \n#&gt; \n#&gt; After Matching Minimum p.value: &lt; 2.22e-16 \n#&gt; Variable Name(s): re74  Number(s): 7\n\n\n\nCode# age 变平衡了\nqqplot(lalonde$age[psm1$index.control],lalonde$age[psm1$index.treated])\nabline(a=0,b=1)\n\n\n\n\n\n\nCode\n# re74 更不平衡了\nqqplot(lalonde$re74[psm1$index.control],lalonde$re74[psm1$index.treated])\nabline(a=0,b=1)\n\n\n\n\n\n\n\n\nCode# # The covariates we want to match on\nx &lt;- cbind(age , educ , black , hisp , married , nodegr , re74  , re75)\n\n# The covariates we want to obtain balance on\nBalanceMatrix = x\nset.seed(100)\n\n\n\n# Genetic Matching 自动适配平衡\ngen_match &lt;- GenMatch(Tr=treat,\n                      X=glm_ps$fitted.values,\n                      BalanceMatrix = x,\n                      estimand = \"ATT\")\n#&gt; \n#&gt; \n#&gt; Sat Aug 31 15:02:33 2024\n#&gt; Domains:\n#&gt;  0.000000e+00   &lt;=  X1   &lt;=    1.000000e+03 \n#&gt; \n#&gt; Data Type: Floating Point\n#&gt; Operators (code number, name, population) \n#&gt;  (1) Cloning...........................  15\n#&gt;  (2) Uniform Mutation..................  12\n#&gt;  (3) Boundary Mutation.................  12\n#&gt;  (4) Non-Uniform Mutation..............  12\n#&gt;  (5) Polytope Crossover................  12\n#&gt;  (6) Simple Crossover..................  12\n#&gt;  (7) Whole Non-Uniform Mutation........  12\n#&gt;  (8) Heuristic Crossover...............  12\n#&gt;  (9) Local-Minimum Crossover...........  0\n#&gt; \n#&gt; SOFT Maximum Number of Generations: 100\n#&gt; Maximum Nonchanging Generations: 4\n#&gt; Population size       : 100\n#&gt; Convergence Tolerance: 1.000000e-03\n#&gt; \n#&gt; Not Using the BFGS Derivative Based Optimizer on the Best Individual Each Generation.\n#&gt; Not Checking Gradients before Stopping.\n#&gt; Using Out of Bounds Individuals.\n#&gt; \n#&gt; Maximization Problem.\n#&gt; GENERATION: 0 (initializing the population)\n#&gt; Lexical Fit..... 1.180299e-02  1.180299e-02  1.155612e-01  1.186261e-01  1.822343e-01  3.842491e-01  3.842491e-01  4.144313e-01  4.144313e-01  4.610718e-01  5.977650e-01  7.731052e-01  7.731052e-01  8.523060e-01  9.184104e-01  9.749549e-01  \n#&gt; #unique......... 100, #Total UniqueCount: 100\n#&gt; var 1:\n#&gt; best............ 3.729259e+01\n#&gt; mean............ 4.810920e+02\n#&gt; variance........ 7.636997e+04\n#&gt; \n#&gt; GENERATION: 1\n#&gt; Lexical Fit..... 1.180299e-02  1.180299e-02  1.155612e-01  1.186261e-01  1.822343e-01  3.842491e-01  3.842491e-01  4.144313e-01  4.144313e-01  4.610718e-01  5.977650e-01  7.731052e-01  7.731052e-01  8.523060e-01  9.184104e-01  9.749549e-01  \n#&gt; #unique......... 61, #Total UniqueCount: 161\n#&gt; var 1:\n#&gt; best............ 3.729259e+01\n#&gt; mean............ 2.015230e+02\n#&gt; variance........ 6.039634e+04\n#&gt; \n#&gt; GENERATION: 2\n#&gt; Lexical Fit..... 1.180299e-02  1.180299e-02  1.155612e-01  1.186261e-01  1.822343e-01  3.842491e-01  3.842491e-01  4.144313e-01  4.144313e-01  4.610718e-01  5.977650e-01  7.731052e-01  7.731052e-01  8.523060e-01  9.184104e-01  9.749549e-01  \n#&gt; #unique......... 56, #Total UniqueCount: 217\n#&gt; var 1:\n#&gt; best............ 3.729259e+01\n#&gt; mean............ 9.873041e+01\n#&gt; variance........ 3.291501e+04\n#&gt; \n#&gt; GENERATION: 3\n#&gt; Lexical Fit..... 1.180299e-02  1.180299e-02  1.155612e-01  1.186261e-01  1.822343e-01  3.842491e-01  3.842491e-01  4.144313e-01  4.144313e-01  4.610718e-01  5.977650e-01  7.731052e-01  7.731052e-01  8.523060e-01  9.184104e-01  9.749549e-01  \n#&gt; #unique......... 56, #Total UniqueCount: 273\n#&gt; var 1:\n#&gt; best............ 3.729259e+01\n#&gt; mean............ 1.042351e+02\n#&gt; variance........ 2.899583e+04\n#&gt; \n#&gt; GENERATION: 4\n#&gt; Lexical Fit..... 1.180299e-02  1.180299e-02  1.155612e-01  1.186261e-01  1.822343e-01  3.842491e-01  3.842491e-01  4.144313e-01  4.144313e-01  4.610718e-01  5.977650e-01  7.731052e-01  7.731052e-01  8.523060e-01  9.184104e-01  9.749549e-01  \n#&gt; #unique......... 58, #Total UniqueCount: 331\n#&gt; var 1:\n#&gt; best............ 3.729259e+01\n#&gt; mean............ 1.050645e+02\n#&gt; variance........ 2.721152e+04\n#&gt; \n#&gt; GENERATION: 5\n#&gt; Lexical Fit..... 1.541148e-02  2.397991e-02  2.418950e-02  2.418950e-02  1.729273e-01  1.956942e-01  3.942807e-01  3.942807e-01  6.059370e-01  6.059370e-01  6.074259e-01  6.137460e-01  8.414918e-01  8.538318e-01  9.621995e-01  9.621995e-01  \n#&gt; #unique......... 58, #Total UniqueCount: 389\n#&gt; var 1:\n#&gt; best............ 2.941808e-01\n#&gt; mean............ 8.418536e+01\n#&gt; variance........ 1.578216e+04\n#&gt; \n#&gt; GENERATION: 6\n#&gt; Lexical Fit..... 4.145421e-02  4.145421e-02  4.499068e-02  4.499068e-02  1.608408e-01  1.806532e-01  2.764640e-01  4.729068e-01  4.729068e-01  6.940013e-01  6.940013e-01  7.762162e-01  8.635587e-01  8.667712e-01  8.667712e-01  9.507460e-01  \n#&gt; #unique......... 62, #Total UniqueCount: 451\n#&gt; var 1:\n#&gt; best............ 7.310932e-02\n#&gt; mean............ 9.403781e+01\n#&gt; variance........ 2.447312e+04\n#&gt; \n#&gt; GENERATION: 7\n#&gt; Lexical Fit..... 4.177047e-02  4.177047e-02  4.419097e-02  6.248288e-02  1.198352e-01  2.880778e-01  3.513309e-01  4.150287e-01  4.150287e-01  8.316757e-01  8.316757e-01  8.667712e-01  8.667712e-01  8.836843e-01  8.920699e-01  8.920699e-01  \n#&gt; #unique......... 61, #Total UniqueCount: 512\n#&gt; var 1:\n#&gt; best............ 8.760968e-02\n#&gt; mean............ 1.016562e+02\n#&gt; variance........ 4.437002e+04\n#&gt; \n#&gt; GENERATION: 8\n#&gt; Lexical Fit..... 4.177047e-02  4.177047e-02  4.559074e-02  6.427954e-02  1.215371e-01  2.846955e-01  3.519026e-01  4.150287e-01  4.150287e-01  8.316757e-01  8.316757e-01  8.667712e-01  8.667712e-01  8.794500e-01  8.948772e-01  8.948772e-01  \n#&gt; #unique......... 60, #Total UniqueCount: 572\n#&gt; var 1:\n#&gt; best............ 8.627748e-02\n#&gt; mean............ 7.473970e+01\n#&gt; variance........ 2.676016e+04\n#&gt; \n#&gt; GENERATION: 9\n#&gt; Lexical Fit..... 4.177047e-02  4.177047e-02  4.559074e-02  6.427954e-02  1.215371e-01  2.846955e-01  3.519026e-01  4.150287e-01  4.150287e-01  8.316757e-01  8.316757e-01  8.667712e-01  8.667712e-01  8.794500e-01  8.948772e-01  8.948772e-01  \n#&gt; #unique......... 55, #Total UniqueCount: 627\n#&gt; var 1:\n#&gt; best............ 8.627748e-02\n#&gt; mean............ 4.192386e+01\n#&gt; variance........ 1.737331e+04\n#&gt; \n#&gt; GENERATION: 10\n#&gt; Lexical Fit..... 4.177047e-02  4.177047e-02  4.559074e-02  6.427954e-02  1.215371e-01  2.846955e-01  3.519026e-01  4.150287e-01  4.150287e-01  8.316757e-01  8.316757e-01  8.667712e-01  8.667712e-01  8.794500e-01  8.948772e-01  8.948772e-01  \n#&gt; #unique......... 51, #Total UniqueCount: 678\n#&gt; var 1:\n#&gt; best............ 8.627748e-02\n#&gt; mean............ 6.242257e+01\n#&gt; variance........ 2.722981e+04\n#&gt; \n#&gt; GENERATION: 11\n#&gt; Lexical Fit..... 4.177047e-02  4.177047e-02  4.559074e-02  6.427954e-02  1.215371e-01  2.846955e-01  3.519026e-01  4.150287e-01  4.150287e-01  8.316757e-01  8.316757e-01  8.667712e-01  8.667712e-01  8.794500e-01  8.948772e-01  8.948772e-01  \n#&gt; #unique......... 49, #Total UniqueCount: 727\n#&gt; var 1:\n#&gt; best............ 8.627748e-02\n#&gt; mean............ 5.280735e+01\n#&gt; variance........ 1.784927e+04\n#&gt; \n#&gt; GENERATION: 12\n#&gt; Lexical Fit..... 4.177047e-02  4.177047e-02  4.559074e-02  6.427954e-02  1.215371e-01  2.846955e-01  3.519026e-01  4.150287e-01  4.150287e-01  8.316757e-01  8.316757e-01  8.667712e-01  8.667712e-01  8.794500e-01  8.948772e-01  8.948772e-01  \n#&gt; #unique......... 50, #Total UniqueCount: 777\n#&gt; var 1:\n#&gt; best............ 8.627748e-02\n#&gt; mean............ 5.682777e+01\n#&gt; variance........ 2.131922e+04\n#&gt; \n#&gt; GENERATION: 13\n#&gt; Lexical Fit..... 4.177047e-02  4.177047e-02  4.559074e-02  6.427954e-02  1.215371e-01  2.846955e-01  3.519026e-01  4.150287e-01  4.150287e-01  8.316757e-01  8.316757e-01  8.667712e-01  8.667712e-01  8.794500e-01  8.948772e-01  8.948772e-01  \n#&gt; #unique......... 53, #Total UniqueCount: 830\n#&gt; var 1:\n#&gt; best............ 8.627748e-02\n#&gt; mean............ 3.877940e+01\n#&gt; variance........ 1.599211e+04\n#&gt; \n#&gt; 'wait.generations' limit reached.\n#&gt; No significant improvement in 4 generations.\n#&gt; \n#&gt; Solution Lexical Fitness Value:\n#&gt; 4.177047e-02  4.177047e-02  4.559074e-02  6.427954e-02  1.215371e-01  2.846955e-01  3.519026e-01  4.150287e-01  4.150287e-01  8.316757e-01  8.316757e-01  8.667712e-01  8.667712e-01  8.794500e-01  8.948772e-01  8.948772e-01  \n#&gt; \n#&gt; Parameters at the Solution:\n#&gt; \n#&gt;  X[ 1] : 8.627748e-02\n#&gt; \n#&gt; Solution Found Generation 8\n#&gt; Number of Generations Run 13\n#&gt; \n#&gt; Sat Aug 31 15:02:38 2024\n#&gt; Total run time : 0 hours 0 minutes and 5 seconds\n\nPSM &lt;-  Match(Y=re78,\n             Tr = treat,\n             X=glm_ps$fitted.values,\n             estimand = \"ATT\",\n             Weight.matrix = gen_match,\n             replace = TRUE,)\nsummary(PSM)\n#&gt; \n#&gt; Estimate...  2439.3 \n#&gt; AI SE......  813.4 \n#&gt; T-stat.....  2.9989 \n#&gt; p.val......  0.0027099 \n#&gt; \n#&gt; Original number of observations..............  445 \n#&gt; Original number of treated obs...............  185 \n#&gt; Matched number of observations...............  185 \n#&gt; Matched number of observations  (unweighted).  489\n\ncheck_balance2 &lt;- MatchBalance(\n    formul = treat ~ age + educ + black + hisp + married + nodegr + re74  + re75,\n    match.out = PSM,\n    nboots = 1000,data = lalonde\n)\n#&gt; \n#&gt; ***** (V1) age *****\n#&gt;                        Before Matching        After Matching\n#&gt; mean treatment........     25.816             25.816 \n#&gt; mean control..........     25.054             25.217 \n#&gt; std mean diff.........     10.655             8.3769 \n#&gt; \n#&gt; mean raw eQQ diff.....    0.94054            0.46217 \n#&gt; med  raw eQQ diff.....          1                  0 \n#&gt; max  raw eQQ diff.....          7                  9 \n#&gt; \n#&gt; mean eCDF diff........   0.025364           0.012952 \n#&gt; med  eCDF diff........   0.022193           0.010225 \n#&gt; max  eCDF diff........   0.065177            0.03681 \n#&gt; \n#&gt; var ratio (Tr/Co).....     1.0278             1.2224 \n#&gt; T-test p-value........    0.26594             0.3519 \n#&gt; KS Bootstrap p-value..      0.503              0.734 \n#&gt; KS Naive p-value......     0.7481            0.89488 \n#&gt; KS Statistic..........   0.065177            0.03681 \n#&gt; \n#&gt; \n#&gt; ***** (V2) educ *****\n#&gt;                        Before Matching        After Matching\n#&gt; mean treatment........     10.346             10.346 \n#&gt; mean control..........     10.088             10.188 \n#&gt; std mean diff.........     12.806             7.8605 \n#&gt; \n#&gt; mean raw eQQ diff.....    0.40541            0.17587 \n#&gt; med  raw eQQ diff.....          0                  0 \n#&gt; max  raw eQQ diff.....          2                  2 \n#&gt; \n#&gt; mean eCDF diff........   0.028698           0.012562 \n#&gt; med  eCDF diff........   0.012682           0.010225 \n#&gt; max  eCDF diff........    0.12651            0.03681 \n#&gt; \n#&gt; var ratio (Tr/Co).....     1.5513             1.2791 \n#&gt; T-test p-value........    0.15017             0.2847 \n#&gt; KS Bootstrap p-value..      0.011              0.456 \n#&gt; KS Naive p-value......   0.062873            0.89488 \n#&gt; KS Statistic..........    0.12651            0.03681 \n#&gt; \n#&gt; \n#&gt; ***** (V3) black *****\n#&gt;                        Before Matching        After Matching\n#&gt; mean treatment........    0.84324            0.84324 \n#&gt; mean control..........    0.82692              0.868 \n#&gt; std mean diff.........     4.4767            -6.7917 \n#&gt; \n#&gt; mean raw eQQ diff.....   0.016216           0.034765 \n#&gt; med  raw eQQ diff.....          0                  0 \n#&gt; max  raw eQQ diff.....          1                  1 \n#&gt; \n#&gt; mean eCDF diff........  0.0081601           0.017382 \n#&gt; med  eCDF diff........  0.0081601           0.017382 \n#&gt; max  eCDF diff........    0.01632           0.034765 \n#&gt; \n#&gt; var ratio (Tr/Co).....    0.92503             1.1537 \n#&gt; T-test p-value........    0.64736            0.41503 \n#&gt; \n#&gt; \n#&gt; ***** (V4) hisp *****\n#&gt;                        Before Matching        After Matching\n#&gt; mean treatment........   0.059459           0.059459 \n#&gt; mean control..........    0.10769           0.057132 \n#&gt; std mean diff.........    -20.341            0.98148 \n#&gt; \n#&gt; mean raw eQQ diff.....   0.048649            0.00818 \n#&gt; med  raw eQQ diff.....          0                  0 \n#&gt; max  raw eQQ diff.....          1                  1 \n#&gt; \n#&gt; mean eCDF diff........   0.024116            0.00409 \n#&gt; med  eCDF diff........   0.024116            0.00409 \n#&gt; max  eCDF diff........   0.048233            0.00818 \n#&gt; \n#&gt; var ratio (Tr/Co).....    0.58288             1.0382 \n#&gt; T-test p-value........   0.064043            0.86677 \n#&gt; \n#&gt; \n#&gt; ***** (V5) married *****\n#&gt;                        Before Matching        After Matching\n#&gt; mean treatment........    0.18919            0.18919 \n#&gt; mean control..........    0.15385            0.18101 \n#&gt; std mean diff.........     8.9995             2.0837 \n#&gt; \n#&gt; mean raw eQQ diff.....   0.037838           0.018405 \n#&gt; med  raw eQQ diff.....          0                  0 \n#&gt; max  raw eQQ diff.....          1                  1 \n#&gt; \n#&gt; mean eCDF diff........   0.017672          0.0092025 \n#&gt; med  eCDF diff........   0.017672          0.0092025 \n#&gt; max  eCDF diff........   0.035343           0.018405 \n#&gt; \n#&gt; var ratio (Tr/Co).....     1.1802             1.0348 \n#&gt; T-test p-value........    0.33425            0.83168 \n#&gt; \n#&gt; \n#&gt; ***** (V6) nodegr *****\n#&gt;                        Before Matching        After Matching\n#&gt; mean treatment........    0.70811            0.70811 \n#&gt; mean control..........    0.83462            0.75333 \n#&gt; std mean diff.........    -27.751            -9.9207 \n#&gt; \n#&gt; mean raw eQQ diff.....    0.12432           0.034765 \n#&gt; med  raw eQQ diff.....          0                  0 \n#&gt; max  raw eQQ diff.....          1                  1 \n#&gt; \n#&gt; mean eCDF diff........   0.063254           0.017382 \n#&gt; med  eCDF diff........   0.063254           0.017382 \n#&gt; max  eCDF diff........    0.12651           0.034765 \n#&gt; \n#&gt; var ratio (Tr/Co).....     1.4998             1.1123 \n#&gt; T-test p-value........  0.0020368            0.04177 \n#&gt; \n#&gt; \n#&gt; ***** (V7) re74 *****\n#&gt;                        Before Matching        After Matching\n#&gt; mean treatment........     2095.6             2095.6 \n#&gt; mean control..........       2107             2018.1 \n#&gt; std mean diff.........   -0.23437             1.5857 \n#&gt; \n#&gt; mean raw eQQ diff.....     487.98             648.91 \n#&gt; med  raw eQQ diff.....          0                  0 \n#&gt; max  raw eQQ diff.....       8413              10305 \n#&gt; \n#&gt; mean eCDF diff........   0.019223           0.037077 \n#&gt; med  eCDF diff........     0.0158           0.033742 \n#&gt; max  eCDF diff........   0.047089           0.087935 \n#&gt; \n#&gt; var ratio (Tr/Co).....     0.7381            0.86668 \n#&gt; T-test p-value........    0.98186            0.87945 \n#&gt; KS Bootstrap p-value..      0.555              0.002 \n#&gt; KS Naive p-value......    0.97023           0.045591 \n#&gt; KS Statistic..........   0.047089           0.087935 \n#&gt; \n#&gt; \n#&gt; ***** (V8) re75 *****\n#&gt;                        Before Matching        After Matching\n#&gt; mean treatment........     1532.1             1532.1 \n#&gt; mean control..........     1266.9             2079.5 \n#&gt; std mean diff.........     8.2363            -17.005 \n#&gt; \n#&gt; mean raw eQQ diff.....     367.61             532.46 \n#&gt; med  raw eQQ diff.....          0                  0 \n#&gt; max  raw eQQ diff.....     2110.2             8092.9 \n#&gt; \n#&gt; mean eCDF diff........   0.050834           0.040137 \n#&gt; med  eCDF diff........   0.061954             0.0409 \n#&gt; max  eCDF diff........    0.10748           0.083845 \n#&gt; \n#&gt; var ratio (Tr/Co).....     1.0763            0.64518 \n#&gt; T-test p-value........    0.38527            0.12154 \n#&gt; KS Bootstrap p-value..      0.038               0.02 \n#&gt; KS Naive p-value......    0.16449            0.06428 \n#&gt; KS Statistic..........    0.10748           0.083845 \n#&gt; \n#&gt; \n#&gt; Before Matching Minimum p.value: 0.0020368 \n#&gt; Variable Name(s): nodegr  Number(s): 6 \n#&gt; \n#&gt; After Matching Minimum p.value: 0.002 \n#&gt; Variable Name(s): re74  Number(s): 7\n\n# age 变平衡了\nqqplot(lalonde$age[PSM$index.control],lalonde$age[PSM$index.treated])\nabline(a=0,b=1)\n\n\n\n\n\n\nCode\n# re74 也变平衡了\nqqplot(lalonde$re74[PSM$index.control],lalonde$re74[PSM$index.treated])\nabline(a=0,b=1)\n\n\n\n\n\n\n\n\n24.4.3 敏感性分析\n\nCodelibrary(rbounds)\npsens(x =lalonde[PSM$index.treated,\"re78\"],\n      y =lalonde[PSM$index.control,\"re78\"] ,\n      Gamma = 2,\n      GammaInc = 0.1)\n#&gt; \n#&gt;  Rosenbaum Sensitivity Test for Wilcoxon Signed Rank P-Value \n#&gt;  \n#&gt; Unconfounded estimate ....  1e-04 \n#&gt; \n#&gt;  Gamma Lower bound Upper bound\n#&gt;    1.0       1e-04      0.0001\n#&gt;    1.1       0e+00      0.0015\n#&gt;    1.2       0e+00      0.0142\n#&gt;    1.3       0e+00      0.0693\n#&gt;    1.4       0e+00      0.2048\n#&gt;    1.5       0e+00      0.4152\n#&gt;    1.6       0e+00      0.6393\n#&gt;    1.7       0e+00      0.8140\n#&gt;    1.8       0e+00      0.9191\n#&gt;    1.9       0e+00      0.9699\n#&gt;    2.0       0e+00      0.9903\n#&gt; \n#&gt;  Note: Gamma is Odds of Differential Assignment To\n#&gt;  Treatment Due to Unobserved Factors \n#&gt; \n# psens\n\n\n对PSM（Y=re78）使用psens()进行Wilcoxon 符合秩检验，当τ=1.3，p值就大于0.05了，说明处理发生比为1.3时，就可以改变原先对于处理效应的结论，也就是说，这个隐藏性偏差不必太大就可以改变原来的结论，因此分析结果对隐藏性排除的影响非常敏感，结论不可靠。\n对 PSM（Y=re78）使用Hodges-Lehmann点估计检验法 hlsens() ，当τ=1.5，其95%置信区间包含零，说明此时处理效应是无效的。说明处理发生比为1.5时，隐藏性偏差就可以改变原来的结论，因此匹配后的结论不可靠。\n\nCodex = lalonde[PSM$index.treated, \"re78\"]\ny = lalonde[PSM$index.control, \"re78\"]\nhlsens(x, y,Gamma = 2,GammaInc = 0.1)\n#&gt; \n#&gt;  Rosenbaum Sensitivity Test for Hodges-Lehmann Point Estimate \n#&gt;  \n#&gt; Unconfounded estimate ....  1527.95 \n#&gt; \n#&gt;  Gamma Lower bound Upper bound\n#&gt;    1.0 1527.900000      1527.9\n#&gt;    1.1  917.250000      1580.2\n#&gt;    1.2  608.050000      1918.7\n#&gt;    1.3  338.450000      2141.0\n#&gt;    1.4  114.850000      2407.3\n#&gt;    1.5   -0.050046      2631.4\n#&gt;    1.6 -154.050000      2850.3\n#&gt;    1.7 -378.150000      3072.7\n#&gt;    1.8 -545.350000      3258.1\n#&gt;    1.9 -706.350000      3474.2\n#&gt;    2.0 -867.650000      3678.9\n#&gt; \n#&gt;  Note: Gamma is Odds of Differential Assignment To\n#&gt;  Treatment Due to Unobserved Factors \n#&gt; \n\n\n共同支持域的查验\n\nCodesum(glm_ps$fitted.values[lalonde$treat==1]&gt; \n        max(glm_ps$fitted.values[lalonde$treat==0]))\n#&gt; [1] 4\n\nsum(glm_ps$fitted.values[lalonde$treat==1]&lt; \n        min(glm_ps$fitted.values[lalonde$treat==0]))\n#&gt; [1] 0\n\n\n丢弃的实验组样本共有4个。185-181\n\nCodeattach(lalonde)\nsummary(PSM)\n#&gt; \n#&gt; Estimate...  2439.3 \n#&gt; AI SE......  813.4 \n#&gt; T-stat.....  2.9989 \n#&gt; p.val......  0.0027099 \n#&gt; \n#&gt; Original number of observations..............  445 \n#&gt; Original number of treated obs...............  185 \n#&gt; Matched number of observations...............  185 \n#&gt; Matched number of observations  (unweighted).  489\nPSM_CS &lt;-  Match(Y=re78,\n             Tr = treat,\n             X=glm_ps$fitted.values,\n             estimand = \"ATT\",\n             Weight.matrix = gen_match,\n             replace = TRUE,\n             CommonSupport = TRUE)\nsummary(PSM_CS)\n#&gt; \n#&gt; Estimate...  2330 \n#&gt; AI SE......  821.6 \n#&gt; T-stat.....  2.836 \n#&gt; p.val......  0.0045684 \n#&gt; \n#&gt; Original number of observations..............  430 \n#&gt; Original number of treated obs...............  181 \n#&gt; Matched number of observations...............  181 \n#&gt; Matched number of observations  (unweighted).  468\ndetach(lalonde)\n\n\n有查验共同支持域的ATT（2330），与无查验共同支持域（2439.3）存在差异，因此必须重新改进倾向值分析。\n\n24.4.4 MatchIt\n\n24.4.4.1 匹配数据\n\nCodelibrary(MatchIt)\nNM &lt;- MatchIt::matchit(\n    formula = treat ~ age + educ + black + hisp + married + nodegr + re74  + re75,\n    data = lalonde,\n    method = \"nearest\", # 最近邻匹配\n    ratio = 1, # 1:1\n    replace = FALSE\n)\nsummary(NM)\n#&gt; \n#&gt; Call:\n#&gt; MatchIt::matchit(formula = treat ~ age + educ + black + hisp + \n#&gt;     married + nodegr + re74 + re75, data = lalonde, method = \"nearest\", \n#&gt;     replace = FALSE, ratio = 1)\n#&gt; \n#&gt; Summary of Balance for All Data:\n#&gt;          Means Treated Means Control Std. Mean Diff. Var. Ratio eCDF Mean\n#&gt; distance        0.4377        0.4001          0.3935     1.0471    0.1117\n#&gt; age            25.8162       25.0538          0.1066     1.0278    0.0254\n#&gt; educ           10.3459       10.0885          0.1281     1.5513    0.0287\n#&gt; black           0.8432        0.8269          0.0449          .    0.0163\n#&gt; hisp            0.0595        0.1077         -0.2040          .    0.0482\n#&gt; married         0.1892        0.1538          0.0902          .    0.0353\n#&gt; nodegr          0.7081        0.8346         -0.2783          .    0.1265\n#&gt; re74         2095.5740     2107.0268         -0.0023     0.7381    0.0192\n#&gt; re75         1532.0556     1266.9092          0.0824     1.0763    0.0508\n#&gt;          eCDF Max\n#&gt; distance   0.2140\n#&gt; age        0.0652\n#&gt; educ       0.1265\n#&gt; black      0.0163\n#&gt; hisp       0.0482\n#&gt; married    0.0353\n#&gt; nodegr     0.1265\n#&gt; re74       0.0471\n#&gt; re75       0.1075\n#&gt; \n#&gt; Summary of Balance for Matched Data:\n#&gt;          Means Treated Means Control Std. Mean Diff. Var. Ratio eCDF Mean\n#&gt; distance        0.4377        0.4267          0.1152     1.0987    0.0298\n#&gt; age            25.8162       25.8757         -0.0083     0.9551    0.0121\n#&gt; educ           10.3459       10.1459          0.0995     1.3748    0.0220\n#&gt; black           0.8432        0.8486         -0.0149          .    0.0054\n#&gt; hisp            0.0595        0.0649         -0.0229          .    0.0054\n#&gt; married         0.1892        0.2000         -0.0276          .    0.0108\n#&gt; nodegr          0.7081        0.7730         -0.1427          .    0.0649\n#&gt; re74         2095.5740     1659.5326          0.0892     1.1752    0.0351\n#&gt; re75         1532.0556     1359.6980          0.0535     0.9270    0.0502\n#&gt;          eCDF Max Std. Pair Dist.\n#&gt; distance   0.1027          0.1302\n#&gt; age        0.0432          0.8711\n#&gt; educ       0.0757          0.6533\n#&gt; black      0.0054          0.4906\n#&gt; hisp       0.0054          0.2057\n#&gt; married    0.0108          0.7177\n#&gt; nodegr     0.0649          0.2378\n#&gt; re74       0.0865          0.6297\n#&gt; re75       0.1081          0.7019\n#&gt; \n#&gt; Sample Sizes:\n#&gt;           Control Treated\n#&gt; All           260     185\n#&gt; Matched       185     185\n#&gt; Unmatched      75       0\n#&gt; Discarded       0       0\n\n\n\n24.4.4.2 评估质量\n\nCode# 散点图展示了匹配后实验组和对照组样本倾向值的分布，凸显了分布平衡与不平衡，分布缺乏重合\nplot(NM,type = \"jitter\")\n\n\n\n\n\n\n#&gt; To identify the units, use first mouse button; to stop, use second.\n\n\nCode# QQ图 展示了 匹配前（All）匹配后（Matched）的平衡情况\nplot(NM,type = \"QQ\")\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCode\n# 直方图展示了匹配前后倾向值的分布\nplot(NM,type = \"hist\")\n\n\n\n\n\n\n\n\nCode# 标准化平衡统计值，Std. Mean Diff.\nsummary(NM,standardize = TRUE)\n#&gt; \n#&gt; Call:\n#&gt; MatchIt::matchit(formula = treat ~ age + educ + black + hisp + \n#&gt;     married + nodegr + re74 + re75, data = lalonde, method = \"nearest\", \n#&gt;     replace = FALSE, ratio = 1)\n#&gt; \n#&gt; Summary of Balance for All Data:\n#&gt;          Means Treated Means Control Std. Mean Diff. Var. Ratio eCDF Mean\n#&gt; distance        0.4377        0.4001          0.3935     1.0471    0.1117\n#&gt; age            25.8162       25.0538          0.1066     1.0278    0.0254\n#&gt; educ           10.3459       10.0885          0.1281     1.5513    0.0287\n#&gt; black           0.8432        0.8269          0.0449          .    0.0163\n#&gt; hisp            0.0595        0.1077         -0.2040          .    0.0482\n#&gt; married         0.1892        0.1538          0.0902          .    0.0353\n#&gt; nodegr          0.7081        0.8346         -0.2783          .    0.1265\n#&gt; re74         2095.5740     2107.0268         -0.0023     0.7381    0.0192\n#&gt; re75         1532.0556     1266.9092          0.0824     1.0763    0.0508\n#&gt;          eCDF Max\n#&gt; distance   0.2140\n#&gt; age        0.0652\n#&gt; educ       0.1265\n#&gt; black      0.0163\n#&gt; hisp       0.0482\n#&gt; married    0.0353\n#&gt; nodegr     0.1265\n#&gt; re74       0.0471\n#&gt; re75       0.1075\n#&gt; \n#&gt; Summary of Balance for Matched Data:\n#&gt;          Means Treated Means Control Std. Mean Diff. Var. Ratio eCDF Mean\n#&gt; distance        0.4377        0.4267          0.1152     1.0987    0.0298\n#&gt; age            25.8162       25.8757         -0.0083     0.9551    0.0121\n#&gt; educ           10.3459       10.1459          0.0995     1.3748    0.0220\n#&gt; black           0.8432        0.8486         -0.0149          .    0.0054\n#&gt; hisp            0.0595        0.0649         -0.0229          .    0.0054\n#&gt; married         0.1892        0.2000         -0.0276          .    0.0108\n#&gt; nodegr          0.7081        0.7730         -0.1427          .    0.0649\n#&gt; re74         2095.5740     1659.5326          0.0892     1.1752    0.0351\n#&gt; re75         1532.0556     1359.6980          0.0535     0.9270    0.0502\n#&gt;          eCDF Max Std. Pair Dist.\n#&gt; distance   0.1027          0.1302\n#&gt; age        0.0432          0.8711\n#&gt; educ       0.0757          0.6533\n#&gt; black      0.0054          0.4906\n#&gt; hisp       0.0054          0.2057\n#&gt; married    0.0108          0.7177\n#&gt; nodegr     0.0649          0.2378\n#&gt; re74       0.0865          0.6297\n#&gt; re75       0.1081          0.7019\n#&gt; \n#&gt; Sample Sizes:\n#&gt;           Control Treated\n#&gt; All           260     185\n#&gt; Matched       185     185\n#&gt; Unmatched      75       0\n#&gt; Discarded       0       0\n\n\n继续改进，调整模型和协变量\n\n24.4.4.3 计算平均处理效应\n为了简化步骤，以当前的结果进行匹配后分析。\n\nCode\n# 提取匹配后的样本\nmData &lt;- match.data(NM,group = \"all\")\nmData_trt &lt;- match.data(NM,group = \"treat\")\nmData_ctrl &lt;- match.data(NM,group = \"control\")\n \n# 包从CRAN剔除了\n\n\n\nCodelibrary(rbounds)\npsens(x =mData_trt$re78,\n      y =mData_ctrl$re78 ,Gamma = 2,GammaInc = 0.1)\n#&gt; \n#&gt;  Rosenbaum Sensitivity Test for Wilcoxon Signed Rank P-Value \n#&gt;  \n#&gt; Unconfounded estimate ....  0.0199 \n#&gt; \n#&gt;  Gamma Lower bound Upper bound\n#&gt;    1.0      0.0199      0.0199\n#&gt;    1.1      0.0048      0.0639\n#&gt;    1.2      0.0010      0.1491\n#&gt;    1.3      0.0002      0.2749\n#&gt;    1.4      0.0000      0.4248\n#&gt;    1.5      0.0000      0.5755\n#&gt;    1.6      0.0000      0.7076\n#&gt;    1.7      0.0000      0.8108\n#&gt;    1.8      0.0000      0.8844\n#&gt;    1.9      0.0000      0.9328\n#&gt;    2.0      0.0000      0.9627\n#&gt; \n#&gt;  Note: Gamma is Odds of Differential Assignment To\n#&gt;  Treatment Due to Unobserved Factors \n#&gt; \n\nhlsens(x =mData_trt$re78,\n      y =mData_ctrl$re78 ,Gamma = 2,GammaInc = 0.1)\n#&gt; \n#&gt;  Rosenbaum Sensitivity Test for Hodges-Lehmann Point Estimate \n#&gt;  \n#&gt; Unconfounded estimate ....  1435.08 \n#&gt; \n#&gt;  Gamma Lower bound Upper bound\n#&gt;    1.0  1.4351e+03      1435.1\n#&gt;    1.1  8.0828e+02      1515.9\n#&gt;    1.2  4.6298e+02      1809.0\n#&gt;    1.3  1.8238e+02      2178.1\n#&gt;    1.4 -2.0266e-02      2439.4\n#&gt;    1.5 -2.4892e+02      2678.5\n#&gt;    1.6 -4.5162e+02      2937.5\n#&gt;    1.7 -6.7212e+02      3184.0\n#&gt;    1.8 -8.9732e+02      3462.6\n#&gt;    1.9 -1.1328e+03      3651.1\n#&gt;    2.0 -1.3022e+03      3848.9\n#&gt; \n#&gt;  Note: Gamma is Odds of Differential Assignment To\n#&gt;  Treatment Due to Unobserved Factors \n#&gt;",
    "crumbs": [
      "倾向性评分",
      "<span class='chapter-number'>24</span>  <span class='chapter-title'>匹配（Matching）</span>"
    ]
  },
  {
    "objectID": "diagnostic_test.html",
    "href": "diagnostic_test.html",
    "title": "\n25  诊断性测试\n",
    "section": "",
    "text": "25.1 灵敏度（Sensitivity）\n真阳性率：指在所有真实状况为阳性的样本中，被正确识别出阳性的比例。\n\\[\nSe=\\frac{TP}{TP+FN}\n\\]\n其中TP 是真阳性的数量，FN 是假阴性的数量。",
    "crumbs": [
      "研究设计",
      "<span class='chapter-number'>25</span>  <span class='chapter-title'>诊断性测试</span>"
    ]
  },
  {
    "objectID": "diagnostic_test.html#基本特征",
    "href": "diagnostic_test.html#基本特征",
    "title": "\n25  诊断性测试\n",
    "section": "",
    "text": "25.1.1 灵敏度（Sensitivity）\n真阳性率：指在所有真实状况为阳性的样本中，被正确识别出阳性的比例。\n\\[\nSe=\\frac{TP}{TP+FN}\n\\]\n其中TP 是真阳性的数量，FN 是假阴性的数量。\n假阴性率(FNR) /漏诊率\n\\[\nFNR=1-Se\n\\]\n\n25.1.2 特异度（Specificity）\n真阴性率：指在所有真实状况为阴性的样本中，被正确识别出阴性的比例。\n\\[\nSp=\\frac{TN}{TN+FP}\n\\]\n其中 TN 是真阴性的数量，FP 是假阳性的数量。\n假阳性率(FPR) /误诊率\n\\[ FPR=1-Sp \\]\n\n\n\n\n\nCode# 构建列联表\nobserved_sensitivity &lt;- matrix(c(28, 11, 37, 2), nrow = 2, byrow = TRUE,\n                   dimnames = list('检验方式' = c('尿糖检验', '血糖检验'),\n                                   '结果' = c('检出阳性', '未检出阳性')))\nobserved_sensitivity\n#&gt;           结果\n#&gt; 检验方式 检出阳性 未检出阳性\n#&gt;   尿糖检验       28         11\n#&gt;   血糖检验       37          2\n# 进行卡方检验\ns &lt;- chisq.test(observed_sensitivity,correct = F)\n\n# 输出结果\ns\n#&gt; \n#&gt;  Pearson's Chi-squared test\n#&gt; \n#&gt; data:  observed_sensitivity\n#&gt; X-squared = 7.4769, df = 1, p-value = 0.006249\n\n\n# 构建列联表\nobserved_accuracy &lt;- matrix(c(29, 11, 38, 2), nrow = 2, byrow = TRUE,\n                            dimnames = list('检验方式' = c('尿糖检验', '血糖检验'),\n                                            '结果' = c('检准', '不准')))\n\n# 进行卡方检验\naccuracy &lt;- chisq.test(observed_accuracy,correct = F)\n\n# 输出结果\naccuracy\n#&gt; \n#&gt;  Pearson's Chi-squared test\n#&gt; \n#&gt; data:  observed_accuracy\n#&gt; X-squared = 7.4397, df = 1, p-value = 0.00638\n\n\n\n25.1.3 Youden’s Index\n\\[\nJ=Se-FPR =Se+Sp-1,J[1,-1]\n\\]\n\nJ 越大诊断有效性越高\nJ=1 表示完美的诊断性能，因为Se，Sp都是1。\nJ≤0 表示没有诊断价值\n\n25.1.4 Likelihood Ratio\n正似然比\n\\[\nLR+=\\frac{Se}{FPR}=\\frac{Se}{1-Sp}\n\\]\n\nLR+越大表示患病测出阳性结果的优势越大\nLR+=1表示诊断无效\n\n负似然比\n\\[\nLR-=\\frac{FNR}{Sp}=\\frac{1-Sp}{Sp}\n\\]\n\nLR-越小表示患病测出阴性结果的优势越小\nLR-=1表示诊断无效\n\n25.1.5 预测值\n\nCodem\n#&gt;        truth\n#&gt; predict +    -   \n#&gt;       + \"TP\" \"FP\"\n#&gt;       - \"FN\" \"TN\"\n\n\n阳性预测值（Positive Predictive Value, PPV）：在所有被测试为阳性的样本中，真正的阳性比例。\n\\[\nPPV=\\frac{TP}{TP+NP}\n\\]\n阴性预测值（Negative Predictive Value, NPV）：在所有被测试为阴性的样本中，真正的阴性比例。\n\\[\nPPV=\\frac{TN}{TN+FN}\n\\]\n配对样本设计\n\\(\\chi^2\\)配对检验\n完全随机设计\n\\(\\chi^2\\)检验",
    "crumbs": [
      "研究设计",
      "<span class='chapter-number'>25</span>  <span class='chapter-title'>诊断性测试</span>"
    ]
  },
  {
    "objectID": "diagnostic_test.html#一致性agreement",
    "href": "diagnostic_test.html#一致性agreement",
    "title": "\n25  诊断性测试\n",
    "section": "\n25.6 一致性（agreement）",
    "text": "25.6 一致性（agreement）\n准确度（Accuracy）：指测试正确地分类（阳性或阴性）的样本占总样本的比例。\n\\[\nAccuracy=\\frac{TP+TN}{N}\n\\]\nkappa 系数\n\\[\n\\kappa =\\frac{Accuracy-[(a+b)(a+c)+(c+d)(b+d)]/N^2}{1-[(a+b)(a+c)+(c+d)(b+d)]/N^2}\n\\]\n\nκ=1表示完全一致\nκ=-1表示完全不一致\nκ=0表示一致性与偶然一致性Pe相同\n\n通常κ＞0.7即可以认为两种诊断方法有较好的一致性",
    "crumbs": [
      "研究设计",
      "<span class='chapter-number'>25</span>  <span class='chapter-title'>诊断性测试</span>"
    ]
  },
  {
    "objectID": "diagnostic_test.html#roc曲线receiver-operating-characteristic-curve",
    "href": "diagnostic_test.html#roc曲线receiver-operating-characteristic-curve",
    "title": "\n25  诊断性测试\n",
    "section": "\n25.7 ROC曲线（Receiver Operating Characteristic Curve）",
    "text": "25.7 ROC曲线（Receiver Operating Characteristic Curve）\nROC曲线（Receiver Operating Characteristic Curve）：是一个图形工具，用于展示不同阈值下灵敏度和特异度之间的关系。曲线下面积（AUC）越接近1，表示测试的性能越好。\n\nShow the codelibrary(pROC)\n\nroc_data &lt;- aSAH %&gt;%\n    dplyr::filter(gender == \"Female\") %&gt;%\n    roc(outcome, s100b)\n\n\n\n# 绘制ROC曲线\nplot(roc_data, print.thres = \"best\", print.thres.pattern = \"Best cutoff: %.2f\", main = \"ROC Curve\")\n\n\n\n\n\n\nShow the code\n\n# 计算AUC\nauc_value &lt;- auc(roc_data)\nprint(paste(\"AUC:\", auc_value))\n#&gt; [1] \"AUC: 0.72\"\n\n\n\n25.7.1 AUC\nA=P(X&gt;Y)\n\\[\nS(X,Y)=\n\\begin{cases}\n1,\\ \\ \\ \\  X&gt;Y\\\\\n1/2,X=Y\\\\\n0,\\ \\ \\ \\ X&lt;Y\\\\\n\\end{cases}\n\\]\n\\[\n\\hat A=\\frac{1}{n_0n_1}\\sum_1^{n1}\\sum_1^{n_0}S(X, Y)\n\\]\n\n25.7.2 分组AUC的比较\n完全随机设计\n\\[\nZ=\\frac{\\hat A_1-\\hat A_2}{\\sqrt{Var(\\hat A_1)+Var(\\hat A_2)}}\n\\]\n配对样本设计\n\\[\nZ=\\frac{\\hat A_1-\\hat A_2}{\\sqrt{Var(\\hat A_1)+Var(\\hat A_2)-2Cov(\\hat A_1,\\hat A_2)}}\n\\]",
    "crumbs": [
      "研究设计",
      "<span class='chapter-number'>25</span>  <span class='chapter-title'>诊断性测试</span>"
    ]
  },
  {
    "objectID": "correlation.html",
    "href": "correlation.html",
    "title": "\n15  相关性\n",
    "section": "",
    "text": "15.1 分类变量\n如果独立性检验的结果表明两个变量之间不独立，那么如何量化它们之间相关性的强弱?",
    "crumbs": [
      "概率论与数理统计",
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>相关性</span>"
    ]
  },
  {
    "objectID": "correlation.html#分类变量",
    "href": "correlation.html#分类变量",
    "title": "\n15  相关性\n",
    "section": "",
    "text": "15.1.1 Phi 系数、列联系数和 Cramer’s V 系数\n\nvcd 包里的函数 assocstats( )可以用来计算列联表的 Phi 系数、列联系数和 Cramer’s V 系数。其中， Phi 系数只适用于四格表。 　　\n\nCodelibrary(vcd)\nmytable &lt;- table(Arthritis$Sex, Arthritis$Treatment)\nassocstats(mytable)\n#&gt;                      X^2 df P(&gt; X^2)\n#&gt; Likelihood Ratio 0.73748  1  0.39047\n#&gt; Pearson          0.73653  1  0.39078\n#&gt; \n#&gt; Phi-Coefficient   : 0.094 \n#&gt; Contingency Coeff.: 0.093 \n#&gt; Cramer's V        : 0.094\n\n\n\n15.1.2 Kappa 统计量\n对于配对列联表，可以计算一致性指标 Kappa 统计量。 epiDisplay 包里的函数 kap( )可以用于计算一致性的比例以及 Kappa 统计量的值 　　 　　\n\nCodemy.matrix &lt;- matrix(c(11, 2, 12, 33), nrow = 2)\nsum(my.matrix)\n#&gt; [1] 58\nvcd::Kappa(my.matrix)\n#&gt;            value    ASE     z Pr(&gt;|z|)\n#&gt; Unweighted 0.455 0.1153 3.945 7.97e-05\n#&gt; Weighted   0.455 0.1153 3.945 7.97e-05\nepiDisplay::kap(my.matrix)\n#&gt; \n#&gt;  Table for calculation of kappa\n#&gt;    A  B\n#&gt; A 11 12\n#&gt; B  2 33\n#&gt; \n#&gt; Observed agreement = 75.86 % \n#&gt; Expected agreement = 55.71 % \n#&gt; Kappa = 0.455 \n#&gt; Standard error = 0.121 , Z = 3.762 , P value = &lt; 0.001 \n#&gt; \n\n\n　　共 58 个对象，每一对象用两种检测方法检测，其中11 个对象的两种检测结果都为阳性， 33 个对象的两种检测结果都是阴性，所以总一致性为 (11 + 33)/58 ≈ 75.86% 。\n\nCodechisq.test(my.matrix)$expected\n#&gt;          [,1]     [,2]\n#&gt; [1,] 5.155172 17.84483\n#&gt; [2,] 7.844828 27.15517\n\n\n　为了解释期望一致性和 Kappa 值的含义，先计算各个单元格的期望频数。 对角线上的这两个单元格对应的期望频数分别约为5.155172 和27.15517 ，因此期望一致性为 (5.155172+27.15517)/58≈ 55.71% 。期望一致性是假定两种方法的检测结果都是完全随机的情况下的 一致性。也就是说，即使两种检测方法都毫无作用，平均也能达到 55.71% 的一致性。 Kappa 统计量是超出随机的一致性的部分占最大可能超出随机的一致性的比例。在本例中，前者为 75.86% − 55.71% ， 后者为 100% − 55.71% 。 因此， Kappa 值为 (75.86 - 55.71)/(100 - 55.71) ≈ 0.455\n\n15.1.3 马赛克图\n　　马赛克图中的矩形面积正比于多维列联表中单元格的频率 　　\n\nCodemosaicplot(mytable,xlab =\"Sex\",ylab =  \"Treatment\",las = 1)\n\n\n\n\n\n\nCodemosaicplot(my.matrix)",
    "crumbs": [
      "概率论与数理统计",
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>相关性</span>"
    ]
  },
  {
    "objectID": "correlation.html#连续变量",
    "href": "correlation.html#连续变量",
    "title": "\n15  相关性\n",
    "section": "\n15.2 连续变量",
    "text": "15.2 连续变量\n如果两个连续变量不相互独立时，使用协方差（covariance）来描述两个变量的关系。\n协方差（或相关系数）为零，不相关，不存在线性关系，但可能存在非线性关系。\n\nCodedf &lt;- mpg[,c(3,8,9)]\ncov(df)    # 协方差矩阵\n#&gt;           displ      cty       hwy\n#&gt; displ  1.669158 -4.39069 -5.893111\n#&gt; cty   -4.390690 18.11307 24.225432\n#&gt; hwy   -5.893111 24.22543 35.457779\n\n\n\n15.2.0.1 相关系数\n相关系数的取值范围： \\([-1,1]\\)\n\\[\nr(X,Y)=\\frac {\\sum_{i=1}^n (x_i-\\bar x)(y_i-\\bar y)}{\\sqrt{\\sum_{i=1}^n (x_i-\\bar x)^2 \\sum_{i=1}^n (y_i-\\bar y)^2}}\n\\]\n\nCode# Pearson's 积差相关系数 　　一般要求两个连续变量都服从正态分布\ncor(df,use = \"everything\",method=\"pearson\") # default\n#&gt;           displ        cty        hwy\n#&gt; displ  1.000000 -0.7985240 -0.7660200\n#&gt; cty   -0.798524  1.0000000  0.9559159\n#&gt; hwy   -0.766020  0.9559159  1.0000000\n\ncorrelation::correlation(df,method = \"pearson\",p_adjust = \"holm\")\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nParameter1\nParameter2\nr\nCI\nCI_low\nCI_high\nt\ndf_error\np\nMethod\nn_Obs\n\n\n\ndispl\ncty\n-0.7985240\n0.95\n-0.8406782\n-0.7467508\n-20.20515\n232\n0\nPearson correlation\n234\n\n\ndispl\nhwy\n-0.7660200\n0.95\n-0.8142727\n-0.7072539\n-18.15085\n232\n0\nPearson correlation\n234\n\n\ncty\nhwy\n0.9559159\n0.95\n0.9433129\n0.9657663\n49.58470\n232\n0\nPearson correlation\n234\n\n\n\n\n\nCode\n# Spearman's rank相关系数  　　非参数\ncor(df,method = \"spearman\")\n#&gt;            displ        cty        hwy\n#&gt; displ  1.0000000 -0.8809049 -0.8266576\n#&gt; cty   -0.8809049  1.0000000  0.9542104\n#&gt; hwy   -0.8266576  0.9542104  1.0000000\n\ncorrelation::correlation(df,method = \"spearman\",p_adjust = \"holm\")\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nParameter1\nParameter2\nrho\nCI\nCI_low\nCI_high\nS\np\nMethod\nn_Obs\n\n\n\ndispl\ncty\n-0.8809049\n0.95\n-0.9073926\n-0.8474471\n4016568.96\n0\nSpearman correlation\n234\n\n\ndispl\nhwy\n-0.8266576\n0.95\n-0.8643401\n-0.7797446\n3900726.77\n0\nSpearman correlation\n234\n\n\ncty\nhwy\n0.9542104\n0.95\n0.9406973\n0.9647003\n97781.21\n0\nSpearman correlation\n234\n\n\n\n\n\nCode\n# Kendall's tau相关系数  　　非参数\ncor(df,method = \"kendall\")\n#&gt;            displ        cty        hwy\n#&gt; displ  1.0000000 -0.7210828 -0.6536974\n#&gt; cty   -0.7210828  1.0000000  0.8628045\n#&gt; hwy   -0.6536974  0.8628045  1.0000000\ncorrelation::correlation(df,method = \"kendall\",p_adjust = \"holm\")\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nParameter1\nParameter2\ntau\nCI\nCI_low\nCI_high\nz\np\nMethod\nn_Obs\n\n\n\ndispl\ncty\n-0.7210828\n0.95\n-0.7596258\n-0.6774923\n-15.53533\n0\nKendall correlation\n234\n\n\ndispl\nhwy\n-0.6536974\n0.95\n-0.6999287\n-0.6020109\n-14.13933\n0\nKendall correlation\n234\n\n\ncty\nhwy\n0.8628045\n0.95\n0.8392948\n0.8830936\n18.39871\n0\nKendall correlation\n234\n\n\n\n\n\n\n\n15.2.0.2 相关图（correlogram）\n\nCodeggcorrplot::ggcorrplot(\n    corr = cor(df,use = \"everything\",method=\"pearson\") ,\n    lab = T\n)\n\n\n\n\n\n\n\n\n15.2.0.3 显著性检验\n　　零假设为变量之间不相关（即两个总体的相关系数为 0 ） 。函数 cor.test( ) 可用于对相关系数进行显著性检 验。\n统计量\n\\[\nt=\\frac{r\\sqrt{n-2}}{\\sqrt{1-r^2}}\n\\]\n\nCodecor.test(df$displ,df$hwy)\n#&gt; \n#&gt;  Pearson's product-moment correlation\n#&gt; \n#&gt; data:  df$displ and df$hwy\n#&gt; t = -18.151, df = 232, p-value &lt; 2.2e-16\n#&gt; alternative hypothesis: true correlation is not equal to 0\n#&gt; 95 percent confidence interval:\n#&gt;  -0.8142727 -0.7072539\n#&gt; sample estimates:\n#&gt;      cor \n#&gt; -0.76602\n\n\npsych包corr.test() 计算相关系数矩阵和显著性检验\n\nCodepsych::corr.test(df)\n#&gt; Call:psych::corr.test(x = df)\n#&gt; Correlation matrix \n#&gt;       displ   cty   hwy\n#&gt; displ  1.00 -0.80 -0.77\n#&gt; cty   -0.80  1.00  0.96\n#&gt; hwy   -0.77  0.96  1.00\n#&gt; Sample Size \n#&gt; [1] 234\n#&gt; Probability values (Entries above the diagonal are adjusted for multiple tests.) \n#&gt;       displ cty hwy\n#&gt; displ     0   0   0\n#&gt; cty       0   0   0\n#&gt; hwy       0   0   0\n#&gt; \n#&gt;  To see confidence intervals of the correlations, print with the short=FALSE option\n\nprint(psych::corr.test(df), short = FALSE)\n#&gt; Call:psych::corr.test(x = df)\n#&gt; Correlation matrix \n#&gt;       displ   cty   hwy\n#&gt; displ  1.00 -0.80 -0.77\n#&gt; cty   -0.80  1.00  0.96\n#&gt; hwy   -0.77  0.96  1.00\n#&gt; Sample Size \n#&gt; [1] 234\n#&gt; Probability values (Entries above the diagonal are adjusted for multiple tests.) \n#&gt;       displ cty hwy\n#&gt; displ     0   0   0\n#&gt; cty       0   0   0\n#&gt; hwy       0   0   0\n#&gt; \n#&gt;  Confidence intervals based upon normal theory.  To get bootstrapped values, try cor.ci\n#&gt;           raw.lower raw.r raw.upper raw.p lower.adj upper.adj\n#&gt; displ-cty     -0.84 -0.80     -0.75     0     -0.85     -0.74\n#&gt; displ-hwy     -0.81 -0.77     -0.71     0     -0.81     -0.71\n#&gt; cty-hwy        0.94  0.96      0.97     0      0.94      0.97",
    "crumbs": [
      "概率论与数理统计",
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>相关性</span>"
    ]
  },
  {
    "objectID": "chi-square_test.html",
    "href": "chi-square_test.html",
    "title": "\n13  \\(\\chi^2\\) 检验\n",
    "section": "",
    "text": "13.1 卡方分布\n卡方分布可以通过原假设，得到一个统计量来表示期望结果和实际结果之间的偏离程度，进而根据分布，自由度和假设成立的情况，得出观察频率极值的发生概率（比当前统计结果更加极端的概率）。计算方法是对概率分布中的每个频率，用期望频数和实际频数差的平方除以期望频数，最后把所有结果相加。\n\\[ \\chi^2=\\sum \\frac {(O-E)^2} {E} \\]\n得到的统计量结果越大，说明差别越显著，数值越小说明观察和期望的差别越小，当观察频数和期望频数一致是卡方为0。其实就是在比较观测到的比例和期望的比例的关系。\nCodeggplot() + xlim(-10,10) +\n    geom_function(mapping = aes(color=\"normal Distribution\"),\n                  fun = dnorm, args = list(mean = 0, sd = 1),\n                   )+\n    geom_function(mapping = aes(color=\"chi-square Distribution\"),\n                  fun = dchisq, args = list(df = 1 ,ncp=0), \n                 )+\n    scale_color_manual(values = c(\"normal Distribution\" = \"red\",\n                                  \"chi-square Distribution\" = \"blue\"))+\n    labs(color = \"Distribution\")\n卡方分布就可以用来检验某个分类变量各类的出现概率是否等于指定概率，可以检验数据的拟合优度（指定的一组数据与指定分布的吻合度），也可以用来检验两个变量的独立性（两个变量之间是否存在某种关联）。\n在使用卡方检验时，需要的一个参数被称为自由度，指的是独立变量的个数（组数减去限制数）。通常，二项分布已知 \\(\\pi\\) ，泊松分布已知 \\(\\lambda\\) ，正态分布已知 \\(\\mu\\) 和 \\(\\sigma^2\\) 时的自由度是n-1。进行独立性检验时，n行m列联列表的自由度是(n-1) x (m-1)。\nPearson’s \\(\\chi^2\\) 检验 用于检验涉及双向无序多分类变量的概率或比例。",
    "crumbs": [
      "概率论与数理统计",
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>$\\chi^2$ 检验</span>"
    ]
  },
  {
    "objectID": "chi-square_test.html#列联表",
    "href": "chi-square_test.html#列联表",
    "title": "\n13  \\(\\chi^2\\) 检验\n",
    "section": "\n13.2 2×2列联表",
    "text": "13.2 2×2列联表\n独立性：判断两个或多个分类变量之间是否存在关联或取值互不影响，分析联合概率分布是否可以分解为各自概率分布的乘积。\n\n13.2.1 卡方检验\n对于频数表中每个单元格的期望频数都比较大（大于 5）的大样本，correct设为FALSE,不进行连续校正。\n\nCodex &lt;- matrix(c(97,73,7,30),2,dimnames = list(c(\"experiment\",\"control\"),c(\"+\",\"-\")))\nx\n#&gt;             +  -\n#&gt; experiment 97  7\n#&gt; control    73 30\n\n(k1 &lt;- chisq.test(x,correct = F))\n#&gt; \n#&gt;  Pearson's Chi-squared test\n#&gt; \n#&gt; data:  x\n#&gt; X-squared = 17.681, df = 1, p-value = 2.612e-05\n\n# 期望频数列联表\nk1$expected\n#&gt;                   +        -\n#&gt; experiment 85.41063 18.58937\n#&gt; control    84.58937 18.41063\n\nk1$parameter # degrees of freedom\n#&gt; df \n#&gt;  1\n\n\n\n13.2.2 Yate’s 校正\n某些单元格的期望频数接近于或小于 5 时，进行 Yates’ 连续校正以修正卡方统计量提高准确性。\n\nCodex &lt;- matrix(c(1004, 325, 20, 1), 2, \n            dimnames = list(c(\"experiment\", \"control\"), c(\"+\", \"-\")))\nx\n#&gt;               +  -\n#&gt; experiment 1004 20\n#&gt; control     325  1\n\nchisq.test(x,correct = F)$expected\n#&gt;                    +         -\n#&gt; experiment 1008.0711 15.928889\n#&gt; control     320.9289  5.071111\n\n# 校正\n(k2 &lt;- chisq.test(x,correct = T))\n#&gt; \n#&gt;  Pearson's Chi-squared test with Yates' continuity correction\n#&gt; \n#&gt; data:  x\n#&gt; X-squared = 3.3678, df = 1, p-value = 0.06648\n\n\n\n13.2.3 Fisher’s Exact 检验\nFisher 精确概率检验（Fisher’s Exact Test）通常在以下情况中使用：\n\n总样本数 n 小于 40；\n列联表中任何一个单元格的期望频数小于 5。\n\n\nCodex &lt;- matrix(c(7,2,7,17),2,dimnames = list(c(\"A\",\"B\"),c(\"Yes\",\"No\")))\nx\n#&gt;   Yes No\n#&gt; A   7  7\n#&gt; B   2 17\n\n(k5 &lt;- fisher.test(x))\n#&gt; \n#&gt;  Fisher's Exact Test for Count Data\n#&gt; \n#&gt; data:  x\n#&gt; p-value = 0.01914\n#&gt; alternative hypothesis: true odds ratio is not equal to 1\n#&gt; 95 percent confidence interval:\n#&gt;   1.134346 96.442876\n#&gt; sample estimates:\n#&gt; odds ratio \n#&gt;   7.892809\n chisq.test(x)\n#&gt; \n#&gt;  Pearson's Chi-squared test with Yates' continuity correction\n#&gt; \n#&gt; data:  x\n#&gt; X-squared = 4.4985, df = 1, p-value = 0.03393\n\nE &lt;- chisq.test(x)$expected\n\nchisq &lt;- sum((x-E)^2/E)\nchisq \n#&gt; [1] 6.332237\n\np_value_asymptotic &lt;- 1 - pchisq(chisq, df = 1)\n\n\n\n13.2.4 超几何分布\n\n\nCode\ntibble(\n    x = -10:10,\n    y_hyper = dhyper(x, m = 10,n = 7,k = 8),\n) %&gt;% \n    ggplot()+\n    geom_col(aes(x=x,y = y_hyper,color=\"Hypergeometric Distribution\"),fill=NA)+\n    geom_function(aes(color=\"Normal Distribution\"),\n                  fun= dnorm, args = list(mean = 0, sd = 1))+\n    scale_color_manual(values = c(\"Normal Distribution\" = \"red\",\n                                  \"Hypergeometric Distribution\" = \"blue\"))+\n    labs(color = \"Distribution\")",
    "crumbs": [
      "概率论与数理统计",
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>$\\chi^2$ 检验</span>"
    ]
  },
  {
    "objectID": "chi-square_test.html#配对四格表",
    "href": "chi-square_test.html#配对四格表",
    "title": "\n13  \\(\\chi^2\\) 检验\n",
    "section": "\n13.3 配对四格表",
    "text": "13.3 配对四格表\n\n13.3.1 二项分布\n\nCode\ntibble(\n    x = -5:15,\n    y_binom = dbinom(x, size = 10,prob = 0.5),\n) %&gt;% \nggplot()+\n    geom_col(aes(x=x,y=y_binom,color=\"binomal Distribution\"),fill=NA)+\n    geom_function(mapping = aes(color=\"normal Distribution\"),\n                  fun = dnorm, args = list(mean = 5, sd = 1),\n                   )+\n    scale_color_manual(values = c(\"normal Distribution\" = \"red\",\n                                  \"binomal Distribution\" = \"blue\"))+\n    labs(color = \"Distribution\")\n\n\n\n\n\n\n\n\n13.3.2 McNemar’s 检验\n20 &lt; b+c =5 + 34 &lt; 40\n\nCodex &lt;- matrix(c(36,34,5,135),2,dimnames = list(c(\"A+\",\"A-\"),c(\"B+\",\"B-\")))\nx\n#&gt;    B+  B-\n#&gt; A+ 36   5\n#&gt; A- 34 135\n\n(k3 &lt;- mcnemar.test(x,correct = F))\n#&gt; \n#&gt;  McNemar's Chi-squared test\n#&gt; \n#&gt; data:  x\n#&gt; McNemar's chi-squared = 21.564, df = 1, p-value = 3.422e-06\n\n\n# 对于配对四格表，如果样本量较小（不一致的结果的总数小于 40 ） ，则需要进行连续性校正。\n(k4 &lt;- mcnemar.test(x,correct = T))\n#&gt; \n#&gt;  McNemar's Chi-squared test with continuity correction\n#&gt; \n#&gt; data:  x\n#&gt; McNemar's chi-squared = 20.103, df = 1, p-value = 7.34e-06\n\n\n\nCode#　　某实验室分别用免疫荧光法和乳胶凝集法对 58 名疑似系统性红斑狼疮患者血清中抗 核抗体进行测定\nresult&lt;- matrix(c(11, 2, 12, 33), nrow = 2,dimnames = list(c(\"+\",\"-\"),c(\"+\",\"-\")))\nresult\n#&gt;    +  -\n#&gt; + 11 12\n#&gt; -  2 33\n\n#　　对于配对四格表，如果样本量较小（不一致的结果的总数小于 40 ） ，则需要进行连续性校正。\nmcnemar.test(result,correct = TRUE)\n#&gt; \n#&gt;  McNemar's Chi-squared test with continuity correction\n#&gt; \n#&gt; data:  result\n#&gt; McNemar's chi-squared = 5.7857, df = 1, p-value = 0.01616\n\n\n\n13.3.3 精确 McNemar’s 检验\nb+c = 7 + 1 &lt;20\n二项分布B（b+c，0.5），k=min（b，c）\n\\[\nP=\\sum_{i≤k} p_i\n\\]\n\nCodex &lt;- matrix(c(3,1,7,9),2,dimnames = list(c(\"A+\",\"A-\"),c(\"B+\",\"B-\")))\nx\n#&gt;    B+ B-\n#&gt; A+  3  7\n#&gt; A-  1  9\n\nP_two_sided &lt;- 2*sum(dbinom(x=0:1,size = 8,prob = 0.5))\nP_two_sided\n#&gt; [1] 0.0703125",
    "crumbs": [
      "概率论与数理统计",
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>$\\chi^2$ 检验</span>"
    ]
  },
  {
    "objectID": "chi-square_test.html#rc列联表",
    "href": "chi-square_test.html#rc列联表",
    "title": "\n13  \\(\\chi^2\\) 检验\n",
    "section": "\n13.4 R×C列联表",
    "text": "13.4 R×C列联表\n\n13.4.1 卡方检验\n在 R×C 列联表的情况下，如果表中的单元格期望频数满足以下条件：\n\n期望频数 T &lt; 5 的单元格不超过 1/5。\n没有单元格期望频数 T &lt; 1 。\n\n那么可以选择不进行连续校正\n\nCodex &lt;- matrix(c(150,184,198,50,16,2),3,dimnames = list(c(\"A\",\"B\",\"C\"),c(\"Yes\",\"No\")))\nx\n#&gt;   Yes No\n#&gt; A 150 50\n#&gt; B 184 16\n#&gt; C 198  2\n\n(k &lt;- chisq.test(x,correct = F))\n#&gt; \n#&gt;  Pearson's Chi-squared test\n#&gt; \n#&gt; data:  x\n#&gt; X-squared = 60.637, df = 2, p-value = 6.806e-14\n\n\n\nCode(k &lt;- chisq.test(x,correct = T))\n#&gt; \n#&gt;  Pearson's Chi-squared test\n#&gt; \n#&gt; data:  x\n#&gt; X-squared = 60.637, df = 2, p-value = 6.806e-14\nk$expected\n#&gt;        Yes       No\n#&gt; A 177.3333 22.66667\n#&gt; B 177.3333 22.66667\n#&gt; C 177.3333 22.66667\n\n\n\n13.4.2 多重比较\n\\[\n\\alpha'=\\frac {\\alpha}{比较的次数=\\frac{k(k-1)}{2}}\n\\]\n\n13.4.2.1 卡方分割法\n卡方分割法与Bonferroni方法调整p值是两种不同的统计分析方法，主要用于处理多重比较问题。它们的区别如下： 1. 卡方分割法 - 定义：卡方分割法通常用于对卡方检验结果进行后续分析，以确定哪些具体的类别或组之间存在显著差异。该方法基于检验统计量在每对比较中的分布进行分析。 - 应用：常用于发现哪些特定组（行或列）之间存在差异，通常需要进行后续的成对比较。 - 目的：帮助识别在显著性结果中，具体是哪些组之间存在显著差异。\n\n13.4.2.2 Bonferroni方法\n\n定义：Bonferroni方法是一种用于控制多重比较的显著性水平的校正方法。在进行多次假设检验时，原始的显著性水平（例如0.05）会被除以比较次数，从而得出新的显著性水平。\n应用：适用于多个独立检验结果的显著性水平调整，以减少因多重比较导致的假阳性率。\n目的：降低第一类错误的概率（即假阳性），确保在多次检验中保持整体的显著性水平。\n卡方分割法更侧重于分析具体的类别差异，而Bonferroni方法则专注于调整p值以控制错误率。\n如果你已经通过卡方检验发现某些组之间有显著差异，卡方分割法可以帮助你进一步了解哪些组之间有差异。而Bonferroni方法在初步检验前就帮助控制多重比较的问题，确保分析结果的可靠性。 ’\n\n\nCode\n# 创建频率矩阵\ndata &lt;- matrix(c(251, 225,\n                 368, 347,\n                 132, 16,\n                 54, 22,\n                 9, 18,\n                 21, 110,\n                 4, 30,\n                 46, 93), \n               nrow = 8, \n               byrow = TRUE)\n\n# 为矩阵添加行和列名称\nrownames(data) &lt;- c(\"团队\", \"球员\", \"教练\", \"品牌\", \"管理\", \"历史\", \"文化\", \"其他\")\ncolnames(data) &lt;- c(\"Period 1\", \"Period 2\")\n\n# 执行卡方检验\nchi_square_result &lt;- chisq.test(data, correct=T)\n\n# 显示结果\nprint(chi_square_result)\n#&gt; \n#&gt;  Pearson's Chi-squared test\n#&gt; \n#&gt; data:  data\n#&gt; X-squared = 205.38, df = 7, p-value &lt; 2.2e-16\n\n# 提取卡方值，自由度和p值\nchi_square_value &lt;- chi_square_result$statistic\ndegrees_of_freedom &lt;- chi_square_result$parameter\np_value &lt;- chi_square_result$p.value\n\n# 打印结果\ncat(\"卡方值:\", chi_square_value, \"\\n\")\n#&gt; 卡方值: 205.3786\ncat(\"自由度:\", degrees_of_freedom, \"\\n\")\n#&gt; 自由度: 7\ncat(\"显著性水平 (p值):\", p_value, \"\\n\")\n#&gt; 显著性水平 (p值): 8.326236e-41\n\n\n# 进行多重卡方检验\nchi_square_results &lt;- apply(data, 1, function(x) chisq.test(matrix(x, nrow=2)))\n\n# 提取卡方，自由度，p值\n\nX2 &lt;-  sapply(chi_square_results, function(x) x$statistic)\n\np_values &lt;- sapply(chi_square_results, function(x) x$p.value)\n\ndf &lt;- sapply(chi_square_results, function(x) x$parameter)\n\n# 多重比较调整\nadjusted_p_values &lt;- p.adjust(p_values, method = \"bonferroni\")\n\nsignifcance &lt;- case_when(\n    \n    adjusted_p_values&lt;0.001 ~ \"***\",\n    adjusted_p_values&lt;0.01 ~ \"**\",\n    adjusted_p_values&lt;0.05 ~ \"*\",\n    .default = \"ns\"\n    \n)\n    \n    \n    \nresults &lt;- tibble(\n    dimension = rownames(data),\n    chisq_statistic = X2,\n    p_value = p_values,\n    p_adjust = adjusted_p_values,\n    signifcance = signifcance\n)\n\nprint(results)\n#&gt; # A tibble: 8 × 5\n#&gt;   dimension chisq_statistic  p_value p_adjust signifcance\n#&gt;   &lt;chr&gt;               &lt;dbl&gt;    &lt;dbl&gt;    &lt;dbl&gt; &lt;chr&gt;      \n#&gt; 1 团队                1.42  2.33e- 1 1   e+ 0 ns         \n#&gt; 2 球员                0.617 4.32e- 1 1   e+ 0 ns         \n#&gt; 3 教练               90.9   1.50e-21 1.20e-20 ***        \n#&gt; 4 品牌               13.5   2.42e- 4 1.94e- 3 **         \n#&gt; 5 管理                3     8.33e- 2 6.66e- 1 ns         \n#&gt; 6 历史               60.5   7.49e-15 5.99e-14 ***        \n#&gt; 7 文化               19.9   8.24e- 6 6.59e- 5 ***        \n#&gt; 8 其他               15.9   6.71e- 5 5.36e- 4 ***",
    "crumbs": [
      "概率论与数理统计",
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>$\\chi^2$ 检验</span>"
    ]
  },
  {
    "objectID": "chi-square_test.html#拟合优度检验",
    "href": "chi-square_test.html#拟合优度检验",
    "title": "\n13  \\(\\chi^2\\) 检验\n",
    "section": "\n13.5 拟合优度检验",
    "text": "13.5 拟合优度检验\nPearson’s \\(\\chi^2\\) goodness-of-fit test",
    "crumbs": [
      "概率论与数理统计",
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>$\\chi^2$ 检验</span>"
    ]
  },
  {
    "objectID": "chi-square_test.html#cochran-mantel-haenszel-chi2-检验",
    "href": "chi-square_test.html#cochran-mantel-haenszel-chi2-检验",
    "title": "\n13  \\(\\chi^2\\) 检验\n",
    "section": "\n13.6 Cochran-Mantel-Haenszel \\(\\chi^2\\) 检验",
    "text": "13.6 Cochran-Mantel-Haenszel \\(\\chi^2\\) 检验\n又叫行均分检验，常用于按照某个变量进行分层后的检验，用于检验两个有序分类变量是否存在线性相关，但实际上用途很广泛，比如因变量是有序变量的单向有序列联表，也可以用。　　\n两个变量的关联有可能受到第三个变量的影响，因此我们有必要检验两个分类变量在 调整（控制）第三个变量的情况下是否独立。 Cochran-Mantel-Haenszel χ 2 检验常用于探索 变量间的混杂因素。其零假设是：两个分类变量在第三个变量的每一层都是条件独立的。函数 mantelhaen.test( ) 可以用来进行该检验。\n\nCodeRabbits &lt;-\narray(c(0, 0, 6, 5,\n        3, 0, 3, 6,\n        6, 2, 0, 4,\n        5, 6, 1, 0,\n        2, 5, 0, 0),\n      dim = c(2, 2, 5),\n      dimnames = list(\n          Delay = c(\"None\", \"1.5h\"),\n          Response = c(\"Cured\", \"Died\"),\n          Penicillin.Level = c(\"1/8\", \"1/4\", \"1/2\", \"1\", \"4\")))\nRabbits\n#&gt; , , Penicillin.Level = 1/8\n#&gt; \n#&gt;       Response\n#&gt; Delay  Cured Died\n#&gt;   None     0    6\n#&gt;   1.5h     0    5\n#&gt; \n#&gt; , , Penicillin.Level = 1/4\n#&gt; \n#&gt;       Response\n#&gt; Delay  Cured Died\n#&gt;   None     3    3\n#&gt;   1.5h     0    6\n#&gt; \n#&gt; , , Penicillin.Level = 1/2\n#&gt; \n#&gt;       Response\n#&gt; Delay  Cured Died\n#&gt;   None     6    0\n#&gt;   1.5h     2    4\n#&gt; \n#&gt; , , Penicillin.Level = 1\n#&gt; \n#&gt;       Response\n#&gt; Delay  Cured Died\n#&gt;   None     5    1\n#&gt;   1.5h     6    0\n#&gt; \n#&gt; , , Penicillin.Level = 4\n#&gt; \n#&gt;       Response\n#&gt; Delay  Cured Died\n#&gt;   None     2    0\n#&gt;   1.5h     5    0\n\nmantelhaen.test(Rabbits)\n#&gt; \n#&gt;  Mantel-Haenszel chi-squared test with continuity correction\n#&gt; \n#&gt; data:  Rabbits\n#&gt; Mantel-Haenszel X-squared = 3.9286, df = 1, p-value = 0.04747\n#&gt; alternative hypothesis: true common odds ratio is not equal to 1\n#&gt; 95 percent confidence interval:\n#&gt;   1.026713 47.725133\n#&gt; sample estimates:\n#&gt; common odds ratio \n#&gt;                 7",
    "crumbs": [
      "概率论与数理统计",
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>$\\chi^2$ 检验</span>"
    ]
  },
  {
    "objectID": "qualitative_data.html",
    "href": "qualitative_data.html",
    "title": "\n2  定性数据的统计描述\n",
    "section": "",
    "text": "2.0.1 率\n率（rate）表示在一定空间或时间范围内某现象的发生数与可能发生的总数之比，说明某现象出现的频率。\n标准化率（standardized rate）",
    "crumbs": [
      "描述性统计学",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>定性数据的统计描述</span>"
    ]
  },
  {
    "objectID": "qualitative_data.html#构成比",
    "href": "qualitative_data.html#构成比",
    "title": "\n2  定性数据的统计描述\n",
    "section": "\n2.1 构成比",
    "text": "2.1 构成比\n构成比（proportion）",
    "crumbs": [
      "描述性统计学",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>定性数据的统计描述</span>"
    ]
  },
  {
    "objectID": "qualitative_data.html#相对比",
    "href": "qualitative_data.html#相对比",
    "title": "\n2  定性数据的统计描述\n",
    "section": "\n2.2 相对比",
    "text": "2.2 相对比\n相对比（relative ratio）是A和B两个有关联指标值之比。\nUsing R for Biomedical Statistics\n\n\n相对危险度 （Relative Risk，RR），是指暴露组人群的发病率与非暴露组人群的发病率之比。RR 用于反映暴露因素与结局事件的关联程度， 其 取值范围为 0 到无穷大。数值为 1 时，表明暴露因素与结局事件无关联；小于 1 时，表 明暴露因素导致结局事件的发生率降低；大于 1 时，表明暴露因素导致结局事件的发生率增加。相对风险适用于前瞻性队列研究。\n\nCodex &lt;- matrix(c(156,9421,1531,14797),nrow=2,byrow=TRUE,\n             dimnames = list(c(\"Exposed\",\"Unexposed\"),c(\"Disease\",\"Control\")))\n\nx\n#&gt;           Disease Control\n#&gt; Exposed       156    9421\n#&gt; Unexposed    1531   14797\n# RR\n156/(156+9421)*(1531+14797)/1531\n#&gt; [1] 0.1737212\nsource(\"function/calcRelativeRisk.R\")\ncalcRelativeRisk(x,alpha=0.05)\n#&gt; [1] \"category = Exposed , relative risk =  0.173721236521721\"\n#&gt; [1] \"category = Exposed ,  95 % confidence interval = [ 0.147624440337197 , 0.204431379720742 ]\"\n\n# OR\n156/9421/(1531/14797)\n#&gt; [1] 0.1600391\nsource(\"function/calcOddsRatio.R\")\ncalcOddsRatio(x,alpha = 0.05)\n#&gt; [1] \"category = Exposed , odds ratio =  0.160039091621751\"\n#&gt; [1] \"category = Exposed ,  95 % confidence interval = [ 0.135460641900536 , 0.189077140693912 ]\"\n\n\n\n\n优势比（Odds Ratio，OR），是指暴露组中病例与非病例人数的比值除以非暴露组中病例与非病例人数的比值。　　OR 的取值范围也为 0 到无穷大。如果 OR 值大于 1 ，说明该暴露因素更 容易导致结果事件发生，或者说该因素是一个危险因素；小于 1 ，则说明该暴露因素更不 容易导致结果事件发生，或者说该因素是一个保护因素。比值比适用于队列研究和病例对照研究。\n\nCodey &lt;- matrix(c(30,24,76,241,82,509),nrow=3,byrow=TRUE,\n            dimnames = list(c(\"Exposure1\",\"Exposure2\",\"Unexposed\"),\n                            c(\"Disease\",\"Control\")))\ny\n#&gt;           Disease Control\n#&gt; Exposure1      30      24\n#&gt; Exposure2      76     241\n#&gt; Unexposed      82     509\ncalcOddsRatio(y, referencerow=3)\n#&gt; [1] \"category = Exposure1 , odds ratio =  7.75914634146342\"\n#&gt; [1] \"category = Exposure1 ,  95 % confidence interval = [ 4.32163714854064 , 13.9309131884372 ]\"\n#&gt; [1] \"category = Exposure2 , odds ratio =  1.95749418075094\"\n#&gt; [1] \"category = Exposure2 ,  95 % confidence interval = [ 1.38263094540732 , 2.77137111707344 ]\"\ncalcRelativeRisk(y, referencerow=3)\n#&gt; [1] \"category = Exposure1 , relative risk =  4.00406504065041\"\n#&gt; [1] \"category = Exposure1 ,  95 % confidence interval = [ 2.93130744422409 , 5.46941498113737 ]\"\n#&gt; [1] \"category = Exposure2 , relative risk =  1.72793721628068\"\n#&gt; [1] \"category = Exposure2 ,  95 % confidence interval = [ 1.30507489771431 , 2.2878127750653 ]\"",
    "crumbs": [
      "描述性统计学",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>定性数据的统计描述</span>"
    ]
  },
  {
    "objectID": "qualitative_data.html#列联表",
    "href": "qualitative_data.html#列联表",
    "title": "\n2  定性数据的统计描述\n",
    "section": "\n2.3 列联表",
    "text": "2.3 列联表\n\nCodeeg &lt;- matrix(c(156,9421,1531,14797),nrow=2,byrow=TRUE)\ncolnames(eg) &lt;- c(\"Disease\",\"Control\")\nrownames(eg) &lt;- c(\"Exposed\",\"Unexposed\")\nprint(eg)\n#&gt;           Disease Control\n#&gt; Exposed       156    9421\n#&gt; Unexposed    1531   14797\nprop.table(eg)          #各单元格比例\n#&gt;               Disease   Control\n#&gt; Exposed   0.006022003 0.3636750\n#&gt; Unexposed 0.059100560 0.5712025\nprop.table(eg,margin = 1)        #行比例 \n#&gt;              Disease   Control\n#&gt; Exposed   0.01628903 0.9837110\n#&gt; Unexposed 0.09376531 0.9062347",
    "crumbs": [
      "描述性统计学",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>定性数据的统计描述</span>"
    ]
  },
  {
    "objectID": "qualitative_data.html#边际列联表",
    "href": "qualitative_data.html#边际列联表",
    "title": "\n2  定性数据的统计描述\n",
    "section": "\n2.4 边际列联表",
    "text": "2.4 边际列联表\n\nCode# 边际\nmargin.table(x=eg,margin = 2)      #列和\n#&gt; Disease Control \n#&gt;    1687   24218\naddmargins(eg)          #添加行和、列和\n#&gt;           Disease Control   Sum\n#&gt; Exposed       156    9421  9577\n#&gt; Unexposed    1531   14797 16328\n#&gt; Sum          1687   24218 25905\naddmargins(eg,1)        #添加列和\n#&gt;           Disease Control\n#&gt; Exposed       156    9421\n#&gt; Unexposed    1531   14797\n#&gt; Sum          1687   24218\naddmargins(eg,2)        #添加行和\n#&gt;           Disease Control   Sum\n#&gt; Exposed       156    9421  9577\n#&gt; Unexposed    1531   14797 16328\naddmargins(prop.table(eg,1))\n#&gt;              Disease   Control Sum\n#&gt; Exposed   0.01628903 0.9837110   1\n#&gt; Unexposed 0.09376531 0.9062347   1\n#&gt; Sum       0.11005434 1.8899457   2\n\nftable(eg)   # \"平铺式\"列联表\n#&gt;            Disease Control\n#&gt;                           \n#&gt; Exposed        156    9421\n#&gt; Unexposed     1531   14797",
    "crumbs": [
      "描述性统计学",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>定性数据的统计描述</span>"
    ]
  },
  {
    "objectID": "qualitative_data.html#混淆矩阵",
    "href": "qualitative_data.html#混淆矩阵",
    "title": "\n2  定性数据的统计描述\n",
    "section": "\n2.5 混淆矩阵",
    "text": "2.5 混淆矩阵",
    "crumbs": [
      "描述性统计学",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>定性数据的统计描述</span>"
    ]
  },
  {
    "objectID": "ANOVA.html",
    "href": "ANOVA.html",
    "title": "\n10  方差分析\n",
    "section": "",
    "text": "10.1 单因素组间方差分析",
    "crumbs": [
      "概率论与数理统计",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>方差分析</span>"
    ]
  },
  {
    "objectID": "ANOVA.html#单因素组间方差分析",
    "href": "ANOVA.html#单因素组间方差分析",
    "title": "\n10  方差分析\n",
    "section": "",
    "text": "10.1.1 计算公式\n\n\n\n\n因子A有\\(A_1,A_2,...,A_k\\)共k个水平\ntotal sum of squares\n\\[\nSS_T=\\sum_{j=1}^{k}\\sum_{i=1}^{n_j}X_{ij}^2-\\frac{(\\sum_{j=1}^{k}\\sum_{i=1}^{n_j}X_{ij})^2}{n}=SS_{组间}+SS_{组内}\n\\]\nbetween groups sum of squares \\[\nSS_{组间}=\\sum_{j=1}^{k}\\frac{(\\sum_{i=1}^{n_j}X_{ij})^2}{n_j}-\\frac{(\\sum_{j=1}^{k}\\sum_{i=1}^{n_j}X_{ij})^2}{n}\n\\]\n自由度\\(\\nu=n-1,\\nu_{组间}=k-1,\\nu_{组内}=\\sum_{j=1}^{k}(n_j-1)=n-k\\)\nBetween groups mean square \\(MS_{组间}=\\frac{SS_{组间}}{k-1}\\)\nWithin groups mean square \\(MS_{组内}=\\frac{SS_{组内}}{n-k}\\)\n\\[H_0:\\mu_1=\\mu_2=...=\\mu_k\\]\n\\[\n\\frac{SS_T}{\\sigma^2}\\sim \\chi^2(\\nu),\\nu=n-1\n\\] \\[\n\\frac{SS_{组内}}{\\sigma^2}\\sim \\chi^2(\\nu),\\nu=n-k\n\\] 因此，\n\\[\n\\frac{SS_{组间}}{\\sigma^2}=\\frac{SS_T}{\\sigma^2}-\\frac{SS_{组内}}{\\sigma^2}\\ \\ \\ \\sim \\chi^2(\\nu),\\nu=k-1\n\\]\n检验统计量\n\\[\nF=\\frac{\\frac{SS_{组间}}{(k-1)\\sigma^2}}{\\frac{SS_{组内}}{(n-k)\\sigma^2}}=\\frac{\\frac{SS_{组间}}{k-1}}{\\frac{SS_{组内}}{n-k}}=\\frac{MS_{组间}}{MS_{组内}}\\ \\ \\ \\sim \\chi^2(\\nu),\\nu=k-1\n\\]\n\n\n\n\n\nCodedf &lt;- tibble(\n    low=c(53.5,43.7,46.5,50.3,56.1),\n    medium=c(33.2,30.6,23.9,26.4,35.9),\n    high=c(11.5,21.9,18.6,13.6,9.5)\n)\n\n\n\n10.1.2 手算\n\nCodek &lt;- 3\ndf_sum &lt;- sum(df)\ndf_sum_square &lt;- sum(df^2)\nn &lt;- 15\nC &lt;- df_sum^2/n\n\nSS_T &lt;- df_sum_square-C\nSS_between &lt;- apply(df, 2, function(x) sum(sum(x)^2/length(x))) |&gt; sum()-C\n\nSS_within &lt;- SS_T-SS_between\n\nMS_between &lt;- SS_between/(k-1)\nMS_within &lt;- SS_within/(n-k)\nF_stat &lt;-MS_between/MS_within \n\np_value &lt;- pf(F_stat,2,12,lower.tail = F)\n\n\n\n10.1.3 stats::aov()\n\n\nCodedf_long &lt;- df |&gt; pivot_longer(cols = everything(),\n                              names_to = \"level\",\n                              values_to = \"value\")\ndf_long$level &lt;- factor(df_long$level)\ndf_aov &lt;- aov(value~level,data = df_long)\n\nanova(df_aov)\n\n\n\n\n\nDf\nSum Sq\nMean Sq\nF value\nPr(&gt;F)\n\n\n\nlevel\n2\n3083.668\n1541.83400\n61.24546\n5e-07\n\n\nResiduals\n12\n302.096\n25.17467\nNA\nNA\n\n\n\n\n\n\n\n10.1.4 ez::ezANOVA()\n\n\nCodedf_long &lt;- df_long |&gt; rowid_to_column(var = \"id\") |&gt; \n    relocate(id,.before = 1) |&gt; mutate(id=factor(id))\n\nez::ezANOVA(data = df_long,\n            dv = value,\n            wid = id,\n            between = level,\n            type = 3,\n            detailed = T)\n#&gt; $ANOVA\n#&gt;        Effect DFn DFd       SSn     SSd         F            p p&lt;.05       ges\n#&gt; 1 (Intercept)   1  12 15054.336 302.096 597.99545 1.318663e-11     * 0.9803277\n#&gt; 2       level   2  12  3083.668 302.096  61.24546 5.045797e-07     * 0.9107746\n#&gt; \n#&gt; $`Levene's Test for Homogeneity of Variance`\n#&gt;   DFn DFd        SSn   SSd           F         p p&lt;.05\n#&gt; 1   2  12 0.05733333 92.36 0.003724556 0.9962835\n\n\n\n10.1.5 stats::lm()\n\n\nCodelm_aov &lt;- lm(formula = value ~  level, data = df_long)\nlm_aov\n#&gt; \n#&gt; Call:\n#&gt; lm(formula = value ~ level, data = df_long)\n#&gt; \n#&gt; Coefficients:\n#&gt; (Intercept)     levellow  levelmedium  \n#&gt;       15.02        35.00        14.98\n\nanova(lm_aov)\n\n\n\n\n\nDf\nSum Sq\nMean Sq\nF value\nPr(&gt;F)\n\n\n\nlevel\n2\n3083.668\n1541.83400\n61.24546\n5e-07\n\n\nResiduals\n12\n302.096\n25.17467\nNA\nNA\n\n\n\n\n\nCode\nmodel.matrix(~ level, data = df_long)\n#&gt;    (Intercept) levellow levelmedium\n#&gt; 1            1        1           0\n#&gt; 2            1        0           1\n#&gt; 3            1        0           0\n#&gt; 4            1        1           0\n#&gt; 5            1        0           1\n#&gt; 6            1        0           0\n#&gt; 7            1        1           0\n#&gt; 8            1        0           1\n#&gt; 9            1        0           0\n#&gt; 10           1        1           0\n#&gt; 11           1        0           1\n#&gt; 12           1        0           0\n#&gt; 13           1        1           0\n#&gt; 14           1        0           1\n#&gt; 15           1        0           0\n#&gt; attr(,\"assign\")\n#&gt; [1] 0 1 1\n#&gt; attr(,\"contrasts\")\n#&gt; attr(,\"contrasts\")$level\n#&gt; [1] \"contr.treatment\"\nlm(formula = value ~ 0 + level, data = df_long)\n#&gt; \n#&gt; Call:\n#&gt; lm(formula = value ~ 0 + level, data = df_long)\n#&gt; \n#&gt; Coefficients:\n#&gt;   levelhigh     levellow  levelmedium  \n#&gt;       15.02        50.02        30.00\nmodel.matrix(~ 0 + level, data = df_long)\n#&gt;    levelhigh levellow levelmedium\n#&gt; 1          0        1           0\n#&gt; 2          0        0           1\n#&gt; 3          1        0           0\n#&gt; 4          0        1           0\n#&gt; 5          0        0           1\n#&gt; 6          1        0           0\n#&gt; 7          0        1           0\n#&gt; 8          0        0           1\n#&gt; 9          1        0           0\n#&gt; 10         0        1           0\n#&gt; 11         0        0           1\n#&gt; 12         1        0           0\n#&gt; 13         0        1           0\n#&gt; 14         0        0           1\n#&gt; 15         1        0           0\n#&gt; attr(,\"assign\")\n#&gt; [1] 1 1 1\n#&gt; attr(,\"contrasts\")\n#&gt; attr(,\"contrasts\")$level\n#&gt; [1] \"contr.treatment\"\n\n\n\n10.1.6 事后检验\n成对比较的数量 \\(N=\\frac{k!}{2!(k-2)!},k≥3\\)，导致犯第Ⅰ类错误的概率迅速增加，\\([1-(1-\\alpha)^N]\\)。\n\n10.1.6.1 Tukey’s test\nTukey’s test 也被称为Tukey’s honestly significant difference (Tukey’s HSD) test。\n\nk个均值从大到小排列；\n均值最大的组依次与均值最小，第二小，……，第二大比较；\n均值第二大的组以同样的方式比较；\n以此类推\n在各组样本量相等的情况下，如果在两个均值之间未发现显著差异，则推断这两个均值所包含的任何均值之间不存在显著差异，并且不再检验所包含均值之间的差异。\n\nstudentized range statistic \\(q=\\frac{\\bar X_{max}-\\bar X_{min}}{S_{\\bar X_{max}-\\bar X_{min}}}\\)，其中\\(S_{\\bar X_{max}-\\bar X_{min}}=\\sqrt{\\frac{MS_{组内}}{n}}\\)，\\(n\\)是每一个治疗组的样本量。\n如果各组样本量不等,则\\(S_{\\bar X_{max}-\\bar X_{min}}=\\sqrt{\\frac{MS_{组内}}{2}(\\frac{1}{n_i}+\\frac{1}{n_j})}\\)\n检验统计量\n\\[\nHSD=q_{(k,\\nu_{组内}),1-\\alpha} \\times S_{\\bar X_{max}-\\bar X_{min}},\\nu_{组内}=k(n_j-1)\n\\]\n对于任意i,j且\\(\\bar X_i＞\\bar X_j\\)，如果\\(\\bar X_i-\\bar X_j＞HSD\\)，那么拒绝\\(H_0\\)，说明这两组存在显著差异。\n\\[\nH_0:\\mu_i=\\mu_j(i≠j)\n\\]\n\nCodek_means &lt;- apply(df,2,mean) |&gt; sort(,decreasing = TRUE)\nk_means\n#&gt;    low medium   high \n#&gt;  50.02  30.00  15.02\n\n# 附录q  q(3,12),1-0.05  3(5-1)=12\nq_critical_value &lt;- 3.77\nnj &lt;- 5\nHSD &lt;- q_critical_value*sqrt(MS_within/nj)\n\nk_means\n#&gt;    low medium   high \n#&gt;  50.02  30.00  15.02\ndiff_means &lt;- c()\nnames_diff_means &lt;- c()\n\nfor(i in 1:(length(k_means)-1)){\n    for(j in length(k_means):(i+1)){\n        diff_value &lt;- k_means[i] - k_means[j]\n        diff_means &lt;- c(diff_means, diff_value)\n        names_diff_means &lt;- c(names_diff_means, paste(names(k_means)[i], \"vs.\", names(k_means)[j],sep = \"_\"))\n    }\n}\nnames(diff_means) &lt;- names_diff_means\ndiff_means\n#&gt;    low_vs._high  low_vs._medium medium_vs._high \n#&gt;           35.00           20.02           14.98\n#全为真，3组成对比较都存在显著差异\ndiff_means &gt; HSD \n#&gt;    low_vs._high  low_vs._medium medium_vs._high \n#&gt;            TRUE            TRUE            TRUE\n\n\n\nCodepairwise &lt;- TukeyHSD(df_aov)\npairwise\n#&gt;   Tukey multiple comparisons of means\n#&gt;     95% family-wise confidence level\n#&gt; \n#&gt; Fit: aov(formula = value ~ level, data = df_long)\n#&gt; \n#&gt; $level\n#&gt;               diff        lwr       upr     p adj\n#&gt; low-high     35.00  26.534054  43.46595 0.0000003\n#&gt; medium-high  14.98   6.514054  23.44595 0.0013315\n#&gt; medium-low  -20.02 -28.485946 -11.55405 0.0001069\n\n\n\n10.1.6.2 Dunnett’s test\nDunnett’s test也称为q’-test,是两独立样本t-test的一种修正。Dunnett’s test 假设数据符合正态分布，并且各组的方差相等。 控制对照组（C）与其他每个实验组（T）比较。\n\\(H_0:\\mu_C=\\mu_T\\)\n\\[\nq'=\\frac{\\bar X_T-\\bar X_C}{\\sqrt{MS_{组内}(\\frac{1}{n_T}+\\frac{1}{n_C})}} \\sim q'(\\nu,a) \\ \\ \\nu=\\nu_{组内},a=k\n\\]\n临界值 \\(q'_{(a,\\nu_E),1-\\alpha/2}\\)\n\nCodenT &lt;- nC &lt;- 5 \n\nSE_mean_diff &lt;- sqrt(MS_within*(1/nT+1/nC))\n\nk_means\n#&gt;    low medium   high \n#&gt;  50.02  30.00  15.02\ndiff_means &lt;- c()\nnames_diff_means &lt;- c()\n\n# 以 low 作控制组\nfor(i in 2:length(k_means)){\n        diff_value &lt;- k_means[i] - k_means[1]\n        diff_means &lt;- c(diff_means, diff_value)\n        names_diff_means &lt;- c(names_diff_means, paste(names(k_means)[1], \"vs.\", names(k_means)[i],sep = \"_\"))\n}\nnames(diff_means) &lt;- names_diff_means\ndiff_means\n#&gt; low_vs._medium   low_vs._high \n#&gt;         -20.02         -35.00\n\nq撇_stat &lt;- diff_means/SE_mean_diff\n\n# 附录q'  q'(3,12),1-0.05/2  \nabs(q撇_stat)&gt;2.50  \n#&gt; low_vs._medium   low_vs._high \n#&gt;           TRUE           TRUE\n#全为真，各实验组与控制组均存在显著差异\n\n\n\nCodelibrary(multcomp)\ndunnett_result &lt;- glht(df_aov, linfct =mcp(level =c(\"medium - low = 0\", \"high - low = 0\")))\n\n# 查看 Dunnett's test 结果\nsummary(dunnett_result)\n#&gt; \n#&gt;   Simultaneous Tests for General Linear Hypotheses\n#&gt; \n#&gt; Multiple Comparisons of Means: User-defined Contrasts\n#&gt; \n#&gt; \n#&gt; Fit: aov(formula = value ~ level, data = df_long)\n#&gt; \n#&gt; Linear Hypotheses:\n#&gt;                   Estimate Std. Error t value Pr(&gt;|t|)    \n#&gt; medium - low == 0  -20.020      3.173  -6.309 7.46e-05 ***\n#&gt; high - low == 0    -35.000      3.173 -11.030 2.38e-07 ***\n#&gt; ---\n#&gt; Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n#&gt; (Adjusted p values reported -- single-step method)\n\n\n\n10.1.6.3 LSD-t test\nleast significant difference t-test\n挑选任意感兴趣的两组进行比较\n\\[\nH_0:\\mu_i=\\mu_j(i≠j)\n\\]\n\\[\nLSD-t=\\frac{\\bar X_i-\\bar X_j}{\\sqrt{MS_{组内}(\\frac{1}{n_i}+\\frac{1}{n_j})}} \\sim t(\\nu) \\ ,\\ \\nu=\\nu_{组内}=n-k,a=k\n\\]\n\nCode# medium high\nLSD &lt;- (k_means[2]-k_means[3])/sqrt(MS_within*(1/5+1/5))\n\n# 附录 t(12,1-0.05/2)=2.719",
    "crumbs": [
      "概率论与数理统计",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>方差分析</span>"
    ]
  },
  {
    "objectID": "ANOVA.html#方差分析假设",
    "href": "ANOVA.html#方差分析假设",
    "title": "\n10  方差分析\n",
    "section": "\n10.2 方差分析假设",
    "text": "10.2 方差分析假设\nhttps://www.statmethods.net/stats/rdiagnostics.html\n\n10.2.1 独立性\n\n10.2.2 正态性\n\nCode# 异常观测点\n\ncar::outlierTest(df_aov) \n#&gt; No Studentized residuals with Bonferroni p &lt; 0.05\n#&gt; Largest |rstudent|:\n#&gt;   rstudent unadjusted p-value Bonferroni p\n#&gt; 6  1.63682            0.12993           NA\n\n\n\n10.2.2.1 直方图/茎叶图\n\n10.2.2.2 P-P图/Q-Q图\n\n10.2.2.3 偏度和峰度\n\\[\nH_0:总体偏度系数\\gamma_1=0 或者总体峰度系数\\gamma_2=0\n\\]\n\\[\nz_i=\\frac{g_i-0}{\\sigma_{g_i}}  \\ \\ \\ \\ 临界值z_{1-\\alpha/2}\n\\]\n\n10.2.2.4 Shapiro-Wilk检验（小样本）\n\nCodeshapiro.test(df$low)  \n#&gt; \n#&gt;  Shapiro-Wilk normality test\n#&gt; \n#&gt; data:  df$low\n#&gt; W = 0.9718, p-value = 0.8867\nshapiro.test(df$medium)  \n#&gt; \n#&gt;  Shapiro-Wilk normality test\n#&gt; \n#&gt; data:  df$medium\n#&gt; W = 0.96762, p-value = 0.8598\nshapiro.test(df$high)  \n#&gt; \n#&gt;  Shapiro-Wilk normality test\n#&gt; \n#&gt; data:  df$high\n#&gt; W = 0.94361, p-value = 0.6916\n\n# 因为观测太少，也可以同时检验\nshapiro.test(c(df$low,df$medium,df$high))  \n#&gt; \n#&gt;  Shapiro-Wilk normality test\n#&gt; \n#&gt; data:  c(df$low, df$medium, df$high)\n#&gt; W = 0.94559, p-value = 0.4578\n\n\n\n10.2.2.5 Kolmogorov-Smirnov检验（Lilliefors correction 大样本）\n\nCodeks.test(c(df$low,df$medium,df$high),\"pnorm\")\n#&gt; \n#&gt;  Exact one-sample Kolmogorov-Smirnov test\n#&gt; \n#&gt; data:  c(df$low, df$medium, df$high)\n#&gt; D = 1, p-value &lt; 2.2e-16\n#&gt; alternative hypothesis: two-sided\nks.test(rnorm(1000),\"pnorm\")\n#&gt; \n#&gt;  Asymptotic one-sample Kolmogorov-Smirnov test\n#&gt; \n#&gt; data:  rnorm(1000)\n#&gt; D = 0.031901, p-value = 0.2607\n#&gt; alternative hypothesis: two-sided\n\n\n\nCodex &lt;- rnorm(50) \ny &lt;- runif(50) \nks.test(x, y)  # perform ks test\n#&gt; \n#&gt;  Exact two-sample Kolmogorov-Smirnov test\n#&gt; \n#&gt; data:  x and y\n#&gt; D = 0.56, p-value = 1.453e-07\n#&gt; alternative hypothesis: two-sided\n\nx &lt;- rnorm(50)\ny &lt;- rnorm(50)\nks.test(x, y) \n#&gt; \n#&gt;  Exact two-sample Kolmogorov-Smirnov test\n#&gt; \n#&gt; data:  x and y\n#&gt; D = 0.2, p-value = 0.2719\n#&gt; alternative hypothesis: two-sided\n\n\n\n10.2.3 方差齐性\nhttp://www.cookbook-r.com/Statistical_analysis/Homogeneity_of_variance/\n\n10.2.3.1 Bartlett’s test\n数据满足正态性\n比较每一组方差的加权算术均值和几何均值。\n\\[\nH_0:\\sigma_1^2=\\sigma_2^2=...=\\sigma_k^2\n\\] 当样本量\\(n_j\\)≥5时，检验统计量(各组样本量相等)\n\\[\nB=\\frac{(n-1)[kln\\bar S^2-\\sum_{j=1}^{k}lnS_j^2]}{1+\\frac{k+1}{3k(n-1)}} \\sim\\ \\chi^2(\\nu)\\ ,\\nu=k-1\n\\] 其中n是每一组的样本量，\\(S_j^2\\)是某一组的样本方差，\\(\\bar S^2\\)是所有k个组样本方差的平均值。\n当各组样本量不等时，\n\\[\nB=\\frac{\\sum_{j=1}^{k}(n_j-1)ln\\frac{\\bar S^2}{S_j^2}}{1+\\frac{1}{3(k-1)}(\\sum_{j=1}^{k}\\frac {1}{n_j-1}-\\frac{1}{\\sum_{j=1}^{k}(n_j-1)})} \\sim\\ \\chi^2(\\nu)\\ ,\\nu=k-1\n\\] 其中\\(h_j\\)是某一组的样本量，\\(\\bar S^2=(\\sum_{j=1}^{k}(n_j-1)S_j^2)/(\\sum_{j=1}^{k}(n_j-1))\\)是所有k个组样本方差的加权平均值。\n\nCoden1=n2=n3=5\nk=3\nS2 &lt;- apply(df,2,var)\nS2\n#&gt;    low medium   high \n#&gt; 25.372 23.895 26.257\n\nlnS2 &lt;- log(S2)\nlnS2\n#&gt;      low   medium     high \n#&gt; 3.233646 3.173669 3.267933\n\nS2_mean &lt;- (5-1)*(sum(S2))/(3*(5-1))\nS2_mean\n#&gt; [1] 25.17467\n\n\n\nB &lt;- ((5-1)*(3*log(S2_mean)-sum(lnS2)))/(1+(3+1)/(3*3*(5-1)))\nB\n#&gt; [1] 0.008159536\n\n\n\nCodebartlett.test(df)\n#&gt; \n#&gt;  Bartlett test of homogeneity of variances\n#&gt; \n#&gt; data:  df\n#&gt; Bartlett's K-squared = 0.0081595, df = 2, p-value = 0.9959\n\n\n\n10.2.3.2 Levene’s test\n数据不满足正态性\n\nk个随机样本是独立的\n随机变量X是连续的\n\nLevene 变换：\n\\[\nZ_{ij}=|X_{ij}-\\bar X_{.\\ j}|(i=1,2...,n_j;\\ j=1,2,...,k)\n\\]\n\nCodeoptions(digits = 2)\nz_df &lt;- bind_cols(\n    low=df[1]-k_means[1],\n    medium=df[2]-k_means[2],\n    high=df[3]-k_means[3]\n) |&gt; abs()\n    \n\nz_df\n\n\n\n\nlow\nmedium\nhigh\n\n\n\n3.48\n3.2\n3.5\n\n\n6.32\n0.6\n6.9\n\n\n3.52\n6.1\n3.6\n\n\n0.28\n3.6\n1.4\n\n\n6.08\n5.9\n5.5\n\n\n\n\n\n\n检验统计量（基于变换后的F检验）\n\\[\nW=\\frac{MS_{组间}}{MS_{组内}}=\\frac{\\sum_jn_j(\\bar Z_{.j}-\\bar Z_{..})^2/(k-1)}{\\sum_j\\sum_i(Z_{ij}-\\bar Z_{.j})^2/(n-k)}  \\sim F(\\nu_1,\\nu_2)   \\ \\ \\ \\ \\nu_1=k-1,\\nu_2=n-k\n\\]\n\nCodev1=3-1\nv2=15-3\n\n\nz.j_mean &lt;- apply(z_df, 2, mean)\nz.j_mean\n#&gt;    low medium   high \n#&gt;    3.9    3.9    4.2\n\nz_mean &lt;- mean(z.j_mean)\nz_mean \n#&gt; [1] 4\n\noptions(digits = 4)\nW &lt;- 12*sum(5*(z.j_mean-z_mean)^2)/(2*(sum((z_df$low-z.j_mean[1])^2)+sum((z_df$medium-z.j_mean[2])^2)+sum((z_df$high-z.j_mean[3])^2)))\n\nW\n#&gt; [1] 0.0254",
    "crumbs": [
      "概率论与数理统计",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>方差分析</span>"
    ]
  },
  {
    "objectID": "ANOVA.html#welchs-anova-test",
    "href": "ANOVA.html#welchs-anova-test",
    "title": "\n10  方差分析\n",
    "section": "\n10.3 Welch’s ANOVA Test",
    "text": "10.3 Welch’s ANOVA Test",
    "crumbs": [
      "概率论与数理统计",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>方差分析</span>"
    ]
  },
  {
    "objectID": "ANOVA.html#数据变换",
    "href": "ANOVA.html#数据变换",
    "title": "\n10  方差分析\n",
    "section": "\n10.4 数据变换",
    "text": "10.4 数据变换\n当方差分析的正态性假设或方差齐性假设不为真时，通常使用(1)数据变换方法；(2)非参数检验方法 比较均值差异\n\n10.4.1 平方根变换\n当每个水平组的方差与均值成比例，尤其是样本来自泊松分布\n\\[\nY=\\sqrt{X}\n\\]\n当数据中有零或非常小的值时，\n\\[\nY=\\sqrt{X+a} \\ \\ \\ \\ a=0.5或0.1\n\\]\n\n10.4.2 对数变换\n当数据方差不齐且每个水平组标准差与均值成比例时\n\\[\nY=\\log{X} \\ \\ \\ \\ base=e或10\n\\]\n当数据中有零或负值时，\n\\[\nY=\\log{(X+a)} \\ \\ \\ \\ a为实数，使得X+a&gt;0\n\\]\n\n10.4.3 反正弦平方根变换\n率，服从二项分布\\(B(n,\\pi)\\)\n\\[\nY=\\arcsin {\\sqrt{\\pi}} \\ \\ \\ \\\n\\]",
    "crumbs": [
      "概率论与数理统计",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>方差分析</span>"
    ]
  },
  {
    "objectID": "rate_proportion_test.html",
    "href": "rate_proportion_test.html",
    "title": "\n12  比例检验\n",
    "section": "",
    "text": "12.1 单总体\n如果样本比较小，则使用二项分布进行统计. 在R中，对于小样本，采用 binom.test()，对于大样本使用正态分布近似二项分布，利用 prop.test()进行分析。 在单样本比例检验中，我们关心的是具有同种特性的两个群体，在该特性总体中所占有的比例情况。\n\\[\nZ=\\frac{p-\\pi_0}{\\sqrt{\\pi_0(1-\\pi_0)/n}}\\sim N(0,1)\n\\]\nCI：\\(\\bar p \\pm z_{1-\\alpha/2}\\sqrt{\\frac{p(1-p)}{n}}\\)\n对于小样本，可以连续校正\n\\[\nZ_{corr}=\\frac{|p-\\pi_0|-1/(2n)}{\\sqrt{\\pi_0(1-\\pi_0)/n}}\\sim N(0,1)\n\\]\n例如，小鼠中公鼠母鼠各有一半，有100只患有某种疾病，其中有公鼠60只，母鼠40只。想知道是否公鼠患病率比母鼠高。在该问题中成功次数为公鼠患病数60，总次数为100，预期比例为50% ( 公母鼠数量相等)\nShow the codep &lt;- 0.6\npi_0 &lt;- 0.5\nn &lt;- 100\nZ &lt;- (p-pi_0)/sqrt(pi_0*(1-pi_0)/n)\nZ_corr &lt;- (p-pi_0-1/(2*n))/sqrt(pi_0*(1-pi_0)/n)\nShow the code# 示例数据\nsuccesses &lt;- 60\ntotal &lt;- 100\np0 &lt;- 0.5\n\n# 使用 prop.test() 函数进行比例检验\nprop.test(\n    x = successes,\n    n = total,\n    p = p0,\n    alternative = \"greater\",\n    correct = F\n)\n#&gt; \n#&gt;  1-sample proportions test without continuity correction\n#&gt; \n#&gt; data:  successes out of total, null probability p0\n#&gt; X-squared = 4, df = 1, p-value = 0.02275\n#&gt; alternative hypothesis: true p is greater than 0.5\n#&gt; 95 percent confidence interval:\n#&gt;  0.5178095 1.0000000\n#&gt; sample estimates:\n#&gt;   p \n#&gt; 0.6\nShow the codeprop.test(\n    x = successes,\n    n = total,\n    p = p0,\n    alternative = \"greater\",\n    correct = T\n)\n#&gt; \n#&gt;  1-sample proportions test with continuity correction\n#&gt; \n#&gt; data:  successes out of total, null probability p0\n#&gt; X-squared = 3.61, df = 1, p-value = 0.02872\n#&gt; alternative hypothesis: true p is greater than 0.5\n#&gt; 95 percent confidence interval:\n#&gt;  0.5127842 1.0000000\n#&gt; sample estimates:\n#&gt;   p \n#&gt; 0.6",
    "crumbs": [
      "概率论与数理统计",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>比例检验</span>"
    ]
  },
  {
    "objectID": "rate_proportion_test.html#两总体",
    "href": "rate_proportion_test.html#两总体",
    "title": "\n12  比例检验\n",
    "section": "\n12.2 两总体",
    "text": "12.2 两总体\n当样本量较小时(所有np和n(1-p)都小于5)，通常采用非参数检验 Fisher Exact probability test 进行分析。当样本量较大时，使用近似正态分布z检验来进行预测。\n当\\(n_ip_i(1-p_i)≥5,(i=1,2)\\)时，\\(p_i\\dot\\sim N(\\pi_i,\\frac{\\pi_i(1-\\pi_i)}{n_i})\\)\n\\[\n(p_1-p_2)\\dot\\sim N(\\pi_1-\\pi_2,\\frac{\\pi_1(1-\\pi_1)}{n_1}+\\frac{\\pi_2(1-\\pi_2)}{n_2})\n\\]\n\\(H_0:\\pi_1=\\pi_2\\)\n\\[\nZ=\\frac{(p_1-p_2)-(\\pi_1-\\pi_2)}{S_{p_1-p_2}}=\\frac{p_1-p_2}{\\sqrt{p_C(1-p_C)(\\frac{1}{n_1}+\\frac{1}{n_2})}}\\dot\\sim N(0,1)\n\\]\n其中,合并比例\\(p_C=\\frac{n_1p_1+n_2p_2}{n_1+n_2}\\) 。\n如果我们已知两组具有不同特性(A和B)样本的样本量和这两样本中具有某种共同特性(C)的个体数量(也就是知道了C特性各自群体比例和总体比例)，想要计算具有C特性的个体在A特性群体和B特性群体中的比例是否一样，就需要用到双比例检验。\n例如，男生500人，女生500人，其中喜欢阅读的男生有400人，喜欢阅读的女生有460人。男生喜欢阅读的比例是否比女生高。我们假设男生喜欢阅读的比例比女生高，则备择假设是男生喜欢阅读的比例比女生低。\n\nShow the code# 示例数据\nsuccesses1 &lt;- 400\ntotal1 &lt;- 500\nsuccesses2 &lt;- 460\ntotal2 &lt;- 500\n\n# 使用 prop.test() 函数进行两总体比例检验\nprop.test(x = c(successes1, successes2), n = c(total1, total2), alternative = \"less\")\n#&gt; \n#&gt;  2-sample test for equality of proportions with continuity correction\n#&gt; \n#&gt; data:  c(successes1, successes2) out of c(total1, total2)\n#&gt; X-squared = 28.912, df = 1, p-value = 3.787e-08\n#&gt; alternative hypothesis: less\n#&gt; 95 percent confidence interval:\n#&gt;  -1.0000000 -0.0824468\n#&gt; sample estimates:\n#&gt; prop 1 prop 2 \n#&gt;   0.80   0.92\n\n\n功效分析\n\n\\(1-\\beta\\)\n\\(n1,n_2=kn_1\\)",
    "crumbs": [
      "概率论与数理统计",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>比例检验</span>"
    ]
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "医学与生物统计学",
    "section": "",
    "text": "推荐阅读\n\nR语言教程 Ⅶ 统计模型 ——李东风\n统计学习 ISLR\nR语言实战医学统计\nhttps://www.tidymodels.org/\n医学研究中的生存数据建模（4e）\nApplied Propensity Score Analysis with R\nModern Statistics for Modern Biology",
    "crumbs": [
      "推荐阅读"
    ]
  },
  {
    "objectID": "simple_linear_regression.html",
    "href": "simple_linear_regression.html",
    "title": "\n16  线性回归\n",
    "section": "",
    "text": "16.1 一元线性回归\nlinear regression model：\n\\[\nY_i=\\beta_0+ \\beta_1 X_i+\\epsilon_i,其中\\epsilon_i\\sim N(0,\\sigma^2)\n\\]\nShow the code#linear model specification 线性模型规范\nlm_spec &lt;-linear_reg() %&gt;%\n  set_mode(\"regression\") %&gt;%\n  set_engine(\"lm\")  \nlm_spec\n#&gt; Linear Regression Model Specification (regression)\n#&gt; \n#&gt; Computational engine: lm\nShow the codelm_tv &lt;- lm_spec %&gt;%  fit(sales ~ TV, data = advertising)\n# 模型摘要\nsummary(lm_tv$fit)\n#&gt; \n#&gt; Call:\n#&gt; stats::lm(formula = sales ~ TV, data = data)\n#&gt; \n#&gt; Residuals:\n#&gt;     Min      1Q  Median      3Q     Max \n#&gt; -8.3860 -1.9545 -0.1913  2.0671  7.2124 \n#&gt; \n#&gt; Coefficients:\n#&gt;             Estimate Std. Error t value Pr(&gt;|t|)    \n#&gt; (Intercept) 7.032594   0.457843   15.36   &lt;2e-16 ***\n#&gt; TV          0.047537   0.002691   17.67   &lt;2e-16 ***\n#&gt; ---\n#&gt; Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n#&gt; \n#&gt; Residual standard error: 3.259 on 198 degrees of freedom\n#&gt; Multiple R-squared:  0.6119, Adjusted R-squared:  0.6099 \n#&gt; F-statistic: 312.1 on 1 and 198 DF,  p-value: &lt; 2.2e-16\n\n# 参数估计值、标准误、统计量、p值\nbroom::tidy(lm_tv, conf.int=T)\n\n\n\n\n\n\n\n\n\n\n\n\n\nterm\nestimate\nstd.error\nstatistic\np.value\nconf.low\nconf.high\n\n\n\n(Intercept)\n7.0325935\n0.4578429\n15.36028\n0\n6.1297193\n7.9354678\n\n\nTV\n0.0475366\n0.0026906\n17.66763\n0\n0.0422307\n0.0528426\n\n\n\n\n\nShow the code# 模型统计信息\nbroom::glance(lm_tv) \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nr.squared\nadj.r.squared\nsigma\nstatistic\np.value\ndf\nlogLik\nAIC\nBIC\ndeviance\ndf.residual\nnobs\n\n\n0.6118751\n0.6099148\n3.258656\n312.145\n0\n1\n-519.0457\n1044.091\n1053.986\n2102.531\n198\n200",
    "crumbs": [
      "推断统计模型",
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>线性回归</span>"
    ]
  },
  {
    "objectID": "simple_linear_regression.html#一元线性回归",
    "href": "simple_linear_regression.html#一元线性回归",
    "title": "\n16  线性回归\n",
    "section": "",
    "text": "16.1.1 点须图\n\nShow the code\n# 整理回归模型结果\ntidy_lm &lt;- tidy(lm_tv, conf.int=T) %&gt;% dplyr::filter(term !='(Intercept)' )\n# 绘制点须图\nggplot(tidy_lm, aes(x = estimate, y = term)) +\n  geom_point(size = 2, color = \"black\") + # 绘制点\n  geom_errorbarh(aes(xmin = conf.low, \n                     xmax = conf.high), \n                 height = 0, color = \"black\") + # 绘制误差线\n  geom_vline(xintercept = 0, colour = \"grey50\", linetype = 2) + # 绘制参考线\n  labs(x = NULL, y = NULL) \n\n\n\n\n\n\n\n\n16.1.2 预测\n\nShow the code# 预测\nstats::predict(lm_tv, new_data = advertising) %&gt;% \n    head(n = 10)\n\n\n\n\n.pred\n\n\n\n17.970775\n\n\n9.147974\n\n\n7.850224\n\n\n14.234395\n\n\n15.627218\n\n\n7.446162\n\n\n9.765950\n\n\n12.746498\n\n\n7.441409\n\n\n16.530414\n\n\n\n\n\nShow the code\n# 置信区间 平均响应值       取决于方差和样本量     随样本量增加收缩\npredict(lm_tv, new_data = advertising, type = \"conf_int\") %&gt;% \n    head(n = 10)\n\n\n\n\n.pred_lower\n.pred_upper\n\n\n\n17.337774\n18.603775\n\n\n8.439101\n9.856848\n\n\n7.024932\n8.675515\n\n\n13.779384\n14.689405\n\n\n15.138794\n16.115642\n\n\n6.582865\n8.309460\n\n\n9.108530\n10.423370\n\n\n12.270304\n13.222691\n\n\n6.577660\n8.305157\n\n\n15.996715\n17.064114\n\n\n\n\n\nShow the code\n# 单个新观测值         主要取决于方差\npredict(lm_tv, new_data = advertising, type = \"pred_int\") %&gt;% \n    head(n = 10)\n\n\n\n\n.pred_lower\n.pred_upper\n\n\n\n11.5135459\n24.42800\n\n\n2.6828666\n15.61308\n\n\n1.3713181\n14.32913\n\n\n7.7921786\n20.67661\n\n\n9.1825560\n22.07188\n\n\n0.9623058\n13.93002\n\n\n3.3062822\n16.22562\n\n\n6.3027510\n19.19024\n\n\n0.9574921\n13.92533\n\n\n10.0821628\n22.97867\n\n\n\n\n\nShow the code\n\n# 比较观测值与预测值\naugment(lm_tv, new_data = advertising) %&gt;%\n    select(sales, .pred) %&gt;%\n    head(n = 10)\n\n\n\n\nsales\n.pred\n\n\n\n22.1\n17.970775\n\n\n10.4\n9.147974\n\n\n9.3\n7.850224\n\n\n18.5\n14.234395\n\n\n12.9\n15.627218\n\n\n7.2\n7.446162\n\n\n11.8\n9.765950\n\n\n13.2\n12.746498\n\n\n4.8\n7.441409\n\n\n10.6\n16.530414\n\n\n\n\n\n\npredict(lm_tv$fit, new_data = advertising, interval = \"confidence\") %&gt;% \n    head(n = 10)\npredict(lm_tv$fit, new_data = advertising, interval = \"prediction\") %&gt;% \n    head(n = 10)",
    "crumbs": [
      "推断统计模型",
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>线性回归</span>"
    ]
  },
  {
    "objectID": "simple_linear_regression.html#线性回归假设",
    "href": "simple_linear_regression.html#线性回归假设",
    "title": "\n16  线性回归\n",
    "section": "\n16.2 线性回归假设",
    "text": "16.2 线性回归假设\n一般线性模型中，其自变量全部为固定效应自变量，3点假设：\n\n线性度\n\n保证各实测点到回归直线的纵向距离的平方和最小，即使得残差平方和最小。\n\\[\nQ=\\sum (Y-\\hat Y)^2\n\\]\n\nShow the code# 可视化\naugment(lm_tv, new_data = advertising) %&gt;%\n    ggplot(aes(x = TV)) +\n    geom_linerange(aes(ymin = sales, ymax = .pred)) +\n    geom_point(aes(y = sales), color = \"red\") +\n    geom_abline(\n        intercept = coef(lm_tv$fit)[1],\n        slope = coef(lm_tv$fit)[2],\n        color = \"blue\",\n        linewidth = 1\n    )\n\n\n\n\n\n\n\n\n同方差性：残差具有常数方差\n残差的正态性\n观测的独立性：通常通过审查研究设计来调查",
    "crumbs": [
      "推断统计模型",
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>线性回归</span>"
    ]
  },
  {
    "objectID": "simple_linear_regression.html#模型诊断",
    "href": "simple_linear_regression.html#模型诊断",
    "title": "\n16  线性回归\n",
    "section": "\n16.3 模型诊断",
    "text": "16.3 模型诊断\n\nShow the codeautoplot(lm_tv, which = 1:6, ncol = 2, label.size = 3)\n\n\n\n\n\n\n\n\n16.3.1 残差图\n预测值与残差的关系，线性度，同方差\n\nShow the code# 检查线性回归模型的残差是否与预测值无关，即残差的分布是否随机。\n# 残差应该随机分布在0附近\ntibble(\n    `Fitted values`=fitted(lm_tv$fit),\n    Residuals = residuals(lm_tv$fit)\n) %&gt;% ggplot(aes(x = `Fitted values` , y = Residuals)) +\n  geom_point(pch=21) +\n    geom_smooth(formula = \"y~x\",color=\"red\",lwd=0.5)+\n  geom_hline(yintercept = 0,lty=2) +\n  labs(x = \"Fitted Values\", y = \"Residuals\")\n\n\n\n\n\n\n\n\n16.3.2 Q-Q图\n标准化残差正态性\n\nShow the codetibble(\n       StandardizedResiduals =rstandard(lm_tv$fit) ) %&gt;% \n    ggplot(aes(sample=StandardizedResiduals)) +\n    stat_qq(pch=21)+\n    stat_qq_line(color=\"red\",lty=2)+\n    labs(x = \"Theoretical Quantiles\", y = \"Sample quantiles\")\n\n\n\n\n\n\n\n\n16.3.3 Scale-Location 图\n检查同方差性，如果看到漏斗形（残差随着拟合值增大而增大），则可能存在异方差性问题。\n标准化残差平方根图\n检查残差的正态性，如果看到残差的分布围绕 0 随机散布，没有明显的模式，模型拟合是理想的。\n\nShow the codeplot(lm_tv$fit, which = 3)\n\n\n\n\n\n\n\n\nShow the code# 绘制 Scale-Location 图\ntibble(\n    fitted_values=fitted(lm_tv$fit),\n    StandardizedResiduals = rstudent(lm_tv$fit) ,\n) %&gt;%\n    ggplot(aes(x = fitted_values, y = sqrt(abs(StandardizedResiduals)))) +\n    geom_point(pch=21) +\n    geom_smooth(color=\"red\",lwd=0.5)+\n    labs(title = \"Scale-Location Plot\",x = \"Fitted Values\", y = \"√|Standardized residuals|\")\n\n\n\n\n\n\n\n\n16.3.4 Cook’s距离\n\n\nShow the codeset.seed(1011)\nx&lt;-rnorm(9)               #random 9 values\nx[10]&lt;-5                  #value far from the others\ny&lt;-rnorm(10,0.5+2*x,1)   #generate y\n\n#plot the data\nlmodel&lt;-lm(y~x)           #fit the model\nplot(x,y)                 #plot the data\nabline(line(x,y))        # add the regression line\n\n\n\n\n\n\nShow the codeinfluence.measures(lmodel)   \n#&gt; Influence measures of\n#&gt;   lm(formula = y ~ x) :\n#&gt; \n#&gt;     dfb.1_   dfb.x   dffit cov.r  cook.d   hat inf\n#&gt; 1  -0.0724 -0.0137 -0.0837 1.431 0.00397 0.103    \n#&gt; 2  -0.2607  0.1637 -0.2717 1.388 0.03993 0.157    \n#&gt; 3   0.0822 -0.0555  0.0869 1.554 0.00430 0.169    \n#&gt; 4   0.2679  0.0174  0.2935 1.178 0.04433 0.100    \n#&gt; 5   0.1102  0.0548  0.1490 1.408 0.01238 0.116    \n#&gt; 6  -0.5785  0.1207 -0.5854 0.724 0.13792 0.104    \n#&gt; 7   0.4851 -0.1676  0.4851 0.925 0.10651 0.114    \n#&gt; 8  -0.6059  0.3277 -0.6179 0.848 0.16313 0.139    \n#&gt; 9   0.4957 -0.2572  0.5034 0.996 0.11760 0.135    \n#&gt; 10  0.0157 -1.0428 -1.1090 9.033 0.68380 0.863   *\n\n\n\nShow the codeplot(lm_tv$fit,4)  \n\n\n\n\n\n\n\n\nShow the codethreshold &lt;- 4 / (nrow(advertising)-length(lm_tv$fit$coefficients)-2)\n                  \n                 \ntibble(\n    x = 1:nrow(advertising),\n    cooks_distance = cooks.distance(lm_tv$fit),\n    label = factor(if_else(cooks_distance&gt;threshold,x,NA))\n) %&gt;% \n    ggplot() +\n    geom_segment(aes(\n        x = x,\n        xend = x,\n        y = 0,\n        yend = cooks_distance ,\n    )) +\n    geom_text(aes(\n        x = x,\n        y =cooks_distance ,\n        label =label,\n    ), vjust = -0.2) +\n    labs(x = \"Observation Index\", y = \"Cook's Distance\")\n\n\n\n\n\n\n\n\n16.3.5 残差-杠杆值图\n\n\nShow the code\ninfluence(lmodel)$hat     #leverage\n#&gt;         1         2         3         4         5         6         7         8 \n#&gt; 0.1027407 0.1570337 0.1686229 0.1003533 0.1156210 0.1044403 0.1135604 0.1391403 \n#&gt;         9        10 \n#&gt; 0.1353478 0.8631394\n\n\n1/10 + (x-mean(x))^2/(var(x)*9)  #leverage manually computed \n#&gt;  [1] 0.1027407 0.1570337 0.1686229 0.1003533 0.1156210 0.1044403 0.1135604\n#&gt;  [8] 0.1391403 0.1353478 0.8631394\n\n\n\n\nShow the codeinfluence(lmodel)$coefficients     #DFBETA\n#&gt;     (Intercept)            x\n#&gt; 1  -0.015131790 -0.001678535\n#&gt; 2  -0.053246101  0.019647712\n#&gt; 3   0.017216660 -0.006821716\n#&gt; 4   0.053369207  0.002038393\n#&gt; 5   0.022861311  0.006672433\n#&gt; 6  -0.101915091  0.012493753\n#&gt; 7   0.090627673 -0.018400391\n#&gt; 8  -0.109982670  0.034951829\n#&gt; 9   0.093779788 -0.028593745\n#&gt; 10  0.003248704 -0.126864091\n\ndfbeta(lmodel)  \n#&gt;     (Intercept)            x\n#&gt; 1  -0.015131790 -0.001678535\n#&gt; 2  -0.053246101  0.019647712\n#&gt; 3   0.017216660 -0.006821716\n#&gt; 4   0.053369207  0.002038393\n#&gt; 5   0.022861311  0.006672433\n#&gt; 6  -0.101915091  0.012493753\n#&gt; 7   0.090627673 -0.018400391\n#&gt; 8  -0.109982670  0.034951829\n#&gt; 9   0.093779788 -0.028593745\n#&gt; 10  0.003248704 -0.126864091\n#computing the DFBETA manually for the 10th observation\ncoef(lm(y~x)) - coef(lm(y[-10]~x[-10]))\n#&gt;  (Intercept)            x \n#&gt;  0.003248704 -0.126864091\n\n\n\nShow the codeplot(lm_tv$fit,5)  \n\n\n\n\n\n\n\nhat 统计量\n\nShow the codetibble(\n    x = 1:nrow(advertising),\n    leverage = hatvalues(lm_tv$fit),\n    StandardizedResiduals = rstandard(lm_tv$fit) ,\n    cooks_distance = cooks.distance(lm_tv$fit),\n    label = factor(if_else(cooks_distance&gt;threshold,x,NA))\n) %&gt;%\n    ggplot(aes(x = leverage, y = StandardizedResiduals)) +\n    geom_point(pch=21) +\n    geom_smooth(color=\"red\",lwd=0.5)+\n    scale_x_continuous(limits = c(0, NA)) +\n    geom_vline(xintercept = 0, lty = 2) +\n    geom_hline(yintercept = 0, lty = 2) +\n    ggrepel::geom_text_repel(mapping = aes(label = label))+\n    labs(x = \"Leverage Values\", y = \"Standardized residuals\")\n\n\n\n\n\n\n\n\n16.3.6 Cook‘s距离和杠杆值\n\nShow the codeplot(lm_tv$fit,6)",
    "crumbs": [
      "推断统计模型",
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>线性回归</span>"
    ]
  },
  {
    "objectID": "diagnostic_test.html#灵敏度sensitivity",
    "href": "diagnostic_test.html#灵敏度sensitivity",
    "title": "\n25  诊断性测试\n",
    "section": "",
    "text": "25.1.1 假阴性率(FNR) /漏诊率\n\\[\nFNR=1-Se\n\\]",
    "crumbs": [
      "研究设计",
      "<span class='chapter-number'>25</span>  <span class='chapter-title'>诊断性测试</span>"
    ]
  },
  {
    "objectID": "diagnostic_test.html#特异度specificity",
    "href": "diagnostic_test.html#特异度specificity",
    "title": "\n25  诊断性测试\n",
    "section": "\n25.2 特异度（Specificity）",
    "text": "25.2 特异度（Specificity）\n真阴性率：指在所有真实状况为阴性的样本中，被正确识别出阴性的比例。\n\\[\nSp=\\frac{TN}{TN+FP}\n\\]\n其中 TN 是真阴性的数量，FP 是假阳性的数量。\n\n25.2.1 假阳性率(FPR) /误诊率\n\\[ FPR=1-Sp \\]\n\n\n\n\n\nShow the code# 构建列联表\nobserved_sensitivity &lt;- matrix(c(28, 11, 37, 2), nrow = 2, byrow = TRUE,\n                   dimnames = list('检验方式' = c('尿糖检验', '血糖检验'),\n                                   '结果' = c('检出阳性', '未检出阳性')))\nobserved_sensitivity\n#&gt;           结果\n#&gt; 检验方式 检出阳性 未检出阳性\n#&gt;   尿糖检验       28         11\n#&gt;   血糖检验       37          2\n# 进行卡方检验\ns &lt;- chisq.test(observed_sensitivity,correct = F)\n\n# 输出结果\ns\n#&gt; \n#&gt;  Pearson's Chi-squared test\n#&gt; \n#&gt; data:  observed_sensitivity\n#&gt; X-squared = 7.4769, df = 1, p-value = 0.006249\n\n\n# 构建列联表\nobserved_accuracy &lt;- matrix(c(29, 11, 38, 2), nrow = 2, byrow = TRUE,\n                            dimnames = list('检验方式' = c('尿糖检验', '血糖检验'),\n                                            '结果' = c('检准', '不准')))\n\n# 进行卡方检验\naccuracy &lt;- chisq.test(observed_accuracy,correct = F)\n\n# 输出结果\naccuracy\n#&gt; \n#&gt;  Pearson's Chi-squared test\n#&gt; \n#&gt; data:  observed_accuracy\n#&gt; X-squared = 7.4397, df = 1, p-value = 0.00638",
    "crumbs": [
      "研究设计",
      "<span class='chapter-number'>25</span>  <span class='chapter-title'>诊断性测试</span>"
    ]
  },
  {
    "objectID": "diagnostic_test.html#youdens-index",
    "href": "diagnostic_test.html#youdens-index",
    "title": "\n25  诊断性测试\n",
    "section": "\n25.3 Youden’s Index",
    "text": "25.3 Youden’s Index\n\\[\nJ=Se-FPR =Se+Sp-1,J[1,-1]\n\\]\n\nJ 越大诊断有效性越高\nJ=1 表示完美的诊断性能，因为Se，Sp都是1。\nJ≤0 表示没有诊断价值",
    "crumbs": [
      "研究设计",
      "<span class='chapter-number'>25</span>  <span class='chapter-title'>诊断性测试</span>"
    ]
  },
  {
    "objectID": "diagnostic_test.html#likelihood-ratio",
    "href": "diagnostic_test.html#likelihood-ratio",
    "title": "\n25  诊断性测试\n",
    "section": "\n25.4 Likelihood Ratio",
    "text": "25.4 Likelihood Ratio\n\n25.4.1 正似然比\n\\[\nLR+=\\frac{Se}{FPR}=\\frac{Se}{1-Sp}\n\\]\n\nLR+越大表示患病测出阳性结果的优势越大\nLR+=1表示诊断无效\n\n25.4.2 负似然比\n\\[\nLR-=\\frac{FNR}{Sp}=\\frac{1-Sp}{Sp}\n\\]\n\nLR-越小表示患病测出阴性结果的优势越小\nLR-=1表示诊断无效",
    "crumbs": [
      "研究设计",
      "<span class='chapter-number'>25</span>  <span class='chapter-title'>诊断性测试</span>"
    ]
  },
  {
    "objectID": "diagnostic_test.html#预测值",
    "href": "diagnostic_test.html#预测值",
    "title": "\n25  诊断性测试\n",
    "section": "\n25.5 预测值",
    "text": "25.5 预测值\n\nShow the codem\n#&gt;        truth\n#&gt; predict +    -   \n#&gt;       + \"TP\" \"FP\"\n#&gt;       - \"FN\" \"TN\"\n\n\n阳性预测值（Positive Predictive Value, PPV）：在所有被测试为阳性的样本中，真正的阳性比例。\n\\[\nPPV=\\frac{TP}{TP+NP}\n\\]\n阴性预测值（Negative Predictive Value, NPV）：在所有被测试为阴性的样本中，真正的阴性比例。\n\\[\nPPV=\\frac{TN}{TN+FN}\n\\]\n配对样本设计\n\\(\\chi^2\\)配对检验\n完全随机设计\n\\(\\chi^2\\)检验",
    "crumbs": [
      "研究设计",
      "<span class='chapter-number'>25</span>  <span class='chapter-title'>诊断性测试</span>"
    ]
  },
  {
    "objectID": "GLM.html#数据来源",
    "href": "GLM.html#数据来源",
    "title": "\n19  广义线性模型\n",
    "section": "\n19.2 数据来源",
    "text": "19.2 数据来源\n数据下载网站\n\nShow the codelibrary(tidyverse)\nlibrary(patchwork)\ndf &lt;- read_csv(\"data/ISLR/Default.csv\")\n\ndf &lt;- df %&gt;% \n    mutate(across(1:2, ~ factor(.x,levels = c(\"No\",\"Yes\"),labels = c(0,1))\n                  )\n           )\nstr(df)\n#&gt; tibble [10,000 × 4] (S3: tbl_df/tbl/data.frame)\n#&gt;  $ default: Factor w/ 2 levels \"0\",\"1\": 1 1 1 1 1 1 1 1 1 1 ...\n#&gt;  $ student: Factor w/ 2 levels \"0\",\"1\": 1 2 1 1 1 2 1 2 1 1 ...\n#&gt;  $ balance: num [1:10000] 730 817 1074 529 786 ...\n#&gt;  $ income : num [1:10000] 44362 12106 31767 35704 38463 ...\n\n# 是否违约 是否学生 余额 收入\nhead(df)\n#&gt; # A tibble: 6 × 4\n#&gt;   default student balance income\n#&gt;   &lt;fct&gt;   &lt;fct&gt;     &lt;dbl&gt;  &lt;dbl&gt;\n#&gt; 1 0       0          730. 44362.\n#&gt; 2 0       1          817. 12106.\n#&gt; 3 0       0         1074. 31767.\n#&gt; 4 0       0          529. 35704.\n#&gt; 5 0       0          786. 38463.\n#&gt; 6 0       1          920.  7492.\ntable(df$default,df$student)\n#&gt;    \n#&gt;        0    1\n#&gt;   0 6850 2817\n#&gt;   1  206  127\n\n\n\nShow the codeggplot(df,aes(balance,income))+\n  geom_point(aes(shape=default,color=default),show.legend = F)|\nggplot(df,aes(default,balance,fill=default),)+\n  geom_boxplot(show.legend = F)+\nggplot(df,aes(default,income,fill=default))+\n  geom_boxplot()",
    "crumbs": [
      "推断统计模型",
      "<span class='chapter-number'>19</span>  <span class='chapter-title'>广义线性模型</span>"
    ]
  },
  {
    "objectID": "GLM.html#恒等链接线性回归",
    "href": "GLM.html#恒等链接线性回归",
    "title": "\n19  广义线性模型\n",
    "section": "\n19.3 恒等链接线性回归",
    "text": "19.3 恒等链接线性回归\n线性回归是一种简单的线性回归模型，其中假设响应变量服从正态分布，并且使用恒等链接函数（identity link function），t-statistic\n\nShow the codelibrary(tidymodels)\nlibrary(ggfortify)\n# 使用 glm() 函数进行高斯线性回归\nglm_gauss &lt;- linear_reg() %&gt;% \n  set_engine(\"glm\", family = stats::gaussian(link = \"identity\")) %&gt;% \n  fit(as.numeric(default)-1~balance,data=df)\n\n# 查看模型的系数\ntidy(glm_gauss)\n#&gt; # A tibble: 2 × 5\n#&gt;   term         estimate  std.error statistic   p.value\n#&gt;   &lt;chr&gt;           &lt;dbl&gt;      &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;\n#&gt; 1 (Intercept) -0.0752   0.00335        -22.4 1.26e-108\n#&gt; 2 balance      0.000130 0.00000347      37.4 2.77e-286\n\n# 查看模型性能的 AIC 和 Deviance\nglance(glm_gauss) %&gt;% dplyr::select(AIC, deviance)\n#&gt; # A tibble: 1 × 2\n#&gt;      AIC deviance\n#&gt;    &lt;dbl&gt;    &lt;dbl&gt;\n#&gt; 1 -7284.     282.\n\n\n# Change the theme and colour\nautoplot(glm_gauss, which = 1:6, ncol = 2, label.size = 3,\n         colour = \"steelblue\") + theme_bw()\n\n\n\n\n\n\n\n\nShow the codeggplot(df,aes(balance,as.numeric(default)-1))+\n  geom_point(color=\"orange\",size=1.25)+\n  geom_smooth(method = \"lm\",se=FALSE)+\n  geom_hline(yintercept = c(0,1),linetype=2)+\n  ggtitle(\"linear regression\")",
    "crumbs": [
      "推断统计模型",
      "<span class='chapter-number'>19</span>  <span class='chapter-title'>广义线性模型</span>"
    ]
  },
  {
    "objectID": "GLM.html#零膨胀模型zero-inflated",
    "href": "GLM.html#零膨胀模型zero-inflated",
    "title": "\n19  广义线性模型\n",
    "section": "\n19.7 零膨胀模型（zero-inflated）",
    "text": "19.7 零膨胀模型（zero-inflated）\n逻辑回归+以上之一",
    "crumbs": [
      "推断统计模型",
      "<span class='chapter-number'>19</span>  <span class='chapter-title'>广义线性模型</span>"
    ]
  }
]